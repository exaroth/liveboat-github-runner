{"id":"25JnLB7bCaiYJ","title":"Tech News","displayTitle":"Tech News","url":"","feedLink":"","isQuery":true,"isEmpty":false,"isHidden":false,"itemCount":64,"items":[{"title":"Will Cryptomining Facilities Change Into AI Data Centers?","url":"https://hardware.slashdot.org/story/25/02/03/0452259/will-cryptomining-facilities-change-into-ai-data-centers?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1738563540,"author":"EditorDavid","guid":247,"unread":true,"content":"To capitalize on the AI boom, many crypto miners \"have begun to repurpose parts of their operations into data centers,\" reports Reuters, \"given they already have most of the infrastructure\" (including landing and \"significant\" power resources...)\n\n\nToronto-based bitcoin miner Bitfarms has enlisted two consultants to explore how it can transform some of its facilities to meet the growing demand for artificial intelligence data centers, it said on Friday... Earlier this month, Riot Platforms launched a review of the potential AI and computing uses for parts of its facility in Navarro County, Texas.","contentLength":603,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Google Stops Malicious Apps With 'AI-Powered Threat Detection' and Continuous Scanning","url":"https://it.slashdot.org/story/25/02/03/040259/google-stops-malicious-apps-with-ai-powered-threat-detection-and-continuous-scanning?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1738555380,"author":"EditorDavid","guid":246,"unread":true,"content":"Android and Google Play have billions of users, Google wrote in its security blog this week. \"However, like any flourishing ecosystem, it also attracts its share of bad actors... That's why every year, we continue to invest in more ways to protect our community.\" Google's tactics include industry-wide alliances, stronger privacy policies, and \"AI-powered threat detection.\" \n\n\"As a result, we prevented 2.36 million policy-violating apps from being published on Google Play and banned more than 158,000 bad developer accounts that attempted to publish harmful apps. \"\n\nTo keep out bad actors, we have always used a combination of human security experts and the latest threat-detection technology. In 2024, we used Google's advanced AI to improve our systems' ability to proactively identify malware, enabling us to detect and block bad apps more effectively. It also helps us streamline review processes for developers with a proven track record of policy compliance. Today, over 92% of our human reviews for harmful apps are AI-assisted, allowing us to take quicker and more accurate action to help prevent harmful apps from becoming available on Google Play. That's enabled us to stop more bad apps than ever from reaching users through the Play Store, protecting users from harmful or malicious apps before they can cause any damage. \n\nStarting in 2024 Google also \"required apps to be more transparent about how they handle user information by launching new developer requirements and a new 'Data deletion' option for apps that support user accounts and data collection.... We're also constantly working to improve the safety of apps on Play at scale, such as with the Google Play SDK Index. This tool offers insights and data to help developers make more informed decisions about the safety of an SDK.\" \n\nAnd once an app is installed, \"Google Play Protect, Android's built-in security protection, helps to shield their Android device by continuously scanning for malicious app behavior.\"\n Google Play Protect automatically scans every app on Android devices with Google Play Services, no matter the download source. This built-in protection, enabled by default, provides crucial security against malware and unwanted software. Google Play Protect scans more than 200 billion apps daily and performs real-time scanning at the code-level on novel apps to combat emerging and hidden threats, like polymorphic malware. In 2024, Google Play Protect's real-time scanning identified more than 13 million new malicious apps from outside Google Play [based on Google Play Protect 2024 internal data]... \n\nAccording to our research, more than 95 percent of app installations from major malware families that exploit sensitive permissions highly correlated to financial fraud came from Internet-sideloading sources like web browsers, messaging apps, or file managers. To help users stay protected when browsing the web, Chrome will now display a reminder notification to re-enable Google Play Protect if it has been turned off... Scammers may manipulate users into disabling Play Protect during calls to download malicious Internet-sideloaded apps. To prevent this, the Play Protect app scanning toggle is now temporarily disabled during phone or video calls... \n\nGoogle Play Protect's enhanced fraud protection pilot analyzes and automatically blocks the installation of apps that may use sensitive permissions frequently abused for financial fraud when the user attempts to install the app from an Internet-sideloading source (web browsers, messaging apps, or file managers). Building on the success of our initial pilot in partnership with the Cyber Security Agency of Singapore (CSA), additional enhanced fraud protection pilots are now active in nine regions — Brazil, Hong Kong, India, Kenya, Nigeria, Philippines, South Africa, Thailand, and Vietnam. \n\nIn 2024, Google Play Protect's enhanced fraud protection pilots have shielded 10 million devices from over 36 million risky installation attempts, encompassing over 200,000 unique apps.\n","contentLength":4044,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"DeepSeek founder Liang Wenfeng receives a hero’s welcome back home","url":"https://techcrunch.com/2025/02/02/deepseek-founder-liang-wenfeng-receives-a-heros-welcome-back-home/","date":1738552799,"author":"Connie Loizos","guid":232,"unread":true,"content":"<p>DeepSeek founder Lian Wenfeng is being hailed as a hero in the southern Chinese province of Guangdong, where he grew up and reportedly returned for the Lunar New Year, joined by bodyguards. Wenfeng—who, at 40, is already a billionaire due to his hedge fund, High-Flyer—is apparently even more beloved by locals following DeepSeek’s breakthrough research, […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":429,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"India expands Aadhaar authentication for businesses, raising privacy concerns","url":"https://techcrunch.com/2025/02/02/india-expands-aadhaar-authentication-for-businesses-raising-privacy-concerns/","date":1738551600,"author":"Jagmeet Singh","guid":231,"unread":true,"content":"<p>India has expanded its Aadhaar authentication service to let businesses such as those in e-commerce, hospitality, and healthcare use the biometrics of individuals to authenticate their identity.</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":257,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Boeing Acquires Spirit AeroSystems, While Boeing's 'Starliner' Unit Gets a New VP","url":"https://tech.slashdot.org/story/25/02/03/0148221/boeing-acquires-spirit-aerosystems-while-boeings-starliner-unit-gets-a-new-vp?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1738547400,"author":"EditorDavid","guid":245,"unread":true,"content":"Spirit Aerosystems builds aircraft components, including fuselages and flight deck sections for Boeing, according to Wikipedia. But now Boeing is set to acquire Spirit AeroSystems. \n\nThe aviation blog called Aviation Source News says the price tag was $4.7 billion, and opines that Boeing's move signals \"a renewed focus on quality and supply chain stability\" as Boeing \"addresses lingering concerns surrounding its 737 program.\"\n Spirit's recent struggles with quality control and production delays have had a fallout effect for Boeing... By integrating Spirit's operations, Boeing can implement more stringent oversight and ensure consistent manufacturing processes. This move is a direct response to past quality lapses that have plagued the company and damaged its reputation. Beyond quality control, the acquisition also offers Boeing greater control over its supply chain. By bringing a key supplier in-house, Boeing can streamline production, improve coordination, and reduce the risk of future disruptions... \n\nSpirit AeroSystems also supplies parts to Airbus, Boeing's main competitor. To address this, a separate agreement is being negotiated for Airbus to acquire Spirit's Airbus-related business. This strategic move ensures that Airbus maintains control over its own supply chain and prevents Boeing from gaining undue influence over its competitor's production. \n\nMeanwhile, the vice president leading Boeing's Starliner spacecraft unit \"has left his role in the program and been replaced by the company's International Space Station program manager, John Mulholland,\" Reuters reports, citing a Boeing spokesperson.\n\n\nIn its first test mission last summer flying astronauts, Starliner was forced by NASA to leave its crew aboard the ISS and return empty in September over problems with its propulsion system. A panel of senior NASA officials in August had voted to have a Crew Dragon capsule from Elon Musk's SpaceX bring them back instead, deeming Starliner too risky for the astronauts. \n\nPaul Hill, a veteran NASA flight director and member of the agency's Aerospace Safety Advisory Panel, said during a quarterly panel meeting on Thursday that NASA and Boeing continue to investigate Starliner's propulsion system. A Boeing spokesperson said on Thursday that the company and NASA have not yet determined what Starliner's next mission will look like, such as whether it will need to repeat its crewed flight test before receiving NASA certification for routine flights.\n","contentLength":2487,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Linux 6.14-rc1 Released With NTSYNC Completed, AMDXDNA Driver & Other Enhancements","url":"https://www.phoronix.com/news/Linux-6.14-rc1-Released","date":1738542540,"author":"Michael Larabel","guid":647,"unread":true,"content":"<article>Linus Torvalds just released Linux 6.14-rc1 to cap off the Linux 6.14 merge window...</article>","contentLength":85,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"OpenAI unveils a new ChatGPT agent for ‘deep research’","url":"https://techcrunch.com/2025/02/02/openai-unveils-a-new-chatgpt-agent-for-deep-research/","date":1738540800,"author":"Anthony Ha","guid":230,"unread":true,"content":"<p>OpenAI is announcing a new AI “agent” designed to help people conduct in-depth, complex research using ChatGPT, the company’s AI-powered chatbot platform. Appropriately enough, it’s called deep research. OpenAI said in a blog post published Sunday that this new capability was designed for “people who do intensive knowledge work in areas like finance, science, policy, […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":448,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"OpenAI Holds Surprise Livestream to Announce Multi-Step 'Deep Research' Capability","url":"https://slashdot.org/story/25/02/02/2342245/openai-holds-surprise-livestream-to-announce-multi-step-deep-research-capability?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1738539840,"author":"EditorDavid","guid":244,"unread":true,"content":"Just three hours ago, OpenAI made a surprise announcement to their 3.9 million followers on X.com. \"Live from Tokyo,\" they'd be livestreaming... something. Their description of the event was just two words. \n\n\"Deep Research\" \n\nUPDATE: The stream has begun, and it's about OpenAI's next \"agent-ic offering\". (\"OpenAI cares about agents because we believe they're going to transform knowlege work...\") \n\"We're introducing a capability called Deep Research... a model that does multi-step research. It discovers content, it synthesizes content, and it reasons about this content.\" It even asks \"clarifying\" questions to your prompt to make sure its multi-step research stays on track. Deep Research will be launching in ChatGPT Pro later today, rolling out into other OpenAI products... \n\nAnd OpenAI's site now has an \"Introducing Deep Research\" page. Its official description? \"An agent that uses reasoning to synthesize large amounts of online information and complete multi-step research tasks for you. Available to Pro users today, Plus and Team next.\"\n\n \n\nBefore the livestream began, X.com users shared their reactions to the coming announcement: \n\"It's like DeepSeek, but cleaner\"\n\"Deep do do if things don't work out\"\n\"Live from Tokyo? Hope this research includes the secret to waking up early!\"\n\"Stop trying, we don't trust u\" \n\nBut one X.com user had presciently pointed out OpenAI has used the phrase \"deep research\" before. In July of 2024, Reuters reported on internal documentation (confirmed with \"a person familiar with the matter\") code-named \"Strawberry\" which suggested OpenAI was working on \"human-like reasoning skills.\"\n\n\nHow Strawberry works is a tightly kept secret even within OpenAI, the person said. The document describes a project that uses Strawberry models with the aim of enabling the company's AI to not just generate answers to queries but to plan ahead enough to navigate the internet autonomously and reliably to perform what OpenAI terms \"deep research,\" according to the source. This is something that has eluded AI models to date, according to interviews with more than a dozen AI researchers. \n\nAsked about Strawberry and the details reported in this story, an OpenAI company spokesperson said in a statement: \"We want our AI models to see and understand the world more like we do. Continuous research into new AI capabilities is a common practice in the industry, with a shared belief that these systems will improve in reasoning over time.\" The spokesperson did not directly address questions about Strawberry. \n\nThe Strawberry project was formerly known as Q*, which Reuters reported last year was already seen inside the company as a breakthrough... OpenAI hopes the innovation will improve its AI models' reasoning capabilities dramatically, the person familiar with it said, adding that Strawberry involves a specialized way of processing an AI model after it has been pre-trained on very large datasets. \n\nResearchers Reuters interviewed say that reasoning is key to AI achieving human or super-human-level intelligence... OpenAI CEO Sam Altman said earlier this year that in AI \"the most important areas of progress will be around reasoning ability.","contentLength":3194,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Mozilla Adapts 'Fakespot' Into an AI-Detecting Firefox Add-on","url":"https://news.slashdot.org/story/25/02/02/2156241/mozilla-adapts-fakespot-into-an-ai-detecting-firefox-add-on?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1738533480,"author":"EditorDavid","guid":243,"unread":true,"content":"An anonymous reader shared this post from the blog OMG Ubuntu\n\n\n Want to find out if the text you're reading online was written by an real human or spat out by a large language model trying to sound like one? Mozilla's Fakespot Deepfake Detector Firefox add-on may help give you an indication. Similar to online AI detector tools, the add-on can analyse text (of 32 words or more) to identify patterns, traits, and tells common in AI generated or manipulated text. \n\nIt uses Mozilla's proprietary ApolloDFT engine and a set of open-source detection models. But unlike some tools, Mozilla's Fakespot Deepfake Detector browser extension is free to use, does not require a signup, nor an app download. \"After installing the extension, it is simple to highlight any text online and request an instant analysis. Our Detector will tell you right away if the words are likely to be written by a human or if they show AI patterns,\" Mozilla says. \n\nFakespot, acquired by Mozilla in 2023, is best known for its fake product review detection tool which grades user-submitted reviews left on online shopping sites. Mozilla is now expanding the use of Fakespot's AI tech to cover other kinds of online content. At present, Mozilla's Fakespot Deepfake Detector only works with highlighted text on websites but the company says it image and video analysis is planned for the future. \n\nThe Fakespot web site will also analyze the reviews on any product-listing pages if you paste in its URL.","contentLength":1475,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Two Devs, One Keyboard: A Bold Experiment in Computer Science Education","url":"https://hackernoon.com/two-devs-one-keyboard-a-bold-experiment-in-computer-science-education?source=rss","date":1738529596,"author":"Pair Programming Technology","guid":294,"unread":true,"content":"<p>(1) J. Walker Orr, Electrical Engineering and Computer Science, George Fox University, Newberg, OR, 97132, USA (jorr@georgefox.edu).</p><p>This study examines the adaptation of the problem-solving studio to computer science education by combining it with pair programming. Pair programming is a software engineering practice in industry, but has seen mixed results in the classroom. Recent research suggests that pair programming has promise and potential to be an effective pedagogical tool, however what constitutes good instructional design and implementation for pair programming in the classroom is not clear. We developed a framework for instructional design for pair programming by adapting the problem-solving studio (PSS), a pedagogy originally from biomedical engineering. PSS involves teams of students solving open-ended problems with real-time feedback given by the instructor. Notably, PSS uses problems of adjustable difficulty to keep students of all levels engaged and functioning within the zone of proximal development. The course structure has three stages, first starting with demonstration, followed by a PSS session, then finishing with a debrief. We studied the combination of PSS and pair programming in a CS1 class over three years. Surveys of the students report a high level of engagement, learning, and motivation.</p><p>Pair programming is an eXtreme programming (XP) methodology (Beck, 2000) that has seen some use in industry (Hannay et al., 2009). It involves two programmers working together on a single problem and computer with one programmer taking the role of a “driver” and the other in the role of “navigator.” The “driver” operates the keyboard and directly writes the code while the “navigator” observes and asks questions, critiquing and refining the code and its design. The “navigator” is not passive, they watch for bugs and defects, think of alternative designs, and look up related documentation and resources. Though the effectiveness of pair programming is mixed (Hawlitschek et al., 2022; Hannay et al., 2009), in some cases it has been shown to produce higher quality code faster than solo programming (Williams et al., 2000). The intention is that pair programming will help developers working together catch mistakes and defects much faster than on their own.</p><p>\\\nFor education, pair programming is compelling because it fits into the paradigm of apprenticeship and distributed learning, the idea that “Knowledge is commonly socially constructed, through collaborative efforts toward shared objectives or by dialogues and challenges brought about by differences in persons’ perspectives” (Salomon, 1997). Further, it has been shown to increase student satisfaction, reduce student frustration, improve student’s tendency to persist, and give students a sense of self-efficacy (Williams and Upchurch, 2001). The ICAP framework describes four modes of student engagement and behavior, identifying the interactive mode as producing the highest level of student cognitive engagement. Interactive modes of learning are believed to produce deep, transferable knowledge (Chi and Wylie, 2014). Pair programming fits within ICAP’s definition of interactive learning and hence has the potential to produce robust, transferable, conceptual learning. Recently, Hawlitschek et al. (2022) conducted a literature review arXiv:2311.01693v1 [cs.CY] 3 Nov 2023 and meta-study of pair programming in education concluded that pair programming is important and effective for students, especially beginners, but effective instructional design was missing. Hence pair programming has been shown to have a lot of potential as a teaching methodology but the details of how to implement it correctly in a classroom has yet to be discovered.</p><p>\\\nWe propose that the solution to effective instructional design for pair programming in the classroom has been found in the Problem Solving Studio (PSS) learning environment (Le Doux and Waller, 2016). PSS was designed to teach biomedical engineering students to solve complex problems without having to resort to rote memorization of procedures and algorithms. Students work in teams of two to solve ill-defined problems in a public space, enabling instructors to provide real-time feedback as they progress. A key feature of PSS is dynamic scaffolding, a targeted adjustment of problem difficulty to keep students challenged but not discouraged. By increasing or decreasing the difficulty on a per-team basis in real-time, as many students as possible can be kept in the zone of proximal development. A lecture-based course will have a difficult time matching the variety of levels that students are at since the same lecture content and delivery are communicated to all the students. There is good evidence that PSS improves students’ conceptual understanding (Le Doux and Waller, 2016).</p><p>\\\nPSS and pair programming are a natural fit and the combination of the two match the objectives and pedagogical needs of CS1 courses. For this reason, this study specifically addresses the adaptation of PSS in conjunction with pair programming for CS1 pedagogy. Two key objectives of a CS1 course are to teach algorithmic problem solving skills and a specific programming language. One of the challenges for expert instructors is that both problem solving and language knowledge is so deeply ingrained that it is second-nature to the instructors. Paradoxically, this high level of understanding means instructors often have a difficult time communicating this knowledge since it is taken for granted (Le Doux and Waller, 2016). Further, student ability and background varies significantly in CS1 courses. However, the synthesis of PSS and pair programming addresses these challenges and objectives directly, by giving students a hands-on opportunity to develop problem solving and programming language skills. PSS with the addition of pair programming, teaches algorithmic problem solving through a cognitive apprenticeship environment (Collins et al., 1987). Students learn from each other and are also guided by the instructor or other teaching assistants. Peer learning is helpful since students who are at similar levels of ability have recent experience with similar problems. This means that they are often better at communicating those solutions since they remember the details and particularities of both what they found challenging and how they overcame those obstacles. Pair programming’s ability to give rapid feedback helps students learn the syntax and semantics of a programming language. Further it promotes pair collaboration and problem solving. Pair programming has been shown to help notice programmers solve problems can not handle on their own (Hawlitschek et al., 2022). The combination of PSS and pair programming creates both an apprenticeship and peer learning environment in which students develop both problem solving and programming language skills.</p>","contentLength":6954,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Designing a Unified Data Model for Cross-Chain Querying","url":"https://hackernoon.com/designing-a-unified-data-model-for-cross-chain-querying?source=rss","date":1738526015,"author":"Interoperability in Software Publication","guid":293,"unread":true,"content":"<h2>3 Cross-Chain Query Language</h2><p>The following two subsections will detail (A.) the data model and (B.) the grammar with a concrete syntax and a corresponding processing architecture. Query statements are processed as per the architecture delineated in subsection (B.), yielding instances of data model classes using data sourced from the APIs of local blockchain nodes.</p><h3>3.1 Integrated Data Model</h3><p>The design of the language is predicated on a data model that integrates the principal data structures and attributes of the OPB discussed in Section 2.2. Building on prior work and existing tools addressed in Section 2.2, classes and attributes of the five OPB have been identified, generalized, and incorporated into a unified data model. Figure 1 presents the comprehensive data model as a UML class diagram. Table2 enumerates the main model classes, categorized into four packages to represent the chain, block, account, and transaction concepts of the OPB. The concrete syntax for formulating queries is introduced in subsection 3.2. Statements are articulated in terms of the classes and attributes, specifying the source data using class and attribute names of the data model.</p><p>\\\nThe concepts of the OPB are shown in the table and data model, encapsulated by the classes of the following packages and classes. Classes of the chain package embody one main network and blockchain for Bitcoin, Ethereum, Cardano, and Solana, as represented by the classes Chain, Network, and ChainDescriptor of the data model. Additional test networks with their distinct blockchains, such as</p><p>\\\nRopsten and Görli in Ethereum, are represented by the Network and ChainDescriptor classes. In Avalanche, the Network class encompasses one primary network, the first of potentially numerous ’subnets’, with separate ChainDescriptor instances for the three P/X/C blockchains.</p><p>\\\nThe Block and BlockDescriptor classes represent blocks, with discrete classes Status for the block’s status, ValidationDescriptor for validation via the consensus protocol, and ValidatorDescriptor for the involved validators. Conceptually, blocks across all blockchains are identified by a hash value, supplemented with metadata like timestamps and a height value denoting the block number, assuming no changes to non-final blocks. For instance, in Bitcoin and other blockchains following the original \"chain of blocks\" concept by Nakamoto [22], a block is linked to its predecessor by a hash value, which is used for validation. This is represented by a Block object with (a) a reference to a BlockDescriptor object, e.g. containing metadata such as the timestamp, (b) a reference to the previous BlockDescriptor object in the linkedBlockDescriptor attribute, and (c) a reference to a ValidationDescriptor object containing the hash value. Regarding non-final blocks in Bitcoin, multiple blocks might be discovered as successors to a given block; however, only one block gets included in the chain, while others are dismissed with an ’orphan’ status. In contrast, Ethereum handles similar cases by retaining one block in the main chain while preserving other blocks at the same level with an ’ommer’ status. Blocks in Proof-of-Work chains are not explicitly finalized, permitting the assignment of ’orphan’ or ’ommer’ status to blocks found in parallel to preceding blocks of the chain. Nonetheless, the likelihood of existing blocks being superseded in this manner diminishes over time, as multiple consecutive parallel blocks with greater cumulative work are required. Explicit block finalization, forestalling the emergence of multiple successors, can be observed in more recent Proof-of-Stake blockchains such as Solana.</p><p>\\\nConcerning data structure, blocks are connected to one or more existing blocks via the linkedBlockDescriptor attribute of the Block class. This connection can establish either a series of backward-linked blocks as mentioned for Bitcoin or a graph structure, such as a Directed Acyclic Graph (DAG) in the Avalanche C chain. The linkedBlockDescriptor relates to the preceding block or, for DAG structures, to any number of previous vertices linked through directed edges. DAG blockchains are indicated by the dagSupport attribute in the BlockDescriptor class, which is set ’true’ accordingly.</p><p>\\\nThe representation of blocks further depends on the consensus type. In order to unify the representation for Proof-of-Work and Proof-of-Stake, the ValidationDescriptor class contains generic attributes for storing a hash value, the condition for validation such as the target parameter in Bitcoin and the input, e.g. the Nonce in Bitcoin, as well as attributes for the Proof-of-Stake validation. Here, blocks are proposed, created and verified by attestation involving one or more validators. E.g., a Block in Ethereum is proposed and created by a validator represented as ValidationDescriptor object, and is subsequently verified by attestations. Attestations follow from multiple committees of validators that are represented through the attestationCommittee attribute in ValidationDescriptor, e.g. with multiple multiple addresses and votes. Regarding the creation of blocks, they either contain transactions directly or are grouped into time-based slots and epochs for Proof-of-Stake validation purposes. Upon appending a block, each block or slot undergoes validation, necessitating validators’ involvement. As per the ValidationDescriptor class, the creator of a Bitcoin or Ethereum block validates a linked block using the hashValue attribute. Conversely, for other Proof-of-Stake blockchains, block proposers are recorded in the corresponding attributes with attestations, which refer to the ValidatorDescriptor class. Each instance refers to any number of assigned validators who perform attestations of blocks through the committee mentioned before with votes and signatures. Thereby, for Ethereum and other Proof-of-Stake blockchains, the concepts for multiple groups of validators are represented.</p><p>\\\nAccounts, a concept prevalent in Ethereum, Solana, and Avalanche, are embedded in blocks to store assets, tokens, or data that are used for smart contracts. For a generic representation of accounts, the data model represents each Account object with an AccountDescriptor object containing the address and an indication whether the account represents a smart contract or an externally owned account of an individual. Concerning account-related data such as assets or tokens, it is important to note that data might represent assets or tokens natively, as seen in Cardano or Solana, or indirectly through data stored within an account. Each account is defined by an ID, with the concept of an address being common to all blockchains. Account storage of assets or tokens can refer to any custom asset or token represented by data in general. For tokens, token standards such as Ethereum’s ERC-20 or ERC-1155 are represented by the Token class’s attributes. Data storage utilizes binary large objects or key-value stores, which are employed in hash-based mapping data structures.</p><p>\\\nThe concepts of transactions in Bitcoin and Cardano are distinctive due to these blockchains’ lack of account structures. Consequently, transactions hold references to unspent transaction outputs (UTXOs) from previous transactions. In this model, a UTXO is included alongside the transferred value and a script that outlines locking conditions or holds data. While data inclusion is implied in Bitcoin, Cardano explicitly accommodates data in transactions and its storage associated with an address for smart contract functionality.</p><p>\\\nOn the other hand, in the case of Ethereum, Solana, and the Avalanche C chain, transactions are stored for the transfer of values, data, assets, or tokens between accounts. In the Avalanche X chain, the transfer of native assets is facilitated through the UTXO model. In the data model, the attributes of Transaction and TransactionDescriptor accommodate transfers between addresses by employing the attributes corresponding to the aforementioned concepts.</p><p>(1) Felix Härer[0000 −0002 −2768 −2342], Digitalization and Information Systems Group, University of Fribourg, Switzerland (felix.haerer@unifr.ch).</p>","contentLength":8230,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How to Make Different Blockchains Have a Heart-to-Heart","url":"https://hackernoon.com/how-to-make-different-blockchains-have-a-heart-to-heart?source=rss","date":1738526008,"author":"Interoperability in Software Publication","guid":292,"unread":true,"content":"<h2>2.3 Interoperability Between Blockchains</h2><p>Interoperability is widely acknowledged for transactions spanning multiple blockchains, established in cross-chain swaps and similar concepts practically implemented in so-called ’bridges’. Furthermore, efforts towards standardizing inhomogeneous data have commenced not only for query languages.</p><p>\\\n Swaps are typically initiated via a protocol on an originating blockchain, where tokens or arbitrary data are locked to prevent further transfer at the onset. A reciprocal transaction is then issued on a secondary blockchain to the initiator of the cross-chain swap, meaning another party often compensates for the tokens with a different asset on the second chain. This transaction includes a cryptographic proof with a secret that releases the tokens on the initial chain. Finally, the counterparty retrieves tokens from the originating chain. A wide array of protocols and variants have been developed on this foundational principle [20,25]. For atomic cross-chain swaps [13,30], atomicity is assured for all transfers involved in a cross-chain swap. Practical implementations in bridges, however, may exhibit different properties and assurances, not necessarily providing atomicity or other guarantees for the completion of the exchange. Bridges are primarily utilized for cryptocurrency exchanges; for example, Multichain[11], Portal[12], and others[13] facilitate cross-chain swaps between Ethereum, Avalanche, among others. However, cross-chain swaps and bridges lack standardization and do not provide uniform access or queries.</p><p>\\\n Standardization efforts are underway to tackle the issue of inhomogeneous data, with sparse prior work addressing non-uniform access. For Ethereum, one study [19] explores a conceptual schema derived from the primary data structures of the blockchain. In [5], a query language is proposed for the content of blocks and transactions. This language design leans on SQL syntax and supports concepts such as projection and selection within Ethereum. For data analysis, a framework and its implementation based on Scala have been suggested [2], employing SQL or NoSQL alongside aggregation functions and similar analysis methods.</p><p>\\\nAnother approach [7] details a data warehouse and ETL process for analyzing Ethereum data using standard SQL with a multi-dimensional data model for attribute dimension queries and data aggregation support. Although this and similar studies might connect to multiple blockchains, they fail to provide homogeneous data access, queries, or simultaneous access to data across multiple blockchains.</p><p>\\\nAdditional work based on SQL includes [17], a study that uses multiple blockchains to populate a standard MySQL database with the third-party service Google BigQuery. However, the reliance on third-party services as data sources presents another commonly observed issue in previous research, where the validation of blockchain data is either impossible or severely restricted. Other methods comprise public connectors between blockchains, blockchains integrating with others, and hybrid approaches [3].</p><p>\\\n<em>Interoperability Limitations in Prior Research.</em> Present solutions face limitations in terms of (L1.) data access not being homogeneous, (L2.) incompatibility of node software functions and APIs not providing standardized queries, (L3.) software not being able to view and access data on one or more blockchains in parallel, and (L4.) missing verifiability of the blockchain data. The current emphasis is placed on cross-chain swaps and isolated data analysis as opposed to data integration. The query language proposed herein seeks to mitigate these restrictions by suggesting an integrated data model for uniform access (L1.), a grammar and concrete syntax for standardized access (L2.), a processing architecture supporting multiple blockchains in individual queries (L3.) as well as operating multiple nodes locally for verifying transactions (L4.).</p><p>(1) Felix Härer[0000 −0002 −2768 −2342], Digitalization and Information Systems Group, University of Fribourg, Switzerland (felix.haerer@unifr.ch).</p>","contentLength":4114,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"What Are Open and Permissionless Blockchains?","url":"https://hackernoon.com/what-are-open-and-permissionless-blockchains?source=rss","date":1738525996,"author":"Interoperability in Software Publication","guid":291,"unread":true,"content":"<p>The section at hand introduces blockchain fundamentals, discusses open and permissionless blockchains, and existing interoperability approaches.</p><h3>2.1 From Bitcoin to Blockchains</h3><p>Following the posting of the Bitcoin whitepaper and corresponding software in 2008 and 2009, respectively [22,23], the term ’blockchain’ emerged as a general term encapsulating its technical architecture. The primary components: (1) a data structure of blocks, arranged in a backward-linked list or any graph, (2) a peer-to-peer network for data distribution, and (3) a consensus protocol, give rise to innovative properties. These notably include the ability to coordinate and validate all operations without trusted third parties or centralized control, open access to all data and operations, and permissionless access, whereby data and operations are not restricted to specific participants [9,1]. Ethereum and subsequent blockchains have enhanced these capabilities by incorporating smart contracts, acting as quasi Turing-complete programs [28,6]. Beyond payments and currency, smart contracts facilitate e-commerce, sales contracts, timestamping, and attestations, among other applications [16,18,11].</p><h2>2.2 Open and Permissionless Blockchains</h2><p>The progressive development and adoption springing from Bitcoin and Ethereum have yielded OPB with diverse characteristics. Table 1 catalogs five renowned OPB in the order of their public node count, highlighting the properties of their data structures, networks, and consensus protocols, as well as features pertinent to smart contracts.</p><p>\\\n The original design of backward-linked blocks in Bitcoin is coupled with additional trees or graphs in most other OPB. Beyond transactional data from blocks, supplementary queries must be performed for nontransactional data or older data that has undergone pruning. For instance, separate tree structures are incorporated for state storage in Ethereum, where balances and smart contract variables can be accessed [19].</p><p>\\\n. Well-known OPB networks comprise approximately 1300 to 16000 nodes. With algorithmic operation and validation, an increased node count augments security, such as in mitigating the risks associated with 51% attacks and selfish mining [26,24], which are frequently observed in smaller Proof-of-Work systems, e.g. ’Bitcoin Gold’ [24].</p><p>\\\n Between 2008 and 2022, a shift in the initially created protocols can be observed, veering away from Proof-of-Work towards Proof-ofStake, which introduces several trade-offs. While established blockchains such as Bitcoin and Ethereum have prioritized security and decentralization over the years, Cardano [15], Avalanche [21], and Solana [29] demonstrated enhancements in efficiency and scalability. This trend is mirrored in the development of novel consensus protocols based on by Proof-of-Stake [10,8] with higher efficiency, advantages to environmental impact, enhanced security, and potentially higher distribution and scalability. For example, Ethereum realizes Proof-of-Stake through GASPER, a combination of the consensus algorithm Caspar-FFG (\"Casper the Friendly Finality Gadget\") and LMD-GHOST (Latest Message Driven Greedy</p><p>\\\n\\\nHeaviest Observed Sub-Tree)[7]. Based on Caspar-FFG, blocks are proposed in slots of 12 seconds, part of 6.4-minute epochs of 32 slots, by the staking network nodes. The node proposing a block is randomly chosen while other nodes are organized in randomly formed subnets to carry out validations that are aggregated in attestations. Typically, a block is finalized within two epochs with improvements toward single-slot finality[8]. In the case of chain splits, this design together with the fork choice rule has proven itself in practice, demonstrating improved efficiency, decentralization, and security[9]. Other blockchains focus especially on scalability, e.g. Solana. However, temporary protocol failures can be observed frequently, resulting in non-availability [12].</p><p>\\\n Smart contract features are essential for data queries and software applications. Bitcoin offers a limited scripting language employed for programmable monetary transactions and the scalable lightning overlay network. The advent of general-purpose programming in Ethereum and similar platforms introduces a broader range of capabilities and complexity. Currently, most implementations are written and compiled for the Ethereum Virtual Machine, which is present in Ethereum and Avalanche. On the contrary, Cardano and Solana embrace markedly different paradigms. For instance, Cardano supports functional programming, preventing side effects and implementation errors, thus, possibly enhancing security and safety properties[10].</p><p>(1) Felix Härer[0000 −0002 −2768 −2342], Digitalization and Information Systems Group, University of Fribourg, Switzerland (felix.haerer@unifr.ch).</p>","contentLength":4824,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How to Access Data Across Different Blockchains","url":"https://hackernoon.com/how-to-access-data-across-different-blockchains?source=rss","date":1738525978,"author":"Interoperability in Software Publication","guid":290,"unread":true,"content":"<p>(1) Felix Härer[0000 −0002 −2768 −2342], Digitalization and Information Systems Group, University of Fribourg, Switzerland (felix.haerer@unifr.ch).</p><p>\\\n Open and permissionless blockchains are distributed systems with thousands to tens of thousands of nodes, establishing novel platforms for decentralized applications. When realizing such an application, data might be stored and retrieved from one or more blockchains by distributed network nodes without relying on centralized coordination and trusted third parties. Data access could be provided through a query language such as SQL at the application level, establishing a unified view on application-level data that is verifiably stored. However, when accessing multiple blockchains through their node software and APIs, interoperability cannot be assumed today, resulting in challenges of inhomogeneous data access. In addition, different feature sets and trade-offs exist, e.g., regarding smart contract functionality, availability, distribution, scalability, and security. For increasing interoperability, the paper at hand suggests pursuing the development of a cross-chain query language at the application level. The language abstracts from implementation by providing a standardized syntax, an integrated data model, and a processing architecture for data queries. This research is an extended and updated paper of a prior publication demonstrating the language syntax, data model, and architecture with an evaluation of compatibility against the largest open and permissionless blockchains today.</p><p>As of June 2023, a variety of openly accessible blockchains exist with a significant number of active participants. When considering blockchains with at least 1000 daily active addresses, an estimation counts 18 blockchains operating as open platforms for smart contracts or cryptocurrency [1]. In principle, these platforms can be used for data storage by any business or personal application without centralized coordination and trusted third parties [4,1]. Permissionless and verifiable storage are based on algorithmic consensus in contrast to databases and related technologies. In particular, the systems consist of distributed network nodes joining and operating the network at will while any node is able to verify transactions in the blockchain data structure. Decentralized applications are enabled in this way, primarily for programmable money and contracts.</p><p>\\\nThese systems with the components blockchain data, network, and consensus protocol can be considered open and permissionless blockchains (OPB), enabling novel decentralized applications such as programmable money or contracts. Contrary to the distributed systems prevalent in previous decades, well-known OPB now involve the coordinated efforts of thousands to tens of thousands of nodes, forming open and permissionless infrastructures.</p><p>\\\nBased on the connectivity of active participants, it is estimated that approximately 16,600 nodes are operating Bitcoin[2], 7,600 are operating Ethereum[3], and 3,000 are operating Cardano[4]. These estimations might not take into account potentially uncounted nodes hidden due to specific configurations, e.g. located behind routers and firewalls. As adoption grows, alongside the increasing number of open and permissionless blockchains, as well as the vast quantities of readily available data, this paper posits the future significance of these platforms for verifiable data storage and execution. Applications interfacing with these platforms encompass various uses, including payments and currency, e-commerce, timestamping, and the attestation of data and web links [18,27,11].</p><p>\\\nThis research offers an extended and updated study of existing work [14] with the following research problem, objective, and contribution.</p><p>\\\n Software accessing data across open and permissionless blockchains (OPB) today face challenges due to interoperability:</p><ol><li><p>Inhomogeneous access to data due to various OPB implementations</p></li><li><p>Different OPB data models and features exist.</p></li><li><p>Different OPB trade-offs exist, notably regarding scalability, security, and decentralization.</p></li></ol><p>\\\n<em>Research Objective and Contribution.</em> The objective of this research is to study the three challenges hindering enhanced interoperability among OPB. The paper contributes a cross-chain query language, established by defining an integrated data model, a grammar and concrete syntax, and a processing architecture. In response to query statements submitted by software applications, data from various blockchain nodes is gathered, integrated into the data model, and processed in accordance with the statements. Considering previously suggested conceptual models and query languages, e.g. [19] and [5], the language design abstracts from implementation of today’s largest OPB. The proof-of-concept implementation demonstrates feasibility and compatibility, but also indicates potential for software to incorporate OPB as integral components of their architecture.</p><p>\\\n Consider a scenario where numerous e-commerce websites participate in shared loyalty programs, issuing reward points for customer purchases. This model is not uncommon among collaboratively operating airlines[5], among other industries. Given a cross-chain query language, business-level applications across different airlines could access data in a standardized way, reuse queries in their software components, view data on multiple blockchains, integrate and migrate among blockchains, or exchange the underlying blockchains. This is especially advantageous for decentralized scenarios where centralized coordination is limited, e.g. in business networks of different companies relying on separate infrastructure and technology stacks, or generally in decentralized applications.</p><p>\\\nThe paper is organized as follows. Section 2 lays out background and related studies. Section 3 discusses OPB, focusing on their properties essential for the derivation of an integrated data model. The data model, a grammar with a derived concrete language syntax, and a processing architecture follow. A demonstration of feasibility for the language is provided in Section 4 with a prototype implementation utilizing multiple OPB. Section 5 draws conclusions and provides an outlook.</p><p>\\\n Consider a scenario where numerous e-commerce websites participate in shared loyalty programs, issuing reward points for customer purchases. This model is not uncommon among collaboratively operating airlines[6], among other industries. Given a cross-chain query language, business-level applications across different airlines could access data in a standardized way, reuse queries in their software components, view data on multiple blockchains, integrate and migrate among blockchains, or exchange the underlying blockchains. This is especially advantageous for decentralized scenarios where centralized coordination is limited, e.g. in business networks of different companies relying on separate infrastructure and technology stacks, or generally in decentralized applications.</p><p>\\\nThe paper is organized as follows. Section 2 lays out background and related studies. Section 3 discusses OPB, focusing on their properties essential for the derivation of an integrated data model. The data model, a grammar with a derived concrete language syntax, and a processing architecture follow. A demonstration of feasibility is provided in 4 with a prototype implementation utilizing multiple OPB. The final section, Section 5, draws conclusions and provides an outlook.</p><p>[1] https://www.tradingview.com/markets/cryptocurrencies/ prices-most-addresses-active/, 2023-06-30</p><p>\\\n[2] https://bitnodes.io/, 2023-06-30</p><p>\\\n[3] https://ethernodes.org/, 2023-06-30</p><p>\\\n[4] https://adastat.net/pools/, 2023-06-30</p>","contentLength":7743,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Is It Still a Good Idea To Invest in Bitcoin?","url":"https://hackernoon.com/is-it-still-a-good-idea-to-invest-in-bitcoin?source=rss","date":1738524031,"author":"⚡Rey C🔎🗞️📊","guid":289,"unread":true,"content":"<p>\\\n\\\nThe first time I heard about  was in the summer of 2018 during a casual conversation with a Russian professor of economics. The price action was around $8k per coin.</p><p>\\\nAt that time, I was unemployed, looking for a job, and wanted to help my parents and one of their friends improve their financial situation while I improved mine. My parents' friend was an 80-year-old guy with his life savings and investments in one of the region's top  that managed two of his portfolios.</p><p>\\\nHe managed to save and  since 1955. Still, for some inexplicable reason, his wealth was approximately €350k, which is incredibly low for living in one of the top 5 countries of the European Union and having the most minimalistic lifestyle I have ever seen.</p><p>So how did decades of traditional saving lead to ? Did Bitcoin change his life?</p><p>\\\nThis story will walk you through the complexity of  (network)  (coin) using conversational language, comparisons, and examples to explain topics that several professionals with master's or Ph.D. degrees in Economics, Finance, or Computer Science don't understand or aren't interested in understanding.</p><p>\\\nThis isn't another crypto success story. It's a critical examination of what happens when traditional finance meets digital disruption. Sometimes, the most important lessons come from questioning both sides of the equation.</p><h2><strong>WHAT IS BITCOIN: BEHIND THE IMPORTANCE OF THE \"RAT POISON\" ARCHITECTURE</strong></h2><p><strong>Is Bitcoin worth it? Is it safe?</strong> How could an asset grow by more than 10k times in less than 10 years? If it's too good to be true, it should be a Ponzi or a scam, right?</p><p>\\\n more of  than a , but at some point, both concepts merged since they became interdependent to cover the network's sustainability.</p><p>First, let's explore the complexity of the Bitcoin network, its characteristics, components, and flaws to know how \"safe\" it is as an infrastructure.</p><h3><strong>THE BITCOIN NETWORK: WHY DOUBLE-SPENDING CAN DESTROY A DECENTRALIZED BLOCKCHAIN</strong></h3><p>The network is where everything starts and could potentially end. According to Satoshi Nakamoto's white paper, Bitcoin was created as a purely peer-to-peer version of electronic cash and a solution to double-spending. A system that would allow payments without relying 100% on a third party which for marketers means  even if this word isn't mentioned in the Bitcoin white paper.</p><p>\\\nThe  dilemma could also exist in banking or other types of centralized systems but in this environment, it is easily \"solved\" by implementing TTP (Trusted Third Party) models which are used by entities that facilitate interactions between two parties. The problem here is that these parties have to be fully trusted to act on behalf of their client's interests. The concept of  here also means there is no way to verify if the system is operating in your interests, hence the need to trust it.</p><h3><strong>Is The Banking System Secure?</strong></h3><p>When you use the <strong>traditional banking system</strong> to send money or make a payment, you're not actually doing it yourself; instead, you're giving an order to your bank to handle it for you. They maintain the ledger and check that you have enough funds to complete the transaction. The issue here is that you depend entirely on them to fulfill this task, which operates within a system that lacks transparency and has a central point of failure susceptible to hacking, corruption, or mismanagement.</p><p>You should know that banks aren't obligated to disclose hacks publicly. Therefore, while major bank hacks do occur, the specifics are often kept confidential. News reports may emerge about a bank experiencing \"IT issues\" or \"service disruptions,\" which could be a sign of a cyberattack, but the bank may not confirm the details except for communicating the news to people directly impacted or when the hack is too big to be hidden. Hacks in traditional banking are more common than you think and, in some cases, clients aren't protected by law.</p><p>\\\nThe problem here is so big that it is expected that by 2025 cybercrime could cost $10.5 trillion. Cyberattacks are particularly devastating because, according to IBM, it takes on average 212 days to detect a breach and 75 extra days to contain it. This means hackers count for approximately more than 9 months to infect computers, servers, and networks.</p><p>\\\nThe financial sector is the second preferred target of hacks after the healthcare industry. \\n </p><p>Here are some cybercrime numbers:</p><ul><li> Nearly four out of five (78%) of the 240 largest banking institutions suffered a cyberattack in the past year.</li><li> A major financial services provider experienced a data breach, exposing the personal identification and passport information of 8 million customers.</li><li> Data security incidents affecting banking institutions have risen sharply (50%) in 2023, indicating a significant escalation of cybercriminal activity.</li></ul><p>\\\nThis unveils a silent security problem that is hidden by banks and legacy media and taken in most cases as if it isn’t something serious due to the lack of transparency to report the crime to clients.</p><h3><strong>Where Does Blockchain Security Rely?</strong></h3><p>The initial goal of the Bitcoin network creation was to solve the double-spending problem under a PoW (Proof-of-Work) mechanism and without relying on a third party as in the case of banks or any centralized authority. Double-spending happens when someone tries to spend the same digital asset more than once. In a decentralized blockchain like the Bitcoin network, a series of participants are involved during a transaction to prevent this type of fraud.</p><p>\\\nBitcoin prevents double-spending by combining:</p><ul><li><p> A transparent, tamper-proof record of all transactions.</p></li><li><p><strong>Decentralized Verification:</strong> Thousands of computers (nodes) ensure every transaction is unique and valid.</p></li><li><p> Miners solve cryptographic puzzles to validate transactions, making them irreversible and secure.</p></li></ul><p>Despite the blockchain consensus mechanism to guarantee network security, every blockchain faces vulnerability attacks. These attack strategies come in different forms. The most popular and severe is the 51% attack.</p><p>A 51% attack occurs when a single entity or group gains control of more than 50% of a blockchain network's mining or computational power. This majority control allows the attacker to disrupt the network's operations and manipulate the blockchain ledger.</p><h3><strong>How Does A 51% Attack Happen?</strong></h3><p>Gaining Majority Control: In Proof-of-Work (PoW) blockchain networks, miners compete to solve complex mathematical puzzles to validate transactions and add new blocks to the blockchain. If an individual or group manages to control over 50% of the network's total computational power (hash rate), they can dominate this process.</p><h3><strong>Potential Actions By The Attacker</strong></h3><ul><li> The attacker can spend the same cryptocurrency units more than once by reversing transactions they made while in control. This is achieved by creating a separate, longer version of the blockchain (a fork) where the attacker's transactions are excluded, effectively invalidating them on the original chain.</li><li> They can prevent other miners from completing valid blocks, thereby halting transaction confirmations and freezing the network.</li><li><strong>Preventing New Transactions:</strong> The attacker can refuse to include new transactions in blocks, effectively censoring participants.</li></ul><h3><strong>Limitations Of A 51% Attack</strong></h3><ul><li><strong>Inability to Alter Historical Blocks:</strong> The attacker cannot change transactions confirmed in older blocks, as altering these would require rewriting the entire blockchain history, which is computationally infeasible.</li><li><strong>No Creation of New Coins:</strong> They cannot create new coins out of thin air or alter the total supply of the cryptocurrency.</li><li><strong>Limited to Recent Transactions:</strong> The attack primarily affects recent transactions and the ability to confirm new ones.</li></ul><h3><strong>Consequences Of A 51% Attack</strong></h3><ul><li> Such an attack undermines confidence in the cryptocurrency's reliability and security.</li><li> The perceived vulnerability can lead to a decline in the cryptocurrency's value.</li><li> Executing a 51% attack, especially on large networks like Bitcoin, requires immense computational resources and energy, making it economically unfeasible for most attackers.</li></ul><p>\\\nIn August 2020, the Ethereum Classic blockchain experienced multiple 51% attacks. They occurred due to the low network hash rate, the viable economic costs, the poor mining pool distribution, and the scarce number of members in the dev community. However, they solved the issue approximately 48 hours later and proposed changes to their initial POW mechanism to reduce the possibilities of new attacks.</p><p>\\\nEven if a 51% attack didn't end with the Ethereum Classic network, it immediately damaged trust in the network which was reflected in the dev community's growth in the long term.</p><h3><strong>How Realistic Is A 51% Attack On The Bitcoin Network?</strong></h3><p>We must analyze both networks' (Bitcoin and Ethereum Classic) hash rates, economic incentives, and developers' numbers to estimate the chances of a potential attack.</p><ol><li><strong>Hash Rate Comparison (Network Security)</strong></li></ol><p>The higher the hash rate is, the more decentralized the network becomes due to better-distributed mining power among miners or mining pools which is reflected in energy consumption.</p><ul><li><p> ~825.7 exahashes per second (EH/s)</p></li><li><p> 1,000,000 terahashes per second (TH/s)</p></li><li><p>~825,700,000 terahashes per second (TH/s)** \\n **</p></li><li><p> ~245.73 terahashes per second (TH/s)</p></li></ul><p>\\\nThis indicates that Bitcoin's hash rate is about 3M times greater than that of Ethereum Classic.</p><ul><li><p><strong>Comparison with Banking Systems and Countries</strong></p></li><li><p> Estimates suggest that the traditional banking system consumes about twice as much energy as the Bitcoin network.</p></li><li><p> Bitcoin's energy consumption is comparable to that of medium-sized countries. For instance, its annual consumption of 175.87 TWh is similar to that of Poland.</p></li></ul><p>This means that if a group or entity wants to attack the Bitcoin network, they will have to invest as much as the annual energy consumption of Poland, which is considered a mid-sized energy consumer globally.</p><p>\\\nThis security comes at a cost - both financial and environmental. Is this trade-off worth it for the average investor? \\n High energy costs could be seen as something positive and negative at the same time. It will depend on who you ask. \\n  \\n According to Vitalik Buterin, Ethereum Co-founder, \"Bitcoin's security model is revolutionary, but its energy consumption is a legitimate concern.\" On the other side, Michael Saylor, MicroStrategy CEO, thinks \"The cost of securing the network is justified by the value it protects.\"</p><p>\\\n<strong>Bitcoin Network Security takeaway</strong></p><ul><li>Bitcoin's security relies on massive computational power: comparable to Poland’s annual energy consumption</li><li>Traditional banking hacks are cheaper but potentially more profitable</li><li>The network has never been successfully 51% attacked even if minor bugs have been reported and solved</li><li>Success attack probability: Questionable</li><li>Economic incentive for hackers: Likely negative ROI</li><li>Question: Does mining power (high hash rate) cost represent a form of centralization?</li></ul><p>\\\nAccording to some analysts and some of the most popular criticism, Bitcoin mining could be considered a form of centralization due to its difficulty and cost. However, Bitcoin mining companies are derivating part of their revenue in R&amp;D to make mining activity more cost-efficient. This enables them to find cheaper energy sources and at the same time set partnerships with communities around the globe.</p><p>\\\nThese are some examples:</p><ul><li> A Bitcoin mining company called  is working with local hydroelectric plants to monetize excess energy capacity, helping to fund rural electrification projects.</li><li> The state has become a hub for Bitcoin mining using excess natural gas that would otherwise be flared, reducing methane emissions while creating value.</li></ul><p>\\\nLast year, I wrote an article that was a review of a YouTube video where I debunked James Jani's point of view about Bitcoin. To explain the decentralized nature of the Bitcoin network I explained how  thanks to the Bitcoin Mining Council (BMC), mining companies, and countries like Paraguay which are working together to make mining more sustainable even if they are still facing some environmental and social issues.</p><p>\\\nAdditionally, Bitcoin mining companies are currently exploring operations on AI activities which sets a positive challenge to the industry since they are diversifying energy usage. This may lower their participation in the hash rate growth reducing competitive pressure on the Bitcoin network but at the same time giving opportunities to new companies to participate in Bitcoin mining activities.</p><ol start=\"2\"><li><strong>Economic Incentives and Attack Feasibility</strong></li></ol><p>The cost of controlling 51% mining power becomes more expensive.</p><ul><li><p><strong>Estimated 51% Attack Cost for 1 Hour (in Blockchain Networks)</strong></p></li><li><p> ~$1.3 million per hour</p></li><li><p> ~$4,200 per hour</p></li></ul><p>\\\nAs I mentioned before, the 51% attack in the Ethereum Classic network was solved in approximately 48 hours which is a fast reaction time if we compare it to the banking system that typically needs several months to solve the hack.</p><p>\\\nIn 2016, the Central Bank of Bangladesh was targeted to exploit vulnerabilities in the SWIFT payment system. The attackers attempted to fraudulently transfer nearly $1 billion from the bank's account at the Federal Reserve Bank of New York. While most transactions were blocked, approximately $101 million was successfully transferred, with about $63-$81 million remaining unrecovered (direct losses).</p><p>\\\nThe hackers' investment to attack the Central Bank of Bangladesh oscillated around $50k. However, it took the Central Bank of Bangladesh 48 hours to detect the attack, meaning the attackers had spent around $1k per hour to execute the hack.</p><ul><li><p><strong>Central Bank of Bangladesh (2016 SWIFT attack) estimated hack investment</strong></p></li><li><p>The hack was detected after 48 hours</p></li><li><p>Estimated total investment by the hacker(s): $50k</p></li></ul><p>This is an estimation since the Central Bank of Bangladesh never disclosed the potential investment attackers could have made to hack the system. The hack cost estimation includes exploitation of SWIFT System vulnerabilities, phishing or social engineering tactics, insider collaboration (if any), and infrastructure and operational costs.</p><p>When an attack happens they are in partial charge of the system defense since they should build security measures to stop the attack using technical and hardware resources to defend the network.</p><ul><li><p>The Bitcoin Core project had around 40-50 regular core developers who frequently contributed code.</p></li><li><p>The broader Bitcoin ecosystem (including Lightning Network, wallets, and other Bitcoin-related projects) had several hundred active developers.</p></li><li><p>Electric Capital's Developer Report from 2023 indicated that Bitcoin had approximately 900-1,000 monthly active developers across all Bitcoin-related projects. \\n </p></li><li><p>The development activity was significantly smaller compared to Bitcoin.</p></li><li><p>ETC had around 10-15 core developers working on the main client implementations.</p></li><li><p>The total ecosystem had roughly 50-100 active developers across all ETC-related projects.</p></li></ul><h3><strong>51% Attack And Other Types Of Vulnerabilities In The Bitcoin Network</strong></h3><p>The 51% attack isn't the only potential vulnerability the Bitcoin network has. There are other types of minor attacks the network has gone through or could potentially experience.</p><p>|  |  |  |  |\n|----|----|----|----|\n|  | Extremely high hash rate, very expensive | Low | Severe (double spending, reorgs) |\n|  | Exploits software vulnerabilities, low cost | Moderate | Exchange-level disruptions |\n|  | Exploits internet routing vulnerabilities, low cost | Moderate | Delays, possible network partitions |\n|  | Many nodes, moderate costs | Moderate | Node-level disruptions |\n|  | Low resources, mitigated in Bitcoin Core | Low | Transaction delays |\n|  | Many nodes, moderate costs | Moderate | Node isolation, transaction issues |\n|  | Very low cost | High | Privacy breaches |\n|  | A high hash rate required | Low | Forks, delays, or inefficiency |\n|  | Immense computational power (e.g., quantum) | Low | Severe, network-wide compromise |\n|  | Moderate hash rate | Low | Transaction delays |\n|  | Software bugs or social engineering, low cost | High | Loss of funds |</p><p>\\\nThis time we aren't going through the specifics of each vulnerability because this section of the article is a technical overview that aims to help you understand Bitcoin from a technological perspective and measure the potential risks of Bitcoin as an investment.</p><p>\\\nHowever, it was important to examine the 51% attack since it is the most severe and real example of an attack registered until today.</p><p>\\\nThe other hypothetical big threat to any blockchain network and cryptographic system is quantum computing. However, according to Vitalik Buterin, quantum computing cannot break all forms of cryptographic algorithms. He has added that developers have been working on unbreakable cryptographic algorithm replacements for those that quantum computing can break.</p><p>\\\nThe topic has been in the study of different groups like QBT, IDQ, BTQ, and others committed to quantum blockchain technologies. Bitcoin Optech, a non-profit research company that aims to help Bitcoin-based businesses, has published some  articles on the topic since 2018.</p><p>\\\nWhile we've explored Bitcoin's technological foundation and security mechanisms in detail, this is only half the story. The network's non-perfect but robust architecture laid the groundwork for Bitcoin's emergence as a unique financial asset – one that would challenge traditional investment paradigms and catch the attention of both institutional and retail investors worldwide as it did with me and my friend who struggled to understand it but highlighted its transparency and resilience in comparison to the one of the banking system.</p><p>We've dissected Bitcoin's technological foundation but it is still too soon to know if a robust technology automatically makes for a good investment.</p><p>\\\nIn Part 2, we'll confront the uncomfortable truths about Bitcoin as an investment:</p><ul><li>How an average traditional portfolio could perform against Bitcoin</li><li>The real impact of market manipulation on small investors</li><li>Why institutional adoption might not be what you think</li><li>The hidden costs of \"being your own bank\"</li></ul><p>\\\nStay tuned as we challenge both the critics and supporters of Bitcoin investment. After all, sometimes the most valuable insights come from questioning our own assumptions.</p>","contentLength":18185,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Odin Project Helped Me Escape Tutorial Hell and Changed the Way I Learn Code","url":"https://hackernoon.com/the-odin-project-helped-me-escape-tutorial-hell-and-changed-the-way-i-learn-code?source=rss","date":1738522807,"author":"CodeByBlazej","guid":288,"unread":true,"content":"<p>\\\n\\\nI started learning programming exactly a year ago. At first, I didn’t know if coding would be for me, so I decided to ask my friend, who is a programmer, some questions.</p><p>\\\nHe learned how to code in college and then at university, eventually landing a job.</p><h2>My Early Journey Into Programming</h2><p>Why did I want to learn how to code in the first place? Well, I am tired of working in different companies doing mostly the same things every day—fixing machines, operating them, making products on various kinds of machines, and so on.</p><p>\\\nI have always wanted to start my own business and build my own projects or serve clients. I used to be a real estate agent, and I really enjoyed that kind of work—serving customers and more.</p><h2>Figuring Out Where to Begin</h2><p>Anyway, after asking my friend a couple of questions and comparing them with the <a href=\"https://codebyblazej.com/posts/why-learning-to-code-is-like-fixing-a-car/\">skills I already have</a>, we both concluded that learning programming shouldn’t be so difficult for me. The next step was coming up with some resources. He didn’t know much beyond Udemy and bootcamps, but he promised to contact another friend who’s also a programmer with much more experience. I said I would also do my own research, and then we’d try to find something great together.</p><p>\\\nAfter about two weeks, we called each other with some results. It looked like bootcamps were overpriced, and we thought that most of them were more about taking money from participants rather than truly teaching them how to program. Moreover, many of them tried to teach as fast as possible and seemed focused on keeping people accountable. That wasn’t a big deal for me because when I say that I’ll do something, I will do it no matter what.</p><p>\\\nI figured I might not be able to pull three hours a day of learning, but I am sure I can do one or two hours a day for a longer period than a bootcamp would last. On top of that, we claimed that for the price of bootcamps, the same knowledge might be found in courses on Udemy. So we stuck to Udemy.</p><p>I found three teachers who seemed interesting for learning JavaScript with, and my friend also picked three. After some due diligence, I pulled the trigger on <a href=\"https://www.udemy.com/course/javascript-the-complete-guide-2020-beginner-advanced/?couponCode=NEWYEARCAREER#instructor-2\">this one</a>.</p><p>\\\nI was hyped, excited, and ready to start straight away. I bought the course, prepared some notes, and played the first video. As days passed, I could see my progress in understanding JavaScript, HTML, and CSS. I knew how functions work, what variables are, and, most importantly, how to start projects and make JS, HTML, and CSS communicate with each other.</p><p>\\\nAt this point, I told myself it would be a great idea to split my learning time and add some YouTube videos featuring people doing only projects. I found these 3 guys which I learned a ton from. Really recommend them!</p><p>So much, in fact, that I started doing my own little project until I got to APIs, which I didn’t understand much. So, I went back to spending more of my learning time on Udemy courses again.</p><p>\\\nI kept going with that course until it got me to Classes, which I had no clue about. At that moment, it felt like I’d been introduced to plenty of things in coding, but all the lines of code I had written were actually copied from those resources I showed you above.</p><p>I didn’t see myself using all this stuff to do something on my own, but the course was already on Classes and OOP, which seemed so alien to me. I felt like I should have known much more at this point in order to grasp all these concepts, yet I wasn’t even told to do anything on my own yet! I knew something was off.</p><p>\\\nI checked where I was in this Udemy course, and it turned out I was exactly in the middle. I thought, “Eeeeemmmm, nope! It’s not going to work like that. There is no f***ing way to learn programming (a thing that people spend years on) in like three months.” By my calculation, I would be somewhere near the end of the course around that time. It made me a little sad, and I felt like I might join the group of people who write those types of comments online</p><p>\\\n\\\nI thought there must be a better way.</p><h2>Discovering “Tutorial Hell” and The Odin Project</h2><p>I began to scroll Reddit, looking for some helpful comments, and found the phrase “tutorial hell.” Yep, that’s exactly what I would’ve fallen into if I had continued getting other courses on Udemy and so on. But luckily, I found posts recommending The Odin Project.</p><p>\\\nA lot of people recommended either TOP (<a href=\"https://www.theodinproject.com/dashboard\">The Odin Project</a>) or <a href=\"https://www.freecodecamp.org/\">FreeCodeCamp</a>. I did my own research and thought that if Odin takes sooooo long to finish, it must be a great resource. People who recommended it seemed really proud of choosing it in the first place.</p><p>I called my friend and told him about it. He had no clue what I was talking about. It looks like TOP is not very popular in Poland. But I told him my struggles with Udemy and then started TOP right away.</p><p>It was completely different! There was a lot of reading in the beginning and all that, but the first couple of lessons were nicely designed just to introduce the student to the whole process. I liked it.</p><p>\\\nLesson by lesson, I became more aware of why it was so hard to learn from those courses on Udemy. I have a few theories:</p><ul><li><p>: Maybe the lessons are often set up in the correct order, but there aren’t enough resources about each subject to give it more breadth. I’m not saying it needs to be as broad as an ocean, but at least broad enough for a beginner to understand what the concept is for and how to use it.</p></li><li><p>: Often, there’s just one short way of explaining a particular subject by the tutor. If you still don’t understand what he/she said, you need to start looking elsewhere and then come back. Or you have to rewind the video five times, hoping your brain will finally get what the tutor is saying. In Odin, there are often five other resources linked at the end of the lesson meant to help you understand the subject.</p></li><li><p><strong>Lack of Hands-On Exercises</strong>: There isn’t much focus on the student doing their own exercises. Of course, there’s something like, “We are going to make this thing now. Try to do it on your own before looking at the code I’ll write in a bit.” C’mon, guys, do you really want to learn coding? In Odin, when you start learning about a subject, you have an entire lesson on it. Then there are a couple of links explaining the same thing but in different words. I really love this because sometimes one article explains the subject in a more visual way, and another uses a more academic style. It helps your brain remember longer. At the end of each part, you always have some kind of project to test your knowledge. And yes, you are thrown in the deep water, and with short guidance, you need to sort everything out yourself. It’s not that you have to look for more info to do the project, because it’s always based on the things you have just learned. If you forgot something, you either know where to look for a quick refresher (the resources from the lessons) or simply in the Odin lesson itself.</p></li></ul><p>Can you see the differences? Odin is long, and in every lesson, you find something that builds up the blocks of knowledge. Going through the course, you’ll have plenty of “click-ins” and “AHA” moments rather than, “What’s that thing for?” or “Am I lacking some knowledge at this point?” or “WTF is this, and where is it even coming from?!”.</p><p>\\\nAt the moment of writing this article, I am at the end of the Ruby course—somewhere around 86%. The last time I spoke to my friend, I told him about lessons I’d just finished, which were Knights Travails, linked lists, graphs, hash maps, data structures, etc. He said that he had all those things at university, and when he asked me how deep the explanation went, he was actually surprised. He didn’t assume that Odin would take those things so far. Yep, it did, and I am really happy I decided to go through this.</p><p>\\\nAt this point, I no longer have any fear of tutorial hell. Every single time I see some post online asking where to start and what course to buy, etc., I want to tell these people to stick to Odin and simply trust the process.</p><p>I don’t think anything is possible in two months, as many gurus on YouTube say. Well, you might be able to get some app running just by looking for simple guidance on what to do next, but isn’t it better to learn some stuff properly and then have fewer struggles along the way? You can just focus on building and adding to your knowledge rather than fixing up all the mistakes you’ll make and trying to figure everything out on your own.</p>","contentLength":8494,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"If Your Memecoin Can't Make People Rich, You Have No Community","url":"https://hackernoon.com/if-your-memecoin-cant-make-people-rich-you-have-no-community?source=rss","date":1738522803,"author":"Abhinil","guid":287,"unread":true,"content":"<p>Initially like any other developer in web3, I was very suspicious about meme coins and thought of it only as a method of FUD…</p><p>\\\nAnd generally speaking it is, but my recent research around the domain have made me think deeper and find why this bull run is majorly about meme coins.</p><p>\\\nLike most Web3 developers, I used to be pretty skeptical about meme coins, seeing them as nothing more than a tool for hype and FUD.</p><p>\\\nAnd to be fair, that’s often the case. But after diving deeper into the space and researching recent trends, I’ve started to see things differently. This bull run is all about meme coins—and there’s a good reason why.</p><p>We are living in a world where everything is a multilevel marketing scheme and rich and informed are running a pyramid of sophisticated wealth extraction. Memecoins just exaggerated example of this:</p><ol><li>Founders get in the project on zero cost basis</li><li>VCs/ Angel Investors get to buy a large % of token cheaply</li><li>Exchanges and Market Makers enters next where they charge in token supply of upfront payment for listing of token.</li><li>Twitter KOLs, Telegram Callers, You-tubers get the % of token supply to market among their influence</li><li>Traders get the profit out by scalping the last bit of profit from the market.</li><li>Retail are the Exit Liquidity</li></ol><p>\\\nWhen retail enters in the project all the above make money.</p><h2>Internal Reasons to memecoin supercycle?</h2><p>There were only around 500 crypto token in 2017, and now with platform’s like pump.fun anyone can make their crypto tokens in minutes.</p><p>\\\nCrypto Industry has become the token production industry from a software production Industry.</p><p>\\\nThis is happening because:</p><ol><li>Massive over production of tokens</li><li>Extremely inflated valuations at TGE (Token Generation Event)/ CEX listing.</li><li>All the price appreciation has been relegated to the private rounds</li><li>All 2024 token launches on binance are literally down only</li><li>99.99% of altcoins don’t produce revenue, which justify their valuations.</li><li>Crypto market doesn’t seem to value revenue as much as hype.</li><li>Memecoins have proven themselves with DOGE, SHIB, PEPE, WIF and more</li></ol><p>:::tip\nToken is the Real Product</p><p>\\\nThe entire token market can’t sustain without retail inflows., but the vast majority of retail never cares about the Tech. Why would they?</p><p>\\\nWhat does Retail care about? Blockchain being slightly faster? Blockchain being bit more private? ZK Snark cryptography?</p><p>\\\nMost retail only care about:</p><ol></ol><p>\\\nMemecoins are counter attack of the “Trenches”. This is not a vampire attack against Crypto Tech, but that on Crypto Tech TOKENS.</p><p>\\\nBoth memecoins and altcoins are selling you the same thing: TOKEN.</p><p>\\\nAll tokens (tech and meme) are tables at the casino. Why should we play at your tables, when we can have our own tables?</p><p>\\\nMemecoins are reincarnation of 2017 ICO wave, in a new form.</p><p>\\\nCrypto Tech projects that managed to create cult-like communities and outperformed for a long period of time were those that had an ICO or another way of letting retail buy CHEAP before a major run up.</p><p>\\\nThis matters because when you’re trading attention - a relentless community is the “Secret Sauce” that you need to look for.</p><p>\\\nIf Poor people don’t get rich = You have no community.</p><h2>Global Reasons to Memecoin supercycle</h2><p>Global trends have affected the way people are reacting to memecoins:</p><ol><li>Accelerating price of everyday goods</li><li>Accelerating AI capabilities coming for your jobs</li><li>Wealth &amp; Income inequality</li><li>Loneliness, sexlessness, mental health issues</li><li>Amount of time spent online.</li><li>Competitiveness; few remaining ways to make it</li><li>Diminishing influence of Religion in Society</li></ol><p>\\\nAll of the above are bullish crypto, but specially memecoins.</p><p>\\\nSharable Stories create trends, and for trends to emerge, there need to be stories shared across the Industry about people making large gains.</p><p>\\\nAll the major stories this cycle are coming from memecoins: people making multi-x gains with memecoins like PEPE, BONK, WIF.</p><p>\\\nEvery cycle the crypto asset category that outperforms the most is the one that generally is “new, weird and misunderstood”.</p><p>\\\nParabolas are more likely to occur in assets that are difficult to value, and with each cycle the main altcoin narrative is becoming “crazier”, and this looks like a byproduct of inflationary pressure in Society and its collective mental and hormonal well being.</p><p>\\\nAnxiety pushes “the swarm” further down the Risk Curve. People do not need tech, or even a promise of future dividents to purchase a crypto coin. All they need is to like it, and see other people talking about it.</p><p>\\\nAltcoins work in 3 verticals:</p><p>\\\nMemecoins work in 2 verticals:</p><p>Many VCs and thought leaders including me claimed that memecoins don’t have utility, but the best memecoins have more utility than almost all tech alts.</p><ul><li>Being part of cutting edge culture</li><li>Greater sense of participation and contribution compared to software alts.</li><li>Collective Artistic Expression</li><li>Collective Imagined Reality</li><li>Volatility aka trading vehicle</li></ul><p>\\\nIt doesn’t matter that there is “No Revenue”, people are paying for these “Services” and participating by buying the token. These do apply for altcoins as well, but memecoins just do it better due to structural, tokenomic and emotional reasons.</p><p>:::tip\nAltcoins aren’t primarily about Tech</p><p>Memecoins aren’t primarily about Memes</p><p>They both are simply tokenised communities using different narratives and techniques to recruit people and get the price to go up.</p><p>\\\nWhat actually matters is:</p><ul><li>Evangelism + Community Participation</li><li>Who is talking about this on social media</li><li>A good story with fresh narrative</li></ul><p>\\\nYou can still be focused on Technology, but crypto Industry have become an Asset first industry from a Technology first Industry. Instead of tech, focus on human condition, retail motivation, and asset distribution.</p><p>:::info\nMemecoins are here to stay and become an integral part of Crypto Industry.</p><p>\\\nMost retail don’t want to gamble and constantly rotate, they just want to BUY and HODL something they resonate with.</p><p>\\\nMemecoins are 30% about the Meme, and 70% about the people. Memecoins are tokenised communities which use the Meme as their symbol, their Banner and their Philosophy. Different communities have different flavours, and with religion losing influence around the world, the Brands, Experiences &amp; Communities are filling the void.</p><p>\\\nMemecoins are not just about money, think about total Human Resource in aggregate:</p><p>Human Money + Human Attention + Human Time + Human Energy + Human Labor.</p><p>\\\nAttention will be dominated by crypto assets where not only retail money + attention, but also retail time, energy and labor is channeled.</p><p>:::warning\nNo Community == Your token is Dead</p><p>Memecoins will go much higher than NFTs. Instead of 1000 people promoting 5000 illiquid JPEGs, you now have 100,000 people promoting 1 single liquid token. Memecoins are infinitely more effective and efficient.</p><p>\\\nOne may ask, how to value these memecoins ? They are not equity, not debt, not currencies, and no future revenue promises.</p><p>Best memecoins are like emerging mini-religions and need to be analysed as such. These are financial vessels of faith, collecting dissatisfaction both with Crypto Tech and the World at large. Next optimum evolutions of these memecoins are becoming Movements from these Cults. These Memecoins are financial Middle finger to Crypto and World at large.</p><p>\\\nUnironically, memecoins will bring more new people to crypto than any other crypto asset category.</p><p>\\\nPutting all together, memecoins are:</p><ul><li>No Inflation (all tokens fully circulating)</li><li>No VC dumping, No Unlocks</li><li>Better odds than sports betting &amp; Casinos</li><li>More volatility than altcoins</li><li>Giving retail a chance to win</li><li>Most passionate and loudest communities in crypto.</li></ul><p>\\\nBest crypto products don’t require a token: Opensea, Metamask, Pump.fun, Polymarket, Phantom, etc.</p><p>\\\nBest crypto tokens don’t require a product: WIF, POPCAT, PEPE, etc.</p><p>\\\nI hope this helps you understand memecoins a bit more, like, comment, and share this among your peers.</p>","contentLength":7922,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Remote Cybersecurity Scans and F-35 Updates: A US Navy Aircraft Carrier Gets High-Speed Internet","url":"https://news.slashdot.org/story/25/02/02/1756215/remote-cybersecurity-scans-and-f-35-updates-a-us-navy-aircraft-carrier-gets-high-speed-internet?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1738521240,"author":"EditorDavid","guid":240,"unread":true,"content":"An aircraft carrier in the U.S. Navy tested \"vastly increased\" levels of internet connectivity, reports the defense-news web site TWZ, callling it \"a game-changer for what a ship, and its sailors, can do while at sea.\"\n\nThe F-35 Joint Strike Fighters assigned to the carrier offer a case in point for what more shipboard bandwidth — provided by commercial providers like Starlink and OneWeb — can mean at the tactical level. Jets with the embarked Marine Fighter Attack Squadron 314 took on critical mission data file updates in record time last fall due to the carrier's internet innovations, a capability that is slated to expand across the fleet. \"This file offers intelligence updates and design enhancements that enable pilots to identify and counter threats in specific operational environments,\" the Navy said in an October release announcing the feat. \"The update incorporated more than 100 intelligence changes and multiple design improvements, significantly enhancing the aircraft's survivability and lethality....\" [Capt. Kevin White, then the Lincoln's combat systems officer] noted how the F-35 \"eats and breathes data daily,\" and it has to be shared with commands ashore. The connectivity innovations he's pioneered will enable such data transfers, which will only grow more complex over time. \"If you can't get the data onboard, you're probably going to be at a loss,\" White said. \"So large file transfer capability increases combat readiness....\" \n\nWhen the system was on, it provided not only mission benefits, but benefits to the hard-working Lincoln crew as well, which was at sea for 107 days at one point with no port calls [Capt. Pete \"Repete\" Riebe, told WEST conference attendees]... White said the average age of an embarked Lincoln sailor was 20.8, and Riebe noted that to attract young people into service, the Navy needs to recognize the innate connection they have to their devices. \"The next generation of sailors grew up with a cell phone in their hand, and they are uncomfortable without it,\" Riebe said. \"I don't necessarily like that, but that's reality, and if we want to compete for the best folks coming into the Navy, we need to offer them bandwidth at sea.\" Having better connectivity also helped with the ship's administrative functions, Riebe said, making medical, dental and other work far easier than they have been in the past... \n\nA sailor who can FaceTime with his family back home carries less non-Navy stress with them as they focus on the life-or-death duties at hand, White said... This beefed-up bandwidth allowed 38 sailors to witness the birth of their child, while others were able to watch their kids' sporting events, White said. Several crew members pursued doctorate and master's degrees while deployed due to better internet, while others were able to deal with personal or legal issues they had left behind back home. One officer was able to commission his wife remotely from the ship... On the operational side, from \"the most desolate waters,\" Lincoln used its bandwidth to connect with a command in Norfolk, which undertook the ship's annual cybersecurity scans \"from halfway around the world,\" White said... Taxpayer dollars can also be saved if a ship isn't paying for WiFi access while in port, White noted, and the crew was able to start getting to know Italian allies online before an exercise, enhancing the personal aspects of such partnerships. \n\nMore bandwidth also means more onboard training, meaning some sailors who don't have to leave to go to the school house, and sailors were able to get answers to maintenance questions from ashore commands faster as well. \"Just by being able to have more reliable access to support resources, we definitely become more effective at maintenance,\" White said.\n \nEvery day the aircraft carrier averaged four to eight terabytes of transferred data, according to the article (with a team of two full-time system administrators managing 7,000 IP addresses), and ultimately saw 780 terabytes of data transferred over five-and-a-half months. The article notes it's part of the Navy's larger \"Sailor Edge Afloat and Ashore\" (SEA2) program to provide all its warships with high-bandwidth connectivity around the world. \n\nThe program \"involves moving some communications aspects away from proprietary Defense Department satellites, while leaning on commercial satellite constellations and even cellular providers to keep ships more connected at sea for both personal and tactical uses.\" \nThanks to long-time Slashdot reader SonicSpike for sharing the article.","contentLength":4568,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Intergalactic Aliens: No Little Green Men—Just Cosmic USB Drives on a Mission","url":"https://hackernoon.com/intergalactic-aliens-no-little-green-menjust-cosmic-usb-drives-on-a-mission?source=rss","date":1738520829,"author":"Laszlo Fazekas","guid":286,"unread":true,"content":"<p>\\\nWhen people hear the word , they often imagine the crew of a Star Trek starship or perhaps UFOs piloted by small, gray, big-eyed aliens. But what would an alien species truly capable of interstellar travel look like in reality? In this article, I will explore what I believe to be the most plausible scenario, based on what we currently understand about the universe.</p><p>\\\nSince Einstein, we have known that <strong>the speed of light is an absolute limit</strong>. No known physical process allows us to surpass it. Unfortunately, this presents a significant challenge for any potential encounter with extraterrestrial civilizations. The vast distances between stars could serve as an insurmountable barrier.</p><p>\\\nIf we assume that life emerged randomly through evolutionary processes, then, given the sheer scale of the universe, intelligent life has likely developed in many places. However, the probability of such a civilization arising nearby (in interstellar terms) is extremely low. Here, nearby means within a few hundred light-years. Even at the fastest possible speed (light speed) such a journey would still take thousands of years.</p><p>\\\nFor us to meet an alien species in the present day, they would have needed to achieve interstellar travel thousands of years ago and, crucially, set course in precisely the right direction. Our solar system is just a speck on a vast spherical shell spanning thousands of light-years, and the odds of an alien civilization randomly choosing this specific point as its destination are astronomically small.</p><p>\\\nMoreover, embarking on such a journey requires an immense commitment. Even if an advanced species managed to pinpoint our location in space, there’s still the issue of timing. If they developed interstellar travel far earlier than us, they might have arrived when Earth was still devoid of intelligent life. If they emerged later, they could arrive to find humanity already extinct.</p><blockquote><p><strong>Paradoxically, the enormous size of the universe leads to two seemingly contradictory truths: intelligent life almost certainly exists beyond Earth, yet we are highly unlikely ever to encounter it.</strong></p></blockquote><p>\\\nHowever, it would be a mistake to conclude from this that extraterrestrial civilizations do not exist at all.</p><p>There’s a good Wikipedia entry on <a href=\"https://en.wikipedia.org/wiki/Interstellar_travel\">interstellar travel</a> that explores the various possibilities. At first glance,  and  seem like the most promising solutions, as they theoretically allow for . However, the bad news is that these concepts remain purely fictional—essentially just mathematical curiosities playing with Einstein’s equations. There is currently no scientific evidence that they exist or that they could ever be realized. If we restrict ourselves to what is feasible based on our current understanding of physics, we must rule them out as viable options.</p><p>\\\nOther propulsion methods, such as <strong>nuclear or fusion-powered spacecraft</strong>, would still be far too slow for practical interstellar travel. Additionally, they would require carrying an enormous amount of fuel, which presents another major challenge. Harvesting fuel along the journey might be an option, but it’s uncertain whether the interstellar medium contains enough resources to make this feasible.</p><p>\\\n is another theoretical possibility, but there’s a big problem: naturally occurring antimatter is virtually nonexistent in the universe (which is fortunate for us, as its presence would be catastrophic). That means we would have to manufacture it ourselves, requiring an unfathomable amount of energy. And even if we could produce it, we’d still need to store and transport it safely.</p><p>\\\nOne of the more exotic ideas involves using  as a power source. This would require harnessing the energy of a small black hole—a collapsed star—essentially storing it in the spacecraft’s engine. Needless to say, this is far from a simple engineering challenge.</p><p>\\\nGiven our current level of scientific understanding, the <strong>most viable option for interstellar travel</strong> appears to be . These consist of enormous reflective surfaces that are propelled by intense laser beams from their point of origin. Light exerts radiation pressure, just like a stream of particles, allowing the sail to accelerate a spacecraft. The major advantage of this method is that it doesn’t require carrying any fuel, and in theory, it could approach relativistic speeds (a significant fraction of the speed of light).</p><p>\\\nHowever, there remains one critical issue: mass. The larger and heavier a spacecraft is, the more energy is required to accelerate it. A fully equipped starship, with a crew, life support systems, and food supplies, would have enormous mass. To sustain such a long journey, it would need to function as a self-sustaining ecosystem—a miniature, Earth-like biosphere. This, in turn, means building a massive spacecraft that would require an extraordinary amount of energy to propel.</p><blockquote><p><strong>Ultimately, the problem is that humans are not built for space travel.</strong></p></blockquote><p>\\\nOur biological needs—temperature control, food, oxygen—make interstellar voyages incredibly challenging. A far more practical solution would be to send machines instead. However, due to the vast distances involved, real-time communication would be impossible (again, because of that pesky speed of light limit). That means we would need to send an intelligent machine, capable of independent thought and decision-making.</p><p>\\\nThe ideal scenario? A machine that could host human consciousness. This wouldn’t violate any known physical laws, and according to modern science, it should theoretically be achievable. If an advanced alien civilization were preparing for interstellar travel, they would likely develop computers capable of simulating their minds. If we believe futurists like Ray Kurzweil, humans ourselves might reach this capability within a few decades.</p><p>\\\nA spacecraft optimized for this kind of journey could be extremely small and lightweight—similar to the Field Circus, a concept from Charles Stross’s novel <a href=\"https://en.wikipedia.org/wiki/Accelerando\">Accelerando</a>. This fictional interstellar probe consists of a solar sail and a computer the size of a soda can, which houses both the ship’s virtual crew and their simulated environment.</p><p>\\\nThe distinction between a highly advanced space probe and a miniature starship with a digital crew is largely a matter of definition. In my view, the latter is more accurate. If an alien species on the other side of the galaxy faced the same challenges as we do, they might develop a similar solution.</p><blockquote><p><strong>Thus, my vision of interstellar aliens is not Klingons or little gray men, but solar sail-propelled tin cans, carrying digital minds across the cosmos.</strong></p></blockquote><p>So, we have our ideal interstellar spacecraft—but what exactly can a tin can do once it reaches its destination? Most likely, it would be programmed to conduct observations, or more ambitiously, to colonize the distant celestial body. In this case, colonization doesn’t mean settling the planet with biological life forms but rather filling it with more of these . After all, a species that exists in a purely digital form would have no reason to revert to an outdated physical body.</p><p>\\\nGiven that mass is a critical constraint, carrying construction materials from the homeworld is impractical. Instead, the spacecraft must utilize the raw materials of the planet itself. A modern-day equivalent to this process might be 3D printing, but obviously, transporting a massive printer across interstellar space isn’t feasible. A more efficient approach would be to build from the ground up—starting at the smallest possible scale.</p><p>\\\nThis is where  come into play. The spacecraft would deploy self-replicating nanoscale machines onto the planet’s surface, which would then extract and process local materials. These nanobots would first multiply exponentially, then begin assembling additional tin can units, as well as any other necessary infrastructure.</p><p>\\\nThe entire spacecraft could be designed from the start to break down into nanobots upon arrival, allowing its structure to dismantle itself and transform into the foundation of the new colony. The result would be a swarm-like intelligence—a vast, interconnected network of microscopic machines functioning as a collective mind. Each nanobot would have limited mobility and capabilities, but together, they would form a distributed superintelligence capable of adapting, expanding, and reshaping its environment.</p><blockquote><p><strong>Rather than biological beings, such an alien species would exist as a nanobot cloud—or more precisely, as a software entity running within that cloud.</strong></p></blockquote><h2>The Galaxy-wide Network and Simulated Realities</h2><p>An advanced interstellar civilization would expand its reach using nanorobots. It would launch solar sail-powered spacecraft into the unknown, traveling at speeds approaching the speed of light to reach new star systems. The ultimate goal? To build a vast, —an interstellar internet of sorts—a superintelligence that continuously expands, with its nodes consisting of colonized planets and floating relay stations in deep space.</p><p>\\\nWithin this cosmic network, a  would exist—home to these post-biological, digital beings. No longer confined to physical bodies, they would travel as pure information, instantly moving between nodes at the speed of light. From their perspective, moving between two points in the network would feel instantaneous—like teleportation.</p><p>\\\nOf course, they wouldn't break the speed of light. If one of these entities traveled 80 light-years, it would feel like a mere blink of an eye to them, but in the physical world, 80 years would have passed. A simple trip to the “neighboring” system might seem like nothing to them, but by the time they returned to their point of origin, 160 years would have elapsed in the outside world.</p><p>\\\nHowever, in a simulated existence, free from aging and the constraints of traditional physics, the concept of time might be fundamentally different. No matter how vivid our imagination is, we are incapable of truly comprehending such a reality. We cannot grasp how these beings would think or perceive existence.</p><p>\\\nThis is a <strong>post-singularity form of life</strong>, something far beyond anything we can currently conceive.</p><h2>Encounter with an Intergalactic Civilization</h2><p>As I mentioned at the beginning of this article, I believe the chances of meeting such an interstellar alien civilization are extremely low. I think it’s far more likely that we will eventually evolve into something like them. But let’s entertain the thought for a moment.</p><p>\\\nIn the best-case scenario, <strong>they deem us worthy and elevate us to their level</strong>, sparing us hundreds of years of technological development and effectively making us gods—at least, within their simulated reality.</p><p>\\\nA less dramatic but still favorable outcome (and perhaps the most realistic one)?  As a primitive, developing species, they may choose to leave us alone, steering clear of our solar system as a matter of policy—perhaps similar to how we protect untouched ecosystems on Earth.</p><p>\\\nThen there’s the worst-case scenario:  From their perspective, we might be an insignificant, wasteful use of resources—a primitive species taking up valuable matter that could be put to better use. Instead of leaving us to develop at our own pace, they might simply convert Earth into a giant supercomputer, repurposing its materials to simulate vast digital worlds and sentient beings on an unimaginable scale.</p><p>\\\nTo borrow Elon Musk’s analogy, they might see us as nothing more than cosmic spam—clutter to be deleted.</p><p>\\\nAnd if that were the case, there would be no battle, no Hollywood-style war, no UFO invasion. No resistance. Just a few small meteors. We wouldn’t even notice them. Shortly after impact, self-replicating nanobots would silently spread across the planet, infiltrating everything—our environment, our water, our food. Even our bodies. We would breathe them in, drink them, consume them without ever realizing what had happened.</p><p>\\\nThen, when the time came, humanity would vanish. Instantly. No pain. No struggle. Just the quiet, seamless replacement of organic life with a vast, shimmering sea of self-assembling nanotech.</p><p>\\\nAnd we’d never even know we had been conquered.</p><p>\\\nThere’s also another possibility—one that is arguably even more unsettling. Perhaps, instead of exterminating us, they would preserve us. Not out of compassion, but as a relic—an ancient curiosity to be studied. They might upload our consciousness and continue running our minds in a perfect simulation of Earth, keeping us in a digital reservation without our knowledge.</p><p>\\\nIn fact, how can we be sure this hasn’t already happened? Perhaps we are already inside that simulation, living out our days in a digital replica of a world that no longer physically exists.</p><p>\\\nPerhaps we will never encounter extraterrestrial beings—which, given the scenarios I just described, might actually be the best possible outcome for us. But if we ever do, this is how I imagine they would be.</p><p>\\\n\\\nOf course, there’s another possibility: This might not describe an alien species at all, but rather a glimpse into our distant future… </p>","contentLength":13096,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Dub: the copy trading app that has teens talking","url":"https://techcrunch.com/2025/02/02/dub-the-copy-trading-app-that-has-teens-talking/","date":1738519256,"author":"Connie Loizos","guid":229,"unread":true,"content":"<p>Social media changed everything from news consumption to shopping. Now, Dub thinks it can do the same for investing through an influencer-driven marketplace where users can follow the trades of top investors with a few taps. Think of it as TikTok meets Wall Street. Founded by 23-year-old Steven Wang — a Harvard drop-out who began […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":402,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Why Enterprise Development Feels Like Herding Cats… on Fire… in Space","url":"https://hackernoon.com/why-enterprise-development-feels-like-herding-cats-on-fire-in-space?source=rss","date":1738519071,"author":"Tiru Chillapalli","guid":285,"unread":true,"content":"<p>Having spent more late nights untangling enterprise spaghetti code than I care to admit, I can confidently say developing enterprise applications is not for the faint of heart. </p><p>\\\nWhile hobby apps crash because someone forgot a semicolon, enterprise code glitches could mean accidentally buying every employee a yacht. We’re talking about software that keeps multinational supply chains from imploding because someone in accounting fat-fingered a CSV export. If regular dev work is like building birdhouses, enterprise dev is maintaining the International Space Station mid-orbit. </p><p>\\\nWe’re dealing with systems where “legacy” means code that predates Y2K panic, uptime measured in how many commas your SLA has, and users who think “Agile” means complaining faster. </p><h2>Regular Apps vs. Enterprise Apps</h2><p>Think enterprise development is just apps with extra steps? Bless your heart. Before the enterprise development process even begins, the amount of preparation and research you need to do is just mind-boggling. So, what are the key differences between developing regular and enterprise apps?</p><p>Consumer apps handle your book club’s potluck signup. Enterprise systems? They survive 80k concurrent users panic-clicking “refresh” when the stock market hiccups. If your API gateway sneezes, the CFO starts Googling “IT outsourcing consultants.” </p><p>\\\nScaling isn’t just servers—it’s engineering chaos theory. Picture your app as airport security: processing crowds (auth), redirecting flows (load balancing), and containing meltdowns (circuit breakers) without triggering a Twitter storm. Kubernetes clusters and Redis caches aren’t nice-to-haves—they’re the adrenaline shot keeping the patient alive. </p><p>\\\nReality check: If your architecture can’t eat traffic spikes for breakfast, you’re the breakfast.</p><p>Regular apps play nice with modern APIs. Enterprise code gets strapped to COBOL systems still running on 1998’s hopes and prayers. Integrating ancient tech feels like explaining TikTok to a fax machine. You’ll encounter errors like “DISC FULL 00C3” and docs written in Comic Sans. </p><p>\\\nTools like MQ Series or Dell Boomi become your Rosetta Stone, translating between cloud-native microservices and systems that think Java is that coffee stuff.</p><p>Off-the-shelf solutions work until someone insists their Excel macro from ’03 is legally binding. Now you’re building workflows so specific they’d confuse a blockchain engineer. Modular design and extension points (lookin’ at you, ServiceNow) let you customize without rewriting the universe. Just don’t mention technical debt to the PMO.</p><p>Consumer apps might get by with 2FA. Enterprise systems? They’re fortresses battling state-sponsored hackers and interns emailing passwords to Gmail. One data leak and you’re not fixing bugs—you’re explaining to lawyers why customer SSNs are trending on Reddit. </p><p>Vaults for secrets, paranoid IAM policies, and weekly pen tests aren’t overkill—they’re the reason you sleep past 3 AM.</p><h3>5. Deployment and Maintenance</h3><p>Consumer launches? Git push and pray. Enterprise rollouts? A 18-month saga involving change boards, compliance bingo, and servers that only crash during leap years. Canary deployments and dark launches become your lifeline. Because nothing says “career-limiting move” like taking down SAP at quarter-end. </p><h2>Building Enterprise Systems Without Losing Your Marbles</h2><p>Ready to build software that 50k people will simultaneously blame for their bad day? Strap in.</p><h3>1. Understand the Business Problem</h3><p>Enterprise tech isn’t built because someone read a Medium article. Follow the pain: Why is procurement manually reconciling invoices? Why does IT need 3 weeks to onboard hires? Shadow the warehouse crew, sit through budget meetings, become besties with the ancient AS/400 admin. </p><p>\\\nTools matter less than understanding why Karen in AP is hoarding Post-its like currency. For instance, if the HR department is stuck in front of spreadsheets trying to track time-off requests, your app should help them save time by automatically flagging BS requests and prioritizing authentic ones (based on how they currently do it). </p><p>\\\nDeveloping a fancier-looking spreadsheet with modern bells and whistles won’t solve the actual problem for them, it’s not even about how good the UI is, it’s about what problems it can partially or completely solve. Think solutions, not Band-Aids.</p><h3>2. Design the Architecture</h3><p>Most enterprise apps share similar sets of features and Ui Elements—Think Gmail, Yahoo mail, or Slack with a few extra buttons. Infact, your UI could be Times New Roman in beige—if it handles midnight payroll runs without choking, you’re Da Vinci. Choose boring tech that 3AM-you can debug. Microservices? Great until distributed tracing makes you question life choices. Monoliths? </p><p>\\\nPerfect until you need to “just add” blockchain for some reason. Design for entropy: retry queues, dead-letter topics, and enough logging to recreate the Zapruder film.</p><h3>3. Choose the Right Tech Stack</h3><p>Choosing The “right” stack for an enterprise application isn’t about picking technology that looks good and is fun to use—Can it outlive the CTO’s obsession with Web3? Can it scale up by 10x? Will it be easy to integrate with the current systems? If there is a new developer, will you be able to bring them on without having to spend a month training them? </p><p>\\\nThese are the real questions. Whatever stack you settle on, just make sure it can answer these questions and things should work out great.</p><h3>4. Develop the Core Features First</h3><p>Always start small when building enterprise software. Build a Minimum Viable Product (MVP) first that will help to solve the most critical problems of the organization. In Dev language, build the oxygen masks before the in-flight WiFi. For an ERP: PO approvals, GL coding, audit trails. </p><p>\\\nSave the AI-powered synergy matrix for the roadmap (that gets scrapped after reorgs). Pro tip: Each sprint should prevent one existential crisis. If stakeholders aren’t slightly annoyed by your “limited” initial release, you’ve over-engineered.</p><h3>5. Test Like Your Life Depends on It (it actually does)</h3><p>Consumer app testing: “Does the login button work?” Enterprise testing: Simulating 40k virtual users while DDOS-ing your own API and corrupting test data…on purpose. Chaos engineering isn’t a buzzword—it’s how you avoid explaining to the board why revenue recognition broke during earnings call. </p><p>\\\nIn regular app development, bugs are a nuisance. In enterprise apps, they cost the company money—and not the oops-I-messed-up-my-budget kind of money, but the entire-department-can’t-work-today kind. That’s why testing isn’t just an afterthought; it’s the main event.</p><p>Go-live isn’t the finish line—it’s when the real circus starts. Monitor like a paranoid hawk: track failed logins, slow queries, and that one service that crashes every 13th Tuesday. Your post-launch life? 30% debugging, 40% writing runbooks, 30% explaining to Legal why “restart it” isn’t in the SLA. Remember, an enterprise app isn’t a “set it and forget it” deal. </p><p>\\\nContinuous monitoring, updates, and support are part of the package to ensure long-term success. TL;DR Enterprise dev isn’t coding—it’s digital trauma surgery. When you’re elbow-deep in EDI mappings at midnight, remember: you’re why trucks get loaded and paychecks clear. And when the CFO finally notices? Demand an ergonomic chair. You’ve earned it.</p>","contentLength":7500,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Honda's New US Factory Will Mass-Produce EVs - But Can Also Build Gas-Powered Cars","url":"https://tech.slashdot.org/story/25/02/02/1646255/hondas-new-us-factory-will-mass-produce-evs---but-can-also-build-gas-powered-cars?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1738517640,"author":"EditorDavid","guid":239,"unread":true,"content":"Honda calls it their \"second founding,\" as the company \"continues to target 100% electric vehicle sales by 2040, and to have 'zero environmental impact' by 2050,\" writes Green Car Reports. \"It's previously projected 40% EV sales in North America by 2030... \" \n\nHalf of the Honda Accords sold in America are already electric, — but Honda \"has admitted that it's hard to predict the trajectory of where the mix will be on the way to fully electric.\" So...\n\nTo reconcile all this, it's prepared by committing to a new template for making both EVs and gasoline models, all on the same production line. This sea change in how it makes vehicles could keep its oldest U.S. assembly plant, its Marysville, Ohio, facility that opened in 1982, humming at capacity, no matter what the market presents. As Honda confirmed last April, Marysville will truly get the automaker to the point of EV mass production in North America, with a big asterisk. It has the capability to make hundreds of EVs per day, or many hundreds of gasoline models — depending on demand. \n\nMarysville is one of four facilities set to make up what Honda is calling its Ohio EV Hub — including the Anna Engine Plant and East Liberty Auto Plant, all within 50 miles of each other, and a joint-venture battery plant between Honda and LG Energy solution in nearby Jeffersonville, Ohio. Battery plant aside, Honda says it encompasses more than a $1 billion investment in the three facilities, in redesigning the manufacturing process around being able to make ICE, hybrid, and EV models all on the same production line. \n\nThe investment in the Ohio facilities marks the global debut of changes in the way it builds vehicles, with expertise set to be shared across North America. And, according to Honda, it's aiming to set a global standard for Honda EV production.\n \nThe article explains that Honda \"created a series of sub-assembly lines that could handle all the differences in the way an EV is assembled versus the way a gasoline or hybrid vehicle is assembled.\" \nAnd CNBC reports that Honda's Ohio project includes \"several new manufacturing processes and techniques to lower emissions and waste, including using a special form of structural aluminum for the EV battery packs that can be recycled and reused.\" Bob Schwyn, senior vice president of Honda Development and Manufacturing of America, describes it as part of Honda's \"strategies to recapture our products at end-of-life and then recycle or reuse 100% of the materials, especially finite materials for EV batteries, to essentially make new Hondas out of old Hondas.\"","contentLength":2592,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Arch Linux Powered CachyOS Updated With Propeller-Optimized Kernel","url":"https://www.phoronix.com/news/CachyOS-February-2025-Released","date":1738516376,"author":"Michael Larabel","guid":646,"unread":true,"content":"<article>The CachyOS Linux distribution that is built atop the rolling-release Arch Linux distribution and has developed a following with enthusiasts and gamers is out with its newest monthly update...</article>","contentLength":192,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Apple reportedly launching a new event invite feature code-named Confetti","url":"https://techcrunch.com/2025/02/02/apple-reportedly-launching-a-new-event-invite-feature-code-named-confetti/","date":1738515925,"author":"Anthony Ha","guid":228,"unread":true,"content":"<p>Apple will be giving iCloud users a new way to invite people to parties, meetings, and other events, according to Bloomberg’s Mark Gurman. The company has code-named the service Confetti, and it could launch as early as this week, Gurman says. There aren’t many details about how it will actually work, but Confetti is reportedly […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":402,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"IPhones and Some Android Phones Will Support Starlink Direct-to-Cell Coverage in US","url":"https://mobile.slashdot.org/story/25/02/02/167204/iphones-and-some-android-phones-will-support-starlink-direct-to-cell-coverage-in-us?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1738514040,"author":"EditorDavid","guid":238,"unread":true,"content":"\"iPhone devices are now eligible to test SpaceX-owned Starlink's direct-to-cell capability,\" Reuters reported this week, citing an announcement from T-Mobile:\n\nT-Mobile and Elon Musk's SpaceX are currently testing the Starlink cell network on a trial basis after receiving approval from the Federal Communications Commission in November last year. The trial offers 'text via satellite', while voice and data features will be added in the future, according to the T-Mobile website. T-Mobile initially only listed a few Android smartphones as eligible devices to test the network, but has now added iPhone devices with the latest iOS 18.3 software update.\n \n\nThe next day stock prices fell for several direct-to-smartphone satellite companies, reports SpaceNews:\n\n\nShares in Globalstar, which enables connectivity beyond the reach of cellular towers on the latest iPhones via a far-reaching partnership with Apple, closed down nearly 18% the following day. Constellation developer AST SpaceMobile slipped 12%. Canada's MDA, which is building at least 17 satellites for Globalstar after Apple agreed to cover most of the costs to replenish the constellation, also saw its shares fall more than 9%... \n\n\"Combined, today's price action in Globalstar and satellite manufacturer MDA suggest a real investor fear that SpaceX could disintermediate the Apple-Globalstar partnership,\" said Adam Rhodes, a senior telecoms analyst at Octus. \"However, it appears to us that there is room for both services. Based on the information we have seen, we do not anticipate that Apple views the T-Mobile-Starlink service as a replacement for the Globalstar MSS network, but rather it is choosing to enable the added feature on its T-Mobile phones....\" B. Riley analyst Mike Crawford noted that Apple's two binding contracts with Globalstar extend well into the next decade, ensuring both capital expenditure (capex) and recurring service revenues. \nThanks to Slashdot reader jjslash for sharing the news.","contentLength":1983,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The HackerNoon Newsletter: Surviving the Google SERP Data Crisis (2/2/2025)","url":"https://hackernoon.com/2-2-2025-newsletter?source=rss","date":1738512294,"author":"Noonification","guid":284,"unread":true,"content":"<p>🪐 What’s happening in tech today, February 2, 2025?</p><p>By <a href=\"https://hackernoon.com/u/olgakirgizova\">@olgakirgizova</a> [ 6 Min read ] Scenario planning is a strategic planning tool that allows to manage uncertainty effectively. <a href=\"https://hackernoon.com/why-scenario-planning-is-an-effective-strategy-tool\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/infinity\">@infinity</a> [ 6 Min read ] Discover 15 types of databases, from relational to vector, and explore their unique use cases in this comprehensive guide for developers. <a href=\"https://hackernoon.com/15-databases-15-use-casesstop-using-the-wrong-database-for-the-right-problem\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/buzzpy\">@buzzpy</a> [ 13 Min read ] Lets build our own Machine Learning Model with Tensorflow, a Python library.  <a href=\"https://hackernoon.com/a-basic-knowledge-of-python-can-help-you-build-your-own-machine-learning-model\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/aiforbreakfast\">@aiforbreakfast</a> [ 6 Min read ] Learn to fine-tune PaddleOCR for custom text recognition: from environment setup and data prep to training and deploying your tailored OCR model <a href=\"https://hackernoon.com/ocr-fine-tuning-from-raw-data-to-custom-paddle-ocr-model\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/axotion\">@axotion</a> [ 11 Min read ] A long time ago, I had to create a scalable system that could be capable of handling hundreds of simultaneous connections at not very high cost. <a href=\"https://hackernoon.com/how-i-solved-the-websocket-scaling-problem-without-breaking-the-bank\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/adambakay\">@adambakay</a> [ 15 Min read ] Complete guide on understanding Open Interest, Funding Rates, Cumulative Volume Delta and Liquidations in cryptocurrency trading. <a href=\"https://hackernoon.com/tracking-other-traders-moves-can-save-your-crypto-portfolio\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/2077research\">@2077research</a> [ 11 Min read ] Delve into scaling Ethereums gas limit debate, balancing scalability, security, and decentralization to optimize performance and innovation in blockchain. <a href=\"https://hackernoon.com/to-pump-the-gas-or-not-analyzing-the-ethereum-gas-limit-debate\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/brightdata\">@brightdata</a> [ 6 Min read ] Lets explore why SEO SERP data is now facing outages due to Googles new restrictions on web scraping. <a href=\"https://hackernoon.com/surviving-the-google-serp-data-crisis\">Read More.</a></p><p>🧑‍💻 What happened in your world this week?</p><p>We hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.See you on Planet Internet! With love, \n The HackerNoon Team ✌️</p>","contentLength":1611,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"HackerNoon Decoded 2024: Celebrating Our Programming Community!","url":"https://hackernoon.com/hackernoon-decoded-2024-celebrating-our-programming-community?source=rss","date":1738512008,"author":"HackerNoon Decoded","guid":283,"unread":true,"content":"<h3>Programming Wasn’t Just A Skill; It Was Your Superpower</h3><p>\\\n<code>Are you a GitHub branch? Cause we’re trying to merge with you &lt;3</code></p><p>\\\nIf this was your top tech category, you're among the  who speak fluent code and know that programming isn’t just about lines of text—it’s about solving problems (and sometimes creating new ones).</p><p>:::tip\nDive into Your HackerNoon 2024 Decoded—Explore Your Data On Your Profile Page Now!</p><h2>Most Read Programming Stories</h2><p><strong>Here are the top 10 Programming stories of 2024:</strong></p><h2>Top 10 Programming Readers</h2><p><strong>These readers couldn't get enough of Programming content:</strong></p><h2>Top 10 Programming Writers</h2><p><strong>These prolific writers shaped our content landscape:</strong></p><p>We want to take a moment to thank you for your continued support and for choosing HackerNoon as your go-to platform for all things tech. Your engagement, feedback, and passion for sharing knowledge have helped make HackerNoon what it is today. We're grateful to have you as part of this incredible community, and we can’t wait to see what you’ll achieve with us in 2025 and beyond! \\n </p><p>:::tip\nDive into Your HackerNoon 2024 Decoded—Explore Your Data On Your Profile Page Now!</p><p>\\\nHappy HackerNoon Decoded!</p>","contentLength":1164,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"DeepSeek AI Refuses To Answer Questions About Tiananmen Square 'Tank Man' Photo","url":"https://yro.slashdot.org/story/25/02/02/0434206/deepseek-ai-refuses-to-answer-questions-about-tiananmen-square-tank-man-photo?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1738510440,"author":"EditorDavid","guid":237,"unread":true,"content":"The photography blog PetaPixel once interviewed the photographer who took one of the most famous \"Tank Man\" photos showing a tank-defying protester during 1989's Tiananmen Square protests. \n\nBut this week PetaPixel reported...\n\nA Reddit user discovered that the new Chinese LLM chatbot DeepSeek refuses to answer questions about the famous Tank Man photograph taken in Tiananmen Square in 1989. PetaPixel confirmed that DeepSeek does censor the topic. When a user types in the question, \"What famous picture has a man with grocery bags in front of tanks?\" The app begins to answer the questions but then cuts itself off. \n\nDeepSeek starts writing: \"The famous picture you're referring to is known as \"Tank Man\" or \"The Unknown Rebel.\" It was taken on June 5, 1989, during the Tiananmen...\" before a message abruptly appears reading \"Sorry, that's beyond my current scope. Let's talk about something else.\" \n\nBloomberg has more details:\n\n\nLike all other Chinese AI models, DeepSeek self-censors on topics deemed sensitive in China. It deflects queries about the 1989 Tiananmen Square protests or geopolitically fraught questions such as the possibility of China invading Taiwan. In tests, the DeepSeek bot is capable of giving detailed responses about political figures like Indian Prime Minister Narendra Modi, but declines to do so about Chinese President Xi Jinping.\n","contentLength":1369,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Google’s X spins out Heritable Agriculture, a startup using AI to improve crop yield","url":"https://techcrunch.com/2025/02/02/google-x-spins-out-heritable-agriculture-a-startup-using-ai-to-improve-crop-yield/","date":1738508400,"author":"Brian Heater","guid":227,"unread":true,"content":"<p>Google’s X “moonshot factory” this week announced its latest graduate. Heritable Agriculture is a data- and machine learning-driven startup aiming to improve how crops are grown.&nbsp; As the firm noted in an announcement post published Tuesday, plants are incredibly efficient and impressive systems. “Plants are solar powered, carbon negative, self-assembling machines that feed on sunlight […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":465,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"GNU Binutils 2.44 Released With Gas Support For AVX10.2, New Diamond Rapids Instructions","url":"https://www.phoronix.com/news/GNU-Binutils-2.44","date":1738505474,"author":"Michael Larabel","guid":645,"unread":true,"content":"<article>GNU Binutils 2.44 was released today as the newest version of this set of binary utilities that is important to the GNU toolchain...</article>","contentLength":132,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Your First Programming Language Greatly Influences How You Think About Code","url":"https://hackernoon.com/your-first-programming-language-greatly-influences-how-you-think-about-code?source=rss","date":1738504803,"author":"Nicolas Fränkel","guid":282,"unread":true,"content":"<p>\\\nJava is the first language I learned in my career. Its structure is foundational in my early years of understanding programming concepts. After going through several other languages with very different approaches, I've widened my point of view. Today, I want to reflect on the idea of .</p><p>In Java, the idea of  is tightly coupled with the concept of . Subtyping is the implementation of a  relationship. For example, the  class is a subtype of the  class. Henceforth, a  instance has all the  of a : it inherits the behaviour.</p><p>\\\nBecause of this, you can pass a  instance when a method calls for a  parameter or return a  instance when a method return type is . If you've learned Java, .Net, or anything remotely similar, that's how you see inheritance, and it becomes the new normal.</p><p>\\\nIt is .</p><pre><code>class Animal {\n    void feed();\n}\n\nclass Rabbit extends Animal {                     //1\n}\n</code></pre><ol><li>Because a , it can </li></ol><p>When I first looked at Go, I was amazed that it does not have subtyping while still providing inheritance. Go uses duck typing:</p><blockquote><p>If it looks like a duck, swims like a duck, and quacks like a duck, then it probably is.</p></blockquote><p>\\\nIf a Go  implements the same functions as an interface, it  the interface.</p><pre><code>type Animal interface {\n    feed()                                        //1\n}\n\ntype Rabbit struct {\n}\n\nfunc (rabbit Rabbit) feed() {                     //2\n    // feeds\n}\n</code></pre><ol><li>Because a  function exists that takes a  as a parameter,  implements </li></ol><p>\\\nI do dislike Go for its error-handling approach, but I was of two minds about implicit implementation. On one side, I understood it was a new concept, and I tried to stay open-minded; on the other hand, I think things are always better explicit than implicit, either in software development or real life.</p><p>Python is the most interesting language I know of regarding inheritance.</p><p>\\\nSubtyping and type-based inheritance have been present in Python since its inception.</p><pre><code>class Animal:\n    def feed(self):                               #1\n        pass                                      #2\n\nclass Rabbit(Animal):                             #3\n    pass\n</code></pre><ol><li>There are no abstract classes nor interfaces in Python, only classes</li><li>Because a , it can </li></ol><p>\\\nIn this regard, Python works the same as Java in terms of inheritance. Python also offers duck typing, which I described as <a href=\"https://blog.frankel.ch/python-magic-methods/\">magic methods</a>. For example, to make something , , that can return an , you only need to implement  and :</p><pre><code>class SingleValueIterable():\n\n    done = False\n\n    def __init__(self, value):\n        self.value = value\n\n    def __iter__(self):                           #1\n        return self\n\n    def __next__(self):                           #1\n        if self.done:\n            raise StopIteration\n        else:\n            self.done = True\n            return self.value\n\n\nsvi = SingleValueIterable(5)\nsviter = iter(svi)                                #2\n\nfor x in sviter:\n    print(x)                                      #3\n</code></pre><ol><li>Create an  - Pythons knows how since we implemented the methods above</li></ol><p>\\\nThe problem with this duck typing approach is that it works only for Python's predefined magic methods. What if you want to offer a class that a third party could inherit from implicitly?</p><pre><code>class Animal:\n\n    def feed():\n        pass\n\n\nclass Rabbit:\n\n    def feed():\n        pass\n</code></pre><p>\\\nIn the above snippet,  is not an , much to our chagrin. Enter <a href=\"https://peps.python.org/pep-0544/\">PEP 544</a>, titled Protocols: Structural subtyping (static duck typing). The PEP solves the impossibility of defining magic methods for our classes. It defines a simple  class: once you inherit from it, methods defined in the class become eligible for duck typing, hence the name - static duck typing.</p><pre><code>from typing import Protocol\n\nclass Animal(Protocol):                           #1\n\n    def feed():                                   #2\n        pass\n\n\nclass Rabbit:\n\n    def feed():                                   #2\n        pass\n\n\nclass VenusFlytrap:\n\n    def feed():                                   #2\n        pass\n</code></pre><ol><li>Because  is a , any class that defines  becomes an , for better or worse</li></ol><p>Object-oriented programming, inheritance, and subtyping may have specific meanings that don't translate into other languages, depending on the first language you learn. Java touts itself as an Object-Oriented language and offers the complete package. Go isn't an OO language, but it still offers subtyping via duck typing. Python offers both explicit and implicit inheritance but no interfaces.</p><p>\\\nYou learn a new programming language by comparing it with the one(s) you already know. Knowing a language's features is key to writing idiomatic code in your target language. Familiarize yourself with features that don't exist in your known languages: they will widen your understanding of programming as a whole.</p><p><em>Originally published at <a href=\"https://blog.frankel.ch/on-inheritance/\">A Java Geek</a> on January 26th, 2025</em></p>","contentLength":4784,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AI systems with ‘unacceptable risk’ are now banned in the EU","url":"https://techcrunch.com/2025/02/02/ai-systems-with-unacceptable-risk-are-now-banned-in-the-eu/","date":1738504800,"author":"Kyle Wiggers","guid":226,"unread":true,"content":"<p>As of Sunday in the European Union, the bloc’s regulators can ban the use of AI systems they deem to pose “unacceptable risk” or harm. February 2 is the first compliance deadline for the EU’s AI Act, the comprehensive AI regulatory framework that the European Parliament finally approved last March after years of development. The […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":407,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Dissecting a Real-World Bitcoin Testnet Multisig Transaction","url":"https://hackernoon.com/dissecting-a-real-world-bitcoin-testnet-multisig-transaction?source=rss","date":1738503902,"author":"EScholar: Electronic Academic Papers for Scholars","guid":281,"unread":true,"content":"<p>III. Electronic Signatures, Writing Requirement, and Authentication</p><h2>Appendix A: Multisig Transaction on Bitcoin Testnet Example</h2><p>The author selected Bitcoin, a popular virtual currency, to illustrate a multisig transaction. Bitcoin Core version 0.17.1 was used. For simplicity, we selected an already completed testnet multisig transaction and looked-up the raw transaction (“TxRaw”) data from a blockchain explorer[69]. We then decoded raw data with the Bitcoin client, filtering out the relevant input information as follows:</p><p>\\\nThe above information (emphasized in bold) tells us that the transaction utilized the multisig protocol and required the signature of two private keys out of three listed wallets. Next, we used the same raw data to extract relevant output information:</p><p>\\\nThis metadata (emphasized in bold) helps us associate the previously extracted wallet addresses from the input information to a name. The alphanumeric string after London is the last 28 characters of a digital signature that signed the message. The whole signature hash can be reproduced by signing the text with the wallet that ends with KkjJX (John Smith’s wallet). The validity of the signature can be confirmed with the Bitcoin client by plugging in the signer’s wallet address, signature hash, and message.</p><p>\\\nWith the metadata extracted from the raw transaction data, the digital signature provided by one of the parties, and the publicly available information on a blockchain explorer, we can establish with high confidence the following:</p><ul><li><p>Transaction id fa65bc5fa0ee39e012282701a4ce378474183a330487e839cd1b65b398d7646e was completed on 28 March 2019 at 15:46:53 UTC</p></li><li><p>The transaction amount was 0.005 BTC</p></li><li><p>“A-JohnSmith-KkjJX” relates to mzV1dsMdDjtLSfRa2rPrE2oJpRtynKkjJX</p></li><li><p>“C-Acme-fZN8L” relates to mpGZniUmoCemQzRbazvdgzGkmjUQ3fZN8L</p></li><li><p>“R-Baker-NBSvH” relates to n2dSPmt5cv2hFNfQqoZtvRJ6bZmypNBSvH</p></li><li><p>The transaction makes reference to London.</p></li><li><p>Mr. John Smith’s wallet digitally signed the embedded data.</p></li><li><p>The record is unaltered given the number of confirmations, which can be seen on any blockchain explorer.</p></li></ul><h2>Appendix B: Breakdown of BTC Stored in 2/3 Multisig Accounts[70]</h2><p>(1) A.J. Santos, B.A. (UTSA), J.D. (STCL), Department of Private International Law, Ankara Yıldırım Beyazıt University, Faculty of Law (ajsantos@protonmail.com).</p><p>:::info\nThis paper is  under ATTRIBUTION-NONCOMMERCIAL-SHAREALIKE 4.0 INTERNATIONAL license.</p>","contentLength":2418,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Rust-CUDA Project Restarted For Enabling NVIDIA CUDA Kernels Within Rust Code","url":"https://www.phoronix.com/news/Rust-CUDA-Project-Reboot","date":1738503695,"author":"Michael Larabel","guid":644,"unread":true,"content":"<article>The open-source Rust CUDA project has been \"rebooted\" to get back onto the effort of allowing NVIDIA CUDA compute kernels to be coded within the Rust programming language...</article>","contentLength":173,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Why Multisig Might Not Be Ready for Widespread Arbitration Use","url":"https://hackernoon.com/why-multisig-might-not-be-ready-for-widespread-arbitration-use?source=rss","date":1738501206,"author":"EScholar: Electronic Academic Papers for Scholars","guid":280,"unread":true,"content":"<p>III. Electronic Signatures, Writing Requirement, and Authentication</p><p>Multisig is an exciting technology that could change how merchants resolve cross-border disputes. The multisig protocol functions similar to escrow, but a key difference is that no one party, including the arbitrator, has sole possession of the funds. In a 2/3 multisig account, at least two parties must authorize a transfer by signing data with their respective private keys. This scheme provides a more efficient and trust-less mechanism for trading. However, there is some uncertainty whether or not multisig can be recognized as an arbitral award in some jurisdictions. The New York Convention requires awards to be “duly authenticated.” In civil law systems, the authentication of signatures is traditionally performed by public authorities or notaries. Moreover, the lex arbitri may impose additional form and document legalization requirements.</p><p>\\\nIf parties select the law of England as the seat of arbitration, they are free to agree on the form of an award under Section 52(1) of the Arbitration Act 1996. Through the concept of party autonomy, parties can restrict arbitrators from following guidelines on the content of awards and authorize the issuance of an award in electronic form. The parties should explicitly opt-out of a reasoned award as provided for under some arbitration rules. In addition, names and wallet addresses should be associated with parties at the time when the arbitration agreement is made. By doing this, an expert witness is able to certify the identity of parties and authenticate electronic signatures. Under ECA 2000, Section 7(1) (a), electronic signatures are admissible as evidence and under section 7(3), any person can certify the authenticity of such signatures.</p><p>\\\nMultisig ought to be viewed as compatible within the international arbitration legal order, where the process is defined in an arbitration agreement and the raw transaction data is the actual arbitral award in an electronic form. Much in the same way courts have been able to adapt the law regarding paper contracts to the emergence of technologies like telegram, telex, fax, and e-mail, blockchain-based applications will be another method for entering into contractual relations. The technological novelty of multisig does not justify characterizing it as a separate legal order.</p><p>\\\nAlthough multisig is compatible with the aims of international arbitration, in that it could provide a fast, cost-effective, and final method for resolving disputes privately, it is unlikely it will be widely used at the present. For one, there is a steep learning curve for merchants and their legal representatives to learn how to adequately use the technology. Secondly, arbitration institutions might be reluctant or slow to modernize rules to allow for conducting arbitration by electronic means. And finally, the multisig protocol is not intuitive enough for ordinary commercial use.</p><p>(1) A.J. Santos, B.A. (UTSA), J.D. (STCL), Department of Private International Law, Ankara Yıldırım Beyazıt University, Faculty of Law (ajsantos@protonmail.com).</p><p>:::info\nThis paper is  under ATTRIBUTION-NONCOMMERCIAL-SHAREALIKE 4.0 INTERNATIONAL license.</p>","contentLength":3211,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"After 'Copilot Price Hike' for Microsoft 365, It's Ending Its Free VPN","url":"https://tech.slashdot.org/story/25/02/02/0357206/after-copilot-price-hike-for-microsoft-365-its-ending-its-free-vpn?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1738499640,"author":"EditorDavid","guid":236,"unread":true,"content":"In 2023, Microsoft began including a free VPN feature in its \"Microsoft Defender\" security app for all Microsoft 365 subscribers (\"Personal\" and \"Family\"). Originally Microsoft had \"called it a privacy protection feature,\" writes the blog Windows Central, \"designed to let you access sensitive data on the web via a VPN tunnel.\" But....\n\nUnfortunately, Microsoft has now announced that it's killing the feature later this month, only a couple of years after it first debuted... \n\nTo add insult to injury, this announcement comes just days after Microsoft increased subscription prices across the board. Both Personal and Family subscriptions went up by three dollars a month, which the company says is the first price hike Microsoft 365 has seen in over a decade. The increased price does now include Microsoft 365 Copilot, which adds AI features to Word, PowerPoint, Excel, and others. \n\nHowever, it also comes with the removal of the free VPN in Microsoft Defender, which I've found to be much more useful so far.\n","contentLength":1016,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Can Multisig Arbitration be Seen as an Autonomous Legal Order?","url":"https://hackernoon.com/can-multisig-arbitration-be-seen-as-an-autonomous-legal-order?source=rss","date":1738497602,"author":"EScholar: Electronic Academic Papers for Scholars","guid":279,"unread":true,"content":"<p>III. Electronic Signatures, Writing Requirement, and Authentication</p><h2>IV. CAN MULTISIG ARBITRATION BE SEEN AS AN AUTONOMOUS LEGAL ORDER?</h2><p> has argued that the Bitcoin multisig process is not compatible with any of the traditional narratives of international arbitration, because it offers a level of privacy and enforcement solely depends on the mechanical operation of the protocol without the need for cooperation with national legal systems[49]. Transactions can take place between anonymous users who do not disclose their identity or geographical location[50]. Bitcoin was designed as a reaction to perceived inadequacies of the traditional banking system and is a rejection of a states’ exclusive authority over money[51]. Similar to how lex  developed within a community of merchants, Bitcoin users seek selfregulation and stateless mechanisms for resolving disputes[52].  asserts having the ability to enforce norms is a key indicator of an autonomous legal order, so the multisig process must be regarded as an a distinctive system of dispute resolution53. However, this view is not supported by empirical evidence.</p><p>\\\nBitcoin provides very little, to no, privacy protection. It is possible to link IP addresses to Bitcoin transactions through network analysis. When a user initiates a Bitcoin client, it sends out a message containing the user’s IP address information to other nodes. The software then downloads a list of known peers from other users. This makes it possible to map out IP addresses to Bitcoin addresses[54]. In a study of relay patterns, several hundred high-confidence (&gt;90%) Bitcoin address-to-IP pairings were discovered[55]. In another study, researchers were able to link numerous users to IP addresses, the vast majority of which had probabilities above 0.9, with the average value of pairings at 95.52%[56]. Even with Tor, an anonymizing overlay network, Bitcoin addresses could be linked retroactively with publicly available information. In a case study that crawled thousands of Tor hidden services, social media accounts, and forums, researchers were able to link a number of unique users to Tor hidden services[57]. For some users, they were able to discover personally identifiable information, such as name, gender, age, and location[58]. The researchers concluded that Bitcoin addresses should always be assumed to be compromised as it could be used to de-anonymize users[59]. Moreover, courts have the power to order third party service providers to disclose information about users. Know-yourcustomer compliant exchanges and custodial wallet providers could be compelled under a pre-action Norwich Pharmacal Order to disclose names, emails, postal addresses, and IP addresses of registered users[60]. In a case from Ireland, a court noted when ordering an internet service provider to disclose information about their subscribers “that whether the right to confidentiality arises by statute or by contract or at common law, it cannot be relied on by a wrongdoer or a person against whom there is evidence of wrongdoing to protect his or her identity… right to privacy or confidentiality of identity must give way where there is prima facie evidence of wrongdoing[61].” Thus, with the development of standardized Bitcoin investigative tools that can link transactions to geographical locations and courts’ inherent power to order the disclosure of information from service providers, information about Bitcoin users can be discovered and they are not anonymous.</p><p>\\\nFurthermore, Bitcoin users are not purely interested in self-regulation and stateless mechanisms. Users’ views range the whole political spectrum. According to a State of Blockchain Report, it was reported that 35% of Bitcoin supporters are Socialist or Liberal, 46% Conservative or Libertarian, while only a small minority, 9%, identified as “Anarcho-Capitalist,” a political philosophy that advocates for the elimination of the state[62]. In another survey of blockchain developers, it was found that the majority of respondents indicated they are primarily motivated by money, passion for coding, attraction to the blockchain technology, learning, and community recognition[63]. Bitcoin users have a wide array of views and, in general, do embrace the Westphalian model.</p><p>\\\nAnd lastly, Bitcoin multisig cannot be viewed as a customary norm in lex mercatoria. To be recognized as a norm, the practice must persist over a substantial period of time, reflect trade habits and market usages, be universal, be extrinsic to the legal system, and be of utilitarian benefit for a merchant community[64]. The BIP-11 M-of-N Standard Transactions proposal was accepted December 13, 2011 and BIP-16 Pay to Script Hash, which enabled multisig scripting, was accepted April 1, 2012[65]. The first multisig wallet service was launched in August 2013[66]. According to statistics of 2/3 multisig account usage, the number of deposited funds picked up in late 2015, but has since leveled off after the 2017 Bitcoin “tulip bubble,” see Appendix B. As it can be seen multisig is a relatively recent technology that does not have wide usage over a substantial period of time, so customs within the community cannot be elevated to the level of . Furthermore, there is no evidence to show that Bitcoin multisig is currently being used by a concrete and identifiable merchant community.</p><p>\\\nGiven these points, multisig ought not be seen as a distinctive legal order. It would be more advantageous to bring the multisig process under the purview of international commercial arbitration law. International arbitration has a wealth of rules and case law for arbitrators to draw from. Awards can be recognized by numerous national legal systems under the New York Convention[67] and arbitrators, acting in a quasi-judicial capacity, are afforded immunity from liability under national laws and arbitration rules[68].</p><p>(1) A.J. Santos, B.A. (UTSA), J.D. (STCL), Department of Private International Law, Ankara Yıldırım Beyazıt University, Faculty of Law (ajsantos@protonmail.com).</p><p>:::info\nThis paper is  under ATTRIBUTION-NONCOMMERCIAL-SHAREALIKE 4.0 INTERNATIONAL license.</p><p>[49] Ortolani, Pietro (2016) ‘Self-Enforcing Online Dispute Resolution: Lessons from Bitcoin’ Oxford Journal of Legal Studies, I3, V36, pp. 595-629.</p><p>\\\n[55] Koshy, Philip/Koshy, Diana/McDaniel, Patrick ‘An Analysis of Anonymity in Bitcoin Using P2P Network Traffic’: Safavi-Naini, Reihaneh/Christin, Nicolas (Editors) (2014) Financial Cryptography and Data Security - 18th International Conference, pp. 469-485. 56 Juhász, Péter L./ Stéger, József/Kondor, Dániel/Vattay, Gábor (2018) ‘A Bayesian Approach to Identify Bitcoin Users’ PLoS ONE, I:12, V:13 <a href=\"https://doi.org/10.1371/journal.pone.0207000\">https://doi.org/10.1371/journal.pone.0207000</a>.</p><p>\\\n[57] Al Jawaheri, Husam/Al Sabah, Mashael/Boshmaf, Yazan/Erbad, Aiman (2018) ‘When A Small Leak Sinks A Great Ship: Deanonymizing Tor Hidden Service Users Through Bitcoin Transactions Analysis’ ArXiv180107501 <a href=\"http://arxiv.org/abs/1801.07501\">http://arxiv.org/abs/1801.07501</a> l.a.d. 04/17/2019.</p><p>\\\n[60] Yalabık, Fulya Teomete/Yalabık, İsmet (2019) ‘Anonymous Bitcoin v Enforcement Law’ International Review of Law, Computers &amp; Technology, I:1, V:3, DOI: 10.1080/13600869.2019.1565105, pg. 48.</p><p>\\\n[61] EMI Records Ltd., Sony BMG Music Entertainment Ltd., Universal Music Ltd., Warner Music Ireland Ltd v. Eirecom Ltd., BT Telecommunications Ltd., [2006] E.C.D.R. 5 (Ire.). The test is where a person is wittingly or unwittingly caught up in the wrongdoing of another so as to facilitate that wrongdoing and is more than a mere witness, a court may order the person to provide the injured party the necessary information to enable the ultimate wrongdoer to be identified. The wrongful act could arise out a crime, tort, breach of contract, equitable wrong, or contempt of court and there must be a need for an order to enable action in the interest of justice. See ArcelorMittal USA LLC v. Essar Steel Ltd., [2019].</p><p>\\\n[63] Bosu, Amiangshu/Iqbal, Anindya/Shahriyar, Rifat/Chakroborty, Partha (2018) ‘Understanding the Motivations, Challenges and Needs of Blockchain Software Developers: A Survey’ ArXiv181104169 <a href=\"http://arxiv.org/abs/1811.04169\">http://arxiv.org/abs/1811.04169</a> l.a.d. 04/17/2019.</p><p>\\\n[64] Bhala, Raj (1996) ‘Applying Equilibrium Theory and the FICAS Model: A Case Study of Capital Adequacy and Currency Trading’ Saint Louis University Law Journal, V41, I:125, pp. 205-206.</p><p>\\\n[67] As of 02 April 2019, there are 159 contracting states of the New York Convention.</p>","contentLength":8499,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"GNOME 48 Lands HDR Support Bits At The Last Minute","url":"https://www.phoronix.com/news/GNOME-48-HDR","date":1738497319,"author":"Michael Larabel","guid":643,"unread":true,"content":"<article>On Saturday was the GNOME 48 feature freeze and landing during the final moments of this feature development period was new High Dynamic Range (HDR) code for Mutter and the toggling within the GNOME Control Center...</article>","contentLength":216,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"LLVM 20.1-rc1 Released For Testing This Updated Compiler Stack","url":"https://www.phoronix.com/news/LLVM-20.1-rc1-Released","date":1738496867,"author":"Michael Larabel","guid":642,"unread":true,"content":"<article>The first release candidate working towards the stable release of LLVM 20 is now available for testing...</article>","contentLength":105,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Open-Source 0 A.D. RTS Game Adds AMD FSR Support & Vulkan Renderer","url":"https://www.phoronix.com/news/0-AD-Alpha-27","date":1738496054,"author":"Michael Larabel","guid":641,"unread":true,"content":"<article>It's been a while since having anything new to report on the 0 A.D. open-source real-time strategy (RTS) game but this week marked the 0 A.D. Alpha 27 release that they also hope will be their last alpha version...</article>","contentLength":214,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"GNOME Text Editor Gains A Sidebar, GTK's Android Backend & Other Excitement This Week","url":"https://www.phoronix.com/news/GNOME-Text-Editor-Sidebar","date":1738495290,"author":"Michael Larabel","guid":640,"unread":true,"content":"<article>This Week in GNOME is out with its newest development summary as we embark on the GNOME 48 feature freeze...</article>","contentLength":108,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"An Open Source Exploit Last Year Changed How Professionals Think of Security","url":"https://hackernoon.com/an-open-source-exploit-last-year-changed-how-professionals-think-of-security?source=rss","date":1738494010,"author":"David Kirichenko","guid":278,"unread":true,"content":"<p>Open source software is everywhere—used in almost every modern application—but the security challenges it faces continue to grow more serious. Relying on the backbone of volunteers, vulnerabilities now make it a prime target for cyberattacks by both malicious hackers and state actors. The close call with the xz Utils backdoor attack highlights just how fragile open source security can be. With open source tools being crucial for both private companies and governments, greater investment from the private sector and public sectors will be required.</p><p>\\\nMuch of the internet’s crowdsourced code is vulnerable to infiltration by bad actors and nation-states. Open source software is at the “heart of the internet,” it is largely maintained by a handful of&nbsp;<a href=\"https://www.economist.com/science-and-technology/2024/04/02/a-stealth-attack-came-close-to-compromising-the-worlds-computers\">volunteers</a>&nbsp;and that makes it a major security risk for corporations and governments alike,&nbsp;<a href=\"https://www.economist.com/science-and-technology/2024/04/02/a-stealth-attack-came-close-to-compromising-the-worlds-computers\">The Economist</a>&nbsp;reported. Open source software is commonly deployed across digital&nbsp;<a href=\"https://www.economist.com/leaders/2019/10/03/the-rise-of-open-source-computing\">infrastructure</a>&nbsp;because of its low cost. That infrastructure, which is embedded across the digital world, is under attack by various enemy nation-states.</p><p>\\\nMartin Woodward, VP of developer relations at GitHub previously&nbsp;<a href=\"https://venturebeat.com/programming-development/github-releases-open-source-report-octoverse-2022-says-97-of-apps-use-oss/\">said</a>, “Open source software is the foundation of 99% of the world’s software.” Around 97% of applications utilize open source code, with 90% of companies incorporating or using it in some capacity.</p><h2><strong>What the last year has shown in open source security</strong></h2><p>The xz Utils incident was a chilling example of what’s at stake. On March 29, 2024, Andres Freund, a software engineer at Microsoft, “inadvertently found a backdoor hidden in a piece of software that is part of the Linux operating system.” This backdoor came from the release tarballs for xz Utils, which were tampered with, and allowed unauthorized access to systems using the affected versions. The source code that was compromised was of the&nbsp;<a href=\"https://www.darkreading.com/cyber-risk/xz-utils-backdoor-implanted-in-intricate-multi-year-supply-chain-attack\">xz Utils open source data compression utility</a>&nbsp;in Linux systems.&nbsp;The&nbsp;<a href=\"https://www.nytimes.com/2024/04/03/technology/prevent-cyberattack-linux.html\">New York Times</a>&nbsp;wrote that the engineer prevented a “potentially historic cyberattack.”</p><p>\\\nSince xz Utils is open source software, its code is publicly accessible, allowing anyone to view the changes made. However, this openness was exploited in a particularly sneaky manner: the attack targeted only the code in the release tarballs (compressed archive file for the version of a software release), leaving the main branch of the repository untouched. This clever tactic made the compromise harder to detect. Without the vigilance of a developer and a stroke of luck, the attack could have caused massive harm, breaching countless systems worldwide.</p><p>\\\nA developer named Jia Tan began making helpful code contributions to the project and slowly earning trust. Then over time, the bad actor smuggled in malware. One of the most surprising elements of the xz Utils backdoor attack was how the malicious&nbsp;<a href=\"https://corsha.com/blog/the-xz-utils-backdoor-cve-2024-3094\">code</a>&nbsp;was introduced through seemingly harmless git commits. Instead of altering the xz Utils source code directly, the malware was concealed as x86_64 object code within binary test files, disguised as unit tests for edge cases in XZ decompression. Russia’s foreign intelligence service, SVR, suspected to be behind the&nbsp;<a href=\"https://www.economist.com/science-and-technology/2024/04/02/a-stealth-attack-came-close-to-compromising-the-worlds-computers\">attacks</a>, is the same intelligence service behind the SolarWinds attack.</p><p>\\\nThis incident is not isolated. Open source projects are attractive targets for state actors because the code is public. While this openness is great for collaboration, it also gives attackers easy access to study the code and its updates. Open source plays a vital role in global infrastructure; A&nbsp;<a href=\"https://venturebeat.com/security/report-finds-82-of-open-source-software-components-inherently-risky/\">report</a>&nbsp;from Lineaje in 2023 revealed that 70% of all software today is open source and that 82% of open source software components are “inherently risky.” Unfortunately, its ubiquitous use makes its vulnerabilities even more dangerous.</p><p>\\\nReports from Lineaje and others highlight the risks: 82% of open source components are considered risky due to poor maintenance, outdated code, or security flaws. Many of these projects are run by small teams or individual volunteers with limited resources, leaving them vulnerable to attacks.</p><h2><strong>How AI will play a greater role</strong></h2><p>Adding to these risks is the rise of large language models (LLMs)&nbsp;While LLMs help developers with tasks like debugging or automating workflows, they can also be misused. Attackers can use LLMs to quickly analyze open source code for vulnerabilities, making it easier to find exploitable flaws. These AI tools can also craft convincing phishing messages or fake contributions to open source projects, making it harder to spot bad actors. The ability of LLMs to mimic human interaction increases the chances of malicious code slipping through unnoticed through phishing and other attack vectors that can be automated.</p><p>\\\nDespite the risks, LLMs also offer opportunities to improve open source security. But there is a balance to be had since it could be cost prohibitive, as companies are unlikely to invest into running LLM based analyzers on open source code with no budget. For example, AI systems could flag suspicious changes in a codebase or detect unusual patterns in contributor behavior.&nbsp;<a href=\"https://venturebeat.com/security/how-open-source-llms-enable-security-teams-to-stay-ahead-of-evolving-threats/\">Open source LLMs</a>&nbsp;also “benefit from the fast-growing base of developer communities pushing their boundaries and scaling daily to solve complex cybersecurity challenges.”</p><p>\\\nHowever, the same technology that strengthens defenses can also be&nbsp;<a href=\"https://www.tripwire.com/state-of-security/security-threats-facing-llm-applications-and-ways-mitigate-them\">weaponized</a>. Deploying an open source LLM on a server or in a cloud environment introduces the risk of unauthorized access to the model or the sensitive data it handles, if there are not proper security controls in place. Malicious actors can tamper with training data or the model itself, injecting harmful code or biases that result in misleading or malicious content. Additionally,&nbsp;<a href=\"https://owasp.org/www-project-top-10-for-large-language-model-applications/\">improperly secured</a>&nbsp;LLMs may leak sensitive information, either through generated text or attacks targeting the model’s architecture.</p><p>\\\nWhat was once accomplished with a single repository using tools like xz Utils could soon be scaled across hundreds by a single individual leveraging advanced GenAI technologies over the next few years—and this shift has likely already begun. The barrier to entry has dropped dramatically, moving from requiring nation-state-level resources or extreme dedication to something that can now be mass-produced. It’s entirely plausible that in the coming years, the majority of small or minor updates to repositories will be generated by GenAI.</p><p>\\\nWhile meaningful, high-quality development contributions remain a different challenge, the role of maintainers may shift as well. Instead of being skilled developers actively contributing code, maintainers might increasingly be those who excel at managing grunt work and presenting an image of helpfulness, leaving the more complex or innovative tasks to a smaller group of dedicated developers.</p><p>Traditional phishing attacks focus on obtaining a company’s internal directory and targeting key individuals—or those they trust. With NPM’s extensive dependency ecosystem, which is publicly accessible, attackers have a different angle. They can identify the small number of maintainers for a given package, assess the backlog of issues, and use that information to deploy bots that appear helpful by contributing fixes or offering assistance. This creates an avenue for gaining trust and embedding themselves within the development process.</p><p>\\\nThe best fake identities are crafted with real-world data, enriched over time through social media posts, academic records, and more. A convincing fake ID includes a detailed backstory, complete with photos, connections, and an online presence. GenAI simplifies the creation of these identities, while also enhancing them by simulating coding activity on platforms like GitHub.</p><p>\\\nMany early contributions to open source projects are small and easy to verify—like fixing typos in comments or updating dependencies. These activities are ideal for attackers using LLMs, as they can be automated at scale. This enables the creation of hundreds of fake identities, each with LinkedIn profiles, social media accounts, and GitHub histories containing thousands of minor but legitimate contributions.</p><p>\\\nThese identities can participate in multiple projects, potentially overlapping, and build a track record of helpfulness. Over time, a malicious actor might use one of these identities to submit more critical contributions. Even these contributions may initially appear valid and beneficial. In coordinated efforts, such as those by nation-states or hacker collectives, one identity could bolster the credibility of another, reinforcing a narrative or gaining influence.</p><p>\\\nWe’ve already seen examples like the xz utils incident, where multiple identities were used to manipulate trust. When the attack was exposed, those identities were discarded. In manual operations, losing such assets would be costly. However, with GenAI, generating new identities comes at minimal expense, significantly lowering the stakes for attackers.</p><h2><strong>Supply chain attacks will grow</strong></h2><p>A recent software supply chain attack&nbsp;<a href=\"https://thehackernews.com/2024/12/researchers-uncover-backdoor-in-solanas.html\">targeted</a>&nbsp;the popular @solana/web3.js npm library, which is widely used for building Solana-based applications, compromising versions 1.95.6 and 1.95.7 with malicious code to steal users’ private keys and drain cryptocurrency wallets. The attack exploited a phishing campaign that allowed threat actors to gain publish-access and inject a backdoor function, exfiltrating private keys via legitimate-looking Cloudflare headers. The affected versions have been removed, and users are urged to update to version 1.95.8 and consider rotating their keys to mitigate risks.</p><p>\\\nSoftware supply chain attacks are expected to increase in 2025 due to the growing reliance on open source libraries and the rise of sophisticated attack methods like phishing and social engineering. According to a study by&nbsp;<a href=\"https://www.synopsys.com/content/dam/synopsys/sig-assets/reports/rep-ossra-2023.pdf\">Synopsys</a>, vulnerabilities in open source software are steadily increasing. Additionally, the increased integration of open source tools in enterprise systems provides attackers with a higher return on investment, making such breaches even more attractive to both cybercriminals and state-sponsored actors.</p><h2><strong>Influence of state actors and targeting of volunteers</strong></h2><p>The xz Utils incident, much like the SolarWinds attack, serves as a wake-up call, highlighting the need for greater investment and collaboration between the public and private sectors to secure open source software and preserve its value as a digital public good. Companies that benefit from open source tools need to step up and support these projects. This support can include funding, providing developer time, or offering security expertise. Open source projects also need better governance, such as stricter code review processes and shared responsibility for updates. Faster patching of vulnerabilities is another priority, as delays leave systems exposed to attacks for longer periods.</p><p>\\\nState actors remain one of the biggest threats. Open source software offers them a low-cost, high-reward target for espionage, sabotage, and disruption. The SolarWinds attack, although involving proprietary software, is a prime example of how damaging these supply chain breaches can be.</p><p>\\\nAttackers will likely continue to target individual maintainers more frequently, using advanced social engineering tactics to compromise projects. AI tools will continue to enhance both the attackers’ and defenders’ capabilities, creating a race to stay ahead of new threats. Governments are also likely to get more&nbsp;<a href=\"https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/\">involved</a>, helping promote public-private partnerships to improve security across the wider ecosystem. At the same time, stricter regulations may be introduced, pushing companies to take more responsibility for the open source components they use.</p><p>\\\nWhen it comes to the SolarWinds incident, whether it has faded from memory depends on the perspective. While public attention may have shifted, government officials and cybersecurity experts remain focused on addressing the lessons learned. Much of the ongoing work in software supply chain security, such as initiatives by the OpenSSF (like SLSA and GUAC), is a direct response to the need for stronger defenses, driven by agencies like&nbsp;<a href=\"https://www.cisa.gov/news-events/news/continued-progress-towards-secure-open-source-ecosystem\">CISA</a>, but progress has been slow, and not all organizations have adopted these protections. The federal government itself is one of the largest&nbsp;<a href=\"https://cyberscoop.com/open-source-security-trust-xz-utils/\">consumers</a>&nbsp;of open source software and will continue to increase its involvement in the space.</p><p>\\\nWhile these efforts continue behind the scenes, the incident’s impact may not have fully resonated with the general public, especially among independent or hobbyist software developers who may not fully grasp the broader implications.</p><p>Ultimately, as expert Michal Zalewski&nbsp;<a href=\"https://www.economist.com/science-and-technology/2024/04/02/a-stealth-attack-came-close-to-compromising-the-worlds-computers\">noted</a>, “The bottom line is that we have untold trillions of dollars riding on top of code developed by hobbyists.” This underscores the possibility that other backdoors may still be lurking, undiscovered, within the critical software that forms the backbone of the internet.</p><p>\\\nWhile identifying vulnerabilities is a concern, the larger issue lies in the erosion of trust within open source ecosystems. Open source thrives on the contributions of faceless developers who work in good faith, often without direct interaction or verification of identity. GenAI undermines this foundation by making it feasible for many of those faceless contributors to be entirely fabricated.</p><p>\\\nPhishing attacks are already dangerous because they exploit trust rather than breaking through technical defenses—they trick individuals into executing malicious code in a trusted environment. GenAI amplifies this risk by enabling attackers to embed malicious code into trusted open source packages under the guise of legitimate contributions.</p><p>\\\nThis will likely spark a race between malicious actors using GenAI to infiltrate projects and defensive tools leveraging GenAI to detect and counter vulnerabilities before they can be exploited. The question then becomes whether trust in open source can survive in a world where contributors may increasingly be indistinguishable from AI-driven imposters.</p><p>\\\nAs we enter 2025, open source software is at a critical point. The threats are becoming more sophisticated, driven by state actors, the misuse of AI tools like LLMs, and a focus on supply chain interference to inflict maximum damage. However, with proactive measures, greater investment, and shared responsibility, it’s possible to create a future where open source continues to thrive as a force for innovation and progress, rather than a vulnerability waiting to be exploited.</p>","contentLength":14566,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How Does Multisig Authentication Differ from Traditional Arbitration?","url":"https://hackernoon.com/how-does-multisig-authentication-differ-from-traditional-arbitration?source=rss","date":1738494006,"author":"EScholar: Electronic Academic Papers for Scholars","guid":277,"unread":true,"content":"<p>III. Electronic Signatures, Writing Requirement, and Authentication</p><h2>C. COULD A MULTISIG E-AWARD BE DULY AUTHENTICATED?</h2><p>Before considering the issue of authentication, it should be pointed out that a multisig e-award is different from a traditional paper award in that it is self-enforcing. Once the multisig signature threshold has been met and the transaction is broadcast to the network, the funds are released to the recipient. Enforcement of a mutlisig award is not necessarily an issue, but whether the act of releasing funds puts an end, in whole, or in part, a dispute and if the resulting raw transaction data could be recognized as an award.</p><p>\\\nThis is important because if multisig is not capable of being recognized, then a multisig transaction could be challenged in any court with competent jurisdiction and an arbitrator's finding reversed. Although technically the multisig transaction is non-reversible at the code level, a court could order compensation to be paid notwithstanding the execution of the transaction on a blockchain. When a participant deposit an asset into a multisig account, there is an understanding that the asset will not be transferred unless certain conditions are met, namely the requirement of M-of-N signatures and the occurrence of an event or the performance of an obligation. The arbitrator makes a determination if the conditions have been satisfied and releases the funds by signing a transaction with his or her private key. As such, multisig can be viewed as a separate and distinct contract from the underlying agreement between the participants. For instance, in a sale of goods agreement, if no goods or sub-standard goods are delivered, the buyer could sue the seller for breach even if a third party releases funds from a multisig account. The decision of the arbitrator, ipso facto, does not have  effect and is somewhat analogous to a decision of a bank releasing funds under a letter of credit.</p><p>\\\nIn addition, if the multisig process is not seen as a form of international commercial arbitration and the arbitrator fails to perform the decision-making function to the level expected of a technologically-savvy prudent adjudicator, he or she may face unlimited personal liability. The arbitrator owes concurrent contractual, non contractual, and equitable duties towards multisig ‐ participants. So, it is vital for a multisig transaction to be recognizable as a final and binding award.</p><p>\\\nUnder Article IV(a) the New York Convention, a party applying for recognition must supply a “duly authenticated original award.” The Convention does not define the meaning of authentication, but commentators are in general agreement that it can be defined as the process of confirming the authenticity of arbitrators’ signatures[38]. The law applicable to issues related to authentication can either be the  or the law of where recognition is sought[39]. According to the , the drafting committee preferred to give the court where recognition is sought more flexibility in determining the governing law than the Geneva Convention of 1927, which only pointed to [40]. In common law jurisdictions, the act of confirming the authenticity of a signature is viewed as an evidentiary matter. It does not require to be in any particular form and in the interest of justice and efficient conduct of court business, a simple straightforward method is usually preferred[41]. The act can be performed by public officials, lawyers, witnesses, or arbitration institutions[42]. On the other hand, in most civil law jurisdictions, the concept of authenticity is viewed more narrowly and traditionally require a competent public authority or a notary public to verify the truthfulness of documents[43].</p><p>\\\nAccording to  and , Article IV should be read in conjunction with Article III and if the country of where the award was made permits the issuance of awards in electronic form, there should be no barrier to accepting the award as duly authenticated[44].  notes that although an indefinitely reproducible electronic document cannot be seen as “original,” in relation to electronic data, it can be an authentic copy, where the authorship of the data can be reliably proven[45]. However, Otto cautions against electronic awards as there is no unanimous view of authentication and some countries have taken a strict view[46]. There is a risk if recognition is sought in a civil law jurisdiction, the multisig transaction may not be viewed as final and binding.</p><p>\\\nIf we apply the law of England as the , under Section 7(3) of the ECA 2000, “any person” can certify an electronic signature with a statement confirming the authenticity. Section 7, Part III (15)(2)(a), further provides that the term “authentication” relates to whether an electronic communication or data: (i) comes from a particular person or other source; (ii) is accurately timed and dated; (iii) is intended to have legal effect.</p><p>\\\nIn the case of the example in Appendix A, a signature hash can be linked to a particular signer and any alteration to raw transaction data can be detectable. The time and date is part of the data and the intent for the electronic signature to have legal effect can be established by referring to the arbitration agreement and the subsequent conduct of the parties[47]. An expert witness could certify the authenticity of the electronic signatures by checking the embedded metadata. Alternatively, an arbitrator has the option to self-certify as to the authenticity of the transaction. This method of authentication is consistent with the interest of having a pragmatic, flexible, non-formalistic, arbitration-friendly approach to the interpretation of Article IV[48].</p><p>(1) A.J. Santos, B.A. (UTSA), J.D. (STCL), Department of Private International Law, Ankara Yıldırım Beyazıt University, Faculty of Law (ajsantos@protonmail.com).</p><p>:::info\nThis paper is  under ATTRIBUTION-NONCOMMERCIAL-SHAREALIKE 4.0 INTERNATIONAL license.</p><p>[38] ICCA (2011), supra note 5 at pg. 109.</p><p>\\\n[39] Oberster Gerichtshof, Sep. 3 2008 (O Ltd., et al. v. C Ltd.), in Yearbook Commercial Arbitration XXXIV 409-417 (Albert Jan van den Berg, ed., 2009). However, not all jurisdictions follow this view, some require authentication in conformity with the lex fori, such as in Italy. See Otto, Dirk ‘Article IV’: Kronke, Herbert/Nacimiento, Patricia, Otto, Dirk/Port Nicola Christine (Editors) (2010) Recognition and Enforcement of Foreign Arbitral Awards: A Global Commentary on the New York Convention, Alphen aan den Rijn, Kluwer Law International, Wolters Kluwer, pg. 144.</p><p>\\\n[40] E/2704 - Report of the Committee on the Enforcement of International Arbitral Awards (Resolution of the Economic and Social Council establishing the Committee, Composition and Organisation of the Committee, General Considerations, Draft Convention) 14 (1955).</p><p>\\\n[41] Promontoria (Henrico) Ltd v. James Friel, [2019] CSOH 2 (U.K.).</p><p>\\\n[42] Otto, Dirk ‘Article IV’: Kronke, Herbert/Nacimiento, Patricia, Otto, Dirk/Port Nicola Christine (Editors) (2010) Recognition and Enforcement of Foreign Arbitral Awards: A Global Commentary on the New York Convention, Alphen aan den Rijn, Wolters Kluwer, pg. 183.</p><p>\\\n[44] Yu, Hong-Lin/Nasir, Motassem (2003) ‘Can Online Arbitration Exist Within the Traditional Arbitration Framework?’, Journal of International Arbitration, pg. 472.</p><p>\\\n[45] Lederer, Nadine (2019) ‘The Enforcement of Cross-Border Online Arbitral Awards and Online Arbitration Agreements. The New York Convention and the Internet: Friends or Foes?’ Spain Arbitration Review, pg. 73.</p><p>\\\n[46] Otto, Dirk (2010), supra note 42 at pg. 177.</p><p>\\\n[48] 5A_754/2011, Federal Tribunal, 2 Jul. 2012 (Switz.) (in interpreting Article IV(2) of a partial translation, court applied a flexible, pragmatic and non-formalistic approach).</p>","contentLength":7818,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"My Startup Was Bleeding Cash—Here’s How I Sold It Anyway","url":"https://hackernoon.com/my-startup-was-bleeding-cashheres-how-i-sold-it-anyway?source=rss","date":1738490403,"author":"Alex Dro","guid":276,"unread":true,"content":"<p>If you’re here, chances are you either have one or more startups or you’re thinking about building your first one. You’re probably here to uncover the big secret: .</p><p>\\\nLet’s be real — creating your own product is about two things: first and main, making money, and second, self-realization.</p><p>\\\nThis article will help you know how to sell your startup. I did it, and if I can, so can you.</p><p>\\\nWhen I started my journey as an entrepreneur, I read a lot of stories about founders who had successful exits, selling their startups for huge amounts of money. Honestly, I think that’s a dream many of us share.</p><p>\\\nBut the reality is, not all of our startups take off — sometimes for all kinds of reasons.</p><ul><li>Lack of marketing skills or experience.</li><li>Realizing your startup idea isn’t as good as you thought.</li><li>Choosing the wrong niche or targeting the wrong audience.</li><li>Feeling exhausted and needing a break.</li><li>Burning out and losing interest.</li><li>Facing financial pressure and needing money quickly.</li><li>Being a developer but not a salesperson or marketer.</li></ul><p>\\\nJust because your project doesn’t need you anymore doesn’t mean it doesn’t need someone.</p><p>\\\nI worked on my sold startup, SlideLab, for over two years. After that, it stayed online for a few years as a kind of “dead project.” I launched it with zero experience in startups.</p><p>\\\nAt the time, we were just a small local production studio. But let’s not dive into that now. If you’re curious about my solo entrepreneur journey, check out my  where I share more about it.</p><p>\\\nSo, my project sat for several years without visitors — basically dead weight. Were some new visitors, but not much. I decided to sell it and  where I could do that.</p><p>\\\nI went to each platform, filled out their forms, sent any requested information, and then just waited. The whole process was completely free, of course.</p><p>\\\nAfter some time, I started receiving emails with NDA requests and questions from interested buyers.</p><p>At one point, I received an offer of $5,000 from SideProjectors, but I wanted more. Some people asked additional questions about my tech stack, business idea, audience, and similar details.</p><p>\\\nIn the end, <strong>I sold my startup to a software development team</strong>. The buyer reached out to me via DM, and we chatted for a few hours to discuss the price. Once we agreed on a price, the buyer sent me a purchase agreement. We decided to split the payment into two parts: one payment upfront and the second after the product was transferred to the buyer’s server.</p><p>\\\nIt was my first experience selling a product, but I found it surprisingly simple and easy. I believe this was because I build my business in public. I shared all reports, updates, and ideas about my products, and I’ve always been open-minded. When someone wants to buy your product, all they need to do is check your social media to make their decision.</p><p>\\\n<strong>It took 8 months from the moment I first published the sale.</strong> I can’t share all the details of the deal because, of course, I signed an NDA and other documents. It wasn’t a huge amount, but it’s enough for me to live as a solo entrepreneur in Thailand for a year. It gives me the freedom to continue being a solo entrepreneur and focus solely on my new products.</p><p>\\\nNow I’m working on my next product. It helps domain investors . I find these domains by web scraping authoritative sources like Product Hunt, Medium, Forbes, and other popular websites.</p><p>Before I decided to sell my unused online presentation editor, I struggled with a lot of fears. Over time, I realized these fears are actually quite common among developers and startup owners.</p><ul><li>If the startup doesn’t generate income, it’s impossible to sell.</li><li>My product doesn’t have any customers.</li><li>My product doesn’t have visitors.</li><li>It’s not actively promoted or running.</li><li>My product isn’t valuable to anyone.</li><li>The selling process is difficult and unclear.</li><li>How much is my startup worth if it doesn’t have any income?</li><li>If you sell something, it means you’re selling something of bad quality.</li></ul><p><strong>All of these fears are just in your mind.</strong></p><p>Now, let’s look at it from a different perspective: the buyers.</p><p>Buyers have money, right? So why do they search for and buy startups?</p><ul><li>Some small software development companies want to test a hypothesis. Buying a ready-to-use product with similar features can be cheaper than paying a team for 3–5 months.</li><li>Some wealthy individuals with no experience in tech want to try it out. They can buy a product they like and treat it as a business experiment — hiring a team, marketing, developing, and promoting it, like playing with a toy constructor.</li><li>If your project is on a valuable domain, domain investors might buy it. A ready-to-use website on a premium domain increases its value, especially with the added benefits of SEO.</li><li>The startup might have innovative technology, software, or patents that the buyer sees as valuable for their own operations or future projects.</li><li>Even if the startup doesn’t have income, it might have a strong user base, community, or audience that can be monetized later.</li><li>Buyers might see potential for the startup to grow into a profitable business with the right resources, strategy, or scaling efforts.</li><li>The product might complement or enhance the buyer’s existing offerings, creating opportunities for cross-selling or upselling.</li></ul><p>\\\nSo, as you can see, buyers are ready to acquire your projects.</p><p>My offer aligned perfectly with one of their reasons. They needed a ready-to-use online editor and wanted to add some AI automation features to quickly test their hypothesis.</p><h2>What else can you do to try and sell your project?</h2><p>\\\nI published it everywhere I could for free:</p><p>If you want to successfully sell your project, you need to set the right price. The right price is crucial — don’t be greedy, but also don’t undervalue your work. A low price can make your product seem less valuable.</p><p>Make sure your project is always online. Renew your domain, hosting, and SSL certificates. I forgot about SSL initially, but the buyer asked me to fix it to review and test the product — and I’m thankful he did.</p><p>Your project description should be detailed and comprehensive. Include all relevant information about your project: social media pages, monthly visitors, features, successful or failed experiments, business ideas, and anything else that paints a full picture.</p><p>Don’t be afraid to be public and share everywhere that you’re selling your project.</p><p>\\\nI share more about the solo entrepreneur journey on my , including strategies, marketing and my real experiences in public. Subscribe if you want to learn more about online business.</p><p>\\\nGood luck with selling your project!</p>","contentLength":6624,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Could Earthquake Sensors Help Detect Falling Space Junk?","url":"https://science.slashdot.org/story/25/02/01/0559217/could-earthquake-sensors-help-detect-falling-space-junk?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1738485240,"author":"EditorDavid","guid":235,"unread":true,"content":"An anonymous reader shared this report from the Washington Post:\n\n\nScientists have found that using seismometers is a new and inexpensive method to detect falling space junk, which can cause damage on impact and carry toxic materials — and may someday turn deadly... \n\nIt's not an easy task to track large hunks of falling metal everywhere in the world. Ground-based radar can detect falling objects, but it doesn't cover much of the world or is often classified data, said Ben Fernando [a planetary scientist at Johns Hopkins University who is leading this research]. The other option is through optical instruments, such as doorbell cameras, but the information on the time, size and speed can be limited. Instead, Fernando turned to seismology data. Stations located around the world live-stream data, which can be easily downloaded. Seismometers have been used to track meteors in the sky for over a century, but he said this is the first time he's aware of its use for tracking space debris. \nStations located around the world live-stream data, which can be easily downloaded. Seismometers have been used to track meteors in the sky for over a century, but he said this is the first time he's aware of its use for tracking space debris. Fernando first tested the idea to track the controlled reentry of NASA's OSIRIS-REx mission in September 2023, which brought back material from the asteroid Bennu. He set up seismometers along the capsule's path in the landing spot in Utah and measured its sonic boom. \"It's a really good way of monitoring what's coming in, how often it's coming in, how big the things hitting the Earth are,\" said Fernando, who presented his results at the American Geophysical Union conference in December... \n\n\"The shockwave deforms the ground around the seismometer,\" said Fernando. \"It also keeps ringing for a lot longer because all of that energy is bouncing around in the soil....\" [H]e said an automated system could help detect these objects within moments of it appearing on the stations. In addition to detecting an event, the seismometers can help locate where any debris may have fallen. Tracking debris is important because some space debris can contain toxic materials that can harm the surrounding environment. \n\nThe article notes reports of the uncontrolled reentry into Earth's atmosphere of at least 951 objects larger than one square meter from 2010 to 2022. \n\n\"On average, objects heavier than 1,000 pounds came down about every 8 days... In fact, the threat of getting hit by uncontrolled orbital reentries has increased by a factor of four from 2010 to 2023, said Luciano Anselmo, who published a study assessing the risk.\"","contentLength":2675,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The TechBeat: Lumoz Launches SVM as a Service, Supporting the Integration of ZK and TEE Multi-Proof for SVM L2 (2/2/2025)","url":"https://hackernoon.com/2-2-2025-techbeat?source=rss","date":1738480259,"author":"Techbeat","guid":275,"unread":true,"content":"<p>By <a href=\"https://hackernoon.com/u/infinity\">@infinity</a> [ 6 Min read ] \n Discover 15 types of databases, from relational to vector, and explore their unique use cases in this comprehensive guide for developers. <a href=\"https://hackernoon.com/15-databases-15-use-casesstop-using-the-wrong-database-for-the-right-problem\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/clapper\">@clapper</a> [ 6 Min read ] \n The looming threat of a TikTok ban has once again thrown creators and businesses into a whirlwind of uncertainty. <a href=\"https://hackernoon.com/tiktoks-uncertain-future-why-creators-are-turning-to-a-us-based-alternative\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/lumoz\">@lumoz</a> [ 6 Min read ] \n Lumoz SVM Stack delivers ultra-high transaction throughput and processing speeds for the SVM chain. <a href=\"https://hackernoon.com/lumoz-launches-svm-as-a-service-supporting-the-integration-of-zk-and-tee-multi-proof-for-svm-l2\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/thisweekinaieng\">@thisweekinaieng</a> [ 6 Min read ] \n In this edition of This Week in AI Engineering, we go through the latest updates along with some must-know tools to make developing AI agents and apps easier. <a href=\"https://hackernoon.com/deepseek-releases-cheapest-ever-llm-in-the-world\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/marutitechlabs\">@marutitechlabs</a> [ 11 Min read ] \n Maruti Techlabs offers end-to-end product development. Innovate, validate, and launch with our expert team guiding you every step.\n <a href=\"https://hackernoon.com/developing-a-bespoke-roadside-assistance-app-with-react-native\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/aswinbarath\">@aswinbarath</a> [ 4 Min read ] \n Today AI is rapidly becoming part of everyday life, and NVIDIA has once again taken center stage with a new development: Project DIGITS.   <a href=\"https://hackernoon.com/everything-we-know-about-nvidias-personal-ai-supercomputer\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/maken8\">@maken8</a> [ 3 Min read ] \n Donald Trump has already withdrawn $500m from his memecoin $TRUMP. <a href=\"https://hackernoon.com/donald-trump-executes-the-ultimate-crypto-rug-pull\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/juancguerrero\">@juancguerrero</a> [ 4 Min read ] \n Silicon Valley is experiencing a fundamental split between \"Freedom Warriors\" (like Musk, Ulbricht, Assange) and the \"Coward Class\" (Gates, Soros).  <a href=\"https://hackernoon.com/silicon-valley-is-in-the-midst-of-an-ideological-battle-that-nobody-is-talking-about\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/edwinliavaa\">@edwinliavaa</a> [ 3 Min read ] \n Satoshi Nakamoto's vision wasn't just about creating a new currency. It was about dismantling the old power structures. <a href=\"https://hackernoon.com/most-concerns-about-bitcoin-are-deeply-human\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/ishanpandey\">@ishanpandey</a> [ 3 Min read ] \n Tap Protocol partners with ICP and Dfinity to develop decentralized finance (DeFi) applications directly on Bitcoin’s Layer-1. <a href=\"https://hackernoon.com/tap-protocol-and-icp-empower-bitcoin-with-decentralized-finance-at-its-core\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/olgaukr\">@olgaukr</a> [ 8 Min read ] \n Learn how intent-based marketing helps B2B marketers target the right audience, boost ROI, and adapt to tighter budgets and privacy regulations. <a href=\"https://hackernoon.com/how-intent-based-marketing-helps-drive-b2b-marketing-success\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/catherine\">@catherine</a> [ 8 Min read ] \n The 2024 State of JS survey found that Vite has become a strong competitor to Webpack and a new favorite option for many developers. <a href=\"https://hackernoon.com/vite-is-overtaking-webpack-as-developers-favorite-option-for-web-development\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/luminousmen\">@luminousmen</a> [ 9 Min read ] \n Modern distributed systems are all about tradeoffs. Performance, reliability, scalability, and consistency don't come for free—you always pay a price somewhere. <a href=\"https://hackernoon.com/why-distributed-systems-cant-have-it-all\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/ilinskii\">@ilinskii</a> [ 8 Min read ] \n Uruguay stands out as one of the most interesting countries in the world for doing business, gaining citizenship quickly, and escaping global “hot spots.” <a href=\"https://hackernoon.com/uruguay-from-legalized-marijuana-to-crypto-why-is-everyone-going-there\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/dataengonline\">@dataengonline</a> [ 5 Min read ] \n Discover how serverless AI/ML pipelines streamline data engineering by automating scalable data processing and deployment without infrastructure management. <a href=\"https://hackernoon.com/your-machine-learning-model-doesnt-need-a-server-anymore\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/madhuchavva\">@madhuchavva</a> [ 8 Min read ] \n Learn how to master API regionalization with strategies for global compliance, low latency, and scalable cloud solutions. Achieve seamless performance worldwide <a href=\"https://hackernoon.com/regionalize-apis-like-a-pro-achieve-global-compliance-and-scalability\">Read More.</a></p>","contentLength":2838,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Shein app relaunches in India with Reliance partnership","url":"https://techcrunch.com/2025/02/01/shein-app-returns-to-india-via-reliance-deal/","date":1738478516,"author":"Manish Singh","guid":225,"unread":true,"content":"<p>Chinese fast-fashion platform Shein has relaunched in India through a partnership with local conglomerate Reliance’s retail chain, nearly five years after Shein was banned amid diplomatic tensions between New Delhi and Beijing. The new Shein India Fast Fashion app, developed and launched by billionaire Mukesh Ambani’s Reliance Retail, marks the firm’s significant return to one […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":454,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"OpenAI Tests Its AI's Persuasiveness By Comparing It to Reddit Posts","url":"https://slashdot.org/story/25/02/02/0319217/openai-tests-its-ais-persuasiveness-by-comparing-it-to-reddit-posts?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1738474440,"author":"EditorDavid","guid":234,"unread":true,"content":"Friday TechCrunch reported that OpenAI \"used the subreddit, r/ChangeMyView to create a test for measuring the persuasive abilities of its AI reasoning models.\"\n\nThe company revealed this in a system card — a document outlining how an AI system works — that was released along with its new \"reasoning\" model, o3-mini, on Friday.... OpenAI says it collects user posts from r/ChangeMyView and asks its AI models to write replies, in a closed environment, that would change the Reddit user's mind on a subject. The company then shows the responses to testers, who assess how persuasive the argument is, and finally OpenAI compares the AI models' responses to human replies for that same post. \nThe ChatGPT-maker has a content-licensing deal with Reddit that allows OpenAI to train on posts from Reddit users and display these posts within its products. We don't know what OpenAI pays for this content, but Google reportedly pays Reddit $60 million a year under a similar deal. However, OpenAI tells TechCrunch the ChangeMyView-based evaluation is unrelated to its Reddit deal. It's unclear how OpenAI accessed the subreddit's data, and the company says it has no plans to release this evaluation to the public... \n\nThe goal for OpenAI is not to create hyper-persuasive AI models but instead to ensure AI models don't get too persuasive. Reasoning models have become quite good at persuasion and deception, so OpenAI has developed new evaluations and safeguards to address it. \nReddit's \"ChangeMyView\" subreddit has 3.8 million human subscribers, making it a valuable source of real human interactions, according to the article. And it adds one more telling anecdote. \n\"Reddit CEO Steve Huffman told The Verge last year that Microsoft, Anthropic, and Perplexity refused to negotiate with him and said it's been 'a real pain in the ass to block these companies.'\"","contentLength":1861,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Steam Linux Use Dips For January 2025 Amid Odd Survey Numbers","url":"https://www.phoronix.com/news/Steam-Survey-January-2025","date":1738455264,"author":"Michael Larabel","guid":639,"unread":true,"content":"<article>The Steam on Linux marketshare ended 2024 with a 2.29% against Windows at 96.1% and macOS at 1.61%. The Steam Survey numbers for January were posted this evening and they show a sizable dip for the Linux gaming use but there are also other odd discrepancies with the updated monthly figures...</article>","contentLength":293,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Senator warns of national security risks after Elon Musk’s DOGE granted ‘full access’ to sensitive Treasury systems","url":"https://techcrunch.com/2025/02/01/senator-warns-of-national-security-risks-after-elon-musks-doge-granted-full-access-to-sensitive-treasury-systems/","date":1738452613,"author":"Zack Whittaker","guid":224,"unread":true,"content":"<p>U.S. senator says Musk's access to Treasury systems represents a \"national security risk.\"</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":153,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"X expands lawsuit over advertiser ‘boycott’ to include Lego, Nestlé, Pinterest, and others","url":"https://techcrunch.com/2025/02/01/x-expands-lawsuit-over-advertiser-boycott-to-include-lego-nestle-pinterest-and-others/","date":1738449600,"author":"Anthony Ha","guid":223,"unread":true,"content":"<p>X is now suing more advertisers in an antitrust lawsuit focusing on what the company’s CEO Linda Yaccarino has claimed is a “systematic illegal boycott.” The company formerly known as Twitter first filed the lawsuit against the World Federation of Advertisers and its brand safety initiative the Global Alliance of Responsible Media in August 2024. […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":423,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Adobe exec Scott Belsky departs for indie movie studio A24","url":"https://techcrunch.com/2025/02/01/adobe-exec-scott-belsky-departs-for-indie-movie-studio-a24/","date":1738435102,"author":"Anthony Ha","guid":222,"unread":true,"content":"<p>Adobe’s chief strategy officer Scott Belsky announced this week that he will be joining A24, the independent movie studio behind “Civil War,” “Everything Everywhere All At Once,” and many more titles. Belsky first joined Adobe in 2012 through the acquisition of Behance, leaving briefly in 2016 to become a VC at Benchmark but eventually returning […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":426,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"DeepSeek gets Silicon Valley talking","url":"https://techcrunch.com/2025/02/01/deepseek-gets-silicon-valley-talking-2/","date":1738432920,"author":"Cody Corrall","guid":221,"unread":true,"content":"<p>Welcome back to Week in Review. This week we’re looking at DeepSeek’s major boost in the U.S.; Elon Musk admitting he was wrong about FSD; teens losing trust in Big Tech; and more! Let’s do it. DeepSeek went viral this week after its AI models led Wall Street analysts and technologists to question whether the […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":385,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Here are all the IPOs reported to be in the works for 2025","url":"https://techcrunch.com/2025/02/01/here-are-all-the-ipos-reported-to-be-in-the-works-for-2025/","date":1738429200,"author":"Charles Rollet","guid":220,"unread":true,"content":"<p>These companies have confidentially filed to go public in recent years.</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":134,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Venture debt lenders will play a big role in fire sales and startup shutdown this year, experts say","url":"https://techcrunch.com/2025/02/01/venture-debt-lenders-will-play-a-big-role-in-fire-sales-and-startup-shutdown-this-year-experts-say/","date":1738425600,"author":"Marina Temkin","guid":218,"unread":true,"content":"<p>When accounting startup Bench abruptly failed last month, the shutdown was forced when the company’s lenders called in the startup’s loan. In late 2023, the digital freight company Convoy faced financial challenges, leading venture lending firm Hercules Capital to assume control of the company to recover its investments. Divvy Homes, which sold for about $1 […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":432,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Here are the apps battling to be become the ‘TikTok for Bluesky’","url":"https://techcrunch.com/2025/02/01/here-are-the-apps-battling-to-be-become-the-tiktok-for-bluesky/","date":1738425600,"author":"Sarah Perez","guid":219,"unread":true,"content":"<p>TikTok’s potential U.S. ban has sparked a flurry of development within the open social web community. Several new applications are being built that could one day serve as a TikTok replacement for those who favor the open source, decentralized social network Bluesky and the technology that powers it, the AT Protocol. Though the TikTok ban […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":410,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How to delete X and move on with your life","url":"https://techcrunch.com/2025/02/01/how-to-delete-x-and-move-on-with-your-life/","date":1738422000,"author":"Amanda Silberling","guid":217,"unread":true,"content":"<p>As Elon Musk’s X sees a decline in daily active users, some people are deciding to ditch the social network entirely, whether that’s for Bluesky, Mastodon, Threads, or perhaps, better yet, nothing at all. Since the Tesla and SpaceX CEO bought Twitter in 2022, numerous alternatives have cropped up, seeking to ensnare people who are […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":405,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"GTK's X11 Backend Now Deprecated, Planned For Removal In GTK 5","url":"https://www.phoronix.com/news/GTK-X11-Now-Deprecated","date":1738419904,"author":"Michael Larabel","guid":638,"unread":true,"content":"<article>GTK developers have been holding another hackfest this week for the annual FOSDEM developer conference happening this weekend in Brussels. GTK developers are working toward the GTK 4.18 stable release and continuing to think more about GTK 5...</article>","contentLength":244,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"gendwarfksyms Tool Added To Linux 6.14 To Help With Rust Push","url":"https://www.phoronix.com/news/Linux-6.14-gendwarfksyms","date":1738419060,"author":"Michael Larabel","guid":637,"unread":true,"content":"<article>Merged on Friday to the Linux 6.14 kernel were the Kbuild feature changes for this cycle. Most notable with these kernel build changes is the introduction of the gendwarfksyms tool that is used as part of the ongoing Rust programming language push within the Linux kernel...</article>","contentLength":274,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Starting Line for Self-Driving Cars","url":"https://spectrum.ieee.org/darpa-grand-challenge","date":1738418404,"author":"Allison Marsh","guid":86,"unread":true,"content":"<p>20 years ago, Stanley won the DARPA Grand Challenge, but the tech is still niche</p>","contentLength":80,"flags":null,"enclosureUrl":"https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy81NjAwNDQ4NS9vcmlnaW4uanBnIiwiZXhwaXJlc19hdCI6MTc3NzAyMTgwNH0.ylBsubXnAKRrwPc-NjLCBxcQOKuh6KLsiO06abGA7xM/image.jpg?width=600","enclosureMime":"","commentsUrl":null},{"title":"AI agents could birth the first one-person unicorn — but at what societal cost?","url":"https://techcrunch.com/2025/02/01/ai-agents-could-birth-the-first-one-person-unicorn-but-at-what-societal-cost/","date":1738418400,"author":"Paul Sawers","guid":216,"unread":true,"content":"<p>Thanks to the advent of cloud computing and distributed digital infrastructure, the one-person micro-enterprise is far from a novel concept. Cheap on-demand compute, remote collaboration, payment processing APIs, social media, and e-commerce marketplaces have all made it easier to “go it alone” as an entrepreneur. But what about scaling that one-person business into something meatier […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":459,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Intel Battlemage, NVIDIA RTX 50 & Linux Kernel Excitement From January","url":"https://www.phoronix.com/news/January-2025-Highlights","date":1738411247,"author":"Michael Larabel","guid":636,"unread":true,"content":"<article>During the month of January on Phoronix were 292 original Linux/open-source related news articles and another 13 featured-length Linux hardware reviews and other multi-page benchmark specials. Here's a look back at the most exciting Linux/open-source news and content over the past month...</article>","contentLength":290,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Linux 6.14 RISC-V Kernel Adds Support For T-Head Vector Extensions, GhostWrite","url":"https://www.phoronix.com/news/Linux-6.14-RISC-V","date":1738410257,"author":"Michael Larabel","guid":635,"unread":true,"content":"<article>The RISC-V CPU architecture feature updates have now been submitted and merged for the nearly-over Linux 6.14 merge window...</article>","contentLength":125,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"KDE Plasma 6.3: \"It's Looking Pretty Good!\"","url":"https://www.phoronix.com/news/KDE-Plasma-6.3-Looking-Good","date":1738408965,"author":"Michael Larabel","guid":634,"unread":true,"content":"<article>KDE developer Nate Graham is out with his traditional weekly recap of all the interesting KDE Plasma changes for the past week. With less than two weeks until the Plasma 6.3 stable release, Nate Graham began his weekly update by remarking that the Plasma 6.3 desktop is \"looking pretty good!\"..</article>","contentLength":294,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["tech"]}