{"id":"46aP2QbqUqBrWfYqAibo8xS24qkvbDNgWZUrxgZ6XNcyUn6fFxkgS1aSWJWwPwaqFp34erWr8NxVvd6jro8uiaPvDUjw","title":"top scoring links : kubernetes","displayTitle":"Reddit - Kubernetes","url":"https://www.reddit.com/r/kubernetes/top/.rss?sort=top&t=day&limit=6","feedLink":"https://www.reddit.com/r/kubernetes/top/?sort=top&t=day&limit=6","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":6,"items":[{"title":"unsupportedConfigOverrides USAGE","url":"https://www.reddit.com/r/kubernetes/comments/1olodfm/unsupportedconfigoverrides_usage/","date":1762005147,"author":"/u/BigBprofessional","guid":588,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Need Advice: Bitbucket Helm Repo Structure for Multi-Service K8s Project + Shared Infra (ArgoCD, Vault, Cert-Manager, etc.)","url":"https://www.reddit.com/r/kubernetes/comments/1olnp4b/need_advice_bitbucket_helm_repo_structure_for/","date":1762003325,"author":"/u/Dependent_Concert446","guid":587,"unread":true,"content":"<p>I’m looking for some advice on how to organize our <strong>Helm charts and Bitbucket repos</strong> for a growing  setup.</p><p>We currently have  that contains everything — about  several  (like ArgoCD, Vault, Cert-Manager, etc.).</p><p>For our , we created  that’s used for microservices. We <strong>don’t have separate repos for each microservice</strong> — all are managed under the same project.</p><p>Here’s a simplified view of the repo structure:</p><pre><code>app/ ├── project-argocd/ │ ├── charts/ │ └── values.yaml ├── project-vault/ │ ├── charts/ │ └── values.yaml │ ├── project-chart/ # Base chart used only for microservices │ ├── basechart/ │ │ ├── templates/ │ │ └── Chart.yaml │ ├── templates/ │ ├── Chart.yaml # Defines multiple services as dependencies using │ └── values/ │ ├── cluster1/ │ │ ├── service1/ │ │ │ └── values.yaml │ │ └── service2/ │ │ └── values.yaml │ └── values.yaml │ │ # Each values file under 'values/' is synced to clusters via ArgoCD │ # using an ApplicationSet for automated multi-cluster deployments </code></pre><p>The following  are also in the same repo right now:</p><ul><li><strong>Project Contour (Ingress)</strong></li><li><em>(and other cluster-level tools like k3s, Longhorn, etc.)</em></li></ul><p>These are <strong>not tied to the application project</strong> — they’re might shared and deployed across <strong>multiple clusters and environments</strong>.</p><ol><li>Should I move these shared infra components into a <strong>separate “infra” Bitbucket repo</strong> (including their Helm charts, Terraform, and Ansible configs)?</li><li>For GitOps with , would it make more sense to split things like this: <ul><li> → all microservices + base Helm chart</li><li> → cluster-level services (ArgoCD, Vault, Cert-Manager, Longhorn, etc.)</li></ul></li><li>How do other teams structure and manage their repositories, and what are the best practices for this in DevOps and GitOps?</li></ol><p> Used AI to help write and format this post for grammar and readability.</p>","contentLength":1940,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Monthly: Certification help requests, vents, and brags","url":"https://www.reddit.com/r/kubernetes/comments/1olk1no/monthly_certification_help_requests_vents_and/","date":1761991272,"author":"/u/thockin","guid":586,"unread":true,"content":"<p>Did you pass a cert? Congratulations, tell us about it!</p><p>Did you bomb a cert exam and want help? This is the thread for you.</p><p>Do you just hate the process? Complain here.</p><p>(Note: other certification related posts will be removed)</p>","contentLength":223,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Monthly: Who is hiring?","url":"https://www.reddit.com/r/kubernetes/comments/1olk17i/monthly_who_is_hiring/","date":1761991234,"author":"/u/gctaylor","guid":590,"unread":true,"content":"<div><p>This monthly post can be used to share Kubernetes-related job openings within  company. Please include:</p><ul><li>Location requirements (or lack thereof)</li><li>At least one of: a link to a job posting/application page or contact details</li></ul><p>If you are interested in a job, please contact the poster directly. </p><p>Common reasons for comment removal:</p><ul><li>Not meeting the above requirements</li><li>Recruiter post / recruiter listings</li><li>Negative, inflammatory, or abrasive tone</li></ul></div>   submitted by   <a href=\"https://www.reddit.com/user/gctaylor\"> /u/gctaylor </a>","contentLength":461,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"shift left approach for requests and limits","url":"https://www.reddit.com/r/kubernetes/comments/1olaat1/shift_left_approach_for_requests_and_limits/","date":1761955835,"author":"/u/Containertester","guid":585,"unread":true,"content":"<p>We’re trying to solve the classic requests &amp; limits guessing game; instead of setting CPU/memory by gut feeling or by copying defaults (which either wastes resources or causes throttling/OOM), we started experimenting with a benchmark-driven approach: we benchmark workloads in CI/CD and derive the optimal requests/limits based on http_requests_per_second (load testing).</p><p>In our latest write-up, we share:</p><ul><li>Why manual tuning doesn’t scale for dynamic workloads</li><li>How benchmarking actual CPU/memory under realistic load helps predict good limits</li><li>How to feed those results back into Kubernetes manifests</li><li>Some gotchas around autoscaling &amp; metrics pipelines</li></ul><p>Curious if anyone here has tried a similar “shift-left” approach for resource optimization or integrated benchmarking into their pipelines and how that worked out.</p>","contentLength":817,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"What kind of debug tools are available that are cloud native?","url":"https://www.reddit.com/r/kubernetes/comments/1ol64df/what_kind_of_debug_tools_are_available_that_are/","date":1761944378,"author":"/u/lickety-split1800","guid":589,"unread":true,"content":"<p>I'm an SRE and a longtime Linux &amp; automation person, starting in the late 90s.</p><p>With the advent of apps on containers, there are fewer and fewer tools to perform debugging.</p><p>Taking a look at the types of debug tools one has used to diagnose issues.</p><ul><li>even basic tools such as find, grep, ls and others are used in debugging.</li></ul><p>The Linux OS used to be under the control of the system administrator, who would put the tools required to meet operational debugging requirements, increasingly since it is the developer that maintains the container image and none of these tools end up on the image, citing most of the time startup time as the main requirement.</p><p>Now a container is a slice of the operating system so I argue that the container base image should still be maintained by those who maintain Linux, because it's their role to have these tools to diagnose issues. That should be DevOps/SRE teams but many organisations don't see it this way.</p><p>So what tools does Kubernetes provide that fulfil the needs I've listed above?</p>","contentLength":1012,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["dev","reddit","k8s"]}