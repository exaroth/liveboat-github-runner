{"id":"EfcLDDAkyqguXw9Vbtcae7fRhxCsY1chPUNLpwbK9oHS42b4dGEMeGvA2hWHB2j3LFSAo7qhibLNgPBcA5djbGp95Jk5T","title":"top scoring links : programming","displayTitle":"Reddit - Programming","url":"https://www.reddit.com/r/programming/top/.rss?sort=top&t=day&limit=6","feedLink":"https://www.reddit.com/r/programming/top/?sort=top&t=day&limit=6","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":6,"items":[{"title":"The missing cross-platform OS API for timers","url":"https://gaultier.github.io/blog/the_missing_cross_platform_os_api_for_timers.html","date":1738562790,"author":"/u/broken_broken_","guid":322,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1igik53/the_missing_crossplatform_os_api_for_timers/"},{"title":"What Okta Bcrypt incident can teach us about designing better APIs","url":"https://n0rdy.foo/posts/20250121/okta-bcrypt-lessons-for-better-apis/","date":1738523735,"author":"/u/_n0rdy_","guid":327,"unread":true,"content":"<p>Hello there! If you follow tech news, you might have heard about the <a href=\"https://trust.okta.com/security-advisories/okta-ad-ldap-delegated-authentication-username/\" target=\"_blank\">Okta security incident</a> that was reported on 1st of November. The TLDR of the incident was this:</p><blockquote><p>The Bcrypt algorithm was used to generate the cache key where we hash a  combined string of userId + username + password. Under a specific set of conditions, listed below, this could allow users to authenticate by  providing the username with the stored cache key of a previous  successful authentication.</p></blockquote><p>This means that if the user had a username above 52 chars, any password would suffice to log in. Also, if the username is, let’s say, 50 chars long, it means that the bad actor needs to guess only 3 first chars to get in, which is quite a trivial task for the computers these days. Too bad, isn’t it?</p><p>On the other hand, such long usernames are not very usual, which I agree with. However, some companies like using the entire name of the employee as the email address. So, let’s say, Albus Percival Wulfric Brian Dumbledore, a headmaster of Hogwarts, should be concerned, as  is 55 chars. Ooops!</p><p>This was possible due to the nature of Bcrypt hashing algorithm that has a maximum supported input length of 72 characters (read more <a href=\"https://en.wikipedia.org/wiki/Bcrypt#Maximum_password_length\" target=\"_blank\">here</a>), so in Okta case the characters above the limit were ignored while computing the hash, and therefore, not used in the comparison operation. We can reverse engineer that:</p><ul><li> - user id with separators if any</li><li>this way, the password will be outside the 72 chars limit, and, therefore, ignored by the Bcrypt algorithm</li></ul><p>However, there was one thing that made me wonder: if there is a known limit of the algorithm, why is it not enforced by the crypto libraries as a form of input validation? A simple <code>if input length &gt; 72 -&gt; return error</code> will do the trick. I assumed that they might have used some custom library for Bcrypt implementation and simply forgotten about the input validation, which can happen. So, I decided to check how other programming languages behave.</p><p>Let’s start with Go, and implement the Okta incident-like case with the help of the official <code>golang.org/x/crypto/bcrypt</code> library:</p><div><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></div><p>All the code samples can be found <a href=\"https://github.com/n0rdy/n0rdy-blog-code-samples/tree/main/20250122-bcrypt-api\" target=\"_blank\">here</a></p><ul><li>generates 18-chars long userId</li><li>generates 55-chars long username</li><li>concatenates them with each other and a dummy password <code>super-duper-secure-password</code> with the use of  as a separator</li><li>computes Bcrypt hash from the concatenated string</li><li>then concatenates the same userId and username with a different password </li><li>uses bcrypt API to compare whether the 2nd concatenated string matches the hash of the 1st one</li></ul><p>Let’s run the code and see the result:</p><div><pre tabindex=\"0\"><code data-lang=\"plain\"></code></pre></div><p>Good job, Go! If we check the source code of the <code>bcrypt.GenerateFromPassword(...)</code> function, we’ll see this piece of code at the very beginning:</p><div><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></div><p>Perfect! At this point, I became even more suspicious about the tool Okta used, as it seemed like the industry figured that out based on this example. Spoiler alert: it’s not that simple.</p><p><em>Btw, if you like my blog and don’t want to miss out on new posts, consider subscribing to my newsletter <a href=\"https://mail.n0rdy.foo/subscription/form\" target=\"_blank\">here</a>. You’ll receive an email once I publish a new post.</em></p><p>Java doesn’t support Bcrypt from its core API, but my simple Google search showed that Spring Security library has implemented it. For those who are not into Java ecosystem, Spring is the most used and battle-tested frameworks out there, that has libraries for almost anything: Web, DBs, Cloud, Security, AI, etc. Pretty powerful tool, that I’ve used a lot in the past, and still sometimes use for my side projects.</p><p>So, I added the latest version of Spring Security to the project and reproduced the same scenario, as in Go example above:</p><div><pre tabindex=\"0\"><code data-lang=\"java\"></code></pre></div><p>I ran the code, and to my great surprise, saw this outcome:</p><p>I took a peak at the implementation code, and was disappointed: even though there are a bunch of checks on salt:</p><pre tabindex=\"0\"><code>if (saltLength &lt; 28) {\n\tthrow new IllegalArgumentException(\"Invalid salt\");\n}\n...\nif (salt.charAt(0) != '$' || salt.charAt(1) != '2') {\n\tthrow new IllegalArgumentException(\"Invalid salt version\");\n}\n...\nminor = salt.charAt(2);\nif ((minor != 'a' &amp;&amp; minor != 'x' &amp;&amp; minor != 'y' &amp;&amp; minor != 'b') || salt.charAt(3) != '$') {\n\tthrow new IllegalArgumentException(\"Invalid salt revision\");\n}\n...\n</code></pre><p>I didn’t see any validation of the input that will be hashed. Hm…</p><p>I decided to check other Google results, and the next Java library in the list was  from Patrick Favre (<a href=\"https://github.com/patrickfav/bcrypt\" target=\"_blank\">link to GitHub repo</a>) with 513 starts and the last release version 0.10.2 (so, not stable) from 12th of February 2023 (almost 2 years old). This suggested that I’d not use it in production, but why not to run our tests.</p><h3>Bcrypt from Patrick Favre</h3><div><pre tabindex=\"0\"><code data-lang=\"java\"></code></pre></div><div><pre tabindex=\"0\"><code data-lang=\"plain\"></code></pre></div><p>Nice, good job, Patrick, you saved the day for Java!</p><p>After checking the source code, I found this piece:</p><div><pre tabindex=\"0\"><code data-lang=\"java\"></code></pre></div><p>and the strict strategy that threw the exception we’ve seen:</p><div><pre tabindex=\"0\"><code data-lang=\"java\"></code></pre></div><p>We can see that this strict strategy is used as a part of the default configs:</p><div><pre tabindex=\"0\"><code data-lang=\"java\"></code></pre></div><p>Let’s switch to JavaScript.</p><p>Here I used the <a href=\"https://www.npmjs.com/package/bcryptjs\" target=\"_blank\">bcryptjs</a> which has over 2 million weekly downloads based on the NPM stats.</p><div><pre tabindex=\"0\"><code data-lang=\"javascript\"></code></pre></div><p>Not great. The source code reveals that similar to Spring Security, the library validates the salt</p><div><pre tabindex=\"0\"><code data-lang=\"javascript\"></code></pre></div><p>but not the input length.</p><p>Let’s try if Python can do any better.</p><p>Using <a href=\"https://github.com/pyca/bcrypt\" target=\"_blank\">bcrypt</a> library with 1.3k starts and the latest release in November.</p><div><pre tabindex=\"0\"><code data-lang=\"python\"></code></pre></div><p>The result is same as we observed for most of our test subjects:</p><p>All right, but what about some newer and more safety-oriented language - let’s try Rust.</p><p>Here I need to be honest: since I’m not a Rust expert at all, I used a help of a Claude AI to write this code. So, if you see any issues there, please, let me know in the comments section, so I can fix that.</p><p>As a library, I used <a href=\"https://github.com/Keats/rust-bcrypt\" target=\"_blank\">rust-bcrypt</a> based on my AI friend advice.</p><div><pre tabindex=\"0\"><code data-lang=\"rust\"></code></pre></div><p>I can see the validation of the cost:</p><div><pre tabindex=\"0\"><code data-lang=\"rust\"></code></pre></div><p>but not of the input. And here is the place where the explicit truncation of 72 chars happens (the comment is from the library source code):</p><div><pre tabindex=\"0\"><code data-lang=\"rust\"></code></pre></div><p>That was my first question after seeing that the majority of the tools follow the pattern that leads to the vulnerability. <a href=\"https://en.wikipedia.org/wiki/Bcrypt\" target=\"_blank\">Wikipedia article about Bcrypt</a> gave a hint:</p><blockquote><p>Many implementations of bcrypt truncate the password to the first 72 bytes, following the OpenBSD implementation</p></blockquote><p>Interesting! Let’s check the OpenBSD implementation of this algorithm, and <a href=\"https://github.com/openbsd/src/blob/master/lib/libc/crypt/bcrypt.c\" target=\"_blank\">here is the link</a> to it. The first point of interest lies here:</p><div><pre tabindex=\"0\"><code data-lang=\"c\"></code></pre></div><p>And from that moment on,  is used as a limit to iterate over the input string within, for example:</p><div><pre tabindex=\"0\"><code data-lang=\"c\"></code></pre></div><p>Where  is passed as a  parameter. So this piece of code:</p><p>will make sure that no chars over the limit (72) will end up being processed.</p><p>Git blame shows that the  line is 11 years old</p><p>while the <code>if (j &gt;= databytes) j = 0;</code> is 28 years old (what were you busy with in 1997, ah?)</p><p>So, it’s been a while since the API has been reiterated.</p><p>Let me start with a short disclaimer: I have a huge respect for people who spend their free time and mental capacity on maintaining open-source projects. That’s a large amount of work, that is not paid, and, unfortunately, quite often not appreciated by the users of the tools. That’s why they have all the legal and ethical rights to build the project the way they see them. My opinions below are not targeted towards anyone in particular.</p><p>My initial goal was to create issues for each of the mentioned library, but I noticed that this behavior has been already reported to each of them:</p><p>Check the discussions and their outcomes by following those links.</p><p>As a guy who spent a few years of my career on building tools and solutions to be used by other software engineers, I understand the frustration: you invested your time and effort into writing a clear documentation and guides, but a certain number of your users don’t bother checking it at all, and just use the tool the way they think it should be used. However, that’s the reality that I had to accept and started thinking about how can I make my tools handle those use cases. Here are a few principles I came up with in that process.</p><h4>Don’t let the people use your API incorrectly</h4><p>In my opinion, from the API perspective, the approach when the tool silently cuts the part of the input and processes the remaining one only, it is an extremely poor design choice. What makes things worse is the fact that Bcrypt is used in the domain of security and sensitive data, and, as we can see, most of the tools mentioned above, use  as the name of the input parameter of the hashing method. <strong>The good design should explicitly reject the invalid input</strong> with the error / exception / any other mechanism the platform uses. So, basically, exactly what Go and Patrick’s Java library did. This way, incidents like Okta one would be impossible by design (btw, I’m not shifting the blame away from Okta, considering the domain they operate in).</p><p>It is ok, though, to offer the non-default unsafe option, that will let the users pass longer input that will be truncated if the user explicitly asks for that. A prefix/suffix like , , etc. can be a good addition to the names of the method that expose these options.</p><p>If we take a step back from the Bcrypt case, imagine other examples, if such a pattern becomes common in the industry:</p><ul><li>We created a new user account on HBO to watch a new season of Rick and Morty, and there is a warning that the max size of the password should not exceed 18 chars. However, the password generator of your password manager tool uses 25 chars as a default length of the produced password. So, the password manager inserts that password while creating an account, but the server cuts the last 7 chars, hashes the rest, and saves the hash to the DB. How easy would it be for us to be able to log in to HBO next time and watch a new episode?</li><li>The tech lead of the new project configured a linter tool, and set the max line length as 100 chars. While performing a check, linter removes the chars above the defined limit, and informs that the check has passed. How useful would it be?</li></ul><p>A good API design should remember that when it comes to tech, nobody likes surprises.</p><p>While following a few online discussions about the Bcrypt Okta incident, I noticed something else: while the majority of comments agreed that we should design APIs like these better, there were a few folks that took a very defensive stance and exposed their ego: “Read a paper before using anything!”, “APIs are only correcting the input after the stupid users!”, etc. Based on my experience, ego is a big enemy of engineering. And I wouldn’t be surprised if you have a story or two in that regard as well. So, yeah, let’s not bring our egos to our APIs.</p><p>Don’t get me wrong, I do understand the gist that the users should have some basic knowledge before using any tool. But let’s get back to the reality: how many different tools, programming languages, databases, protocols, frameworks, libraries, algorithms, data structures, clouds, AI models, etc. does a software engineer use per week these days? I tried to count for my use case, but stopped after the number had reached 30. Is it possible to know all of them deep? To know all the edge cases and limits? For some of them and to some degree is a reasonable ask, as well as having an expertise in 1 or 2, but definitely not all. The hard truth is that on average, the industry today requires the wide spectrum of knowledge over the deep one (check any job opening to verify that claim). Therefore, while designing the tools, why not to help our fellow colleagues? For example, if our tool accepts only positive numbers, let’s add <code>if num &lt; 1 -&gt; return error</code>  to our solution, and make the life simpler for somebody out there.</p><p>Especially, if the tool might be used in the security-sensitive context, where humans are usually the weak point in the thread modelling. The good API can help there.</p><p>It’s not so often that the API we design is something completely new to the world. Most likely, there are other solutions like ours out there. And the chances are that they’ve been already doing certain things the particular way. However, that doesn’t mean that we need to follow the same path. Kudos to the Go team and Patrick’s Java library for being brave to do things the different way as the industry does in the Bcrypt example. Let’s learn from them.</p><p>Regardless of the original design choices and intentions, it’s never too late to reiterate on some of them if we see a need or have discovered new information. That’s, actually, a place where a lot of us fail due to different reasons, with some of them listed above.</p><p>The Okta incident exposed large security issues out there. Our test showed, even 3 months after the incident, the industry is still vulnerable to the same outcome, so the chances are that more to come. However, we, as software engineers, can learn from that, and apply these lessons while designing APIs to make them predictable and easier to use.</p><p>I hope that was useful, and triggered some thoughts. Thanks a lot for reading my post, and see you in the following ones, there are plenty of topics to discuss. Have fun! =)</p>","contentLength":12880,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1ig50uz/what_okta_bcrypt_incident_can_teach_us_about/"},{"title":"DocumentDB: Open-Source MongoDB implementation based on PostgreSQL (from Microsoft)","url":"https://opensource.microsoft.com/blog/2025/01/23/documentdb-open-source-announcement/","date":1738512549,"author":"/u/mariuz","guid":326,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1ig0jlp/documentdb_opensource_mongodb_implementation/"},{"title":"What is PKCE Flow?","url":"https://www.hemantasundaray.com/blog/pkce-flow","date":1738507682,"author":"/u/sundaray","guid":323,"unread":true,"content":"<p>Proof Key for Code Exchange (PKCE, pronounced \"pixy\") is an extension of the Authorization Code grant type.</p><p>The Authorization Code grant type is used by OAuth 2.0 confidential and public clients to exchange an authorization code for an access token.</p><p>However, OAuth 2.0 public clients using the Authorization Code grant type are susceptible to authorization code interception attacks. This occurs when an attacker intercepts the authorization code within the client's operating system, in communication paths that aren't protected by TLS. The PKCE flow mitigates this security risk.</p><p>The PKCE flow has 5 main steps:</p><h3><a href=\"https://www.hemantasundaray.com/blog/pkce-flow#step-1-client-generates-a-code-verifier-and-a-code-challenge\"></a>Step 1: Client generates a code verifier and a code challenge</h3><p>The client first creates a code verifier.</p><p>A code verifier is a cryptographic random string with a minimum length of 43 characters and maximum length of 128 characters. The code verifier should have high entropy (<em>a high degree of randomness</em>), so that it’s practically impossible for anyone to guess its value.</p><p>The client then derives a code challenge from the code verifier in 3 steps:</p><ol><li>Converts the code verifier string into its byte form.</li><li>Converts the bytes into a fixed-length binary hash using the  algorithm (<em>known as the code challenge method</em>). This conversion is one-way, meaning you can't derive the original code verifier from the hash.</li><li>Converts the binary hash into a string with only URL-safe characters using base64url encoding.</li></ol><h3><a href=\"https://www.hemantasundaray.com/blog/pkce-flow#step-2-client-sends-an-authorization-request\"></a>Step 2: Client sends an Authorization Request</h3><p>The client sends an Authorization Request to the Authorization Server. In the request, it includes two important pieces of information: the code challenge and the code challenge method. The Authorization Server stores both these pieces of information.</p><h3><a href=\"https://www.hemantasundaray.com/blog/pkce-flow#step-3-authorization-server-issues-an-authorization-code\"></a>Step 3: Authorization Server issues an Authorization Code</h3><p>The Authorization Server responds by issuing an authorization code. Note that the server typically stores the code challenge and the code challenge method in an encrypted form in the authorization code itself.</p><h3><a href=\"https://www.hemantasundaray.com/blog/pkce-flow#step-4-client-sends-an-access-token-request\"></a>Step 4: Client sends an Access Token Request</h3><p>The client proceeds to request an access token. This request includes the authorization code and the original code verifier ().</p><h3><a href=\"https://www.hemantasundaray.com/blog/pkce-flow#step-5-authorization-server-issues-an-access-token\"></a>Step 5: Authorization Server issues an Access Token</h3><p>Before issuing an access token, the Authorization Server verifies that the request for access token has come from the same client that made the initial authorization request. This verification happens in two steps:</p><ol><li>The server takes the code verifier and transforms it into a code challenge using the code challenge method it had stored (<em>alongside the original code challenge</em>) in step 1.</li><li>The server then compares this newly generated code challenge with the original code challenge. If they match, proving it's the same client, the server issues an access token.</li></ol><h2><a href=\"https://www.hemantasundaray.com/blog/pkce-flow#how-pkce-flow-prevents-authorization-code-interception-attacks\"></a>How PKCE flow prevents authorization code interception attacks</h2><p>Let's say an attacker intercepts the authorization code. However, the attacker would not be able to exchange the stolen authorization code for an access token, because the attacker wouldn’t have the corresponding code verifier. Note that the code verifier can’t be intercepted by the attacker because it’s sent over TLS.</p><h2><a href=\"https://www.hemantasundaray.com/blog/pkce-flow#important-note-about-pkce\"></a>Important note about PKCE</h2><p>While PKCE was originally designed to secure native applications (<em>applications that are installed directly on a user’s devices such as a smartphone, or desktop and run natively on the operating system</em>), it's now recommended for all types of OAuth clients (<em>including confidential clients like server-side web applications</em>) because it provides strong protection against authorization code interception attacks.</p>","contentLength":3572,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1ifyr4z/what_is_pkce_flow/"},{"title":"Managing Secrets in Docker Compose — A Developer's Guide | Phase Blog","url":"https://phase.dev/blog/docker-compose-secrets/","date":1738501036,"author":"/u/ascendence","guid":325,"unread":true,"content":"<p>It's truly remarkable how much the direction of software engineering is dictated by inertia. Brendan Eich in 1995 designed JavaScript to be a client side scripting language of choice for the Netscape browser, over the years it has evolved to be on the client, server and other technologies like serverless. Similarly, Docker Compose has evolved from a local development tool into a popular choice for deploying applications, even in production environments. While Docker has published guidelines for <a href=\"https://docs.docker.com/compose/how-tos/production/\" rel=\"nofollow\">using Compose in production</a>, one critical aspect often overlooked by users is secure secret management.</p><p>In this guide, we'll explore the best practices for managing secrets in modern Docker Compose deployments and discuss common pitfalls to avoid. We'll progressively build up from basic approaches to more secure configurations.</p><h2>The Problem with Environment Variables</h2><p>Most Docker Compose setups handle secrets in one of two ways: either by hardcoding them directly in the compose file or using a  file:</p><p>While convenient, this approach has several security implications:</p><ol><li>Environment variables are accessible to all processes in a container</li><li>They often appear in logs during debugging</li><li>They can be exposed through application errors</li><li>They make it difficult to maintain separation of concerns between services</li></ol><p>Let's demonstrate why this is problematic. With a basic Postgres container running:</p><p>We can easily inspect all environment variables:</p><p>We can also directly print all environment variables from within the container:</p><p>This exposure of secrets through environment variables has led to numerous security incidents over the years:</p><p>Although the first two examples presume an application misconfiguration and most modern web application frameworks try their best to censor secrets in error logs, this can be a pretty serious issue.</p><p>Let's explore three progressively more secure approaches to managing secrets in Docker Compose.</p><p>First, ensure you're running Docker Compose version 2.30.0 or later for full secrets support:</p><p>Your application should also be configured to read secrets from files rather than environment variables. Here's a pattern we recommend for python, as an example:</p><ul><li>Prioritizes reading secrets from files using the  suffix convention</li><li>Maintains compatibility with environment variables as a fallback</li></ul><ol><li>For a given secret  check if  environment variable containing a file path exists, if yes - read the  secret from the file</li><li>Else, read the secret from the  environment variable</li></ol><h3>Approach 1: Environment Variables - Mount secrets inside your containers based on the values of host environment variables</h3><p>The following implementation uses Docker Compose's secrets feature to read environment variables from the host and mount them as files via a virtual filesystem in each of your services:</p><p>This mounts secrets as read-only virtual filesystem under :</p><ul><li>Easy setup - Simply mount the values of environment variables in memory as a filesystem</li><li>Secrets never written to disk - Secrets remain in memory, reducing attack surface from filesystem access</li><li>Better isolation between services - Each service only receives the secrets provisioned to it</li><li>Read-only mounting - Prevents accidental or malicious corruption of secrets by containers</li></ul><ul><li>Secrets exposed as host environment variables - Secrets must exist as environment variables on the host system - This can be addresses by using runtime secret injection via a secret manager such as <a href=\"https://phase.dev\" rel=\"nofollow\">Phase</a>.</li><li>World-readable within container - Any user, user group or process within the container can read the secrets (addressed in the next section)</li><li>Requires service restart for updates - Changes to secrets require restarting affected services to take effect</li></ul><p>Using things like  on your host system to set secrets as environment can create other unwanted externalities like your secrets getting logged in your shell history. You can use the <a href=\"https://docs.phase.dev/cli/usage#4-run-and-inject-secrets\" rel=\"nofollow\">Phase CLI</a> to to improve the overall secret management workflow by injecting secrets directly inside the docker compose process during runtime. Here's an example:</p><h3>Approach 2: File-Based Secrets - Mount secrets on the host system inside your container</h3><p>The following implementation uses Docker Compose's secrets feature to mount files containing secrets from the host in each of your services:</p><ul><li>Better isolation between services - Each service only receives the secrets provisioned to it</li><li>Dynamic secret updates without restarts - Services can read updated secrets without container restarts</li><li>Inherits host file permissions - Secret files maintain their permission attributes from the host system</li><li>Read-only mounting - Prevents accidental or malicious corruption of secrets by containers</li></ul><ul><li>Secrets written to disk on the host system - Creates potential security risk from filesystem access or backups</li><li>Requires secure file management - Additional operational overhead to secure secret files</li><li>World-readable by default - All users/processes in container can read secrets unless explicitly restricted - Addressed in the next section</li></ul><p>To make creation of secrets on the host system easier and to improve the overall secret management workflow you can use the <a href=\"https://docs.phase.dev/cli/commands#secrets-get\" rel=\"nofollow\">Phase CLI</a>. Here's an example:</p><h3>Controlling access to secrets supplied to your services</h3><p>Now that we have figured out how to supply secrets securely to your services, next let's take a look how at how we can better protect them once provisioned inside our containers:</p><p>Docker Compose supports what they call a 'long syntax' for declaring how secrets are provisioned and controlling their access with more granularity within the respective service's containers.</p><ul><li>: The name of the secret as it exists on the platform.</li><li>: The name of the file to be mounted in /run/secrets/ in the service's task container, or absolute path of the file if an alternate location is required. Defaults to source if not specified.</li><li> and : The numeric UID or GID that owns the file within /run/secrets/ in the service's task containers. Default value is USER running container.</li><li>: The permissions for the file to be mounted in /run/secrets/ in the service's task containers, in octal notation. The default value is world-readable permissions (mode 0444). The writable bit must be ignored if set. The executable bit may be set.</li></ul><p>You can find the  and the  of for a given image by looking at the Dockerfile or if it's your own image add one.</p><p>Here's a postgresql example:</p><ul><li>Restricts secret access to specific users/groups</li><li>Prevents other users from reading secrets</li><li>Maintains write protection</li></ul><p>You can verify the permissions:</p><p>For more information on the Docker Compose secrets long syntax, please see the <a href=\"https://docs.docker.com/reference/compose-file/services/#long-syntax-4\" rel=\"nofollow\">Docker docs</a></p><p>While this is a good start for your docker compose secrets, below are some of the things that you should most consider when dealing with informational fissile materials like secrets:</p><ol><li><p>Keep secrets away from source code, container files and images. Ivory and ebony, AC/AD and secrets and source code and container images; never the two shall meet.</p></li><li><p>Control access to secrets and keep them in sync and up to date with the rest of your team and deployments securely. Please do not add secrets to your git repository, drop your .env files over Slack or add them to your Notion docs as part of getting started with a project.</p></li><li><p>Don't reuse secrets across different environments. Your production database password should never be the same as the  that you are using for local development. Compromise of one will mean de-facto compromise of all.</p></li><li><p>Encrypt secrets at all times, whether they are in flight over a network making they way to your production deployment or waiting in a database patiently to be pulled. <em>\"Dance like no one is watching, but encrypt like everyone is\"</em> - Werner Vogels, Chief Technical Officer Amazon.</p></li><li><p>Keep track of all changes and actions over your secrets. <a href=\"https://www.youtube.com/watch?v=H9DrxT5meE8\" rel=\"nofollow\">It's 4:30 in the morning, do you know where your secrets are?</a> Keep tabs on the who, what, when, and where so you can infer the  if and when there is an incident. Given the outsized number of breaches that occur due to a secret compromise, you will need those audit logs during an investigation.</p></li></ol><p>Some or all of these points may seem obvious to most of you reading this, but what may not be as obvious is how tricky and tedious it can be to follow security best practices without losing development velocity. Consider using open-source secrets management platform like <a href=\"https://phase.dev\" rel=\"nofollow\">Phase</a> which can help streamline the process. We are a bit biased plugging our own solution, but we think you'll find it useful.</p><p>Docker Compose's secret management capabilities have matured significantly, offering features typically found in larger container orchestration systems. While there are still some areas of improvements and limitations around permission enforcement (see <a href=\"https://github.com/docker/compose/issues/12362\" rel=\"nofollow\">docker/compose#12362</a>), the available options provide a solid foundation for securing secrets in both development and smaller production environments.</p>","contentLength":8794,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1ifwnz9/managing_secrets_in_docker_compose_a_developers/"},{"title":"Unexpected Benefits of Building Your Own Tools","url":"https://tiniuc.com/make-more-tools/","date":1738492875,"author":"/u/tiniucIx","guid":324,"unread":true,"content":"<ul></ul><p>Recently I've been thinking a lot about some of the tools I've made, and I have found an insight from game development that I think can apply to the software engineering industry as a whole.</p><h2>The origin of the insight</h2><p>I'm <a href=\"https://tiniuc.com/botnet-of-ares/\">working on a hacking simulator, Botnet of Ares</a> and part of the work involves designing and balancing the parameters for the various Exploits that the player can use. For context, these Exploits are kind of equivalent to items in an Role-Playing Game. They have stats similar to \"Damage\", \"Attack Speed\", \"Mana Cost\", except framed in the context of a computer thread performing work - so the rough equivalents in my game would be \"Machine Speed\", \"Loss Wait Time\" &amp; the various \"Per Machine\" costs, respectively.</p><p>This used to be done in a spreadsheet, and the process involved copy-pasting ~10 fields every time I wanted to move something into or out of the game.</p><img src=\"https://tiniuc.com/make-more-tools/exploit-spreadsheet.png\" alt=\"Spreadsheet editor for Botnet of Ares Exploits, with ~10 user input fields and ~10 descriptive &amp; balance related fields.\"><p>At some point I realized that I am spending an eternity staring at spreadsheets and it was just no fun for this sort of task. Furthermore, I was wasting a lot of time copy-pasting things into Godot (the game engine I am using), play-testing, noticing something is wrong, going back to the spreadsheet, editing, copy-pasting again etc. etc. etc.</p><p>So I decided to implement my own editor which can save &amp; load directly using the Godot  format. It's super quick &amp; dirty &amp; not optimized at all, but it's already made the process of creating content for the game much faster.</p><img src=\"https://tiniuc.com/make-more-tools/exploit-editor.png\" alt=\"Exploit Editor for Botnet of Ares. Has similar fields to the Spreadsheet editor, but provides much more information and is significantly faster to work with.\"><p>All this is is a little editor that lets me input stats for the various exploits, shows a bit of info on the right side about its balance, and then outputs a scene file that can be loaded directly into the game.</p><p>What this has made me realize is that <strong>speeding up part of a workflow can provide value far beyond the mere time savings</strong>: it also unlocks new ways of working that were not possible before. For example, with the Exploit Editor I can go over entire lines of devices and balance them in relation to each other. This used to be incredibly tedious to do with the spreadsheet because of all the tedious copy-pasting required to import from the editor. But now, I can edit dozens of scenes and remain in a state of flow throughout.</p><p>The editor has made the creation of these Exploits at least an order of magnitude faster, and has also increased the quality of content I can make by letting me iterate much faster. Not too shabby for ~4 hours of work!</p><h2>Iteration velocity: the insight from game development</h2><p>I was motivated to build the Exploit Editor for Botnet of Ares thanks to a common principle in game development: to design a good game, you must iterate through as many versions of the game as you can, keeping the parts that are fun, getting rid of the ones that are not &amp; improving the game at any step. Essentially, the more iterations of the design you can make, the higher quality your game will be - limited, of course, by your budget.</p><p>I built the Exploit Editor because I could not iterate through various item designs quickly enough, and as a result I now have many more items in the game, and they are all higher quality than they would be without this tool.</p><p>This is a well-known principle in the games development industry - in bigger studios there is often a team dedicated to building &amp; supporting tools &amp; editors for designers &amp; other folks to use. And I think this principle has applications far beyond game development.</p><h2>Application from work - the chilictl utility</h2><p>During my day job I have worked on an utility called \"chilictl.\" It allows one to list embedded devices connected to the PC, see basic information about them &amp; flash a new application.</p><pre><code>$ ./chilictl list\n2020-12-16 12:53:35.897 NOTE:  Cascoda SDK v0.14 Dec 16 2020\nDevice Found:\n        Device: Chili2\n        App: mac-dongle\n        Version: v0.21-71-g49212790\n        Serial No: FBC647CDB300A0DA \n        Path: 0001:0051:00\n        Available: Yes\n        External Flash Chip Available: Yes\n$ ./chilictl flash -s FBC647CDB300A0DA -df \"~/sdk-chili2/bin/ldrom_hid.bin\"\n2020-12-16 12:56:46.510 NOTE:  Cascoda SDK v0.14 Dec 16 2020\nFlasher [FBC647CDB300A0DA]: INIT -&gt; REBOOT\nFlasher [FBC647CDB300A0DA]: REBOOT -&gt; ERASE\nFlasher [FBC647CDB300A0DA]: ERASE -&gt; FLASH\nFlasher [FBC647CDB300A0DA]: FLASH -&gt; VERIFY\nFlasher [FBC647CDB300A0DA]: VERIFY -&gt; VALIDATE\nFlasher [FBC647CDB300A0DA]: VALIDATE -&gt; COMPLETE\n</code></pre><p>All of these things are things you could already do in other ways before the tool was created. For example, you could find the serial number by connecting to the USB debug API &amp; looking for the right . Or you could flash devices by digging through your drawer, getting your JLink programmer out, making sure the flimsy 10-pin JTAG cable hasn't snapped a wire internally like the other 5 you've had to throw out this year, opening the correct programming utility &amp; then finally flashing.</p><p>You can see where I'm going with this. A single utility was created that removes 90% of the tedium. The tool would have been worth it for this reason alone, but now my colleagues have incorporated it in countless workflows. Here are some examples:</p><ul><li>automated Hardware-In-The-Loop nightly test harness that notifies people whenever someone's  broken prod</li><li>modifying serial numbers &amp; security credentials en masse, for tests &amp; development work that requires devices with different identities.</li><li>unit tests for the parts of the code that were prone to bugs &amp; hard to keep an eye on until now</li><li>tests and experiments involving different binaries across dozens of devices</li><li>simply programming the hardware you're working on without having to fiddle with wires</li></ul><p>The crucial insight is that <strong>none of these applications would have been obvious without being able to flash devices an order of magnitude faster</strong>. And  was not designed to be built into these! All of these applications were unlocked once we had experience with the new utility.</p><p>One of the highest returns on investment I've had on workflow automation was the script below. It rebuilds an OpenWRT image from scratch with updated dependencies.</p><pre data-lang=\"bash\"><code data-lang=\"bash\">#!/bin/sh\n./scripts/feeds update -a\n./scripts/feeds install -a\nmake clean\nmake -j12\n# Write logs to file, for debugging\n#make -j12 V=sc -k 2&gt;&amp;1 | tee build_log.txt\ncmatrix -b\n</code></pre><p>Ive lost count of how many times I ran  without first updating the feed I was working on! The call to  at the end plays a Matrix inspired stream of green characters the moment the build finishes. This solves the problem of starting the build, working on something else &amp; not noticing that the build has completed even when it was a rather high priority task!</p><p>Lets say this script took five minutes to write. If it saves one rebuild, <em>it has already paid for itself four times over</em>. It has saved  more time since. Thanks to this script, debugging certain things that used to take a whole day now can be done in just a few hours.</p><p>I think many people could benefit from creating more tools for their own needs. Think of the fraction of your work that you hate the most, and see if there's any way you can remove some of the tedium from it. Even a little bit of automation helps a lot if you are automating a common frustrating task.</p><p>And often, you will find that these tools will let you work in new and surprising ways. Ways in which would not have been obvious had you not built the tool in the first place. This leads not just to building your application faster, but <em>building a higher quality application</em> as well thanks to the benefits of iterative development. As the saying goes, quantity has a quality all its own.</p>\n\n    \n    tagged\n    \n\t<a href=\"https://tiniuc.com/tags/development/\">Development</a>","contentLength":7515,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1ifunbl/unexpected_benefits_of_building_your_own_tools/"}],"tags":["dev","reddit"]}