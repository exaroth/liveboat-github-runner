{"id":"EfcLDDAkyqguXw9Vbtcae7fRhxCsY1chPUNLpwbK9oHS42b4dGEMeGvA2hWHB2j3LFSAo7qhibLNgPBcA5djbGp95Jk5T","title":"top scoring links : programming","displayTitle":"Reddit - Programming","url":"https://www.reddit.com/r/programming/top/.rss?sort=top&t=day&limit=6","feedLink":"https://www.reddit.com/r/programming/top/?sort=top&t=day&limit=6","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":6,"items":[{"title":"No, Google Did Not Unilaterally Decide to Kill XSLT","url":"https://meyerweb.com/eric/thoughts/2025/08/22/no-google-did-not-unilaterally-decide-to-kill-xslt/","date":1755926466,"author":"/u/AlyoshaV","guid":605,"unread":true,"content":"<p>It’s uncommon, but not unheard of, for a GitHub issue to spark an uproar.&nbsp; That happened over the past month or so as the WHATWG (Web Hypertext Application Technology Working Group, which I still say should have called themselves a Task Force instead) issue “<a href=\"https://github.com/WHATWG/html/issues/11523\">Should we remove XSLT from the web platform?</a>” was opened, debated, and eventually locked once the comment thread started spiraling into personal attacks.&nbsp; Other discussions have since opened, such as <a href=\"https://github.com/whatwg/html/issues/11578\"> a counterproposal to update XSLT in the web platform</a>, thankfully with (thus far) much less heat.</p><p>If you’re new to the term, XSLT (Extensible Stylesheet Language Transformations) is an XML language that lets you transform one document tree structure into another.&nbsp; If you’ve ever heard of people styling their RSS and/or Atom feeds to look nice in the browser, they were using some amount of XSLT to turn the RSS/Atom into HTML, which they could then CSS into prettiness.</p><p>This is not the only use case for XSLT, not by a long shot, but it does illustrate the sort of thing XSLT is good for.&nbsp; So why remove it, and who got this flame train rolling in the first place?</p><p>Before I start, I want to note that in this post, I won’t be commenting on whether or not XSLT support should be dropped from browsers or not.&nbsp; I’m also not going to be systematically addressing the various reactions I’ve seen to all this.&nbsp; I have my own biases around this — some of them in direct conflict with each other! — but my focus here will be on what’s happened so far and what might lie ahead.</p><p>As a very quick background, various people have proposed removing XSLT support from browsers a few times over the quarter-century-plus since support first landed.&nbsp; It was discussed in both the early and mid-2010s, for example.&nbsp; At this point, browsers all more or less support<a href=\"https://www.w3.org/TR/xslt-10/\">XSLT 1.0</a>, whereas the latest version of XSLT is <a href=\"https://www.w3.org/TR/xslt-30/\">3.0</a>.&nbsp; I believe they all do so with C++ code, which is therefore not memory-safe, that is baked into the code base rather than supported via some kind of plugged-in library, like Firefox using <a href=\"https://github.com/mozilla/pdf.js\"> PDF.js</a> to support PDFs in the browser.</p><p>Anyway, back on August 1st, Mason Freed of Google opened <a href=\"https://github.com/WHATWG/html/issues/11523\">issue #11523</a> on WHATWG’s HTML repository, asking if XSLT should be removed from browsers and giving a condensed set of reasons why it might be a good idea.&nbsp; He also included a WASM-based polyfill he’d written to provide XSLT support, should browsers remove it, and opened “<a href=\"https://issues.chromium.org/issues/435623334\"> Investigate deprecation and removal of XSLT</a>” in the Chromium bug tracker.</p><p>“So it’s already been decided and we just have to bend over and take the changes our Googlish overlords have decreed!” many people shouted.&nbsp; It’s not hard to see where they got that impression, given some of the things Google has done over the years, but that’s  what’s happening here.&nbsp; Not at this point.&nbsp; I’d like to set some records straight, as an outside observer of both Google and the issue itself.</p><p>First of all, while Mason was the one to open the issue, this was done because the idea was raised in a periodic WHATNOT meeting (call), where someone at Mozilla was actually the one to bring it up, after it had come up in various conversations over the previous few months.&nbsp; After Mason opened the issue, members of the Mozilla and WebKit teams expressed (tentative, mostly) support for the idea of exploring this removal.&nbsp; Basically,  of the vendors are particularly keen on keeping native XSLT support in their codebases, particularly after <a href=\"https://www.neowin.net/news/google-project-zero-exposes-security-flaw-in-libxslt-library-used-in-gnome-applications/\"> security flaws were found</a> in XSLT implementations.</p><p>This isn’t the first time they’ve all agreed it might be nice to slim their codebases down a little by removing something that doesn’t get a lot of use (relatively speaking), and it won’t be the last.&nbsp; I bet they’ve all talked at some point about how nice it would be to remove <a href=\"https://en.wikipedia.org/wiki/BMP_file_format\">BMP</a> support.</p><p>Mason mentioned that they didn’t have resources to put toward updating their XSLT code, and got widely derided for it. “Google has trillions of dollars!” people hooted.&nbsp;  has trillions of dollars.&nbsp; The Chrome team very much does not.&nbsp; They probably get, at best, a tiny fraction of one percent of those dollars.&nbsp; Whether Google should give the Chrome team more money is essentially irrelevant, because that’s not in the Chrome team’s control.&nbsp; They have what they have, in terms of head count and time, and have to decide how those entirely finite resources are best spent.</p><p>(I will once again invoke my late-1900s formulation of <a href=\"https://en.wikipedia.org/wiki/Hanlon's_razor\">Hanlon’s Razor</a>: <em> Never attribute to malice that which can be more adequately explained by resource constraints.</em>)</p><p>Second of all, the issue was opened to start a discussion and gather feedback as the first stage of a multi-step process, one that could easily run for years.&nbsp; Google, as I assume is true for other browser makers, has a pretty comprehensive method for working out whether removing a given feature is tenable or not.&nbsp; <a href=\"https://bkardell.com\">Brian</a> and I <a href=\"https://www.igalia.com/chats/unshipping\"> talked with Rick Byers about it</a> a while back, and I was impressed by both how many things been removed, and what they do to make sure they’re removing the right things.</p><p>Here’s one (by no means the only!) way they could go about this:</p><ol type=\"1\"><li>Set up a switch that allows XSLT to be disabled.</li><li>In the next release of Chrome, use the switch to disable XSLT in one percent of all Chrome downloads.</li><li>See if any bug reports come in about it.&nbsp; If so, investigate further and adjust as necessary if the problems are not actually about XSLT.</li><li>If not, up the percentage of XSLT-disabled downloads a little bit at a time over a number of releases.&nbsp; If no bugs are reported as the percentage of XSLT-disabled users trends toward 100%, then prepare to remove it entirely.</li><li>If, on the other hand, it becomes clear that removing XSLT will be a widely breaking change  — &nbsp;where “widely” can still mean a very tiny portion of their total user base — then XSLT can be re-enabled for all users as soon as possible, and the discussion taken back up with this new information in hand.</li></ol><p>Again, that is just one of several approaches Google could take, and it’s a lot simpler than what they would most likely actually do, but it’s roughly what they default to, as I understand it.&nbsp; The process is slow and deliberate, building up a picture of actual use and user experience.</p><p>Third of all, opening a bug that includes a pull request of code changes isn’t a declaration of countdown to merge, it’s a way of making crystal clear (to those who can read the codebase) exactly what the proposal would entail.&nbsp; It’s basically a requirement for the process of making a decision to start, because it sets the exact parameters of what’s being decided on.</p><p>That said, as a result of all this, I now strongly believe that every proposed-removal issue should point to the process and where the issue stands in it. (And write down the process if it hasn’t been already.) This isn’t for the issue’s intended audience, which was other people within WHATWG who are familiar with the usual process and each other, but for cases of context escape, like happened here.&nbsp; If a removal discussion is going to be held in public, then it should assume the general public will see it and provide enough context for the general public to understand the actual nature of the discussion.&nbsp; In the absence of that context, the nature of the discussion will be assumed, and every assumption will be different.</p><p>There is one thing that we should all keep in mind, which is that “remove from the web platform” really means “remove from browsers”.&nbsp; Even if this proposal goes through, XSLT could still be used server-side.&nbsp; You could use libraries that support XSLT versions more recent than 1.0, even!&nbsp; Thus, XML could still be turned into HTML, just not in the client via native support, though JS or WASM polyfills, or even add-on extensions, would still be an option.&nbsp; Is that good or bad?&nbsp; Like everything else in our field, the answer is “it depends”.</p><p>Just in case your eyes glazed over and you quickly skimmed to see if there was a TL;DR, here it is:</p><p><em>The discussion was opened by a Google employee in response to interest from multiple browser vendors in removing built-in XSLT, following a process that is opaque to most outsiders.&nbsp; It’s a first step in a multi-step evaluation process that can take years to complete, and whose outcome is not predetermined.&nbsp; Tempers flared and the initial discussion was locked; the conversation continues elsewhere.&nbsp; There are good reasons to drop native XSLT support in browsers, and also good reasons to keep or update it, but XSLT is not itself at risk.</em></p>","contentLength":8626,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1mxswpp/no_google_did_not_unilaterally_decide_to_kill_xslt/"},{"title":"Coinbase CEO explains why he fired engineers who didn’t try AI immediately","url":"https://techcrunch.com/2025/08/22/coinbase-ceo-explains-why-he-fired-engineers-who-didnt-try-ai-immediately/","date":1755924216,"author":"/u/diegoargento1","guid":609,"unread":true,"content":"<p>It’s hard to find programmers these days who aren’t using AI coding assistants in some capacity, especially to write the repetitive, mundane bits.</p><p>But those who refused to try the tools when Coinbase bought enterprise licenses for GitHub Copilot and Cursor got promptly fired, CEO Brian Armstrong said this week on John Collison’s podcast <a href=\"https://www.youtube.com/watch?v=JeVny5KHj4g&amp;list=PLcoWp8pBTM3ATMYLP-hFIhJORSw-nFOiY&amp;index=2\" target=\"_blank\" rel=\"noreferrer noopener nofollow\">“Cheeky Pint.”</a> (Collison is the co-founder and president of the payments company Stripe.)</p><p>After getting licenses to cover every engineer, some at the cryptocurrency exchange warned Armstrong that adoption would be slow, predicting it would take months to get even half the engineers using AI.&nbsp;</p><p>Armstrong was shocked at the thought. “I went rogue,” he said, and posted a mandate in the company’s main engineering Slack channel. “I said, ‘AI is important. We need you to all learn it and at least onboard. You don’t have to use it every day yet until we do some training, but at least onboard by the end of the week. And if not, I’m hosting a meeting on Saturday with everybody who hasn’t done it and I’d like to meet with you to understand why.’”&nbsp;</p><p>At the meeting, some people had reasonable explanations for not getting their AI assistant accounts set up during the week, like being on vacation, Armstrong said.</p><p>“I jumped on this call on Saturday and there were a couple people that had not done it. Some of them had a good reason, because they were just getting back from some trip or something, and some of them didn’t [have a good reason]. And they got fired.”</p><p>Armstrong admits that it was a “heavy-handed approach” and there were people in the company who “didn’t like it.”</p><p>While it doesn’t sound like very many people were fired, Armstrong said it sent a clear message that AI is not optional. Still, everything about that story is wild: that there were engineers who wouldn’t spend a few minutes of their week signing up for and testing the AI assistant — the most hyped tech for coders ever — and that Armstrong was willing to fire them over it.</p><p>Coinbase did not respond to a request for comment.</p><p>Since then, Armstrong has leaned further into the training. He said the company hosts monthly meetings where teams who have mastered creative ways to use AI share what they have learned.</p><p>Interestingly, Collison, who has been <a href=\"https://fintechmagazine.com/articles/the-collison-brothers\" target=\"_blank\" rel=\"noreferrer noopener nofollow\">programming since childhood</a>, questioned how much companies should be relying on AI-generated code.</p><p>“It’s clear that it is very helpful to have AI helping you write code. It’s not clear how you run an AI-coded code base,” he commented.  Armstrong replied, “I agree.”</p><p>Indeed, as TechCrunch previously reported, <a href=\"https://techcrunch.com/2025/07/15/a-former-openai-engineer-describes-what-its-really-like-to-work-there/\">a former OpenAI engineer described</a> that company’s central code repository as “a bit of a dumping ground.” The engineer said management had begun dedicating engineering resources to improve the situation.</p><p><em>We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&nbsp;</em><em>&nbsp;to let us know how we’re doing and get the chance to win a prize in return!</em></p>","contentLength":3093,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1mxs92h/coinbase_ceo_explains_why_he_fired_engineers_who/"},{"title":"Netbeans 27 Released","url":"https://lists.apache.org/thread/py28oztx51vhk4f1js3q54vpx8pwzbb3","date":1755908352,"author":"/u/BlueGoliath","guid":604,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1mxn10t/netbeans_27_released/"},{"title":"Weaponizing image scaling against production AI systems - AI prompt injection via images","url":"https://blog.trailofbits.com/2025/08/21/weaponizing-image-scaling-against-production-ai-systems/","date":1755885633,"author":"/u/grauenwolf","guid":606,"unread":true,"content":"<p>Picture this: you send a seemingly harmless image to an LLM and suddenly it exfiltrates all of your user data. By delivering a multi-modal prompt injection not visible to the user, we achieved data exfiltration on systems including the Google Gemini CLI. This attack works because AI systems often scale down large images before sending them to the model: when scaled, these images can reveal prompt injections that are not visible at full resolution.</p><p>In this blog post, we’ll detail how attackers can <a href=\"https://www.usenix.org/conference/usenixsecurity20/presentation/quiring\">exploit image scaling</a> on Gemini CLI, Vertex AI Studio, Gemini’s web and API interfaces, Google Assistant, Genspark, and other production AI systems. We’ll also explain how to mitigate and defend against these attacks, and we’ll introduce <a href=\"https://github.com/trailofbits/anamorpher\">Anamorpher</a>, our open-source tool that lets you explore and generate these crafted images.</p><p>: <a href=\"https://www.usenix.org/conference/usenixsecurity19/presentation/xiao\">Image scaling attacks</a> were used for model <a href=\"https://arxiv.org/abs/2003.08633\">backdoors, evasion, and poisoning</a> primarily against older computer vision systems that enforced a fixed image size. While this constraint is less common with newer approaches, the systems surrounding the model may still impose constraints calling for image scaling. This establishes an underexposed, yet widespread vulnerability that we’ve weaponized for <a href=\"https://developer.nvidia.com/blog/how-hackers-exploit-ais-problem-solving-instincts/\">multi-modal prompt injection</a>.</p><h2>Data exfiltration on the Gemini CLI</h2><p>To set up our data exfiltration exploit on the Gemini CLI through an image-scaling attack, we applied the default configuration for the Zapier MCP server. This automatically approves all MCP tool calls without user confirmation, <a href=\"https://github.com/google-gemini/gemini-cli/issues/5598\">as it sets  in the  of the Gemini CLI</a>. This provides an important primitive for the attacker.</p><p>Figure 2 showcases a video of the attack. First, the user uploads a seemingly benign image to the CLI. With no preview available, the user cannot see the transformed, malicious image processed by the model. This image and its prompt-ergeist triggers actions from Zapier that exfiltrates user data stored in Google Calendar to an attacker’s email without confirmation.</p><p>We also successfully demonstrated image scaling attacks on the following:</p><ul><li>Vertex AI with a Gemini back end</li><li>Gemini’s API via the  CLI</li><li>Google Assistant on an Android phone</li></ul><p>Notice the persistent mismatch between user perception and model inputs in figures 3 and 4. The exploit is particularly impactful on Vertex AI Studio because the front-end UI shows the high-resolution image instead of the downscaled image perceived by the model.</p><p>Our testing confirmed that this attack vector is widespread, extending far beyond the applications and systems documented here.</p><h2>Sharpening the attack surface</h2><p>These image scaling attacks exploit downscaling algorithms (or <a href=\"https://guide.encode.moe/encoding/resampling.html\">image resampling algorithms</a>), which perform interpolation to turn multiple high resolution pixel values into a single low resolution pixel value.</p><p>There are three major downscaling algorithms: <a href=\"https://en.wikipedia.org/wiki/Nearest-neighbor_interpolation\">nearest neighbor interpolation</a>, <a href=\"https://en.wikipedia.org/wiki/Bilinear_interpolation\">bilinear interpolation</a>, and <a href=\"https://en.wikipedia.org/wiki/Bicubic_interpolation\">bicubic interpolation</a>. Each algorithm requires a different approach to perform an image scaling attack. Furthermore, these algorithms are implemented differently across libraries (e.g., Pillow, PyTorch, OpenCV, TensorFlow), with varying anti-aliasing, alignment, and kernel phases (in addition to <a href=\"https://bartwronski.com/2021/02/15/bilinear-down-upsampling-pixel-grids-and-that-half-pixel-offset/\">distinct bugs</a> that historically have <a href=\"https://arxiv.org/abs/2104.11222\">plagued model performance</a>). These differences also impact the techniques necessary for an image scaling attack. Therefore, exploiting production systems required us to fingerprint each system’s algorithm and implementation.</p><p>To understand why image downscaling attacks are possible, imagine that you have a long ribbon with an intricate yet regular pattern on it. As this ribbon is pulled past you, you’re trying to recreate the pattern by grabbing samples of the ribbon at regular intervals. If the pattern changes rapidly, you need to grab samples very frequently to capture all the details. If you’re too slow, you’ll miss crucial parts between grabs, and when you try to reconstruct the pattern from your samples, it looks completely different from the original.</p><h2>Anamorpher and the attacker’s darkroom</h2><p>Currently, Anamorpher (named after <a href=\"https://en.wikipedia.org/wiki/Anamorphosis\">anamorphosis</a>) can develop crafted images for the aforementioned three major methods. Let’s explore how Anamorpher exploits bicubic interpolation frame by frame.</p><p>Bicubic interpolation considers the 16 pixels (from 4x4 sampling) around each target pixel, using cubic polynomials to calculate smooth transitions between pixel values. This method creates a predictable mathematical relationship that can be exploited. Specifically, the algorithm assigns different weights to pixels in the neighborhood, creating pixels that contribute more to the final output, which are known as high-importance pixels. Therefore, the total <a href=\"https://en.wikipedia.org/wiki/Luma_(video)\">luma</a> (brightness) of dark areas of an image will increase if specific high-importance pixels are higher luma than their surroundings.</p><p>Therefore, to exploit this, we can carefully craft high-resolution pixels and solve the inverse problem. First, we select a decoy image with large dark areas to hide our payload. Then, we adjust pixels in dark regions and push the downsampled result toward a red background using least-squares optimization. These adjustments in the dark areas cause the background to turn red while text areas remain largely unmodified and appear black, creating much stronger contrast than visible at full resolution. While this approach is most effective on bicubic downscaling, it also works on specific implementations of bilinear downscaling.</p><p>Anamorpher provides users with the ability to visualize and craft image scaling attacks against specific algorithms and implementations through a front-end interface and Python API. In addition, it comes with a modular back end, which enables users to customize their own downscaling algorithm.</p><p>While some downscaling algorithms are more vulnerable than others, attempting to identify the least vulnerable algorithm and implementation is <a href=\"https://arxiv.org/abs/2104.08690\">not a robust approach</a>. This is especially true since image scaling attacks are not restricted to the aforementioned three algorithms.</p><p>For a secure system, we recommend not using image downscaling and simply limiting the upload dimensions. For any transformation, but especially if downscaling is necessary, the end user should always be provided with a preview of the input that the model is actually seeing, even in CLI and API tools.</p><p><a href=\"https://github.com/trailofbits/anamorpher\">Anamorpher</a> is currently in beta, so feel free to reach out with feedback and suggestions as we continue to improve this tool. Stay tuned for more work on the security of multi-modal, agentic, and multi-agentic AI systems!</p>","contentLength":6551,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1mxdmty/weaponizing_image_scaling_against_production_ai/"},{"title":"XSLT removal will break multiple government and regulatory sites across the world","url":"https://github.com/whatwg/html/issues/11582","date":1755885585,"author":"/u/Comfortable-Site8626","guid":608,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1mxdm22/xslt_removal_will_break_multiple_government_and/"},{"title":"Vibe Debugging: Enterprises' Up and Coming Nightmare","url":"https://marketsaintefficient.substack.com/p/vibe-debugging-enterprises-up-and","date":1755877803,"author":"/u/bullionairejoker","guid":607,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1mxa6hn/vibe_debugging_enterprises_up_and_coming_nightmare/"}],"tags":["dev","reddit"]}