{"id":"2Qhhdda6Qnbf8RCfUPd4nB9sSt2WDQfEpF7H3gCnZZ4AsfbGMy3RmrCa6gigGY6TkbrrJn4wmHXXNYcVj1bK","title":"top scoring links : rust","displayTitle":"Reddit - Rust","url":"https://www.reddit.com/r/rust/top/.rss?sort=top&t=day&limit=6","feedLink":"https://www.reddit.com/r/rust/top/?sort=top&t=day&limit=6","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":6,"items":[{"title":"hashify: Fast perfect hashing without runtime dependencies","url":"https://www.reddit.com/r/rust/comments/1ib38cg/hashify_fast_perfect_hashing_without_runtime/","date":1737965348,"author":"/u/StalwartLabs","guid":525,"unread":true,"content":"<p>I'd like to announce the release of <a href=\"https://github.com/stalwartlabs/hashify\">hashify</a>, a new Rust procedural macro crate for generating perfect hashing maps and sets at compile time with <strong>zero runtime dependencies</strong>. Hashify provides two approaches tailored to different dataset sizes. For smaller maps (fewer than 500 entries), it uses an optimized method inspired by <a href=\"https://www.gnu.org/software/gperf/\">GNU's perf</a>, while for larger maps, it relies on the <a href=\"https://arxiv.org/abs/2104.10402\">PTHash Minimal Perfect Hashing</a> algorithm to ensure fast and compact lookups.</p><p>Hashify was built with performance in mind. <a href=\"https://github.com/stalwartlabs/hashify/blob/main/benches/phf_bench.rs\">Benchmarks</a> show that tiny maps are over  than the Rust <a href=\"https://crates.io/crates/phf\">phf</a> crate (which uses the <a href=\"http://cmph.sourceforge.net/papers/esa09.pdf\">CHD algorithm</a>), and large maps are about . It’s an excellent choice for applications like compilers, parsers, or any lookup-intensive algorithms where speed and efficiency are critical.</p><p>This initial release uses the FNV-1a hashing algorithm, which performs best with maps consisting of short strings. If you’re interested in using alternative hashing algorithms, modifying the crate is straightforward. Feel free to open a GitHub issue to discuss or contribute support for other algorithms.</p><p>Looking forward to hearing your feedback! The crate is available on <a href=\"https://crates.io/crates/hashify\">crates.io</a>.</p><p>: If you’re attending <a href=\"https://fosdem.org/2025/\">FOSDEM'25</a> this Saturday in Brussels, I’ll be presenting <a href=\"https://github.com/stalwartlabs/mail-server\">Stalwart Mail Server</a> (a Rust-based mail server) at 12 PM in the <a href=\"https://fosdem.org/2025/schedule/event/fosdem-2025-4571-stalwart-mail-server/\">Modern Email devroom</a>. Come by if you’re curious about Rust in email systems, or catch me before or after the presentation to talk about Rust, hashify, or anything else Rust-related.</p>","contentLength":1477,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How do popular Rust UI libraries compare? Iced vs Slint vs Egui","url":"https://www.reddit.com/r/rust/comments/1iavpit/how_do_popular_rust_ui_libraries_compare_iced_vs/","date":1737939640,"author":"/u/nikitarevenco","guid":526,"unread":true,"content":"<div><p>For creating a desktop application, I've come across 3 libraries which I'm thinking of using:</p><p>Which one would you use and why? If you have another library in mind I would love to hear it. </p></div>   submitted by   <a href=\"https://www.reddit.com/user/nikitarevenco\"> /u/nikitarevenco </a>","contentLength":223,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Learning Rust is like running a marathon — you need cardio!","url":"https://www.reddit.com/r/rust/comments/1iaqh5i/learning_rust_is_like_running_a_marathon_you_need/","date":1737925763,"author":"/u/orionwambert","guid":527,"unread":true,"content":"<p>I’ve started learning Rust, and I have to admit, it’s a serious challenge! After years of coding in more \"conventional\" languages (started with Java 7, then moved to JS/TS, Python, Dart…), I thought I was ready for anything. But Rust? It’s a whole different ball game! </p><p>Between memory management, the heap, the stack, borrowing, ownership, and all these concepts that feel out of the ordinary, I’m feeling a bit overwhelmed. This is my second attempt to dive into it seriously, and I have to say, it’s not as \"friendly\" as what I’m used to.</p><p>Do any seasoned Rustaceans have tips to help me keep my head above water? Any resources, tricks, or even personal experiences to help me tame this beast?</p><p>I’m determined to crack the Rust code, but a little boost would be much appreciated! </p>","contentLength":793,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Created my first Tauri app - Timely","url":"https://www.reddit.com/r/rust/comments/1iaoe9l/created_my_first_tauri_app_timely/","date":1737921114,"author":"/u/th3oth3rjak3","guid":524,"unread":true,"content":"<p>Hello my fellow Rust enjoyers, after about 3 months of work I just finished my first project called Timely using Tauri and React. It's a task tracking application with built-in time tracking, comments, tagging, and much, much more. Just wanted to post on here in case anyone has a personal use for it. If you find the application useful or interesting, please leave a star on GitHub.</p><p>Edit: Just wanted to again say thanks to everyone for their support. Your positive comments gave me the much needed energy to get a GitHub action going to build the application for a bunch of the major platforms including targeting an older version of Ubuntu (22.04) in order to reach a wider audience. This community is amazing, thanks for all your hard work.</p>","contentLength":743,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"[Media] Introducing: yeehaw! A TUI Framework with Batteries Included","url":"https://www.reddit.com/r/rust/comments/1ialadw/media_introducing_yeehaw_a_tui_framework_with/","date":1737914311,"author":"/u/bogz314","guid":529,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Rust’s worst feature* (spoiler: it’s BorrowedBuf, I hate it with passion)","url":"https://mina86.com/2025/rusts-worst-feature/","date":1737893558,"author":"/u/mina86ng","guid":528,"unread":true,"content":"<p><small>* available in Rust nightly.</small></p><p>There are several aspects of Rust that I’m&nbsp;not particularly fond of but the one that takes the cake is <a href=\"//doc.rust-lang.org/core/io/struct.BorrowedBuf.html\"></a> which I despise with passion. It’s a&nbsp;nightly feature which puts in question my extreme emotions about it. On the other hand it means there’s time to stop it from getting stabilised and figure out something better.</p><p>In this article I’ll describe the problem the feature addresses, the issues I&nbsp;have with the solution and describe some alternatives. As it turns out, things aren’t as easy as they seem on the first look.</p><p>Consider the  routine below which copies data between two I/O streams. On each iteration of the loop, it zero-initialises the buffer which wastes time considering that  will override the data. The compiler doesn’t know that and has no choice but to fill the array with zeros each time. Even an obvious optimisation of moving the buffer declaration outside of the loop isn’t available to the compiler.</p><pre>fn slow_copy(\n  mut rd: impl std::io::Read,\n  mut wr: impl std::io::Write,\n) -&gt; std::io::Result&lt;()&gt; {\n  loop {\n    let mut buf = [0; 4096];\n    let read = rd.read(&amp;mut buf)?;\n    if read == 0 {\n      break Ok(());\n    }\n    wr.write_all(&amp;buf[..read])?;\n  }\n}</pre><p>An attempt at a&nbsp;solution is to use  which makes it possible to declare a&nbsp;region of uninitialised memory. Some explicit pointer casting is necessary, but otherwise code using it is straightforward.</p><pre>use core::mem::MaybeUninit;\n\npub fn unsound_copy(\n    mut rd: impl std::io::Read\n    mut wr: impl std::io::Write,\n) -&gt; std::io::Result&lt;()&gt; {\n  loop {\n    let mut buf = [MaybeUninit::&lt;u8&gt;::uninit(); 4096];\n    // \n    // <i>For demonstration purposes only.</i>\n    let buf = unsafe {\n      &amp;mut *(&amp;mut buf as *mut [_] as *mut [u8])\n    };\n    let read = rd.read(buf)?;\n    if read == 0 {\n      break Ok(());\n    }\n    wr.write_all(&amp;buf[..read])?;\n  }\n}</pre><p>While replacing the array of zeros by an array of uninitialised values may work in specific circumstances, the code is unsound. Change to the compiler, its options, modification of unrelated parts of the code or using the function for a&nbsp;different  trait implementation may break the program in unpredictable ways.</p><p>The solution in nightly Rust is the  struct. It’s a&nbsp;bytes slice which remembers how much of it has been initialised. It doesn’t own the memory and operates on a&nbsp;borrowed buffer (hence the name). It can point at an array on the stack or a&nbsp;slice living on the heap (such as ’s spare capacity). A&nbsp;naïve use of the feature is the following:</p><pre>#![feature(core_io_borrowed_buf, read_buf)]\n\nuse core::io::BorrowedBuf;\nuse core::mem::MaybeUninit;\n\nfn almost_good_copy(\n    mut rd: impl std::io::Read,\n    mut wr: impl std::io::Write,\n) -&gt; std::io::Result&lt;()&gt; {\n  loop {\n    let mut buf = [MaybeUninit::uninit(); 4096];\n    let mut buf = BorrowedBuf::from(&amp;mut buf[..]);\n    rd.read_buf(buf.unfilled())?;\n    if buf.len() == 0 {\n      break Ok(());\n    }\n    wr.write_all(buf.filled())?;\n  }\n}</pre><h2>Issues with the </h2><p>While  appears to work as expected,  isn’t without its share of problems. I&nbsp;describe them below.</p><p>The  does not seamlessly integrate with existing Rust code. In fact quite the opposite. APIs need to support it explicitly. For example, many third-party  implementations do not provide  method. In its absence, the default version initialises the memory and calls  negating any potential benefits of .</p><p>Similarly, functions which take output slice as an argument — such as <a href=\"//docs.rs/rand/0.8.5/rand/trait.RngCore.html\">’s </a> — could benefit from being able to write to uninitialised memory. However, to offer that benefit, they need to be changed to support . A&nbsp;motivated programmer can try adding necessary support to actively maintained packages, like , but what if one is stuck at an older version of the crate or deals with apparently abandoned crates like  or . To support those cases, forking would be necessary leading the programmer towards deeper circles of dependency hell.</p><p>Then again, should functions such as  integrate with  in the first place instead of taking an  argument? The issue with the latter is that there’s no safe way to convert  into .<a href=\"https://mina86.com/2025/rusts-worst-feature/#f1\"></a> As such, users who so far happily used such functions with regular initialised buffers would need convoluted incantation to make their previously straightforward code to compile. Meanwhile, creating  is somewhat convenient and can be done from initialised and uninitialised buffers alike.</p><p>In addition to , the  crate offers <a href=\"//docs.rs/rand/latest/rand/trait.Rng.html#method.fill\">a&nbsp; method</a> which fills a&nbsp;generic slice of integers with random data. It could easily work with  except that the struct works on  slices only. As a&nbsp;result, a&nbsp;crate which deals with different types cannot consistently use .</p><p>I&nbsp;don’t know the reasons why  is not generic. It’s possible that its design focused on addressing the the  trait use case only. Complications around dealing with  types could have been a&nbsp;contributing factor. However, even then the type could be generic on  types.</p><p> being optional brings another problem. Without full understanding of the behaviour and interactions of the  type, it’s easy to misuse it such as in . One can be excused from assuming that the function eliminates unnecessary initialisation. It declares an uninitialised region, wraps it in  and reads data into it. Even inspection of the assembly output <a href=\"//rust.godbolt.org/z/dvaPqz4co\">shows lack of the  call</a>.</p><p>Alas, while  avoids memory initialisation when reading data from a&nbsp;, it wastes time zeroing the buffer when, for example, decompressing data with help of <a href=\"//crates.io/crates/flate2\"> crate</a> (which does not offer custom  method) effectively becoming a&nbsp;.</p><p>Unless the underlying type is known, the programmer must assume that  may resort to filling the memory. The proper use of  is to construct it only once so that it can remember that the memory has been initialised.</p><pre>#![feature(core_io_borrowed_buf, read_buf)]\n\nuse core::io::BorrowedBuf;\nuse core::mem::MaybeUninit;\n\nfn copy(\n  mut rd: impl std::io::Read,\n  mut wr: impl std::io::Write,\n) -&gt; std::io::Result&lt;()&gt; {\n  let mut buf = [MaybeUninit::uninit(); 4096];\n  let mut buf = BorrowedBuf::from(&amp;mut buf[..]);\n  loop {\n    buf.clear();\n    rd.read_buf(buf.unfilled())?;\n    if buf.len() == 0 {\n      break Ok(());\n    }\n    wr.write_all(buf.filled())?;\n  }\n}</pre><p>With ’s complexity it’s not hard to imagine why people might use it in inefficient way. The struct is harder to understand than the unsound casting in . This may lead people to use the more straightforward option even if it’s not correct. An analogy to a&nbsp; with its contents and spare capacity partially helps — a&nbsp; has analogous filled and unfilled parts — but is an oversimplified view. A&nbsp; is also split into initialised and uninitialised parts. The documentation visualises it as follows:</p><table><tbody></tbody></table><p>There are reasons for this madness. Consider loop in the  function above. If  only knew how much of it was filled, each call to  would lose the information about memory being initialised. In the default implementation of  it would need to unnecessarily zero the whole buffer. Separately storing information about how much of the buffer has been filled and initialised, let the type avoid double-initialisation of memory.</p><p>As an aside, I find modelling  as divided into filled and spare capacity with spare capacity further divided into initialised and uninitialised as more intuitive. Leaning into the analogy of  is in my opinion more natural and it helps by reinforcing terminology used in existing parts of the language rather than introducing new models.</p><table><tbody></tbody></table><p>Having looked at issues with , let’s consider what people actually want.<a href=\"https://mina86.com/2025/rusts-worst-feature/#f2\"></a> The easiest mental model is that uninitialised memory stores arbitrary data, unknown unless accessed. To achieve such semantics, the uninitialised memory would need to be . A&nbsp;frozen region becomes safe to read and can be accessed through regular Rust references. With freezing operation available, the buffer definition in the copying routine could be turned into something like:</p><pre>  let mut buf = [MaybeUninit::uninit(); 4096];\n  // SAFETY: u8 has no invalid bit patterns.\n  let buf = unsafe {\n    MaybeUninit::slice_freeze_mut(&amp;mut buf)\n  };</pre><pre>  let buf = MaybeUninit::frozen();\n  // SAFETY: u8 has no invalid bit patterns.\n  let mut buf: [u8; 4096] = unsafe { buf.assume_init() };</pre><p>Unsafe blocks are required to account for invalid bit patterns. With a&nbsp;trait like <a href=\"//docs.rs/bytemuck/latest/bytemuck/trait.AnyBitPattern.html\"></a>, a&nbsp;safe versions could exist. Either of those alternatives would require no new methods on the  trait and would work without any modifications on methods such as ’s .</p><h2>Why can’t we have what we want?</h2><p>Reading uninitialised memory is hardly an issue when analysing things on hardware level. So long as a&nbsp;memory address is mapped with proper permissions, accessing data from it will always produce some value. There’s no undefined behaviour there.<a href=\"https://mina86.com/2025/rusts-worst-feature/#f3\"></a> In fact, in typical Linux environment all newly allocated anonymous pages are zero-initialised.<a href=\"https://mina86.com/2025/rusts-worst-feature/#f4\"></a></p><figure><pre>tautology:\n  cmp  BYTE PTR [rdi], 0\n  je   tautology_ok\n  cmp  BYTE PTR [rdi], 0\n  jne  tautology_ok\n  mov  al, 0\n  ret\ntautology_ok:\n  mov  al, 1\n  ret</pre><figcaption>An x86 assembly function which checks whether value in memory is zero or non-zero. This seemingly tautological test can fail when operating on a&nbsp;memory page marked with  and the kernel changes the mapping in between the two memory reads.</figcaption></figure><p>Unfortunately, even when looking from the point of view of machine code, this analysis isn’t complete…</p><h3>Giving advice about use of memory</h3><p> flag of the <a href=\"//man7.org/linux/man-pages/man2/madvise.2.html\"></a> system call allows user space to advise the kernel that (until next write) it no longer cares about contents of specified anonymous pages. This optimisation enables the kernel to discard those pages without swapping them to disk. While the advice is in effect, the user space  access the memory, but has no guarantee whether it’ll read the old values or zeros. Even code written directly in assembly language, like the  function on the right can result in unexpected behaviour.</p><p>This isn’t a&nbsp;theoretical concern either. jemalloc, a&nbsp;somewhat popular memory allocator, uses  when memory is freed. As a&nbsp;result, new allocations returned from the allocator may point to region of memory where the  advice is in effect. Nicholas Ormrod, in his <a href=\"//youtu.be/kPR8h4-qZdk?t=1150\">talk about C++  at Facebook</a>, describes how interaction between jemalloc,  and reading uninitialised memory resulted in outages.</p><p>To prevent this issue, the proposed  function would need to write into each page of the slice to make sure the kernel notices that the program cares about contents of the page again. This could be a simple loop stepping 4 KiB at a time and look something like the following:</p><pre>pub unsafe fn slice_freeze_mut&lt;T&gt;(\n  slice: &amp;mut [MaybeUninit&lt;T&gt;]\n) -&gt; &amp;mut [T] {\n  const PAGE_SIZE: usize = 4096;\n  let ptr = slice.as_mut_ptr() as *mut _;\n  let len = slice.len() * size_of::&lt;T&gt;();\n  // SAFETY: It’s always safe to split MU object into MU bytes.\n  let bytes: &amp;mut [MaybeUninit&lt;u8&gt;] = unsafe {\n    core::slice::from_raw_parts(ptr, len);\n  };\n  for el in bytes.iter_mut().step_by(PAGE_SIZE) {\n    let p = el.as_mut_ptr();\n    // SAFETY: Unsafe without language semantics change\n    // since we’re reading uninitialised byte.\n    unsafe { p.write_volatile(p.read()) };\n  }\n  // SAFETY: Caller promises that T has no invalid bit patterns,\n  // but this is still unsafe without language semantics change\n  // since we haven’t initialised all the bytes.\n  unsafe { &amp;mut *(slice as *mut _ as *mut [T]) }\n}</pre><p>Unfortunately, this would hardly be the no-operation that people expect from writing into uninitialised memory. It would be an improvement over a full initialisation and would address some issues with  but would do that at the cost of unavoidable page touching.</p><p>It may seem that the second form — the <code>MaybeUninit::frozen().assume_init()</code> variant — which creates frozen buffer directly on stack could be easier to optimise. The compiler controls the stack and unless it issues , no stack pages will be marked . Unfortunately it’s not clear that always hold true. For example, with async programming the stack lives God-knows-where and there may be other corner cases that would need to be considered.</p><p>I&nbsp;started this article with a&nbsp;promise of some alternatives to  and yet, as I&nbsp;conclude it, no working alternative is presented. Indeed, this is perhaps what frustrates me the most about the . On the face of it, writing data into uninitialised memory is a&nbsp;feature with an obvious solution, but it doesn’t take long before all the obvious solutions clash with Rust’s safety requirements.</p><p>So what’s a&nbsp;lowly programmer to do? Donald Knuth is often quoted as stating that ‘premature optimisation is the root of all evil’. True to that adage, in most cases it’s safe to pay the price of the memory initialisation. I/O operations usually take orders of magnitude more time so the time saved not initialising the memory is often negligible.</p><p>But there is more to Knuth’s quote:</p><blockquote><p>We  forget about small efficiencies, say about 97% of the time: premature optimisation is the root of all evil.</p><p>Yet we should not pass up our opportunities in that critical 3%. A&nbsp;good programmer will not be lulled into complacency by such reasoning, he will be wise to look carefully at the critical code; but only after that code has been identified.<a href=\"https://mina86.com/2025/rusts-worst-feature/#f5\"></a></p></blockquote><p>For the remaining 3%, the options now are somewhat bleak and depend on the particular code base. They may require switching to nightly compiler, patching third-party crates, going straight to doing unsafe syscalls (e.g. <a href=\"//man7.org/linux/man-pages/man2/read.2.html\"></a>) or isolating critical code paths and writing them in C.</p><p>And while we deal with the lack of ideal solution for writing to uninitialised memory, maybe someone will figure out some alternative fast and ergonomic approach.</p><p><a href=\"https://mina86.com/2025/rusts-worst-feature/#b1\">1</a> The reference conversion itself is safe since all possible values of type  are valid values of type  and both those types have the same layout. However, the latter allows writing arbitrary data into the object which may result in invalid representation of  (see <a href=\"//play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2021&amp;gist=72ca09295e9b98dfdd85a3af573aa0b9\">playground demonstration</a>). With interior mutability, even converting shared references may lead to issues.</p><p><a href=\"https://mina86.com/2025/rusts-worst-feature/#b2\">2</a> I&nbsp;am aware that I&nbsp;presumptuously speak for everyone. However, I&nbsp;do believe that alternatives presented here, if they existed, would be favoured by everyone and that includes contributors to the  struct. As I&nbsp;discuss later, the type is the way it is not because that’s what anyone finds appealing but due to other constraints.</p><p><a href=\"https://mina86.com/2025/rusts-worst-feature/#b3\">3</a> Semantics that reading uninitialised memory has arbitrary but consistent value can be useful in practice. Briggs and Torczon describe in <a href=\"//doi.org/10.1145/176454.176484\">An efficient representation for sparse sets</a> an algorithm which is built on such semantics.</p><p><a href=\"https://mina86.com/2025/rusts-worst-feature/#b3\">4</a> The atypical environment is µClinux which runs on platforms without memory management unit (MMU). <a href=\"//www.kernel.org/doc/Documentation/admin-guide/mm/nommu-mmap.rst\">It supports  option</a> which skips zeroing of the memory region. However, even with that flag, allocated pages maintain consistent state.</p><p><a href=\"https://mina86.com/2025/rusts-worst-feature/#b5\">5</a> Donald E. Knuth. 1974. Structured Programming with  Statements. ACM Computing Surveys. Vol. 6, Issue 4 (Dec. 1974), 261–301. <a href=\"//doi.org/10.1145/356635.356640\">doi:10.1145/356635.356640</a>.</p>","contentLength":14955,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/rust/comments/1iad0lk/rusts_worst_feature_spoiler_its_borrowedbuf_i/"}],"tags":["dev","reddit"]}