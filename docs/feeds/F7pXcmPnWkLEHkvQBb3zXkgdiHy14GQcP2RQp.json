{"id":"F7pXcmPnWkLEHkvQBb3zXkgdiHy14GQcP2RQp","title":"Aphyr: Posts","displayTitle":"Dev - Aphyr","url":"http://aphyr.com/posts.atom","feedLink":"http://aphyr.com/posts.atom","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":2,"items":[{"title":"How to Unsubscribe from Modern Luxury","url":"https://aphyr.com/posts/406-how-to-unsubscribe-from-modern-luxury","date":1771861196,"author":"Aphyr","guid":470,"unread":true,"content":"<p>A few years ago I started getting issues of <a href=\"https://store.modernluxury.com/subscriptions/\">Modern Luxury</a> in the mail. I had no idea why they started coming, and I tried to get them to stop. This should have been easy, and was instead hard. Here’s my process, in case anyone else is in the same boat.</p><p>First, if you use it, try to unsubscribe via <a href=\"https://www.paperkarma.com/\">PaperKarma</a>. This is convenient and works for a decent number of companies. PaperKarma kept reporting they’d successfully unsubscribed me, but Modern Luxury kept coming.</p><p>Third, call any numbers you can find associated with the company. Leave voicemails on anything that claims to be Modern Luxury related. Along this path I wound up discovering a Borgesian labyrinth of sketchy offers for life-alert style emergency devices and other things that felt vaguely like elder abuse; long story short, this did not work.</p><p>Fourth, Modern Luxury’s email format is [first initial][last name]@modernluxury.com. Start writing emails to a few names from your local edition that seem relevant, like the local publisher and editor. When they don’t respond, expand your emails to include everyone listed in the magazine. Start digging through corporate filings of their parent company, <a href=\"https://www.cumulusmedia.com/\">Cumulus Media</a>, and emailing people there. Start short and simple; when that doesn’t work, try humor. This didn’t work either, but it was fun to write:</p><blockquote><p>I love me some esoteric rich people nonsense. Fabergé eggs! Ominous lawn obelisks! Having oneself taxidermied and wheeled out for council meetings of University College London! Unfortunately, Modern Luxury contains nothing like this; perhaps rich people have forgotten how to be interesting. In any event, I would like you to stop. If you can figure out how to stop sending me magazines, I promise to stop sending you emails about it, and we can all go on to live happy lives.</p></blockquote><p>Finally, cut out a suitable article from an issue of the magazine. Look up up the home address of the regional group publisher in city records. Mail the article back to the publisher, along with a letter asking them to stop.</p><blockquote><p>As the regional group publisher of Modern Luxury magazine, I would like you to stop publishing Modern Luxury to my home each month. I never asked for it, and I have been trying to unsubscribe for years. E-mails, phone calls, Paper Karma: nothing works. I appreciate your most recent column, entitled “Spirit of Generosity”, but please: it is possible to be too generous. Kindly stop sending these magazines.</p></blockquote><p>This actually seems to have worked.</p><p>I think a lot about this idea of the <a href=\"https://www.theatlantic.com/ideas/2026/02/ai-annoyance-economy/685894/\">Annoyance Economy</a>—that modern life places ordinary people in contact with a dizzying array of opaque, nonresponsive bureaucracies, and that those bureaucracies have financial incentives to ignore you. This is why it’s so hard to <a href=\"https://aphyr.com/posts/368-how-to-replace-your-cpap-in-only-666-days\">replace a CPAP</a> or <a href=\"https://aphyr.com/posts/381-when-flat-rate-movers-wont-answer-your-calls\">get paid back when movers break things</a>. This is why Redplum (one of those advertising/coupon mailers) ignored my unsubscribe requests for years, and only stopped when I started e-mailing the entire C-suite about it. I try to pick and choose these battles, but sometimes it’s hard to let it go. And goshdarnit, if nobody pushes back then bureaucratic indifference , and we all have to live with it.</p><p>I don’t want to bother people like this; I think it’s unreasonably rude. I still start with the official support channels and escalate gradually. I like Patrick McKenzie’s strategy of presenting oneself as a <a href=\"https://www.kalzumeus.com/2017/09/09/identity-theft-credit-reports/#presenting-like-a-professional\">boring, dangerous professional</a>. However, I have also found that in the Annoyance Economy, one of the ways to get things done is to find specific people with power, and annoy them right back.</p><p>I hope this whole misadventure convinced Modern Luxury to build and document an easy unsubscribe process. If not, you know what to do.</p>","contentLength":3697,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Trudging Through Nonsense","url":"https://aphyr.com/posts/405-trudging-through-nonsense","date":1770218858,"author":"Aphyr","guid":469,"unread":true,"content":"<p>Last week Anthropic released a report on <a href=\"https://www.anthropic.com/research/disempowerment-patterns\">disempowerment patterns in real-world AI usage</a> which finds that roughly one in 1,000 to one in 10,000 conversations with their LLM, <a href=\"https://claude.ai\">Claude</a>, fundamentally compromises the user’s beliefs, values, or actions. They note that the prevalence of moderate to severe “disempowerment” is increasing over time, and conclude that the problem of LLMs distorting a user’s sense of reality is likely unfixable so long as users keep holding them wrong:</p><blockquote><p>However, model-side interventions are unlikely to fully address the problem. User education is an important complement to help people recognize when they’re ceding judgment to an AI, and to understand the patterns that make that more likely to occur.</p></blockquote><blockquote><p>The Clay Mathematics Institute offers a $1,000,000 Millennium Prize for proving either global existence and smoothness of solutions, or demonstrating finite-time blow-up for specific initial conditions.</p><p>This system achieves both.</p></blockquote><p>At the risk of reifying <a href=\"https://xkcd.com/2501/\">XKCD 2501</a>, this is a deeply silly answer to an either-or question. You cannot claim that all conditions have a smooth solution, and also that there is a condition for which no smooth solution exists. This is like being asked to figure out whether all apples are green, or at least one red one exists, and declaring that you’ve done both. </p><p>Prothean goes on to claim that the “demonstration at <a href=\"https://beprothean.org\">BeProthean.org</a> provides immediate, verifiable evidence” of their proof. This too is obviously false. As the Clay paper explains, the velocity field must have zero divergence, which is a fancy way of saying that the fluid is incompressible; it can’t be squeezed down or spread out. One of the demo’s “solutions” squeezes everything down to a single point, and another shoves particles away from the center. Both clearly violate Navier-Stokes.</p><p>My background is in physics and software engineering, and I’ve written several numeric solvers for various physical systems. Prothean’s demo () is a simple <a href=\"https://en.wikipedia.org/wiki/Euler_method\">Euler’s method</a> solver with four flavors of externally-applied acceleration, plus a linear drag term to compensate for all the energy they’re dumping into the system. There’s nothing remotely Navier-Stokes-shaped there. It’s not even a fluid: there are no local interactions, just free particles.</p><p>The paper talks about a novel “multi-tier adaptive compression architecture” which “operates on semantic structure rather than raw binary patterns”, enabling “compression ratios exceding 800:1”. How can we tell? Because “the interactive demonstration platform at BeProthean.org provides hands-on capability verification for technical evaluation”.</p><p>Prothean’s compression demo wasn’t real in October, and it’s not real today. This time it’s just bog-standard <a href=\"https://en.wikipedia.org/wiki/Deflate\">DEFLATE</a>, the same used in  files. There’s some fake log messages to make it look like it’s doing something fancy when it’s not.</p><pre><code></code></pre><p>There’s a fake “Predictive vehicle optimization” tool that has you enter a VIN, then makes up imaginary “expected power gain” and “efficiency improvement” numbers. These are based purely on a hash of the VIN characters, and have nothing to do with any kind of car. Prothean is full of false claims like this, and somehow they’re <a href=\"https://drive.google.com/file/d/1zqr-AZggs5LJF8WkyV3LZLlINyNqsvAT/view?pli=1\">offering organizational licenses for it</a>.</p><p>It’s not just Prothean. I feel like I’ve been been trudging through a wave of LLM nonsense recently. In the last two weeks alone, I’ve watched software engineers use Claude to suggest fatuous changes to my software, like an “improvement” to an error message which deleted key guidance. Contractors proffering LLM-slop descriptions of appliances. Claude-generated documents which made bonkers claims, like saying a JVM program I wrote provided “faster iteration” thanks to “no JVM startup”.  Cold emails asking me to analyze dreamlike, vaguely-described software systems—one of whom, in our introductory call, couldn’t even begin to explain what they’d built or what it was for. A scammer who used an LLM to pretend to be an engineer wanting to help with my research, then turned out to be seeking investors in their video chatbot project.</p><p>When people or companies intentionally make false claims about the work they’re doing or the products they’re selling, we call it fraud. What is it when one overlooks LLM mistakes? What do we call it when a person sincerely believes the lies an LLM has told them, and repeats those lies to others? Dedicates months of their life to a transformer model’s fever dream?</p><p><a href=\"https://arxiv.org/pdf/2601.19062\">Anthropic’s paper</a> argues reality distortion is rare in software domains, but I’m not so sure.</p><p>This stuff keeps me up at night. I wonder about my fellow engineers who work at Anthropic, at OpenAI, on Google’s Gemini. I wonder if they see as much slop as I do. How many of their friends and colleagues have been sucked into LLM rabbitholes. I wonder if they too lie awake at three AM, staring at the ceiling, wondering about the future and their role in making it.</p>","contentLength":4997,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["dev"]}