{"id":"4W3i2hyrJTVfcLq85rWgduVQ3y3BMzrSD4pVUCMqPpFhmXWpqxQ","title":"Hacker News: Front Page","displayTitle":"HN Front","url":"https://hnrss.org/frontpage?points=75","feedLink":"https://news.ycombinator.com/","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":15,"items":[{"title":"Don't \"optimize\" conditional moves in shaders with mix()+step()","url":"https://iquilezles.org/articles/gpuconditionals/","date":1739104974,"author":"romes","guid":192,"unread":true,"content":"<div>\nIn this article I want to correct a popular misconception that's been making the rounds in computer graphics aficionado circles for a long time now. It has to do with branching in the GPUs. Unfortunately there are a couple of educational websites out there that are spreading some misinformation and it would be nice correcting that. I tried contacting the authors without success, so without further ado, here goes my attempt to fix things up:\nSo, say I have this code, which I actually published the other day:<div> snap45(  v )\n{\n     s = (v);\n     x = (v.x);\n     x&gt;?(s.x,):\n           x&gt;?s*():\n                      (,s.y);\n}</div>\nThe exact details of what it does don't matter for this discussion. All we care about is the two ternary operations, which as you know, implement conditional execution. Indeed, depending on the value of the variable , the function will return different results. This could be implemented also with regular  statements, and all that I'm going to say stays the same.<p>\nBut here's the problem - when seeing code like this, somebody somewhere will invariably propose the following \"optimization\", which replaces what they believe (erroneously) are \"conditional branches\" by arithmetical operations. They will suggest something like this:</p><div> snap45(  v )\n{\n     s = (v);\n     x = (v.x);\n\n     w0 = (,x);\n     w1 = (,x)*(-w0);\n     w2 = -w0-w1;\n\n     res0 = (s.x,);\n     res1 = (s.x,s.y)*();\n     res2 = (,s.y);\n\n     w0*res0 + w1*res1 + w2*res2;\n}</div>\nThere are two things wrong with this practice. The first one shows an incorrect understanding of how the GPU works. In particular, the original shader code had no conditional branching in it. Selecting between a few registers with a ternary operator or with a plain  statement does not lead to conditional branching; all it involves is a conditional move (a.k.a. \"select\"), which is a simple instruction to route the correct bits to the destination register. You can think of it as a bitwise AND+NAND+OR on the source registers, which is a simple combinational circuit. Again, there is no branching - the instruction pointer isn't manipulated, there's no branch prediction involved, no instruction cache to invalidation, no nothing.<p>\nFor the record, of course real branches do happen in GPU code, but those are not what's used by the GPU for small moves between registers like we have here. This is true for any GPU made in the last 20+ years. While I'm not an expert in CPUs, I am pretty sure this is true for them as well.</p><p>\nThe second wrong thing with the supposedly optimizer version is that it actually runs much slower than the original version. The reason is that the </p> function is actually implemented like this:<div> step(  x,  y )\n{\n     x &lt; y ?  : ;\n}</div>\nSo people using the step() \"optimization\" are using the ternary operation anyways, which produces the  or  which they will use to select the output, only wasting two multiplications and one or two additions. The values could have been conditionally moved directly, which is what the original shader code did.<p>\nBut don't take my word for it, let's look at the generated machine code for the relevant part of the shader I published:</p><div><div>\nGLSL<div> x&gt;?(s.x,):\n       x&gt;?s*():\n                  (,s.y);</div></div><div>\nAMD Compiler<div>     s0,      v3, , v1\n     v4, , v0\n     s1,   vcc, (v2), s0\n v3, 0, v3, vcc\n v0, v0, v4, vcc\n vcc, (v2), s1\n v1, v1, v3, vcc\n v0, 0, v0, vcc</div></div><div>\nMicrosoft Compiler<div>   r0.xy, l(, ), v0.xy\n   r0.zw, v0.xy, l(, )\n r0.xy, -r0.xyxx, r0.zwzz\n r0.xy, r0.xyxx\n  r1.xyzw, r0.xyxy, l4()\n   r2.xy, l(,), v0.xx  r0.z, l()\n r1.xyzw, r2.yyyy, r1.xyzw, r0.zyzy\n o0.xyzw, r2.xxxx, r0.xzxz, r1.xyzw</div></div></div>\nHere we can see that the GPU is not branching. Instead, according to the AMD compiler, it's performing the required comparisons ( and  - cmp=compare, gt=greater than, ngt=not greated than), and then using the result to mask the results with the bitwise operations mentioned earlier ( - cnd=conditional).<p>\nThe Microsoft compiler has expressed the same idea/implementation in a different format, but you can still see the comparison (</p> - \"lt\"=less than) and the masking or conditional move ( - mov=move, c=conditionally).<p>\nNot related to the discussion, but also note that the </p> call does not become a GPU instruction and instead becomes an instruction modifier, which is free.\nSo, if you ever see somebody proposing this<div> a = ( b, c, ( y, x ) );</div>\nas an optimization to\nthen please correct them for me. The misinformation has been around for 20 years / 10 GPU generation, and that's more than too long.</div>","contentLength":4492,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42990324"},{"title":"Classic Data science pipelines built with LLMs","url":"https://github.com/Pravko-Solutions/FlashLearn/tree/main/examples","date":1739101178,"author":"galgia","guid":191,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42990036"},{"title":"RetroFab: Playable 3D simulations of vintage electronic games","url":"https://itizso.itch.io/retrofab","date":1739094635,"author":"todsacerdoti","guid":190,"unread":true,"content":"<div><div>( April 1980 - October 1980 )</div><div>In 1980 Nintendo released it's first series of handheld electronic games each featuring a dedicated LCD game with a bonus watch function. The silver metallic front plate gave the series it's name. </div></div><div><div>( January 1981 - April 1981 )</div><div>After the huge success of the Silver Series Nintendo released the next generation of it's Game &amp; Watch™ handhelds the following year, featuring a new alarm function, color background-foils and a distinctive gold metallic front plate.  </div></div><div><div>( June 1981 - April 1982 )</div><div>Featuring a wide LCD screen and impressive line-up of timeless classics (including some of the first licenced titles) Nintendo's Wide Screen Series ranks among some of the most popular Game &amp; Watch™ titles.  </div></div><div><div>( May 1982 - August 1989 )</div><div>In 1982 Nintendo introduced the innovative Multi Screen series whose most prominent feature was the use of two LCD screens in one foldable handheld with beautiful background-foil artwork and fine LCD elements.</div></div><div><div>( October 1982 - October 1991 )</div><div>Nintendo made further subtle improvements to the earlier Wide Screen series with a new box design featuring vivid artwork and a more colorful metallic front plate making the single screen LCD handhelds even classier.</div></div><div><div>( April 1983 - August 1983 )</div><div>Nintendo fulfilled the dream of many gamers to have their own mini arcade machine with the introduction of the Table Top Series which featured full color LCD graphics for the first time.</div></div><div><div>( August 1983 - September 1984 )</div><div>A few months after the introduction of the Table Top Series, Nintendo released a refinement of that technology in the form of the more portable Panorama Screen Series\\.</div></div><div><div>( July 1984 - November 1984 )</div><div>The Micro Vs. System introduced two-player gaming to the Game &amp; Watch™ series by attaching two wired controllers to a foldable unit that featured a wide LCD screen.</div></div><div><div>( June 1986 - November 1986 )</div><div>The Crystal Screen series introduced a new wide format translucent LCD handheld featuring a transparent see-thru screen and innovative side-scrolling gameplay.</div></div><div><div>Featuring a colored LCD screen that no longer required an external light source (required by the Table Top and Panorama Screen series) and a new large portrait format LCD screen, the Super Color Series was perfectly suited for the two games released in this format.</div></div><div><div>Nintendo released a limited edition of it's Super Mario Bros handheld LCD game as a prize for winners of a competition it held in 1987. Only 10,000 copies were given away, making it the most rare of the 3 Game &amp; Watch versions of the game.</div></div>","contentLength":2511,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42989628"},{"title":"Mathematics in the 20th century, by Michael Atiyah [pdf] (2002)","url":"https://marktomforde.com/academic/miscellaneous/images/atiyah20thcentury.pdf","date":1739091277,"author":"practal","guid":189,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42989419"},{"title":"Modern-Day Oracles or Bullshit Machines","url":"https://thebullshitmachines.com/","date":1739089457,"author":"ctbergstrom","guid":188,"unread":true,"content":"<p>In a series of five- to ten-minute lessons, we will explain what these machines are, how they work, and how to thrive in a world where they are everywhere.</p><p>You will learn when these systems can save you a lot of time and effort. You will learn when they are likely to steer you wrong. And you will discover how to see through the hype to tell the difference. </p>","contentLength":358,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42989320"},{"title":"Brain Hyperconnectivity in Children with Autism and Its Links to Social Deficits (2013)","url":"https://www.cell.com/cell-reports/fulltext/S2211-1247(13)00570-6","date":1739073244,"author":"stmw","guid":187,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42988303"},{"title":"Jacksonpollock.org (2003)","url":"https://jacksonpollock.org/","date":1739049769,"author":"memalign","guid":186,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42986320"},{"title":"Tips for mathematical handwriting (2007)","url":"https://johnkerl.org/doc/ortho/ortho.html","date":1739042410,"author":"susam","guid":185,"unread":true,"content":"<p>Now that you’re majoring in one of the technical disciplines\n(engineering, science, or math), you’re going to be spending a\nsignificant amount of time communicating in writing with others.  You may find\nthat previously unimportant details, such as crossing your ’s,\nnow become essential — not only so that others can understand you, but\nalso so that you can avoid mistaking your own 2 for\n and so on.  This is especially important if your\nhandwriting (like mine!) is less than perfect.\n\n</p><p>Before I continue, take a fresh look at our Roman alphabet, the digits, and\nthe Greek alphabet:\n\n</p><p>Notice that these mechanically typeset symbols are all clear and distinct\n(except that lowercase omicron and most of the uppercase Greek letters look\nlike Roman letters — we don’t use these “duplicates”).\n\n</p><p> When we write by hand, though, symbols can become ambiguous —\nwe’re not machines, and things get a little loopy when we hurry.  In\nprose, surrounding letters can disambiguate a questionable letter — e.g.\nyou can guess that the fourth letter of  has to be an .\nBut in mathematical expressions we mix symbols from different alphabets, in\ndifferent orders, so context can’t assist us — and when we guess,\nwe often guess wrong.  So it now becomes very important that each letter be\nclearly recognizable on its own merits.\n\n</p><p>Here are samples, followed by the points I consider most important.\n\n</p>","contentLength":1405,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42985427"},{"title":"Writing a simple windows driver in Rust","url":"https://scorpiosoftware.net/2025/02/08/writing-a-simple-driver-in-rust/","date":1739035503,"author":"ingve","guid":184,"unread":true,"content":"<p>The Rust language ecosystem is growing each day, its popularity increasing, and with good reason. It’s the only mainstream language that provides memory and concurrency safety at compile time, with a powerful and rich build system (cargo), and a growing number of packages (crates).</p><p>My daily driver is still C++, as most of my work is about low-level system and kernel programming, where the Windows C and COM APIs are easy to consume. Rust is a system programming language, however, which means it plays, or at least can play, in the same playground as C/C++. The main snag is the verbosity required when converting C types to Rust. This “verbosity” can be alleviated with appropriate wrappers and macros. I decided to try writing a simple WDM driver that is not useless – it’s a Rust version of the “Booster” driver I demonstrate in my book (<a href=\"https://www.amazon.com/Windows-Kernel-Programming-Pavel-Yosifovich/dp/1977593372\" target=\"_blank\" rel=\"noreferrer noopener\">Windows Kernel Programming</a>), that allows changing the priority of any thread to any value.</p><p>To prepare for building drivers, consult <a href=\"https://github.com/microsoft/windows-drivers-rs\" target=\"_blank\" rel=\"noreferrer noopener\">Windows Drivers-rs</a>, but basically you should have a WDK installation (either normal or the <a href=\"https://learn.microsoft.com/en-us/legal/windows/hardware/enterprise-wdk-license-2022\" target=\"_blank\" rel=\"noreferrer noopener\">EWDK</a>). Also, the docs require installing <a href=\"https://llvm.org/\" target=\"_blank\" rel=\"noreferrer noopener\">LLVM</a>, to gain access to the <a href=\"https://clang.llvm.org/\" target=\"_blank\" rel=\"noreferrer noopener\">Clang </a>compiler. I am going to assume you have these installed if you’d like to try the following yourself.</p><p>We can start by creating a new Rust library project (as a driver is a technically a DLL loaded into kernel space):</p><p>We can open the booster folder in VS Code, and begin are coding. First, there are some preparations to do in order for actual code to compile and link successfully. We need a  file to tell cargo to link statically to the CRT. Add a  file to the root booster folder, with the following code:</p><div><pre title=\"\">fn main() -&gt; Result&lt;(), wdk_build::ConfigError&gt; {\n    std::env::set_var(\"CARGO_CFG_TARGET_FEATURE\", \"crt-static\");\n    wdk_build::configure_wdk_binary_build()\n}\n</pre></div><p>(Syntax highlighting is imperfect because the WordPress editor I use does not support syntax highlighting for Rust)</p><p>Next, we need to edit  and add all kinds of dependencies. The following is the minimum I could get away with:</p><div><pre title=\"\">[package]\nname = \"booster\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n[package.metadata.wdk.driver-model]\ndriver-type = \"WDM\"\n\n[lib]\ncrate-type = [\"cdylib\"]\ntest = false\n\n[build-dependencies]\nwdk-build = \"0.3.0\"\n\n[dependencies]\nwdk = \"0.3.0\"       \nwdk-macros = \"0.3.0\"\nwdk-alloc = \"0.3.0\" \nwdk-panic = \"0.3.0\" \nwdk-sys = \"0.3.0\"   \n\n[features]\ndefault = []\nnightly = [\"wdk/nightly\", \"wdk-sys/nightly\"]\n\n[profile.dev]\npanic = \"abort\"\nlto = true\n\n[profile.release]\npanic = \"abort\"\nlto = true\n</pre></div><p>The important parts are the WDK crates dependencies. It’s time to get to the actual code in . </p><p>We start by removing the standard library, as it does not exist in the kernel:</p><p>Next, we’ll add a few  statements to make the code less verbose:</p><div><pre title=\"\">use core::ffi::c_void;\nuse core::ptr::null_mut;\nuse alloc::vec::Vec;\nuse alloc::{slice, string::String};\nuse wdk::*;\nuse wdk_alloc::WdkAllocator;\nuse wdk_sys::ntddk::*;\nuse wdk_sys::*;\n</pre></div><p>The  crate provides the low level interop kernel functions. the  crate provides higher-level wrappers.  is an interesting one. Since we can’t use the standard library, you would think the types like  are not available, and technically that’s correct. However,  is actually defined in a lower level module named , that can be used outside the standard library. This works because the only requirement for  is to have a way to allocate and deallocate memory. Rust exposes this aspect through a global allocator object, that anyone can provide. Since we have no standard library, there is no global allocator, so one must be provided. Then,  (and ) can work normally:</p><div><pre title=\"\">#[global_allocator]\nstatic GLOBAL_ALLOCATOR: WdkAllocator = WdkAllocator;\n</pre></div><p>This is the global allocator provided by the WDK crates, that use <a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/ddi/wdm/nf-wdm-exallocatepool2\" target=\"_blank\" rel=\"noreferrer noopener\"></a>and <a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/ddi/wdm/nf-wdm-exfreepool\" target=\"_blank\" rel=\"noreferrer noopener\"></a>to manage allocations, just like would do manually.</p><p>Next, we add two  crates to get the support for the allocator and a panic handler – another thing that must be provided since the standard library is not included.  has a setting to abort the driver (crash the system) if any code panics:</p><div><pre title=\"\">extern crate wdk_panic;\nextern crate alloc;\n</pre></div><p>Now it’s time to write the actual code. We start with , the entry point to any Windows kernel driver:</p><div><pre title=\"\">#[export_name = \"DriverEntry\"]\npub unsafe extern \"system\" fn driver_entry(\n    driver: &amp;mut DRIVER_OBJECT,\n    registry_path: PUNICODE_STRING,\n) -&gt; NTSTATUS {\n</pre></div><p>Those familiar with kernel drivers will recognize the function signature (kind of). The function name is  to conform to the snake_case Rust naming convention for functions, but since the linker looks for , we decorate the function with the  attribute. You could use  and just ignore or disable the compiler’s warning, if you prefer.</p><p>We can use the familiar  macro, that was reimplemented by calling , as you would if you were using C/C++. You can still call , mind you, but  is just easier:</p><div><pre title=\"\">println!(\"DriverEntry from Rust! {:p}\", &amp;driver);\nlet registry_path = unicode_to_string(registry_path);\nprintln!(\"Registry Path: {}\", registry_path);\n</pre></div><p>Unfortunately, it seems  does not yet support a , so we can write a function named  to convert a  to a normal Rust string:</p><div><pre title=\"\">fn unicode_to_string(str: PCUNICODE_STRING) -&gt; String {\n    String::from_utf16_lossy(unsafe {\n        slice::from_raw_parts((*str).Buffer, (*str).Length as usize / 2)\n    })\n}\n</pre></div><p>Back in , our next order of business is to create a device object with the name “\\Device\\Booster”:</p><div><pre title=\"\">let mut dev = null_mut();\nlet mut dev_name = UNICODE_STRING::default();\nstring_to_ustring(\"\\\\Device\\\\Booster\", &amp;mut dev_name);\n\nlet status = IoCreateDevice(\n    driver,\n    0,\n    &amp;mut dev_name,\n    FILE_DEVICE_UNKNOWN,\n    0,\n    0u8,\n    &amp;mut dev,\n);\n</pre></div><p>The  function converts a Rust string to a :</p><div><pre title=\"\">fn string_to_ustring&lt;'a&gt;(s: &amp;str, uc: &amp;'a mut UNICODE_STRING) -&gt; Vec&lt;u16&gt; {\n    let mut wstring: Vec&lt;_&gt; = s.encode_utf16().collect();\n    uc.Length = wstring.len() as u16 * 2;\n    uc.MaximumLength = wstring.len() as u16 * 2;\n    uc.Buffer = wstring.as_mut_ptr();\n    wstring\n}\n</pre></div><p>This may look more complex than we would like, but think of this as a function that is written once, and then just used all over the place. In fact, maybe there is such a function already, and just didn’t look hard enough. But it will do for this driver.</p><p>If device creation fails, we return a failure status:</p><div><pre title=\"\">if !nt_success(status) {\n    println!(\"Error creating device 0x{:X}\", status);\n    return status;\n}\n</pre></div><p> is similar to the  macro provided by the WDK headers.</p><p>Next, we’ll create a symbolic link so that a standard  call could open a handle to our device:</p><div><pre title=\"\">let mut sym_name = UNICODE_STRING::default();\nlet _ = string_to_ustring(\"\\\\??\\\\Booster\", &amp;mut sym_name);\nlet status = IoCreateSymbolicLink(&amp;mut sym_name, &amp;mut dev_name);\nif !nt_success(status) {\n    println!(\"Error creating symbolic link 0x{:X}\", status);\n    IoDeleteDevice(dev);\n    return status;\n}\n</pre></div><p>All that’s left to do is initialize the device object with support for Buffered I/O (we’ll use  for simplicity), set the driver unload routine, and the major functions we intend to support:</p><div><pre title=\"\">    (*dev).Flags |= DO_BUFFERED_IO;\n\n    driver.DriverUnload = Some(boost_unload);\n    driver.MajorFunction[IRP_MJ_CREATE as usize] = Some(boost_create_close);\n    driver.MajorFunction[IRP_MJ_CLOSE as usize] = Some(boost_create_close);\n    driver.MajorFunction[IRP_MJ_WRITE as usize] = Some(boost_write);\n\n    STATUS_SUCCESS\n}\n</pre></div><p>Note the use of the Rust  type to indicate the presence of a callback.</p><p>The unload routine looks like this:</p><div><pre title=\"\">unsafe extern \"C\" fn boost_unload(driver: *mut DRIVER_OBJECT) {\n    let mut sym_name = UNICODE_STRING::default();\n    string_to_ustring(\"\\\\??\\\\Booster\", &amp;mut sym_name);\n    let _ = IoDeleteSymbolicLink(&amp;mut sym_name);\n    IoDeleteDevice((*driver).DeviceObject);\n}\n</pre></div><p>We just call  and , just like a normal kernel driver would. </p><p>We have three request types to handle – , , and . Create and close are trivial – just complete the IRP successfully:</p><div><pre title=\"\">unsafe extern \"C\" fn boost_create_close(_device: *mut DEVICE_OBJECT, irp: *mut IRP) -&gt; NTSTATUS {\n    (*irp).IoStatus.__bindgen_anon_1.Status = STATUS_SUCCESS;\n    (*irp).IoStatus.Information = 0;\n    IofCompleteRequest(irp, 0);\n    STATUS_SUCCESS\n}\n</pre></div><p>The  is an  but it’s defined with a  containing  and . This seems to be incorrect, as  should be in a  with  (not ). Anyway, the code accesses the  member through the “auto generated” union, and it looks ugly. Definitely something to look into further. But it works.</p><p>The real interesting function is the  handler, that does the actual thread priority change. First, we’ll declare a structure to represent the request to the driver:</p><div><pre title=\"\">#[repr(C)]\nstruct ThreadData {\n    pub thread_id: u32,\n    pub priority: i32,\n}\n</pre></div><p>The use of  is important, to make sure the fields are laid out in memory just as they would with C/C++. This allows non-Rust clients to talk to the driver. In fact, I’ll test the driver with a C++ client I have that used the C++ version of the driver. The driver accepts the thread ID to change and the priority to use. Now we can start with :</p><div><pre title=\"\">unsafe extern \"C\" fn boost_write(_device: *mut DEVICE_OBJECT, irp: *mut IRP) -&gt; NTSTATUS {\n    let data = (*irp).AssociatedIrp.SystemBuffer as *const ThreadData;\n</pre></div><p>First, we grab the data pointer from the  in the IRP, as we asked for Buffered I/O support. This is a kernel copy of the client’s buffer. Next, we’ll do some checks for errors:</p><div><pre title=\"\">let status;\nloop {\n    if data == null_mut() {\n        status = STATUS_INVALID_PARAMETER;\n        break;\n    }\n    if (*data).priority &lt; 1 || (*data).priority &gt; 31 {\n        status = STATUS_INVALID_PARAMETER;\n        break;\n    }\n</pre></div><p>The  statement creates an infinite block that can be exited with a . Once we verified the priority is in range, it’s time to locate the thread object:</p><div><pre title=\"\">let mut thread = null_mut();\nstatus = PsLookupThreadByThreadId(((*data).thread_id) as *mut c_void, &amp;mut thread);\nif !nt_success(status) {\n    break;\n}\n</pre></div><p> is the one to use. If it fails, it means the thread ID probably does not exist, and we break. All that’s left to do is set the priority and complete the request with whatever status we have:</p><div><pre title=\"\">        KeSetPriorityThread(thread, (*data).priority);\n        ObfDereferenceObject(thread as *mut c_void);\n        break;\n    }\n    (*irp).IoStatus.__bindgen_anon_1.Status = status;\n    (*irp).IoStatus.Information = 0;\n    IofCompleteRequest(irp, 0);\n    status\n}\n</pre></div><p>The only remaining thing is to sign the driver. It seems that the crates support signing the driver if an INF or INX files are present, but this driver is not using an INF. So we need to sign it manually before deployment. The following can be used from the root folder of the project:</p><div><pre title=\"\">signtool sign /n wdk /fd sha256 target\\debug\\booster.dll\n</pre></div><p>The  uses a WDK test certificate typically created automatically by Visual Studio when building drivers. I just grab the first one in the store that starts with “wdk” and use it.</p><p>The silly part is the file extension – it’s a DLL and there currently is no way to change it automatically as part of cargo build. If using an INF/INX, the file extension does change to SYS. In any case, file extensions don’t really mean that much – we can rename it manually, or just leave it as DLL. </p><p>The resulting file can be installed in the “normal” way for a software driver, such as using the  tool (from an elevated command window), on a machine with test signing on. Then  can be used to load the driver into the system:</p><div><pre title=\"\">sc.exe sc create booster type= kernel binPath= c:\\path_to_driver_file\nsc.exe start booster\n</pre></div><p>I used an existing C++ application that talks to the driver and expects to pass the correct structure. It looks like this:</p><div><pre title=\"\">#include &lt;Windows.h&gt;\n#include &lt;stdio.h&gt;\n\nstruct ThreadData {\n\tint ThreadId;\n\tint Priority;\n};\n\nint main(int argc, const char* argv[]) {\n\tif (argc &lt; 3) {\n\t\tprintf(\"Usage: boost &lt;tid&gt; &lt;priority&gt;\\n\");\n\t\treturn 0;\n\t}\n\n\tint tid = atoi(argv[1]);\n\tint priority = atoi(argv[2]);\n\n\tHANDLE hDevice = CreateFile(L\"\\\\\\\\.\\\\Booster\",\n\t\tGENERIC_WRITE, 0, nullptr, OPEN_EXISTING, 0,\n\t\tnullptr);\n\n\tif (hDevice == INVALID_HANDLE_VALUE) {\n\t\tprintf(\"Failed in CreateFile: %u\\n\", GetLastError());\n\t\treturn 1;\n\t}\n\n\tThreadData data;\n\tdata.ThreadId = tid;\n\tdata.Priority = priority;\n\tDWORD ret;\n\tif (WriteFile(hDevice, &amp;data, sizeof(data),\n\t\t&amp;ret, nullptr))\n\t\tprintf(\"Success!!\\n\");\n\telse\n\t\tprintf(\"Error (%u)\\n\", GetLastError());\n\n\tCloseHandle(hDevice);\n\n\treturn 0;\n}\n</pre></div><p>Here is the result when changing a thread’s priority to 26 (ID 9408):</p><p>Writing kernel drivers in Rust is possible, and I’m sure the support for this will improve quickly. The WDK crates are at version 0.3, which means there is still a way to go. To get the most out of Rust in this space, safe wrappers should be created so that the code is less verbose, does not have  blocks, and enjoys the benefits Rust can provide. Note, that I may have missed some wrappers in this simple implementation.</p><p>You can find a couple of more samples for KMDF Rust drivers <a href=\"https://github.com/microsoft/Windows-rust-driver-samples\" target=\"_blank\" rel=\"noreferrer noopener\">here</a>.</p>","contentLength":12934,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42984457"},{"title":"The Deck: An open-source cross-platform multiplayer card game engine in Flutter","url":"https://github.com/xajik/thedeck","date":1739029656,"author":"igor_st","guid":183,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42983699"},{"title":"Obscure islands I find interesting","url":"https://amanvir.com/obscure-islands","date":1738967011,"author":"venusgirdle","guid":182,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42978199"},{"title":"Do-nothing scripting: the key to gradual automation (2019)","url":"https://blog.danslimmon.com/2019/07/15/do-nothing-scripting-the-key-to-gradual-automation/","date":1738957696,"author":"tehnub","guid":181,"unread":true,"content":"<p>Every ops team has some manual procedures that they haven’t gotten around to automating yet. <a href=\"https://landing.google.com/sre/sre-book/chapters/eliminating-toil/\">Toil</a> can never be totally eliminated.</p><p>Very often, the biggest toil center for a team at a growing company will be its procedure for modifying infrastructure or its procedure for provisioning user accounts. Partial instructions for the latter might look like this:</p><ol><li>Create an SSH key pair for the user.</li><li>Commit the public key to Git and push to master.</li><li>Wait for the build job to finish.</li><li>Find the user’s email address in the employee directory.</li><li>Send the user their private key via 1Password.</li></ol><p>This is a relatively short example. Sometimes there are 20 steps in the process. Sometimes there are branches and special cases to keep track of as you go. Over time, these procedures can become unmanageably large and complex.</p><p>Procedures like this are frustrating because they’re focus-intensive yet require very little thought. They demand our full attention, but our attention isn’t rewarded with interesting problems or satisfying solutions – just another checkbox checked. I have a word for a procedure like this: a .</p><p>We know that this procedure is ripe for automation. We can easily see how to automate any given step. And we know that a computer could carry out the instructions with far greater speed and accuracy than we can, and with less tendency toward <a href=\"https://risk-engineering.org/concept/Rasmussen-practical-drift\">practical drift</a>.</p><p>However, automating slogs sometimes feels like an all-or-nothing proposition. Sure, we could write a script to handle step 2, or step 5. But that wouldn’t  make the procedure any less cumbersome. It would lead to a proliferation of single-purpose scripts with different conventions and expectations, and you’d still have to follow a documented multi-step procedure for using those scripts.</p><p>This perception of futility is the problem we really need to solve in order to escape from these manual slogs. I’ve found an approach that works pretty reliably: .</p><p>Almost any slog can be turned into a . A do-nothing script is a script that encodes the instructions of a slog, encapsulating each step in a function. For the example procedure above, we could write the following do-nothing script:</p><div><pre title=\"\">import sys\n\ndef wait_for_enter():\n    raw_input(\"Press Enter to continue: \")\n\nclass CreateSSHKeypairStep(object):\n    def run(self, context):\n        print(\"Run:\")\n        print(\"   ssh-keygen -t rsa -f ~/{0}\".format(context[\"username\"]))\n        wait_for_enter()\n\nclass GitCommitStep(object):\n    def run(self, context):\n        print(\"Copy ~/new_key.pub into the `user_keys` Git repository, then run:\")\n        print(\"    git commit {0}\".format(context[\"username\"]))\n        print(\"    git push\")\n        wait_for_enter()\n\nclass WaitForBuildStep(object):\n    build_url = \"http://example.com/builds/user_keys\"\n    def run(self, context):\n        print(\"Wait for the build job at {0} to finish\".format(self.build_url))\n        wait_for_enter()\n\nclass RetrieveUserEmailStep(object):\n    dir_url = \"http://example.com/directory\"\n    def run(self, context):\n        print(\"Go to {0}\".format(self.dir_url))\n        print(\"Find the email address for user `{0}`\".format(context[\"username\"]))\n        context[\"email\"] = raw_input(\"Paste the email address and press enter: \")\n\nclass SendPrivateKeyStep(object):\n    def run(self, context):\n        print(\"Go to 1Password\")\n        print(\"Paste the contents of ~/new_key into a new document\")\n        print(\"Share the document with {0}\".format(context[\"email\"]))\n        wait_for_enter()\n\nif __name__ == \"__main__\":\n    context = {\"username\": sys.argv[1]}\n    procedure = [\n        CreateSSHKeypairStep(),\n        GitCommitStep(),\n        WaitForBuildStep(),\n        RetrieveUserEmailStep(),\n        SendPrivateKeyStep(),\n    ]\n    for step in procedure:\n        step.run(context)\n    print(\"Done.\")\n</pre></div><p>This script doesn’t actually  any of the steps of the procedure. That’s why it’s called a do-nothing script. It feeds the user a step at a time and waits for them to complete each step manually.</p><p>At first glance, it might not be obvious that this script provides value. Maybe it looks like all we’ve done is make the instructions harder to read. But the value of a do-nothing script is immense:</p><ul><li>It’s now much less likely that you’ll lose your place and skip a step. This makes it easier to maintain focus and power through the slog.</li><li>Each step of the procedure is now encapsulated in a function, which makes it possible to replace the text in any given step with code that performs the action automatically.</li><li>Over time, you’ll develop a library of useful steps, which will make future automation tasks more efficient.</li></ul><p>A do-nothing script doesn’t save your team any manual effort. It lowers the activation energy for automating tasks, which allows the team to eliminate toil over time.</p>","contentLength":4783,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42976698"},{"title":"Cities can cost effectively start their own utilities","url":"https://kevin.burke.dev/kevin/norcal-cities-new-utility/","date":1738950940,"author":"kevinburke","guid":180,"unread":true,"content":"<p>PG&amp;E's rates are high enough that, even with the massive headache and expense\ninvolved, it's feasible for cities to create their own utility and undercut\nPG&amp;E's rates. When the savings per household are around $800-$1200 per\nyear, though, they should take it seriously.</p><p>Here are the basic components of how much it costs to get electricity to your\nhouse.</p><ul><li><p> The cost to actually generate the electricity in a power plant\nor utility-scale solar farm. This varies by time of day but typically costs\nabout 4 cents per kilowatt hour; you can see the current wholesale rate on <a href=\"https://www.caiso.com/todays-outlook/prices\">the\nCAISO website</a>.</p></li><li><p> How much it costs to move the power from the power source to\na local substation/transformer, over large transmission lines. PG&amp;E breaks this\nout in its detailed rate chart at about 4 cents per kilowatt hour.</p></li><li><p> How much to get the power from your local substation to your\nhouse over local power lines. In PG&amp;E's rate chart, they charge <em>20 cents per\nkilowatt hour</em> for this. That just does not match up with how much it actually\ncosts them to transmit power over local lines and keep the lines maintained.</p></li><li><p> Operations, maintenance, profit. This is where PG&amp;E is\nactually seeing large expenses, because their coverage area is massive, it\ncosts a lot of money to deliver power to rural customers, and they are also\nundertaking a massive project to underground utility lines in fire-prone areas.</p></li></ul><p>The high price and design of the electricity system have a number of bad\neffects:</p><ul><li><p>People really hate inflation. When utility bills spike, it makes people\nunhappy and also fuels the (not incorrect) perception that California is poorly\ngoverned.</p></li><li><p>Lower income people spend a higher percentage of their income on electricity,\nso higher utility bills disproportionately hurt them.</p></li><li><p>The net effect of charging higher rates to everyone to pay for undergrounding\nis that people who live in urban areas are paying more money to subsidize\nenergy transmission for people who live in $2 million houses in places like the\nBerkeley and Orinda hills. This makes no sense.</p></li><li><p>Higher rates for electricity make electricity less competitive vs. gasoline\nwhen people are considering a car purchase. It makes electricity less\ncompetitive vs. natural gas for heating a house, heating water, or choosing a\nlaundry machine. As gas is warming the planet and electricity is substantially\neasier to generate in abundance from renewable sources, it's just bad policy to\nhave high electricity rates.</p></li></ul><p>Let's walk through what this might look like for a particular city to undercut\nPG&amp;E's rates. I will pick Walnut Creek because it's a reasonably big city with\na good mix of detached homes and multifamily. Walnut Creek also has experience\nwith public ownership of amenities - the City operates a golf course and a\ndowntown parking garage with ground floor retail.</p><p>There are a number of particular problems with applying PG&amp;E's rates to Walnut\nCreek:</p><ul><li><p>Walnut Creek is an urban area with a compact footprint that has little acreage\nin a high severity wildfire zone. It has two transmission lines as well as a\nlocal transformer grid along Ygnacio Valley Road. It is very cheap to transmit\npower from power plants to Walnut Creek, and from transmission lines to every\nhouse in Walnut Creek.</p></li><li><p>Walnut Creek has an above average number of apartments. Apartments do not\nhave as much space for rooftop solar, and landlords don't have an incentive to\nprovide rooftop solar because they typically pass through utility costs. This\nmeans NEM1 and NEM2 subsidies — <a href=\"https://lao.ca.gov/reports/2025/4950/Residential-Electricity-Rates-010725.pdf#page=8\">12% of the average non-solar bill</a>\n— disproportionately hurt Walnut Creek renters.</p></li><li><p>Local businesses have disproportionately high energy costs. Safeway and Whole\nFoods need to keep a row of refrigerators and freezers running 24/7. When they\npay PG&amp;E's rates to do that, those high energy costs are passed through as\nhigher food prices.</p></li></ul><p>Palo Alto's total electric consumption was 830 gigawatt hours in 2024 - 19% of\nthis usage was residential, and 81% was businesses and industry uses. Applying\nsome adjustments for Walnut Creek - our population is bigger, it's a bit hotter\nhere, and energy use has increased - let's say Walnut Creek uses about 1150\ngigawatt hours per year.</p><p>Palo Alto earned $172 million in revenue for 830 gigawatt hours, which is about\n20 cents per kilowatt hour.</p><p>Here's where Palo Alto's utility company spends money:</p><h4>Acquisition of the network and financing cost</h4><p>The first thing you need to do is buy out PG&amp;E's distribution network - all of\nthe power poles and local equipment that sits between the transmission lines and\npeople's houses. San Francisco proposed buying this for $2.5 billion in 2019;\nPG&amp;E rejected this offer for being too low. Adjusted for inflation and Walnut\nCreek's population, this is about $230 million, let's round up and say $350\nmillion. Let's also assume it costs $50 million in startup costs and one time\nexpenses to hire utility staff, buy equipment, marketing expense.</p><p>Cities with an AA credit rating can issue a 30 year loan at about 4% interest.\nBorrowing $400 million would cost about $23 million per year in interest and\nprincipal payments.</p><p>$23 million per year of financing cost spread across 1150 gigawatt hours is\nonly about 2 cents per kilowatt hour.</p><h4>Generation and distribution</h4><p>Palo Alto spent $114 million buying energy in 2024, about 14 cents per kilowatt\nhour. Let's assume Walnut Creek can get power for about 17 cents per kWh.</p><p>This covers customer service, financial management, billing, engineering work\nfor maintenance (tree trimming etc), and resource management. Palo Alto spent\n$65 million on these expenses in 2023. Let's assume Walnut Creek's costs are\nmuch higher at $90 million per year. This is about 8 cents per kilowatt hour.</p><p>Another $25 million per year is allocated for grid modernization,\nundergrounding, and reliability work. Let's assume this is $35 million per year\nfor Walnut Creek, which would be about 3 cents per kilowatt hour.</p><p>Adding this up, we get 30 cents per kilowatt hour, which is ten cents lower than\nPG&amp;E's base rate and about 15 cents lower than PG&amp;E's blended rate. At 1150\ngigawatt hours, <em>this would save Walnut Creek residential ratepayers about $23\nmillion per year in total, about $800 per ratepayer, and Walnut Creek businesses\nabout $92 million per year.</em> That is a  amount of money that could go\ntoward much more productive uses - paying higher salaries, lowering prices for\ngoods, spending more at local businesses.</p><p>Most elected officials would jump at the chance to mail every household a $800\ncheck every year. The next best thing is to put $800 back in their pocket.</p><h3>Other Benefits for Walnut Creek</h3><p>There are huge ancilliary benefits for Walnut Creek to running its own utility\nnetwork.</p><ul><li><strong>Green infrastructure investments:</strong> Walnut Creek has made sustainability a\nkey priority. Palo Alto owns a share in a hydroelectric dam, and Santa Clara\nowns a share in a geothermal plant. At a time when there are exciting new\ntechnologies that have the potential to reduce greenhouse gas emissions and\ndeliver clean, cheap energy to residents - things like Fervo Energy that <a href=\"https://www.washingtonpost.com/climate-environment/interactive/2024/fracking-geothermal-energy-plant-technology/\">use\nthe tech behind fracking to deliver geothermal power</a> - Walnut\nCreek can use its very low cost of capital to finance these investments. <strong>This\nis something PG&amp;E cannot do as effectively, because as a public utility with\nmassive amounts of debt and wildfire liability, their borrowing cost is much\nhigher.</strong> Public ownership would enable transformative green energy investments\nwith a low borrowing cost.</li></ul><ul><li><p><strong>Encouraging the green transition:</strong> A 25% reduction in the cost of\nelectricity relative to natural gas would make electric upgrades like heat pump\nwater heaters or electric cars much more financially prudent investments.</p></li><li><p> Like every city in California, Walnut Creek has boom\nand bust cycles. Utilities have much more stable revenues than cities. Walnut\nCreek could borrow from its utility in recessions, and loan money during booms.</p></li><li><p> Walnut Creek has a number of unincorporated\npockets (<a href=\"https://en.wikipedia.org/wiki/San_Miguel,_Contra_Costa_County,_California\">San Miguel CDP</a>, Shell Ridge CDP) that\nadministratively make little sense - they are served by different police,\nthey have different tax rules. If these homes could save $800 per year on\ntheir utility bill by joining Walnut Creek, this may provide an incentive to\nincorporate, which would ultimately lead to better governance.</p></li></ul><ul><li><p>Even if Walnut Creek doesn't ultimately pursue its own utility, just\ninvestigating the possibility may lead PG&amp;E to <em>offer concessions such as\nundergrounding the transmission line over downtown.</em> Because you can't\nbuild under a transmission line, this makes a 100 foot wide strip of very\nvaluable land undevelopable. St. Paul's would love to redevelop its parking\nlot under the transmission line for affordable housing, but can only develop\ntiny corners of the lot with the transmission line overhead. Undergrounding\nthe line would deliver huge benefits to Walnut Creek.</p></li><li><p><strong>Lowering the cost of urban living in safe places:</strong> PG&amp;E's current rate\nstructure has urban rate payers subsidize rural rate payers and people who live\nin wildfire zones in e.g. the Orinda Hills, who need substantial investment in\norder to receive power without sparking wildfires. This is bad policy - instead\nof subsidizing fire zones, it should be cheap to live in safe places and more\nexpensive to live in dangerous places. Lower cost of electricity would reverse\nthese trends.</p></li></ul><p>California is kneecapping its own climate transition with high electricity\nprices. The resulting inflation hurts our state's ability to retain a high\nclass, diverse workforce. Perversely, it also serves as a subsidy to wildfire\nzones at the expense of infill areas. It's time to reverse those trends and\ndeliver lower energy prices in places we want more Californians to live.</p><p><strong>What should I do if I want this to happen?</strong> Cities around the region are\ndoing \"priority setting\" exercises for 2025. Contact your Mayor or City\nCouncil and ask them to explore the possibility of creating their own utility,\npotentially partnering with other cities. I would probably select cities that do\nnot have large fire zones (ie, not Orinda or Moraga).</p>","contentLength":10023,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42975492"},{"title":"Noether's Theorem Revolutionized Physics","url":"https://www.quantamagazine.org/how-noethers-theorem-revolutionized-physics-20250207/","date":1738938812,"author":"MindGods","guid":179,"unread":true,"content":"<p>But symmetries go beyond shape. Imagine you do an experiment, then you move 10 meters to the left and do it again. The results of the experiment don’t change, because the laws of physics don’t change from place to place. This is called translation symmetry.</p><p>Now wait a few days and repeat your experiment again. The results don’t change, because the laws of physics don’t change as time passes. This is called time-translation symmetry.</p><p>Noether started with symmetries like these and explored their mathematical consequences. She worked with established physics using a common mathematical description of a physical system, called a Lagrangian.</p><p>This is where Noether’s insight went beyond the symbols on the page. On paper, symmetries seem to have no impact on the physics of the system, since symmetries don’t affect the Lagrangian. But Noether realized that symmetries must be mathematically important, since they constrain how a system can behave. She worked through what this constraint should be, and out of the mathematics of the Lagrangian popped a quantity that can’t change. That quantity corresponds to the physical property that’s conserved. The impact of symmetry had been hiding beneath the equations all along, just out of view.</p><p>In the case of translation symmetry, the system’s total momentum should never change. For time-translation symmetry, a system’s total energy is conserved. Noether discovered that conservation laws aren’t fundamental axioms of the universe. Instead, they emerge from deeper symmetries.</p><p>The conceptual consequences are hard to overstate. Physicists of the early 20th century were shocked to realize that a system that breaks time-translation symmetry can break energy conservation along with it. We now know that our own universe does this. The cosmos is expanding at an accelerating rate, stretching out the leftover light from the early universe. The process reduces the light’s energy as time passes.</p><p>“Before Noether’s theorem, the principle of conservation of energy was shrouded in mystery,” the physicist and mathematician Feza Gürsey wrote in 1983. “… Noether’s simple and profound mathematical formulation did much to demystify physics.”</p><p>Noether’s theorem has shaped the quantum world too. In the 1970s, it played a big role in the construction of the Standard Model of particle physics. The symmetries of quantum fields dictate laws that restrict how fundamental particles behave. For instance, a symmetry in the electromagnetic field forces particles to conserve their charge.</p><p>“There’s a lot we have left to learn by thinking hard about Noether’s theorem,” the mathematical physicist John Baez said. “It has layers and layers of depth to it.”</p>","contentLength":2738,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42972982"},{"title":"3D reconstruction of the capital of the Aztec empire","url":"https://tenochtitlan.thomaskole.nl/","date":1738770027,"author":"simonpure","guid":178,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42950059"}],"tags":["dev","hn"]}