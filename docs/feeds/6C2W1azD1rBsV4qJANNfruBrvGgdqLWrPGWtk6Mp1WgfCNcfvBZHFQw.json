{"id":"6C2W1azD1rBsV4qJANNfruBrvGgdqLWrPGWtk6Mp1WgfCNcfvBZHFQw","title":"The System Design Newsletter","displayTitle":"Dev - System Design Newsletter","url":"https://newsletter.systemdesign.one/feed","feedLink":"https://newsletter.systemdesign.one/","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":9,"items":[{"title":"A Crash Course on High Availability","url":"https://newsletter.systemdesign.one/p/what-is-high-availability","date":1772283429,"author":"Neo Kim","guid":40,"unread":true,"content":"<p>Why should we care about uptime? And what exactly is high availability?</p><p>A payment system that goes down during peak shopping hours bleeds revenue. A hospital record system that crashes mid-shift puts patients at risk. An app going offline for ten minutes triggers trending hashtags from angry users.</p><p>Downtime is never abstract‚Ä¶</p><p>It translates into lost money, lost trust, and sometimes even legal penalties. Some of it can never be recovered. High availability started long before the cloud. In the 1960s, defense and finance systems had to run nonstop. Those engineers designed machines that could keep working even when parts failed. When the internet arrived, that same discipline moved online. Banks, retailers, and payment networks learned that a brief outage can erase months of profit.</p><p>With the widespread use of technology, the expectation of ‚Äúalways on‚Äù has never been greater. Now, uptime is not a luxury but a baseline.</p><p>The goal never changed: build systems that keep running when the world shakes.</p><p>So failures will happen. No matter how hard we try, we can‚Äôt avoid them. Hardware burns out, networks drop packets, software engineers create bugs. High availability () is about absorbing those failures behind the scenes‚Ä¶it‚Äôs about the service being available regardless of failures.</p><p>People don‚Äôt think about their car tires until one goes flat.</p><p>High availability is having a spare one in the trunk. After we replace them, we can drive again. We can‚Äôt always control why the tire got flat, but we can carry a spare one. This is the core idea of high availability.</p><p>Now let‚Äôs put some numbers to it.</p><p>Treat your app like an Orchid: A beautiful flower that needs sunlight and a bit of water üå∏</p><p>Most ‚ÄúAI builders‚Äù make you grow your app in their pot. Same stack. Same limits. Same rules. And on their databases.</p><ul><li><p>It‚Äôs your build space, set up your way.</p></li><li><p>Build anything, Web app, mobile app, Slack bot, Chrome extension, Python script, whatever.</p></li><li><p>Bring your own AI subscriptions so you‚Äôre not paying twice.</p></li><li><p>Plug in the database you already use and trust.</p></li><li><p>Use any payment infra you want.</p></li></ul><p>(Thanks, <a href=\"https://orchidsapp.link/neokim\">Orchids</a>, for partnering on this post.)</p><p><strong>Use this discount code to get a one time 15% off during checkout: MARCH15</strong></p><p>HA means keeping a system running even when parts of it fail.</p><p>The higher the availability, the less impact each individual failure has. To manage HA, engineers use . These turn vague ideas like ‚Äúkeep it up and running‚Äù into numbers we can measure:</p><ul><li><p><strong>Service Level Agreement (SLA):</strong> Contract with customers about service performance.</p><ul><li><p>This contract keeps a record of what the service provider promises to deliver</p></li><li><p>There are penalties or costs if the contract is not respected</p></li><li><p>In HA, this is an agreement about how much downtime is acceptable</p></li><li><p>For example, ‚Äúour app will be online 99.9% of the time. If not, we‚Äôll give your money back.‚Äù</p></li></ul></li><li><p><strong>Service Level Objective (SLO):</strong> Specific internal goal for the service performance.</p><ul><li><p>This is the target that internal teams are trying to hit with a desired metric</p></li><li><p>Your SLA is the minimum you promise customers; your SLO is the better performance you target internally</p></li><li><p>For example, if the SLA is 95% uptime, the SLO might be 98% to leave a 3% safety margin</p></li></ul></li><li><p><strong>Service Level Indicator (SLI):</strong> Metric used to measure service performance.</p><ul><li><p>Without measuring service performance, we can‚Äôt know if we‚Äôre hitting the targets</p></li><li><p>These metrics should reflect the SLO and SLA</p></li><li><p>For example, ‚ÄúPercentage of failed requests.‚Äù</p></li></ul></li></ul><p>Let‚Äôs illustrate it with an example:</p><ul><li><p>A restaurant promises customers that their food will be delivered within 20 minutes of ordering (SLA).</p></li><li><p>The kitchen aims to finish orders in 15 minutes to stay ahead (SLO).</p></li><li><p>They track the average order completion time (SLI).</p></li></ul><p>These targets get expressed in ‚Äúnines of availability‚Äù.</p><p>One nine means 90% uptime; two nines mean 99%; and so on‚Ä¶</p><p>Each extra nine sounds small, but cuts downtime by a ton. For example, 99% uptime allows over 3 days of outage a year, while 99.9% (‚Äúthree nines‚Äù) allows only about 8 hours. Every nine added costs more. It needs better hardware, more redundancy, and more monitoring.</p><p>The closer you aim for perfect uptime, the more effort and money it takes to maintain it.</p><p>When failures occur,&nbsp;<a href=\"https://www.atlassian.com/incident-management/kpis/common-metrics\">recovery metrics</a>&nbsp;help us measure how quickly and effectively we can recover. Here are the most important ones:</p><ul><li><p><strong>Recovery Time Objective (RTO)</strong></p><ul><li><p>How fast should the system recover from failure? How long can it be down for?</p></li><li><p>Larger RTO means more downtime is acceptable; smaller RTO means less downtime</p></li><li><p>For example, an RTO of 10 minutes means that the system should be able to recover within 10 minutes of failing</p></li></ul></li><li><p><strong>Recovery Point Objective (RPO)</strong></p><ul><li><p>To what point in time does the system recover? How much data loss is acceptable?</p></li><li><p>Larger RPO means more data loss, smaller RPO means less</p></li><li><p>For example, an RPO of 5 minutes means 5 minutes of data gets lost</p></li></ul></li></ul><ul><li><p><strong>MTTD (Mean Time to Detect)</strong></p><ul><li><p>This is the mean time needed to notice a failure</p></li><li><p>How long does it usually take for the system or team to detect that something is wrong?</p></li><li><p>Smaller MTTD means faster detection; larger MTTD means slower detection</p></li><li><p>For example, an MTTD of 30 seconds means issues get found half a minute after they occur on average</p></li></ul></li></ul><ul><li><p><strong>MTTR (Mean Time to Repair)</strong></p><ul><li><p>This is the mean time needed to fix a failure. How long does the system usually take to recover?</p></li><li><p>Larger MTTR means more time to recover, smaller MTTR means less</p></li><li><p>For example, an MTTR of 5 minutes means the failure will take 5 minutes to recover on average</p></li></ul></li><li><p><strong>MTBF (Mean Time Between Failures)</strong></p><ul><li><p>This is the mean time between two failures. How often does the system usually fail?</p></li><li><p>Larger MTBF means failures happen less often &amp; vice-versa</p></li><li><p>For example, an MTBF of 1h means failures usually happen every hour</p></li></ul></li><li><p><strong>MTTF (Mean Time to Failure)</strong></p><ul><li><p>This metric is designed for non-recoverable components. How long is the lifespan of this component?</p></li><li><p>This metric differs from MTBF because it lacks a recovery component. The component is alive, and then it crashes without recovery. MTTF is the time between those two points.</p></li><li><p>A larger MTTF means a component has a longer lifespan, and a smaller MTTF means a shorter one</p></li><li><p>For example, an MTTF of 3 years means a component usually lasts for 3 years before becoming unusable</p></li></ul></li></ul><p>Availability links uptime &amp; downtime in one line:</p><div data-attrs=\"{&quot;language&quot;:&quot;plaintext&quot;,&quot;nodeId&quot;:&quot;2263ec8c-47cd-441d-988c-7e9d581966a6&quot;}\" data-component-name=\"HighlightedCodeBlockToDOM\"><pre><code>Availability = MTBF / (MTBF + MTTR)</code></pre></div><p>If the system runs for 1000 hours before a 1-hour fix, uptime is 99.9%.</p><p>Every extra nine costs more to achieve. Past ‚Äúthree nines,‚Äù you buy less outage and pay more in redundancy, automation, and testing.</p><p>HA is measurable. Metrics turn abstract goals into clear engineering targets.</p><p>What gets measured gets managed.</p><p><em><strong>Reminder: this is a teaser of the subscriber-only post, exclusive to my golden members.</strong></em></p><p>When you upgrade, you‚Äôll get:</p><ul><li><p><strong>Full access to System Design Case Studies</strong></p></li><li><p>FREE access to (coming) Interview Academy</p></li><li><p><strong>FREE access to (coming) Design, Build, Scale newsletter series</strong></p></li></ul><p>Get 10x the results you currently get with 1/10th the time, energy &amp; effort.</p>","contentLength":6924,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/3dcd543a-ebea-4765-a859-d4bae681e495_1280x720.png","enclosureMime":"","commentsUrl":null},{"title":"System Design Interview: Design ChatGPT","url":"https://newsletter.systemdesign.one/p/chatgpt-system-design","date":1772037056,"author":"Neo Kim","guid":39,"unread":true,"content":"<p>Most engineers think designing an AI chat system is just <em>‚Äúcalling OpenAI API and saving messages to a database‚Äù.</em></p><p><em>That approach doesn‚Äôt work when you need to handle ChatGPT‚Äôs scale:</em></p><ul><li><p><em>5.8 billion visits per month</em></p></li><li><p><em>1 billion weekly active users sending 2.5+ billion prompts per day</em></p></li></ul><p>Your database can‚Äôt store 500TB per year. API costs will hit $145 million per month. And you‚Äôll need 11.4 million concurrent connections that no single server can handle.</p><p>This problem shows up in senior and staff-level interviews at companies building AI products because it tests the exact skills that separate mid-level engineers from seniors:</p><ul><li><p>handling stateful connections at scale,</p></li><li><p>managing expensive external dependencies,</p></li><li><p>keeping costs under control while maintaining good UX,</p></li><li><p>and designing for failures when parts of your system go down.</p></li></ul><p>We‚Äôre going to build this from scratch at ChatGPT‚Äôs real scale, starting with clarifying requirements, then moving through frontend and backend design, database sharding, the complete user flow, GPU infrastructure, and finally explaining how to scale even further to 1 billion users.</p><p>Before we design anything, we need to understand exactly what we‚Äôre building and at what scale‚Ä¶</p><p>Give your agents the understanding they need to generate reliable code, reviews, and answers.  builds context from your team‚Äôs code, PR history, conversations, documentation, planning tools, and runtime signals. It surfaces the insights that matter so AI outputs reflect how your system actually works.</p><p>(Thank you, <a href=\"https://getunblocked.com/?utm_source=systemdesign&amp;utm_medium=email&amp;utm_campaign=contextengine\">Unblocked</a>, for partnering on this post.)</p><p>He‚Äôs a senior software engineer specializing in helping developers break through their career plateaus and secure senior roles.</p><p>If you want to master the essential system design skills and land senior developer roles, I highly recommend checking out Hayk‚Äôs .</p><p>His approach focuses on what top employers actually care about: system design expertise, advanced project experience, and elite-level interview performance.</p><p> In interviews, candidates who skip this step fail immediately.</p><ul><li><p>Are we building the AI model itself or integrating with existing ones?</p></li><li><p>Do we need streaming responses (word by word) or complete responses?</p></li><li><p>What‚Äôs our expected scale? Thousands or millions of users?</p></li><li><p>Do users need accounts and conversation history?</p></li><li><p>Are conversations private or shareable?</p></li><li><p>Do we support multiple languages?</p></li><li><p>How do we handle rate limiting? Free vs paid tiers?</p></li><li><p>Text only, or images and files too?</p></li><li><p>Do we need content moderation?</p></li></ul><p><strong>For this design, let‚Äôs assume:</strong></p><ul><li><p>Integrating with existing LLM (not building the model ourselves)</p></li><li><p>Streaming responses required for good UX</p></li><li><p>As of January 2026, ChatGPT has 800-900 million weekly active users, with an average of 2.5+ billion prompts per day</p></li><li><p>Users need accounts, private conversations with history</p></li><li><p>Rate limiting on both requests and tokens</p></li><li><p>Basic content moderation required</p></li></ul><p>Now that we‚Äôve defined our requirements, let‚Äôs start with what users actually see and interact with.</p><h2><strong>Frontend Interface Design</strong></h2><p>Let‚Äôs visualize what we‚Äôre building. This clarifies requirements and influences backend decisions.</p><h4><strong>Critical frontend decision: Streaming</strong></h4><p><strong>Option 1: Wait for complete response</strong></p><ul><li><p>Simple HTTP POST, and get a full response back</p></li><li><p>User waits 10-30 seconds staring at the loading spinner</p></li></ul><p><strong>Option 2: Stream word by word</strong></p><ul><li><p>Requires a persistent connection</p></li><li><p>User sees progress immediately</p></li></ul><p>ChatGPT, Claude, and Gemini all use streaming.</p><p>Let me verify the exact implementation.</p><h3><strong>How streaming actually works:</strong></h3><p>All major AI chat products use Server-Sent Events (SSE), not WebSockets.</p><ul><li><p>Browser has a built-in EventSource API</p></li><li><p>Auto-reconnection handled automatically</p></li><li><p>One-way communication (server to client)</p></li><li><p>Simpler to implement and debug</p></li><li><p>Lower overhead than WebSockets</p></li></ul><p><strong>WebSockets (what ChatGPT doesn‚Äôt use):</strong></p><ul><li><p>Requires protocol upgrade from HTTP</p></li><li><p>Bidirectional communication</p></li><li><p>More complex to implement</p></li><li><p>Useful for collaborative features, typing indicators</p></li><li><p>Overkill for just streaming AI responses</p></li></ul><p><strong>Example of SSE streaming:</strong></p><p>User types: </p><p>Each word appears in the UI as it arrives, creating the typing effect.</p><ul><li><p>EventSource API for SSE connection</p></li><li><p>State management (Zustand or Redux) for conversations</p></li><li><p>Optimistic updates (show user message immediately)</p></li><li><p>Error handling for network failures, rate limits</p></li></ul><p>The frontend sets user expectations for real-time streaming.</p><p>Now, let‚Äôs formalize what our system must do.</p><ul><li><p>User registration and authentication</p></li><li><p>Create and manage conversations</p></li><li><p>Send messages and receive streaming AI responses via SSE</p></li><li><p>Save all conversations with full history</p></li><li><p>Retrieve past conversations</p></li><li><p>Stream responses token by token</p></li><li><p>Rate limiting (requests + tokens)</p></li><li><p>Content moderation for harmful requests</p></li></ul><p>We‚Äôve defined what the system does. But how well must it perform?</p><p>These requirements will drive our architectural decisions.</p><h2><strong>Non-Functional Requirements</strong></h2><p>How well it must perform (we‚Äôll connect these to design decisions later):</p><ul><li><ul><li><p>Max 43 minutes of downtime per month</p></li></ul></li><li><p>Latency: First token &lt; 2 seconds</p><ul><li><p>Users wait no more than 2 seconds</p></li></ul></li><li><p>Scalability: 200M DAU, 20M concurrent conversations</p></li><li><p>Consistency: Zero message loss</p><ul><li><p>Every message must be saved</p></li></ul></li><li><ul><li><p>LLM APIs are expensive and need optimization</p></li></ul></li><li><p>Security: End-to-end encryption</p></li></ul><p>We‚Äôll show how our design achieves each of these.</p><p>We‚Äôve set our performance targets. Now let‚Äôs run the numbers to see what infrastructure we actually need.</p><h2><strong>Capacity and Storage Estimation</strong></h2><p>Math matters because it drives infrastructure decisions.</p><p>Let‚Äôs use ChatGPT‚Äôs actual scale of growth projections:</p><ul><li><p>1 billion weekly active users (WAU)</p><ul><li><p>The current sources show 800-900 million weekly active users.</p></li><li><p>To accommodate growth and simplify our calculations, let‚Äôs design for 1 billion weekly active users.</p></li></ul></li><li><p>~200 million daily active users (DAU)</p></li><li><p>2.5 billion prompts/messages per day</p><ul><li><p>ChatGPT‚Äôs actual processing volume</p></li></ul></li><li><p>12.5 messages per user per day average</p></li><li><p>Peak hours (20% of daily traffic in 2 hours)</p></li><li><p>Concurrent conversations at peak: ~20 million</p><ul><li><p>Assuming 10% of DAU are chatting simultaneously</p></li></ul></li></ul><p><strong>Storage per conversation:</strong></p><ul><li><p>User message: 100 characters = 100 bytes</p></li><li><p>AI response: 500 characters = 500 bytes</p></li><li><p>12.5 exchanges/day/user: 7.5 KB/user/day</p></li><li><p>200M DAU √ó 7.5KB = 1.5TB/day</p></li></ul><ul><li><p>User profiles (1KB each): 1B √ó 1KB = 1TB</p></li><li><p>Conversation metadata (500 bytes each, 10 per user average): 10B conversations √ó 500B = 5TB</p></li></ul><p> (need distributed database, single PostgreSQL won‚Äôt cut it)</p><ul><li><p>20M concurrent SSE connections at peak</p></li><li><p>Each connection: ~10-30 seconds average</p></li><li><p>Need infrastructure that can handle millions of long-lived connections</p></li></ul><ul><li><p>Average response: 750 bytes streamed over 20 seconds</p></li><li><p>20M concurrent: 20M √ó 750B / 20s = 750 MB/s = 6 Gbps</p></li><li><p>Peak outbound bandwidth requirement</p></li></ul><p> At ChatGPT‚Äôs scale, single-server solutions don‚Äôt work. We need distributed systems, sharding, and multi-region deployment from day one.</p><p>Now that we know the scale we‚Äôre dealing with, let‚Äôs design the actual system that can handle it.</p><p>Before diving into costs and implementation details, let‚Äôs map out the complete system architecture.</p><p>OpenAI uses a multi-cloud setup to secure enough compute power and avoid relying on a single vendor:</p><ul><li><p> Still their leading provider. They have a massive, long-term partnership in which Microsoft builds specialized supercomputers for training OpenAI‚Äôs models.</p></li><li><p> OpenAI signed a $38 billion deal with Amazon in late 2025. They now run significant workloads on AWS‚Äôs GPU clusters and specialized AI hardware.</p></li><li><p> As of mid-2025, OpenAI uses GCP to power parts of ChatGPT Enterprise and the Team tiers, as well as their API.</p></li><li><p> They have a multi-billion dollar agreement to use Oracle‚Äôs data center capacity, specifically for the massive ‚ÄúStargate‚Äù infrastructure project.</p></li><li><p> They also use this specialized ‚Äúneocloud‚Äù provider for dedicated access to high-performance NVIDIA GPUs.</p></li></ul><p>Our system has three main layers:</p><ol><li><ul><li><p>Mobile apps (iOS/Android)</p></li><li><p>SSE connections for real-time streaming</p></li></ul></li></ol><ol start=\"2\"><li><p>Service Layer (Microservices)</p><ul><li><p>API Gateway: Entry point, SSL termination, request routing</p></li><li><p>Auth Service: JWT authentication, user session management</p></li><li><p>Message Service: Core orchestrator for message processing and streaming</p></li><li><p>Conversation Service: CRUD operations for conversations and message history</p></li><li><p>Rate Limiter Service: Track and enforce request/token limits per user</p></li><li><p>Moderation Service: Content filtering for harmful requests</p></li><li><p>LLM Gateway Service: Routes requests to GPU clusters, handles streaming responses</p></li></ul></li></ol><ul><li><ul><li><p>Load Balancer is ‚Äúdumb‚Äù - it just distributes TCP/HTTP connections across servers.</p></li><li><p>API Gateway is ‚Äúsmart‚Äù - reads the URL path and routes:  ‚Üí Auth Service, ‚Üí Conversation Service, etc.</p></li></ul></li></ul><ol start=\"3\"><li><ul><li><p>PostgreSQL: Single primary + 20 read replicas (user data, conversations, messages)</p></li><li><p>Redis Cluster: Rate limiting state, conversation history cache, response cache</p></li><li><p>GPU Cluster: 17,500 H100 GPUs for model inference</p></li><li><p>Azure Blob Storage: Long-term archive for old conversations</p></li></ul></li></ol><h4><strong>How Does the User Receive the Response?</strong></h4><p>The response flows back through the SAME connection path, reversed:</p><ul><li><p>The HTTP connection stays open from:</p><div data-attrs=\"{&quot;language&quot;:&quot;plaintext&quot;,&quot;nodeId&quot;:&quot;f8e55f7f-bc55-485a-9fa6-113aef0c44ab&quot;}\" data-component-name=\"HighlightedCodeBlockToDOM\"><pre><code> Browser ‚Üí Load Balancer ‚Üí API Gateway ‚Üí Message Service</code></pre></div></li><li><p>Message Service writes tokens to the response stream</p></li><li><p>Each token flows backward:</p><div data-attrs=\"{&quot;language&quot;:&quot;plaintext&quot;,&quot;nodeId&quot;:&quot;88ebc8e3-65fe-418a-869a-50a9bbff9379&quot;}\" data-component-name=\"HighlightedCodeBlockToDOM\"><pre><code>Message Service ‚Üí API Gateway ‚Üí Load Balancer ‚Üí Browser</code></pre></div></li><li><p>Browser‚Äôs EventSource API receives each event in real-time</p></li><li><p>Connection closes when streaming completes</p></li></ul><p>Think of it like a phone call:</p><div data-attrs=\"{&quot;language&quot;:&quot;plaintext&quot;,&quot;nodeId&quot;:&quot;6df3e375-83fe-457d-8e3d-7b009eb68ba1&quot;}\" data-component-name=\"HighlightedCodeBlockToDOM\"><pre><code>You call (request) ‚Üí they answer and KEEP TALKING for 20 seconds (streaming) ‚Üí then hang up.</code></pre></div><p>Same connection, just stays open longer.</p><h3><strong>Key Architectural Decisions</strong></h3><p><strong>Single Primary PostgreSQL (not sharded)</strong></p><ul><li><p>Why: ChatGPT‚Äôs workload is 90% reads, 10% writes</p></li><li><p>OpenAI‚Äôs proven architecture: handles 800M users without sharding</p></li><li><p>Writes: All go through a single primary instance</p></li><li><p>Reads: Distributed across 20+ replicas in 6 regions</p></li><li><p>Trade-off: Single writer bottleneck, but application simplicity wins</p></li></ul><p><em><strong>Why reads dominate despite 2.5B prompts/day</strong></em></p><p>Think about what happens per user prompt:</p><ul><li><p>Load subscription/quota info</p></li><li><p>Load conversation metadata</p></li><li><p>Load recent messages for context</p></li><li><p>Maybe load feature flags, experiments, and so on.</p></li></ul><p>Writes usually happens only when:</p><ul><li><p>Conversation metadata is updated</p></li><li><p>Usage counters are incremented</p></li></ul><p>So one prompt can trigger many reads, but only a few writes.</p><p><strong>Microservices Architecture</strong></p><ul><li><p>Why: Independent scaling and deployment</p></li><li><p>Each service scales independently based on its load</p></li><li><p>LLM Gateway can scale GPU clusters without touching other services</p></li><li><p>Rate Limiter needs different scaling than Conversation Service</p></li><li><p>Trade-off: Operational complexity vs scaling flexibility</p></li></ul><p><strong>SSE for Streaming (not WebSockets)</strong></p><ul><li><p>Why: Simpler, one-way communication is sufficient</p></li><li><p>Browser has a built-in EventSource API with auto-reconnection</p></li><li><p>Lower overhead than WebSockets</p></li><li><p>Most AI products (ChatGPT, Claude, Gemini) use SSE</p></li><li><p>Trade-off: Can‚Äôt do bidirectional communication (acceptable for chat)</p></li></ul><p><strong>Self-Hosted GPU Infrastructure</strong></p><ul><li><p>Why: At 2.5B messages/day, API costs would be $159M/month</p></li><li><p>Self-hosting: $52.4M/month (67% cheaper)</p></li><li><p>Requires: 17,500 H100 GPUs across multiple cloud providers</p></li><li><p>Trade-off: $525M upfront cost vs ongoing API expenses</p></li></ul><ul><li><p>6 regions: 2 Americas, 2 Europe, 2 Asia-Pacific</p></li><li><p>Why: Global low-latency (users connect to the nearest region)</p></li><li><p>Each region has a full application stack + read replicas</p></li><li><p>GPU clusters are centralized in 3-4 major data centers</p></li><li><p>Trade-off: Operational complexity vs user experience</p></li></ul><p>We've mapped out the architecture.</p><p>The interesting part comes next: how much this actually costs to run, why OpenAI made the controversial choice to not shard their database, and what changes at 500M and 1B users.</p><p>First, let's trace a message from the send button to the AI response‚Ä¶</p>","contentLength":11483,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/f0475035-1015-4e4d-8d47-0c650b185661_1280x720.png","enclosureMime":"","commentsUrl":null},{"title":"System Design Interview: Design Web Crawler and Search Engine","url":"https://newsletter.systemdesign.one/p/web-crawler-system-design","date":1771674316,"author":"Neo Kim","guid":38,"unread":true,"content":"<p>You type something in the Google Search bar and get instant results.</p><p>Today‚Äôs newsletter will teach you the architecture of search systems.</p><p>At a high level, a search system has two components: <strong>a web crawler and a search engine.</strong></p><ul><li><p>A web crawler crawls webpages and stores them in a datastore.</p></li><li><p>A search engine looks through the data in the datastore to answer user search queries.</p></li></ul><p>Let‚Äôs start by understanding the system requirements‚Ä¶</p><p> turns search results into predictable JSON with built-in scale, location options, and protection from blocks.</p><p>That‚Äôs why engineers use it to ship:</p><ul></ul><p>All without maintaining scrapers or infrastructure.</p><p>(I‚Äôd like to thank <a href=\"https://serpapi.com/?utm_source=thesystemdesignnewsletter\">SerpApi</a> for partnering on this post.)</p><p>He‚Äôs an author, educator, and software engineer with a strong passion for building simple, scalable systems. He authored the O'Reilly book \"System Design on AWS\" and supports others' learning and development by sharing lessons on Cloud and System Design on <a href=\"https://www.youtube.com/@MsDeepSingh\">YouTube</a>.</p><p><em>(There are two kinds of requirements: functional and non-functional.)</em></p><p>Functional requirements are functionalities from the user's perspective.</p><ul><li><p>Fetching top results for a search query.</p></li><li><p>Including the web page URL, title, and subtitle in each result.</p></li><li><p>Avoiding outdated results.</p></li></ul><p>Search systems are large and support many functionalities. So let‚Äôs limit the scope:</p><ul><li><p>Queries can only be done in English.</p></li><li><p>Exclude what, why, and how of machine learning components.</p></li></ul><p>The system must follow certain constraints to maintain quality. These are called non-functional requirements ().</p><ul><li><p>Availability: System must be up and able to respond to search requests.</p></li><li><p>Reliability: System must return correct and consistent results.</p></li><li><p>Scalability: User traffic grows over time, so does the content on the internet. The system must handle this growth without performance issues.</p></li><li><p>Low Latency: Search results should be returned in milliseconds.</p></li></ul><p>These requirements guide the system design. Another important factor is the expected scale, which directly affects design decisions.</p><p>Let‚Äôs estimate the system scale next‚Ä¶</p><p>In system design interviews, it‚Äôs recommended to make some assumptions after discussion with the interviewer.</p><p>Here are some estimations:</p><p>The scale of a web crawler depends on how many pages it crawls.</p><ul><li><p>Active websites: 200 million</p></li><li><p>Average pages per website: 50</p></li></ul><p>Now, for each website, there can be both internal and external redirects. The external redirects are part of 200 million.</p><p>Then, for internal redirects:</p><ul><li><p>Total pages = 200 million √ó 50 = 10 billion pages</p></li></ul><ul><li><p>Total storage = 10 billion √ó 2 MB = 20 PB</p></li></ul><p>NOTE: Web pages can include text, images, and videos. In practice, a crawler may store only the parts needed for search. This estimate assumes we store pages as-is, in the same format in which we download them.</p><p>Let‚Äôs look into the scale of the search engine system next‚Ä¶</p><p>Assume Google scale traffic:</p><ul><li><p>Searches per day: 8.5 billion</p></li><li><p>Searches per second: ~100,000</p></li></ul><p>These rough numbers help shape the design choices.</p><p>Next, we‚Äôll dive into the high-level system design‚Ä¶</p><p>We‚Äôll design a scalable system and discuss the key components of each subsystem separately. Keep in mind that Google has evolved significantly to support this scale, and it is not possible to capture all details in this post.</p><p>We‚Äôll first design the web crawler, and then move on to the search engine:</p><p>The crawler needs an initial list of URLs to start with. These are called .</p><p>There is no single source that contains all websites. So we start with well-known domains and discover new URLs as we crawl.</p><p>Here are several ways to discover new website URLs:</p><ul><li><p>Create a platform for new website owners to submit their site details.</p></li><li><p>Retrieve the list of website links from the website being crawled.</p></li><li><p>New website URL queried by the user.</p></li></ul><p>The crawler does not visit every website at the same rate. Some sites change frequently, while others rarely update.</p><p>The process of deciding how often to visit a website is called <strong>crawl scheduling (politeness)</strong>. The component that decides which URL to crawl next is called the .</p><p>The design shown in Figure 1 is inspired by the <a href=\"https://www.cs.cornell.edu/courses/cs685/2002fa/mercator.pdf\">Mercator</a> crawler. It uses a two-stage queue system to handle both priority and politeness.</p><p>Here‚Äôs the architecture overview:</p><ul><li><p>Front queues represent different priority levels. The prioritizer assigns a priority (for example, 1 to n) to each URL. Based on this value, the URL gets placed into a specific front queue. The front queue selector picks URLs using a weighted round-robin approach, so higher-priority URLs get chosen more often.</p></li><li><p>From the front queues, URLs move to the back queues. A domain-to-back-queue database ensures that all URLs from the same host (for example, example.com) go to the same back queue. This helps enforce politeness rules per host.</p></li><li><p>A priority queue (implemented as a min-heap) keeps track of when each host can be contacted again. There is one entry per back queue. The heap stores the next allowed fetch time for that host/domain.</p></li><li><p>The back queue selector removes the host with the earliest allowed time from the heap. It then fetches one URL from that host‚Äôs back queue. After the URL gets crawled, the system updates the heap with the next allowed fetch time according to politeness rules.</p></li></ul><p>While Mercator provides a strong foundation, there can be bottlenecks at internet scale:</p><ul><li><p>FIFO queues keep a fixed number of URLs in memory and store most URLs on disk to support a high crawl rate on commodity hardware. At a large scale, frequent disk reads and writes can become a bottleneck. More advanced disk-based algorithms (such as those discussed in <a href=\"https://irl.cs.tamu.edu/people/hsin-tsang/papers/www2008.pdf\">IRLBot research paper</a>) can help reduce this overhead.</p></li><li><p>Another issue is static priority and politeness logic. If a website becomes slow or starts returning errors, the crawler should adjust its crawl rate dynamically. Instead of fixed rules, the system should use adaptive politeness. HTTP response code could be an important factor in this decision.</p><ul><li><p>HTTP 200: Crawl at normal rate.</p></li><li><p>HTTP 429: Reduce crawl rate and retry later.</p></li><li><p>HTTP 500: Retry only after a longer cooldown.</p></li></ul></li><li><p>Many domains could share the same IP address (shared hosting, CDNs, cloud providers). Using a single back queue per host can cause skew or a hotspot. The solution is to enforce limits at both the host and IP levels.</p><ul><li><p> can be crawled once every 10 seconds.</p></li><li><p>IP  can be crawled up to 5 times per second across all domains hosted on that IP.</p></li></ul></li></ul><p>URL frontier acts on a continuous feedback loop. URL fetcher (Figure 2) reports metrics such as latency and error rate. URL frontier adjusts crawl rate and priority based on these signals.</p><ul><li><p>If a website responds slowly, increase politeness (reduce crawl rate).</p></li><li><p>If there are repeated 500 errors, lower the website‚Äôs priority.</p></li></ul><p>Once URL frontier selects a URL, the crawler visits the page. Before crawling, the system should check whether the page has already been fetched or modified. There is no benefit in fetching the same content repeatedly.</p><p>Next, let‚Äôs discuss URL duplication and content duplication handling...</p><h3>2. Web Page Similarity and URL Duplication</h3><p>A web crawler can run into infinite loops. This can happen if:</p><ul><li><p>The same URL appears many times in different places.</p></li><li><p>URLs are generated dynamically in large numbers.</p></li></ul><p>To prevent this, the crawler must detect duplicate URLs before crawling them.</p><p>How do we check if a URL was crawled?</p><p>One approach is to store all crawled URLs in a global lookup table (HashMap). As many crawler instances run in parallel, this lookup must be shared across machines. A distributed key-value database can be used for this purpose.</p><p>This lookup needs to be fast.</p><p>Disk-based databases increase latency because of disk reads. An in-memory system is faster but must handle very large amounts of data. The data can be partitioned (sharded) across many machines to scale.</p><p>We can use a Bloom filter to reduce memory usage.</p><p>A Bloom filter is a space-efficient data structure that checks whether an element already exists in a set. It‚Äôs probabilistic, that is:</p><ul><li><p>If it says ‚Äú,‚Äù the URL definitely has not been seen.</p></li><li><p>If it says ‚Äú,‚Äù the URL  have been seen.</p></li></ul><p>This can sometimes cause a new URL to be skipped, but for large-scale crawling, this tradeoff is acceptable.</p><p>The URL set can be distributed across machines using consistent hashing. This ensures even distribution and supports adding or removing servers without major reshuffling.</p><p>Now let‚Äôs focus on content duplication‚Ä¶</p><p>Even if URLs are different, page content might be the same.</p><p>A simple word-by-word comparison is expensive and inefficient. Instead, crawlers compute a fingerprint of the page content. One common technique is <a href=\"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/33026.pdf\">Simhash algorithm</a>, which generates a compact representation of the page.</p><p>Similar pages will have similar fingerprints, making duplicate detection efficient.</p><h4>Handling Intentional Duplicates</h4><p>Some websites intentionally publish the same content under different URLs.</p><p>Search engines support a <a href=\"https://en.wikipedia.org/wiki/Canonical_link_element\">canonical link element</a> to handle this scenario. Website owners can specify the preferred URL for a piece of content. The crawler stores only the canonical version for indexing.</p><ul><li><p>URL deduplication occurs before crawling.</p></li><li><p>Content deduplication occurs after fetching the page.</p></li></ul><p>Before crawling, the system must check whether the URL is allowed.</p><p>Web servers can define rules in the robots.txt file to control crawler access. The crawler must respect these rules. Also, the crawler may maintain its own blocklist for certain websites or regions.</p><p>After passing these checks and finishing the crawl, the system stores the page content.</p><p>Next, let‚Äôs discuss storage design‚Ä¶</p><p>The choice of database depends on what we want to store and what format.</p><ol><li><p>Store the entire webpage as-is</p><ul><li><p>This is like saving a webpage using ‚ÄúSave Page As‚Äù in a browser. The full HTML content is stored without modification.</p></li></ul></li><li><p>Extract and store only the required data</p><ul><li><p>The crawler processes the page and saves only useful parts, such as text and metadata.</p></li></ul></li><li><p>Store the page in a document database</p><ul><li><p>Since a webpage is essentially a document, it can be stored in a document database.</p></li></ul></li></ol><p>In our case, the data has no fixed structure, and we do not need to run complex queries on it. So the simplest approach is to store the entire webpage.</p><p>An object store, such as Amazon S3, is a good fit for this.</p><p>Object stores are scalable and highly durable, so we don‚Äôt have to worry about scalability and reliability. At a very large scale, some companies build and manage their own distributed storage systems, but that is a separate and complex topic.</p><p>NOTE: <a href=\"https://cloud.google.com/blog/products/storage-data-transfer/a-peek-behind-colossus-googles-file-system\">Colossus</a> is Google‚Äôs distributed storage system. It replaced Google File System () and is designed to support Google‚Äôs massive scale.</p><p>We also need to store metadata. It includes:</p><ul><li><p>Location of stored content</p></li></ul><p>This requires a key-value style database, where:</p><ul></ul><p>A relational database could also work, but since we do not need complex joins or relationships, a distributed key-value store is more suitable. The data should be partitioned (sharded) for scale.</p><p>Now that we have covered the main crawler components, let‚Äôs discuss how these components work together to crawl the web‚Ä¶</p><h3>4. Web Crawler Components Coordination</h3><p>There are a few ways to coordinate the crawler components. Each option has its tradeoffs:</p><h4>Approach #1: Synchronous communication</h4><p>Each component exposes an API and calls the next component directly. If different components run inside the same service (microservice), they can call each other via local method calls.</p><h4>Approach #2: Choreography</h4><p>Each component publishes an event when it finishes its work. The next component consumes the event and continues the workflow. This is also known as event-driven architecture.</p><h4>Approach #3: Orchestration</h4><p>Add an orchestrator to manage the crawler‚Äôs lifecycle. The orchestrator triggers each step, tracks progress, and handles retries. Components can still communicate synchronously or asynchronously, depending on what fits.</p><p><em>‚Ä¶So which approach fits best here?</em></p><p>You might have heard the statement: Everything is a tradeoff in system design.‚Äù This is very true: all approaches are best in one scenario but can be the worst in others.</p><p>Let‚Äôs do a trade-off analysis for the web crawler system:</p><p>For the crawler, Approach #3 (Orchestration) makes more sense. Here‚Äôs why:</p><ul><li><p>End-to-end monitoring: You can track, retry, or debug each component.</p></li><li><p>Failure handling: If a component is unhealthy, the orchestrator can trigger a retry, pause, or reroute work.</p></li><li><p>Scheduling support: Orchestrator can schedule recrawls and also handle new URLs discovered during crawling.</p></li></ul><p>Next, let‚Äôs combine these components and create a high-level diagram‚Ä¶</p><h3>5. Web Crawler System Components</h3><p>Figure 3 shows the end-to-end workflow.</p><p>The blocks in the diagram are logical components, not separate microservices. You can deploy them together or separately, depending on scale, cost, and operational needs.</p><p>Let‚Äôs summarize all the components and workflow:</p><ol><li><ul><li><p>Starts with seed URLs and outputs the next URLs to crawl.</p></li></ul></li><li><p>URL goes through certain validations, such as:</p><ul><li><p>URL uniqueness (have we seen this URL before?)</p></li><li><p>Verification in robots.txt cache (is crawling allowed?)</p></li><li><p>Fetch IP address from DNS cache. This cache is continuously updated once the URL is fetched from the internet.</p></li></ul></li><li><ul><li><p>Downloads the page content and stores it in the content database.</p></li><li><p>Some pages load content in multiple steps using JavaScript. For this, fetcher may need a headless browser to render the page and get the final content.</p></li><li><p>To save bandwidth, the system can cache shared resources, such as common JavaScript and CSS files, instead of downloading them repeatedly.</p></li></ul></li><li><p>Webpage Processing System</p><ul><li><p>Parses the downloaded page to extract new links. Then it filters these links using rules such as:</p><ul><li><p>Region-based restrictions</p></li></ul></li></ul></li><li><ul><li><p>The extracted URLs are then sent back to the URL frontier, and the crawl cycle continues.</p></li></ul></li></ol><p>NOTE: A Domain Name System () handles mapping between domain names (such as ) to their IP addresses. </p><p>Web crawler‚Äôs job finishes as soon as the web page is downloaded and stored. Search engine then takes this content, builds indexes, and serves user queries.</p><p>Next, let‚Äôs explore the architecture of the search engine system‚Ä¶</p><blockquote><p><em><strong>This newsletter is inspired by Chapter 15 of the O‚ÄôReilly book ‚Äú<a href=\"https://msdeepsingh.com/books/\">System Design on AWS</a>‚Äù. Get a copy of the book right now.</strong></em></p></blockquote><p><em><strong>Reminder: this is a teaser of the subscriber-only post, exclusive to my golden members.</strong></em></p><p>When you upgrade, you‚Äôll get:</p><ul><li><p><strong>Full access to system design case studies</strong></p></li><li><p>FREE access to (coming) Design, Build, Scale newsletter series</p></li><li><p><strong>FREE access to (coming) popular interview question breakdowns</strong></p></li></ul>","contentLength":14401,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/b92c2e4c-68dd-4314-a663-9d2eadd1f51b_1280x720.png","enclosureMime":"","commentsUrl":null},{"title":"Timsort Algorithm - A Deep Dive","url":"https://newsletter.systemdesign.one/p/timsort-algorithm","date":1771500021,"author":"Neo Kim","guid":37,"unread":true,"content":"<p>This post outlines Timsort, a popular sorting algorithm known for its speed and efficiency.</p><p>Timsort is one of those foundational sorting algorithms used everywhere, but most explanations of how it works shy away from going into its behavior in depth.</p><p>We are going to fix that in this newsletter.</p><p>By the end, not only will you be able to explain how Timsort works at various levels of detail, but you will also see a simplified JavaScript implementation so you can see how the concepts translate into an implementation you can try out on your own computer.</p><p>Tech moves fast, but you‚Äôre still playing catch-up?</p><p>That‚Äôs exactly why 150K+ engineers working at Google, Meta, and Apple read <a href=\"https://codenewsletter.ai/subscribe?utm_source=nl_ad_system\">The Code</a> twice a week.</p><ul><li><p><strong>Curated tech news that shapes your career </strong>- Filtered from thousands of sources so you know what‚Äôs coming 6 months early.</p></li><li><p><strong>Practical resources you can use immediately</strong> - Real tutorials and tools that solve actual engineering problems.</p></li><li><p><strong>Research papers and insights decoded</strong> - We break down complex tech so you understand what matters.</p></li></ul><p>All delivered twice a week in just 2 short emails.</p><p><strong>Sign up and get access to the Ultimate Claude code guide to ship 5X faster.</strong></p><p>I want to introduce <a href=\"https://www.kirupa.com\">Kirupa Chinnathambi</a>, a connoisseur of explaining hard technical topics in a simple, easy-to-digest way:</p><p>In parallel, he is <a href=\"https://www.linkedin.com/in/kirupa/\">a hands-on Product Manager</a>&nbsp;at Microsoft, working at the intersection of how AI and developers can build great things faster and more securely on Windows.</p><p>When it comes to sorting algorithms, none of them is perfect.</p><p>Take a look at the following table of running times for the sorting algorithms we‚Äôve seen so far:</p><p>These sorting algorithms that seem perfect often show really poor behavior in worst-case scenarios. Their best-case performance may be suboptimal, too.</p><p>Take quicksort, for example.</p><p>Quicksort looks pretty good, right? On average, it runs at a very respectable  time. Now, what if we ask it to sort a fully sorted collection of values, and our pivot selection is having an off day? In this case, quicksort will slow to a crawl and sort our input with an  time.</p><p>That makes it as bad as some of our slowest sorting algorithms.</p><p>The opposite holds true as well.</p><p>Our slowest sorting algorithms, like Selection Sort, Insertion Sort, or Bubble Sort, have the potential to run really fast. For example, Bubble Sort normally runs at . If the values we ask it to sort happen to already be sorted, Bubble Sort will sort the values at a blazing fast  time.</p><p>That‚Äôs even faster than Quicksort‚Äôs best sorting time:</p><p>How well our sorting algorithms work depends largely on the arrangement of our unsorted input values:</p><ol><li><p>Are the input values random?</p></li><li><p>Are they sorted in reverse?</p></li><li><p>Is the range of values inside them large or small?</p></li></ol><p>Based on our answers to these questions, the performance of our sorting algorithms will vary.</p><p>As we described a few seconds ago, seemingly great sorting algorithms will crumble with the wrong arrangement of values, and terrible sorting algorithms will shine on the same arrangement of values.</p><p>So...what can we do here?</p><p>Instead of using a single sorting algorithm for our data, we can choose from a variety of sorting algorithms optimized for the kind of data we are dealing with. We can use something known as a . A hybrid sorting algorithm takes advantage of the strengths of multiple sorting algorithms to create some sort of a super algorithm‚Ä¶<a href=\"https://upload.wikimedia.org/wikipedia/commons/0/09/Tyrannosaurus-rex-Profile-steveoc86.png\">like our T-Rex over here</a>:</p><p>By relying on multiple sorting algorithms, we can <strong>minimize the worst-case behavior of individual sorting algorithms</strong> by switching between algorithms based on the characteristics of the unsorted input data being sorted.</p><p>In this newsletter, we are going to learn about one of the greatest hybrid sorting algorithms ever created. We are going to learn about .</p><div data-attrs=\"{&quot;url&quot;:&quot;https://newsletter.systemdesign.one/p/timsort-algorithm?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}\" data-component-name=\"CaptionedButtonToDOM\"><div><p>Share this post &amp; earn rewards for referrals.</p></div></div><blockquote><p>Timsort is a hybrid sorting algorithm that combines the best features of two other sorting algorithms:</p><ul><li><p>Merge sort (where you divide your input, sort, merge recursively),</p></li><li><p>Insertion sort (where you start from a blank output and insert elements into place).</p></li></ul></blockquote><p>The key idea behind Timsort is <strong>to take advantage of the existing order in the data</strong>. It‚Äôs especially efficient for real-world scenarios where the values we‚Äôll be sorting will often have some pre-existing order or patterns.</p><p>The way Timsort works can be grossly oversimplified as follows:</p><ol><li><p>Divide the data into small chunks</p></li><li><p>Sort these chunks using Insertion sort</p></li><li><p>Merge the sorted chunks using a smart merging strategy found in Merge sort</p></li></ol><p>The best way to make sense of how Timsort works is by walking through an example, so we‚Äôll do that next.</p><p>As with all great sorting algorithm walkthroughs, we‚Äôre going to start with some unsorted data that needs to be sorted:</p><p>This list of unsorted values is pretty long to help us better appreciate how Timsort works. To help make all of this data easier for us to visualize here, let‚Äôs wrap this long list of data as follows:</p><p>Nothing about our data has changed except how we can represent it on this page.</p><p>The first thing we do with Timsort is divide the data we wish to sort into smaller chunks. These chunks are more formally known as . The size of these runs usually varies between 32 and 64 items, but for our example, we‚Äôll keep the size of our runs much smaller at 4:</p><p>Notice that we divided our entire unsorted collection into runs of four items each, except for the last run, which only has two values.</p><h3>Sorting with Insertion Sort</h3><p>Now that we have our runs,  on each run to sort these values. We sort our first run:</p><p>Next, we sort our second run:</p><p>This sorting repeats until all of our individual runs are sorted:</p><p>An important detail is that only the values within each run are sorted.</p><p>In aggregate, our collection of items is still unsorted. We will address that next.</p><p>The final step is to take our individually sorted runs and merge them into larger and larger sorted runs. At the end of all this, the result will be one combined sorted collection of data.</p><p>We start by merging adjacent runs together, and I have color-coded the adjacent runs that will be merged first:</p><p>The merging operation will use a subset of merge sort‚Äôs capabilities, where we need to merge the individually sorted runs into a final sorted order.</p><p>After the first round of merging, our collection will look as follows:</p><p>Our runs are now around double in size. We now repeat the process by merging adjacent runs again. After this round of merging, we will be left with two sorted runs:</p><p>We are almost done here. All that remains is one last step, where we merge our two unsorted runs to create our sorted output:</p><p>At this moment, no further runs need to be merged.</p><p>Timsort is finished sorting our data. Also, at this very moment, you probably have many questions about what exactly happened to make Timsort seem like a superior sorting algorithm to most other sorting algorithms out there.</p><div data-attrs=\"{&quot;url&quot;:&quot;https://newsletter.systemdesign.one/p/timsort-algorithm?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}\" data-component-name=\"CaptionedButtonToDOM\"><div><p>Share this post &amp; earn rewards for referrals.</p></div></div><p>The above walkthrough highlighted how we can use Timsort to sort our unsorted collection of numbers.</p><p>We broke our larger input into runs, sorted each run using insertion sort, and then merged adjacent runs until we had a single fully sorted run.</p><p>If we analyzed our walkthrough at face value, Timsort‚Äôs performance may not seem very fast when we have n items, n running time for insertion sort, and a logarithmic running time for merging values. This is where some optimizations Timsort is known for kick in‚Ä¶dramatically speeding things up in many cases.</p><p>These optimizations focus on detecting common patterns in our data and customizing next steps based on how the data is structured.</p><h3>Detecting Ascending and Descending Runs</h3><p>The worst-case running time for insertion sort occurs when the values to be sorted are in reverse order.</p><p>To avoid this, Timsort will try to identify runs that are strictly in reverse (aka descending) order and do an in-place reverse on them first before attempting to sort and merge them:</p><p>The best-case performance of insertion sort occurs when the runs are in ascending order.</p><p>In these cases, . There is no need to sort them. The only real work Timsort will need to perform is merging, which is consistently fast.</p><h3>Galloping Mode and Already Sorted Runs</h3><p>Galloping mode (also known as  by distant friends and relatives) is an optimization technique used in Timsort algorithm . It‚Äôs designed to handle cases where a run has many elements that are already in their final sorted position relative to the other run.</p><ol><li><p>During merging, if Timsort notices that many consecutive elements from one run are being chosen, it switches to galloping mode.</p></li><li><p>In galloping mode, instead of comparing elements one by one, Timsort jumps (or ‚Äúgallops‚Äù) over multiple elements at a time, making the merging faster</p></li><li><p>This can significantly reduce the number of comparisons needed when merging runs that are already partially ordered relative to each other.</p></li></ol><p>This will make more sense with an example, so here are two sorted runs we would like to merge:</p><p>In an unoptimized merge, we would compare each element between both runs and add the smaller of the values to our merged collection.</p><p>When we look at the values in Run A, we can see that the first five numbers are all consistently less than the first value in Run B. If we elaborate on that using a loose array-like syntax, we have:</p><ul><li><p>Compare RunA[0] (1) with RunB[0] (10): 1 is smaller, so 1 is added to the merged collection.</p></li><li><p>Compare RunA[1] (2) with RunB[0] (10): 2 is smaller, so 2 is added to the merged collection.</p></li><li><p>Compare RunA[2] (3) with RunB[0] (10): 3 is smaller, so 3 is added to the merged collection.</p></li><li><p>Compare RunA[3] (4) with RunB[0] (10): 4 is smaller, so 4 is added to the merged collection.</p></li><li><p>Compare RunA[4] (5) with RunB[0] (10): 5 is smaller, so 5 is added to the merged collection.</p></li></ul><p>At this point, our merged collection looks as follows:</p><p>Now, Timsort will compare RunA[5] (31) with RunB[0] (10):</p><p>At this point, 10 is smaller than 31, so Timsort will now check the next few elements from Run B to see if they should be added in bulk:</p><ul><li><p>Compare RunA[5] (31) with RunB[1] (11): 11 is smaller, so Timsort continues.</p></li><li><p>Compare RunA[5] (20) with RunB[2] (12): 12 is smaller, so Timsort continues.</p></li><li><p>Compare RunA[5] (20) with RunB[3] (14): 14 is smaller, so Timsort continues.</p></li><li><p>Compare RunA[5] (20) with RunB[4] (16): 16 is smaller, so Timsort continues.</p></li><li><p>Compare RunA[5] (20) with RunB[5] (17): 17 is smaller, so Timsort continues.</p></li><li><p>Compare RunA[5] (20) with RunB[6] (18): 18 is smaller, so Timsort continues.</p></li></ul><p>Since all elements in Run B are smaller than RunA[5], Timsort  to the merged collection:</p><p>After adding all the elements from Run B, Timsort reverts to the regular comparison mode and continues merging the remaining items. In this case, both 31 and 48 from Run A will be added to the end of the merged collection.</p><p>By using galloping mode, Timsort can speed up merging by quickly adding multiple consecutive elements from one run when it‚Äôs clear they are all smaller (or larger) than the next element in the other run.</p><p>This reduces the number of comparisons and overall sorting time, especially when merging runs of significantly different sizes.</p><p>Timsort‚Äôs merging strategy is adaptive, meaning it can vary the merging order based on the sizes of the runs. The goal is to maintain balance among the runs and avoid having a single, large run at the end that would make the final merge costly.</p><p>For example, let‚Äôs say these are the runs we are dealing with:</p><p>The actual values of the runs aren‚Äôt important.</p><p>What is important is the size of the runs. To avoid any run from being too large and making the merge waaaaay unbalanced, we start by merging the two smallest runs:</p><p>This would result in Runs C and D merging to create Run CD:</p><p>This process continues to ensure that the smallest runs are merged into a final merge pair with similar sizes.</p><h3>Insertion Sort All the Way for Smaller Inputs</h3><p>Yes, insertion sort is a slow sorting algorithm.</p><p>When sorting a small number of values, though, this slowness isn‚Äôt very noticeable. This is especially true in a world where our computers can process millions and billions (and trillions?) of operations a second.</p><p>For this reason, Timsort will often fall back to using plain old insertion sort when the size of the input it is trying to sort is less than the run size threshold, which is usually 32 or 64 items in length:</p><p>This avoids the added overhead of the merging operation, breaking runs, and so on.</p><p>Why is Timsort so efficient?</p><p>It‚Äôs because it tries to detect patterns in the sorted data and special-case the sorting behavior accordingly. Whether by identifying natural runs, detecting reversed runs, using galloping mode to avoid unnecessary merging-related work, enforcing minimum run lengths, or performing adaptive merges, Timsort seeks the most efficient path whenever possible.</p><p>A subtle but important detail is that these pattern matching optimizations ensure that Timsort performs well on&nbsp;&nbsp;data, which is the most common type&nbsp;we will encounter in the real world.</p><h2>Performance Characteristics</h2><p>Timsort is one of the best sorting algorithms out there, and we can see it live up to its grandness when we summarize its time and memory complexity below:</p><p>At its best, Timsort can run in linear time.</p><p>This happens when the data is already sorted or nearly sorted as part of a few large runs, and we know that Insertion Sort runs in linear time for sorted data:</p><p>Merging runs is a fast operation as well, and if we throw in any optimizations, such as galloping mode if the range of sorted numbers doesn‚Äôt overlap, the merging is almost a trivial operation.</p><p>In the average and worst cases, Timsort runs at .</p><p>The bulk of the complexity here goes into identifying runs and merging them. This puts its performance on par with Quicksort‚Äôs average performance, but Timsort‚Äôs optimizations give it an edge as being a !</p><p>This is validated by benchmarks <a href=\"https://v8.dev/blog/array-sort\">such as the following</a> that compares Timsort with Quicksort on partially sorted data:</p><p>Notice how much faster Timsort is compared to Quicksort.</p><p>The more Timsort is used in real-world data scenarios, the more we‚Äôll see it soaring faster than every other sorting algorithm we have seen so far.</p><p>Lastly, from a space point of view, Timsort needs an  amount of memory to run. This has to do with the data structures Timsort creates behind the scenes when merging the runs.</p><p>Timsort is a very complex sorting algorithm to implement.</p><p>The core insertion sort and merging capabilities are straightforward. Identifying and handling all the various patterns to optimize for...is less straightforward. For that reason, most examples of Timsort we will run into are based on the original Python implementation itself. I am not going to paste the massive amount of code needed to implement Timsort in JavaScript.</p><p>As we scan through the code, we‚Äôll see a lot of familiar patterns. Towards the bottom, the example code to initialize Timsort and use it to sort some values is provided:</p><pre><code>let example = [-7, 10, 50, 3, 940, 1, 4, -8, 24, 40, 33, 12, 10];\n\n// Comparison function\nfunction numberCompare(a, b) {\n  return a - b;\n}\n\n// Sort our example array\ntimsort.sort(example, numberCompare);\nconsole.log(example);</code></pre><p>Feel free to try it out and use this in your own projects, but as we will discuss in a few moments, Timsort is already the default sorting algorithm used in many situations in our favorite programming languages.</p><p>Timsort, as the preeminent hybrid sorting algorithm, is among the fastest sorting algorithms available.</p><p>When we say this, this  isn‚Äôt qualified with caveats where the unsorted input needs to be of a certain arrangement. Timsort‚Äôs worst-case behavior is very good. Timsort‚Äôs best-case behavior is very, VERY good. The upper and lower bounds of its performance make it an excellent choice for any kind of unsorted (or sorted) input we throw at it. This flexibility and power are what make Timsort one of the&nbsp;<a href=\"https://www.kirupa.com/data_structures_algorithms/default_sorting_algorithms.htm\">default sorting algorithms</a>&nbsp;in programming languages such as Python, Java, Rust, and more.</p><p>Now, Timsort isn‚Äôt the only hybrid sorting algorithm in town.</p><p>Another popular hybrid sorting algorithm is  (sometimes referred to as ), which uses a combination of quicksort, heapsort, and insertion sort for its sorting shenanigans. Introsort is the default sorting algorithm in Swift, C#, and other languages. As we look ahead into the future and run into more interesting and new data scenarios, we may see more hybrid sorting algorithms emerge.</p><p>We are in the early days, so there will be more fun times ahead with hybrid sorting algorithms.</p><p>üëã I‚Äôd like to thank  for sharing this deep dive into Timsort.</p><p>I launched  (newsletter series exclusive to PAID subscribers).</p><p>When you upgrade, you‚Äôll get:</p><ul><li><p><strong>High-level architecture of real-world systems.</strong></p></li><li><p>Deep dive into how popular real-world systems actually work.</p></li><li><p><strong>How real-world systems handle scale, reliability, and performance.</strong></p></li><li><p>10x the results you currently get with 1/10th of your time, energy, and effort.</p></li></ul><p><strong>Want to reach 200K+ tech professionals at scale? </strong>üì∞</p><p>Thank you for supporting this newsletter.</p><p>You are now 200,001+ readers strong, very close to 201k. Let‚Äôs try to get 201k readers by 25 February. Consider sharing this post with your friends and get rewards.</p>","contentLength":17091,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/911f89b9-13e8-4180-88c9-0125c1c6b654_1280x720.png","enclosureMime":"","commentsUrl":null},{"title":"I struggled with system design until I learned these 114 concepts","url":"https://newsletter.systemdesign.one/p/system-design-core-concepts","date":1771086026,"author":"Neo Kim","guid":36,"unread":true,"content":"<p>Following is the second of a premium 3-part newsletter series‚Ä¶ If you‚Äôre just getting started with system design or want a super strong foundation, then this newsletter is for you.</p><p>On with part 2 of the newsletter:</p><p>Some of these are foundational, and some are quite advanced. ALL of them are super useful to software engineers building distributed systems‚Ä¶</p><p>Curious to know how many were new to you:</p><ol start=\"39\"><li><p>Block vs File vs Object Storage</p></li><li><p>Clock Synchronization Problem</p></li></ol><p>(‚Ä¶and much more in part 3!)</p><ul><li><p>What it is &amp; how it works--in simple words</p></li></ul><p> is the only AI code review tool that has a deep understanding of your codebase, docs, and past decisions, giving you thoughtful feedback that feels like it came from your best engineer.</p><blockquote><p>WebSockets provide full-duplex, bidirectional communication between client &amp; server over a single, long-lived TCP connection.</p></blockquote><p>Unlike HTTP, where the client always initiates requests, WebSockets allow the server to push data to clients in real-time.</p><p>After an initial HTTP handshake, the connection upgrades to the WebSocket protocol. Both the client and the server can then send messages at any time.</p><p>WebSockets is like a phone call where both people can talk and listen simultaneously‚Ä¶</p><p>Compare this to HTTP, which is like sending letters back and forth,,, where you wait for a reply before sending the next message.</p><p>They‚Äôre more complex to implement and scale since each connection consumes server resources. Also, load balancing becomes tricky because connections are long-lived and stateful.</p><p>Plus, some proxies/firewalls ‚Äúblock‚Äù WebSocket upgrades or long-lived connections, so compatibility can vary.</p><p>Use for real-time apps like chat systems, live sports scores, collaborative editing, online gaming, or stock trading platforms. But avoid for simple request-response patterns where HTTP is enough.</p><blockquote><p>An API gateway is a server that acts as a SINGLE entry point for all client requests to your microservices.</p></blockquote><p>It handles request routing, composition, and protocol translation. Instead of clients calling different microservices directly, they make ‚Äòone call‚Äô to the gateway.</p><p>An API gateway is like a hotel concierge:</p><p>Instead of guests figuring out which department to call, they call the concierge desk. The concierge knows which department to contact and gets back to the guest with answers.</p><p>They can become a bottleneck or a single point of failure if not deployed redundantly. Besides, they increase latency because of the extra network hop. So the gateway itself needs to scale &amp; be highly available.</p><p>Useful in microservices because it provides clients with a single entry point.</p><p>Also, it handles common tasks like authentication, authorization, and rate limiting in one place, and can return different responses for different clients, such as web or mobile apps.</p><blockquote><p>Distributed cache spreads cached data across many cache servers instead of a single cache instance.</p></blockquote><p>Each cache node stores a portion of the data, typically determined by consistent hashing. Popular implementations include Redis Cluster and Memcached.</p><p>Multiple fast-food locations across a city instead of one central kitchen.</p><p>Each location stores popular items for quick service. Total capacity increases by opening more locations, and no single location becomes overwhelmed during rush hour.</p><p>They add operational complexity (partitioning, rebalancing, replication) and can incur overhead during rebalancing/failover. Also, there‚Äôs a risk of cache misses when keys get redistributed.</p><p>Plus, debugging becomes harder with many nodes.</p><p>Use a distributed cache in high-traffic sites when one cache server can‚Äôt handle the traffic, when the data no longer fits in one machine‚Äôs memory, or when you need high availability.</p><p>Start with a single cache server‚Ä¶Move to a distributed cache setup only when you reach scaling or reliability limits.</p><h2><strong>42. Cache Eviction Policies</strong></h2><blockquote><p>Cache eviction policies decide which data to remove when the cache is full and new data needs space.</p></blockquote><ul><li><p>Least Recently Used () removes the data that has NOT been accessed for the longest time.</p></li><li><p>Least Frequently Used () removes the data that is accessed the least often.</p></li><li><p>First In, First Out () removes the oldest data first, based on when it was added.</p></li><li><p>Time To Live () automatically removes data after a fixed time period.</p></li></ul><p>Think of your phone storage:</p><ul><li><p>LRU deletes photos you haven‚Äôt opened in a long time.</p></li><li><p>LFU deletes photos you rarely look at.</p></li><li><p>FIFO deletes the oldest photos first.</p></li><li><p>TTL is like a message that automatically disappears after 24 hours.</p></li></ul><p>Different policies work well for different access patterns‚Ä¶</p><ul><li><p>LRU works well when recently accessed data is likely to be used again. Yet it can perform poorly if large amounts of data are accessed only once.</p></li><li><p>LFU works well when frequently accessed data stays popular over time, but it reacts slowly if usage patterns change.</p></li><li><p>FIFO is simple but does not consider how often or recently data is used.</p></li><li><p>TTL ensures data does not stay in the cache forever, but it may remove useful data too early or keep stale data too long.</p></li></ul><p>Each policy has overhead in tracking metadata for eviction decisions.</p><ul><li><p>LRU for general-purpose caching where recent data is likely to be reused.</p></li><li><p>LFU when certain data remains popular for long periods.</p></li><li><p>TTL when data naturally becomes stale after some time, such as API responses or session data.</p></li></ul><p>Most systems combine TTL with LRU or LFU.</p><h2><strong>43. Proxy vs Reverse Proxy</strong></h2><blockquote><p>A forward proxy sits between clients and the Internet. It sends requests to external servers on behalf of the client.</p><p>A reverse proxy sits in front of your servers. It receives requests from clients and forwards them to the correct backend server.</p></blockquote><p>With a forward proxy, client is configured to use it. With a reverse proxy, the client usually doesn‚Äôt know it exists.</p><p>A forward proxy is like an assistant who makes calls for you, so the person on the other end doesn‚Äôt talk with you directly.</p><p>A reverse proxy is like a company receptionist. Callers think they are contacting the company directly,,, but the receptionist routes the call internally.</p><p>Forward proxies can improve privacy, enforce security policies, and filter traffic. Yet they add extra network hops and can increase latency.</p><p>Reverse proxies provide load balancing, SSL termination, caching, and protection from direct exposure of backend servers. But they must be deployed redundantly to avoid becoming a single point of failure.</p><p>Both require proper configuration to prevent security risks‚Ä¶</p><ul><li><p>Use forward proxies in corporate networks for content filtering, monitoring &amp; privacy control.</p></li><li><p>Use reverse proxies in production systems for load balancing, SSL termination, traffic routing, and protection against attacks.</p></li></ul><p>Most apps use reverse proxies such as Nginx, HAProxy, or cloud load balancers.</p><blockquote><p>Hypertext Transfer Protocol (HTTP) sends data in ‚Äòplain text‚Äô.</p><p>Hypertext Transfer Protocol Secure (HTTPS) is HTTP encrypted using Transport Layer Security (TLS).</p></blockquote><p>HTTPS encrypts communication between the client and server, protecting data from eavesdropping and tampering. The server provides a certificate to prove its identity. Modern browsers mark HTTP sites as ‚ÄúNot Secure.‚Äù</p><p>HTTP is like sending a postcard. Anyone who intercepts it can read the message.</p><p>HTTPS is like sending a sealed, locked box. Even if someone intercepts it, they cannot read or change what‚Äôs inside.</p><p>HTTPS requires managing digital certificates and adds a small performance cost because of the TLS handshake. Yet these costs are minimal compared to the security benefits.</p><p>HTTPS protects against eavesdropping and man-in-the-middle attacks, where attackers intercept or modify traffic.</p><p>HTTPS is also a positive ranking factor for search engines and is required for many modern web features, such as HTTP/2, service workers, and secure cookies.</p><blockquote><p>Transmission Control Protocol (TCP) is a connection-oriented protocol that provides reliable, ordered delivery of data.</p><p>User Datagram Protocol (UDP) is connectionless and sends packets without guaranteeing delivery, order, or protection against duplication.</p></blockquote><p>TCP establishes a connection using a handshake, retransmits lost packets, and performs congestion control.</p><p>UDP sends packets independently with minimal overhead &amp; no built-in reliability. i.e., UDP is faster but less reliable.</p><p>TCP is like certified mail with tracking and delivery confirmation.</p><p>UDP is like sending postcards. They usually arrive, but they might be lost or arrive out of order‚Ä¶</p><p>TCP adds latency due to the handshake, acknowledgments, retransmissions, and head-of-line blocking (where a lost packet delays subsequent packets).</p><p>UDP doesn‚Äôt guarantee delivery or order. If reliability is needed,,, the application code must handle it.</p><ul><li><p>Use TCP for web browsing, email, file transfers, database connections, and APIs where accuracy matters more than speed.</p></li><li><p>Use UDP for real-time applications such as video calls, live streaming, and online gaming, where low latency is more important than reliability.</p></li></ul><p>NOTE: DNS typically uses UDP for speed, but it can fall back to TCP for large responses or specific operations.</p><p><em><strong>Reminder: this is a teaser of the subscriber-only post, exclusive to my golden members.</strong></em></p><p>When you upgrade, you‚Äôll get:</p><ul><li><p><strong>Full access to system design case studies</strong></p></li><li><p>FREE access to (coming) Design, Build, Scale newsletter series</p></li><li><p><strong>FREE access to (coming) popular interview question breakdowns</strong></p></li></ul><p>Get 10x the results you currently get with 1/10th the time, energy &amp; effort.</p>","contentLength":9359,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/e9e8cf9a-93be-4a9c-9512-1d9cdb098857_1280x720.png","enclosureMime":"","commentsUrl":null},{"title":"Behavioral Interview Playbook for Software Engineers","url":"https://newsletter.systemdesign.one/p/common-behavioral-interview-questions","date":1770888085,"author":"Prasad Rao","guid":35,"unread":true,"content":"<p>You‚Äôve prepared for the technical interview‚Ä¶You‚Äôve solved the system design problem‚Ä¶You‚Äôve written clean code‚Ä¶</p><p>Yet the hiring decision often comes down to something completely different: ‚Äúyour behavioral interview‚Äù.</p><p>This is the conversation where the interviewer asks, <em>‚ÄúTell me about a time when you disagreed with your manager,‚Äù</em> or <em>‚ÄúDescribe a situation where you had to make a decision with incomplete information.‚Äù</em></p><p>It‚Äôs where they assess not just what you can build, but how you work, how you think, and how you‚Äôll show up in their organization.</p><p> turns search results into predictable JSON with built-in scale, location options, and protection from blocks.</p><p>That‚Äôs why engineers use it to ship:</p><ul></ul><p>All without maintaining scrapers or infrastructure.</p><p>Check out his LinkedIn, newsletter, and offerings:</p><ul><li><p> - If you‚Äôre preparing for interviews, I highly recommend this course as it focuses specifically on behavioral interviews, setting it apart from other courses. You can use code NEO25 for 25% off.</p></li></ul><p>Ask any experienced interviewer at Big Tech why candidates fail their interviews.</p><p>Their #1 reason is consistent:</p><blockquote><p><em>‚ÄúSmart technical professionals who can‚Äôt clearly articulate their past work. They ramble too much, miss the main points, and can‚Äôt explain their decision-making process.‚Äù</em></p></blockquote><p>For many engineers, this feels unfair‚Ä¶</p><p>You‚Äôre hired to write code, not to tell stories. But behavioral interviews exist for a reason, and understanding that reason changes everything about how you prepare.</p><h4><strong>What We Mean by Behavioral Skills</strong></h4><p>Before we dive deeper, let‚Äôs clarify what behavioral skills actually are:</p><p>These are your personal attributes and interpersonal abilities that shape how you work, interact with others, and approach challenges. Unlike technical skills, which are specific to a particular job or industry, behavioral skills are transferable across various roles and sectors.</p><p>You might be an exceptional backend Java programmer, but that skill won‚Äôt directly transfer to a data engineer role‚Ä¶ Your ability to handle conflict, though? That transfers everywhere. Your capacity to make decisions with incomplete information? That applies in any organization.</p><p>This is why companies prioritize these skills.</p><h4><strong>Why Companies Care About Behavior</strong></h4><p>Technical skills are table stakes.</p><p>Any engineer applying to a senior role can solve problems and write decent code. What separates a senior engineer from a staff/principal engineer, or what prevents someone from getting stuck at the senior level for years? It‚Äôs how they operate in ambiguity, how they lead without authority, how they make decisions that affect hundreds of engineers, and how they communicate complexity to non-technical leaders.</p><p>These are behavioral competencies‚Ä¶and they‚Äôre harder to assess in a coding or system design interview.</p><p>The primary reason employers focus on behavioral skills is that past behavior is often the best predictor of future performance. This concept, known as <strong>‚Äúbehavioral consistency,‚Äù</strong> is a fundamental principle in psychology and human resources.</p><blockquote><p><em>Behavioral consistency suggests that the way a person has behaved in the past is likely to be consistent with how they will behave in the future, especially in similar situations.</em></p></blockquote><p>By asking about how you‚Äôve handled situations in the past, interviewers get a sense of how you‚Äôre likely to act in similar scenarios if hired.</p><p>A behavioral interview is a risk-mitigation tool for the hiring manager.</p><blockquote><p>When they ask about a conflict you resolved, they‚Äôre trying to understand:</p><p><em>Do you escalate appropriately?</em></p><p><em>Do you compromise or dig in?</em></p><p><em>Do you think about the other person‚Äôs perspective?</em></p></blockquote><p>For example, if you can describe a time when you successfully resolved a conflict with a manager, it suggests you‚Äôll be able to handle such situations in the new role as well. This gives employers confidence in your ability to navigate workplace challenges.</p><p>If you‚Äôve successfully led a team project in the past, you‚Äôre likely to demonstrate good leadership skills in future team projects. If you‚Äôve shown creativity in solving problems at your previous job, you‚Äôre likely to bring that same innovative thinking to new challenges.</p><h4><strong>How Behavioral Interviews Evaluate Seniority</strong></h4><p>Here‚Äôs something most engineers don‚Äôt realize: same behavioral question is asked to candidates at different levels, but the bar changes dramatically.</p><p><em>Same question. Completely different answers. The difference is scope, self-awareness, and impact.</em></p><p>Interviewers check behavioral responses for key signs.</p><p>They want to see if you understand complexity. They also look for how well you‚Äôve handled ambiguity. Learning from mistakes is important as well. Finally, you need to communicate all this clearly.</p><p>As you climb the ladder, they want to see that you can make decisions for larger groups. They look for your ability to influence others without authority. Also, they want to know if you consider the organization‚Äôs impact, not just technical correctness.</p><p>Behavioral interviews are a gating mechanism:</p><p>Companies use them to calibrate your level. Get them right, and you move up. Get them wrong, and you get downleveled‚Äîplaced in a role one or two levels below what you applied for.</p><p>Downleveling happens when your behavioral responses don‚Äôt match the seniority you‚Äôre targeting. You may have the skills for a staff role, but your stories matter. If you sound junior‚Äîfocusing on your own work instead of the impact, or lacking proof of handling uncertainty or influencing others‚Äîthen you might get a senior role instead. Same company, same team, potentially 20-30% lower salary, and a much slower path to where you wanted to be.</p><p>This is why behavioral interviews matter more than most engineers realize. They‚Äôre not a soft skill afterthought. They‚Äôre the primary mechanism through which companies evaluate whether you‚Äôre ready for the level you‚Äôre targeting.</p><blockquote><p><em>Technical skills get you hired. Behavioral skills get you hired at the right level.</em></p></blockquote><div data-attrs=\"{&quot;url&quot;:&quot;https://newsletter.systemdesign.one/p/common-behavioral-interview-questions?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}\" data-component-name=\"CaptionedButtonToDOM\"><div><p>Share this post &amp; earn rewards for referrals.</p></div></div><h4><strong>What This Playbook Will Do</strong></h4><p>Over the next few sections, you‚Äôll learn how you should be preparing for your behavioral interviews.</p><p>You‚Äôll master the STAR framework‚Äîthe real version, not the generic one you‚Äôve likely heard. This one actually prevents downleveling. And you‚Äôll see real examples of answers that landed offers at Big Tech companies.</p><p>More importantly, you‚Äôll learn to think like an interviewer. When you understand what they really want to hear, you can tell stories that address their true questions. These aren‚Äôt just surface-level questions. They go deeper, focusing on your judgment, impact, and readiness for the role.</p><p>The engineers who excel at behavioral interviews aren‚Äôt necessarily the best storytellers. They‚Äôre the ones who understand what‚Äôs being evaluated and can connect their experiences to those evaluation criteria.</p><p>To start, let‚Äôs understand when and how your behavioral skills are evaluated during an interview process.</p><p>Here‚Äôs something that surprises most engineers: behavioral skills aren‚Äôt just evaluated during the dedicated behavioral interview round. They‚Äôre being evaluated from the very first question, often before the technical interview even starts.</p><p>Many candidates believe behavioral assessment happens in a separate block, usually near the end of the interview process.</p><p>In reality, hiring teams are evaluating your behavioral competencies across every single interview. Your ability to be hired at the right level depends on consistent performance across three distinct evaluation moments. Each one needs different preparation.</p><h3><strong>Three Moments When Behavioral Skills Are Evaluated</strong></h3><p>First, there‚Äôs the opening conversation‚Ä¶</p><p>This starts with your recruiter call and continues into the first technical interview. Then, behavioral evaluation occurs throughout your technical interviews. Finally, there‚Äôs the dedicated behavioral interview round.</p><p>Each moment assesses different aspects of your competencies and requires different strategies.</p><p>Most engineers focus only on the third moment‚Ä¶</p><p>They prepare answers to ‚Äú<em>Tell me about a time when...‚Äù</em> questions but neglect the other two. This is a critical mistake. The interviewer who speaks to you first forms an impression that influences how every other interviewer perceives you. The technical interviewer who watches you explain your architectural choices is simultaneously assessing your judgment and decision-making process. By the time you reach the dedicated behavioral round, the narrative about you is already partially written.</p><p>Let‚Äôs look at each moment, what‚Äôs being evaluated, and how to prepare‚Ä¶</p><h4><strong>Moment 1: Tell Me About Yourself</strong></h4><p>The question ‚Äú‚Äù appears everywhere.</p><ul><li><p>It‚Äôs asked by the recruiter on your initial call.</p></li><li><p>It‚Äôs asked by the technical interviewer at the beginning of the coding round.</p></li><li><p>It‚Äôs asked by the hiring manager.</p></li><li><p>It‚Äôs asked by the panel interviewer before the system design discussion. </p></li></ul><p>Some candidates face this question five times in a single interview loop, sometimes with slightly different framings like <em>‚ÄúWalk me through your resume‚Äù</em> or <em>‚ÄúTell me about your background.‚Äù</em></p><p>Most engineers completely underestimate its importance. When you‚Äôre asked, ‚Äú the interviewer isn‚Äôt looking for your resume recited out loud.</p><p>They‚Äôre assessing several behavioral competencies simultaneously.</p><blockquote><p>Can you communicate concisely?</p><p>Do you highlight impact or just responsibilities?</p><p>Do you show self-awareness about your growth?</p><p>Do you understand what matters for this specific role?</p><p>Can you tell a coherent story about your career progression?</p></blockquote><p>Your answer shapes how the interviewer perceives you before any technical question is asked.</p><p>If you ramble for five minutes without clarity, they‚Äôve already formed an impression... If you jump between random accomplishments without connection, they‚Äôre questioning your communication skills‚Ä¶ If you focus entirely on what you did without explaining the impact, they‚Äôre seeing a junior mindset.</p><p>This first impression compounds throughout the interview.</p><h4><strong>Moment 2: Behavioral Skills During Technical Interviews</strong></h4><p>Many candidates don‚Äôt realize that behavioral assessment happens throughout technical interviews, not just when answering explicit behavioral questions.</p><p>During a coding interview, the interviewer might ask, <em>‚ÄúWhy did you choose this data structure?‚Äù</em> or <em>‚ÄúHow would you optimize this further?‚Äù</em> These are behavioral moments. They‚Äôre assessing how you think about tradeoffs, whether you consider constraints, how you handle feedback, and whether you communicate reasoning clearly.</p><p>During a system design interview, when you‚Äôre drawing architecture on the whiteboard, behavioral evaluation is happening constantly.</p><blockquote><p>Can you explain your decision-making process?</p><p>Do you consider the viewpoint of your interviewer?</p><p>Do you ask clarifying questions before diving in?</p><p>Do you acknowledge tradeoffs, or do you present your solution as obviously optimal?</p><p>Do you listen when challenged, or do you defend rigidly?</p></blockquote><p>The technical answer is only part of the evaluation. How you arrive at that answer, how you explain your reasoning, and how you discuss tradeoffs all signal your seniority level.</p><p>This is where the behavioral framework from later in this playbook becomes critical.</p><p>You need to communicate not just your solution, but your thinking process. You need to show scope, evidence of learning, and organizational awareness.</p><h4><strong>Moment 3: Dedicated Behavioral Interview Questions</strong></h4><p>It‚Äôs where you have the most time and space to demonstrate behavioral competencies in depth.</p><p>It‚Äôs where you seal the narrative that‚Äôs been building throughout the interview and get hired at the right level. (We will dive into how to prepare for behavioral interviews in this playbook.)</p><p><strong>What This Means for Your Preparation</strong></p><p>You need to prepare for all three moments, not just the behavioral round.</p><p>First, master your  answer.</p><p>This is your opening act. Make it strategic, concise, and tailored to the role. Practice it until it feels natural, not robotic. Know multiple versions for different interview contexts.</p><p>Second, develop the ability to articulate your thinking during technical interviews.</p><p>Learn to explain not just what you decided, but why. Practice talking through your decision-making process, assumptions, and trade-offs. When an interviewer asks a clarifying question or pushes back, view it as a chance to show your thought process. It‚Äôs not an attack.</p><p>Third, prepare deep answers for behavioral questions using the frameworks we‚Äôll cover in this playbook.</p><p>Have eight to fifteen strong stories ready. You can adjust them for different questions based on the company you‚Äôre interviewing with. Know the underlying behavioral competencies you‚Äôre demonstrating with each story.</p><p>The engineers who get hired at the right level aren‚Äôt necessarily the smartest in the room. They‚Äôre the ones who  across all three moments. They tell a coherent story about their career, their judgment, and their impact from the first question to the last.</p><p>Let‚Äôs dive into frameworks for preparing for each of these 3 moments, starting from ‚Äù</p><p>When an interviewer asks, <em>‚ÄúTell me about yourself,‚Äù</em> the interviewer is actually asking, <em>‚ÄúTell me why I should hire you?‚Äù</em></p><p>So instead of focusing on your entire career experience, you need to focus only on the highlights of your career experience that are most relevant to the job role you‚Äôre applying for.</p><p>You need to have a 1-minute elevator pitch for yourself.</p><p>That one minute not only helps you connect with the interviewer but also steers the interview. You subtly drop in the keywords and your strong areas on which you would like the interviewer to probe further.</p><p>I understand keeping it under one minute is extremely difficult. You can have it as 2 min max.</p><h4><strong>Here is the framework you can use to write your introduction:</strong></h4><ol><li><p>Career Summary [keep it to 20 seconds max]</p><ul><li><p>This is your hook to keep the interviewer engaged for the next 1-2 minutes as you power through your introduction.</p></li></ul></li><li><p>Main Body [45-90 seconds]</p><ul><li><p>This section should explain why you are a strong fit for the role. In no particular order or specific time allocation, talk about following:</p><ul></ul></li><li><p>You‚Äôll notice in my example below that I start this section with a recent project, as it aligns with the role's experience requirements. I have not explicitly discussed key skills, but I have woven them into the two project examples I have provided.</p></li></ul></li><li><p>Personal Interest [Optional. Keep it very short]</p><ul><li><p>It‚Äôs a nice-to-have section where you can talk about what you do outside of your work.</p></li></ul></li></ol><p>As a mental model, to create your 1-2 mins introduction, you can use this flowchart:</p><h4><strong>Example of an Elevator Pitch</strong></h4><p>Let‚Äôs understand how you can put the framework I mentioned into action to write your own introduction using an example.</p><p>Here is the elevator pitch I used in my first technical round at AWS in 2019:</p><blockquote><p><em>I started my career as a .NET developer, and over the last 10 years, I have gained extensive experience in developing and architecting applications using Microsoft workloads stack.</em></p><p><em>In my current project, I‚Äôm working as a tech lead helping a UK financial institution in digitally transforming their re-mortgage platform. Their legacy platform was built as a monolithic application in .NET with Winforms as frontend and SQL Server Database as backend. Their team was following the waterfall SDLC. I, along with my team, are helping them adopt agile development methodology and are modernizing their monolithic application by breaking it into microservices and implementing Jenkins CI/CD pipeline.</em></p><p><em>Prior to it, in my previous project, I was involved in building a product called the Compliance Management Reporting System (CMRS). The tech stack was .NET, SQL Server, XSLT, Biztalk, WCF, Winforms /WPF - basically it was all Microsoft stack. I started on the project as a senior developer and then became a track lead. Once that product was launched, I moved from India to London and joined the pre-sales team. I helped pitch the product to multiple financial institutions here and implemented it for them.</em></p><p><em>Outside of work, I enjoy running. Last month I ran the London Marathon. It was tough, but was an amazing experience to train for it and run alongside 40,000 runners.</em></p><p>I‚Äôm happy to dive deep into any of my experiences.</p></blockquote><p>The pitch was in no way perfect. But it was specifically tailored for the job I was applying for and also the interviewer‚Äôs profile.</p><blockquote><p><em>I applied for the role of Senior Solutions Architect, Microsoft Dev tools. The role was to help AWS customers/partners migrate and modernise Microsoft Workloads (like .NET applications and SQL Server) on AWS.</em></p></blockquote><blockquote><p><em>I looked up the interviewer on LinkedIn. Before joining AWS, they were working as Application Development Lead at one of the Microsoft consulting company and had written a book on cross-platform .NET.</em></p></blockquote><p>I didn‚Äôt have experience working with cloud/AWS at the time. My best approach was to leverage my strengths and highlight my experience developing applications on Microsoft workloads. As this was a customer-facing role, I discussed my pre-sales experience.</p><p>And it worked out pretty well‚Ä¶</p><p>Most of the technical questions were on .NET, SQL, application development, microservices, and CI/CD pipelines. In the behavioral question (yes, even in technical interviews, there are behavioral questions), I discussed a pre-sales experience with a major financial custodian.</p><p>It‚Äôs easy to understand that an introduction needs to be tailored to the job role, but should it be tailored to the interviewer‚Äôs background?</p><p>For example, in my case, the interviewer had a .NET background, so I doubled down on that and mentioned the tech stack. Now, let‚Äôs say the interviewer had been from a Java background. I would have focused more on design patterns and my architectural skills rather than the Microsoft tech stack.</p><p>If the interviewer held a managerial or leadership position or came from a business background, I would have emphasized my business acumen and stakeholder management. I wouldn‚Äôt focus as much on my technical abilities.</p><p>It‚Äôs about finding common ground with the interviewer so the discussion can focus on topics we both know. Yes, it may be tedious, but you need to research the role and the interviewer and tailor your elevator pitch accordingly.</p><p>Next, let‚Äôs dive into how to showcase behavioral skills in technical interviews‚Ä¶</p><p>Let me start this section with a personal anecdote.</p><p>In one of my technical interview rounds at AWS in 2019, I was asked, ‚ÄúWhat is an Idempotent API?‚Äù</p><p>My response was in 3 steps:</p><ol><li><p><strong>Answered the technical question asked upfront</strong></p></li></ol><blockquote><p>I explained what an Idempotent API is, showcasing my technical knowledge.</p></blockquote><ol start=\"2\"><li><p><strong>Shared my previous project where I implemented an idempotent API</strong></p></li></ol><blockquote><p>I showcased my actual hands-on work experience without the interviewer even asking me.</p></blockquote><ol start=\"3\"><li><p><strong>Explained my project experience in STAR format</strong></p></li></ol><p>[<em>I‚Äôll cover STAR (Situation Task Action Result) format in the next section</em>]</p><blockquote><p>While explaining my project experience in STAR format, I also explained WHY the idempotent API was required in that scenario. I talked about how the APIs I built were reporting trades worth millions in real-time to regulators and the reason I had to implement them as idempotent.</p><p>This is where I showcased my behavioral skills. I demonstrated I understand the business impact of the technical solutions I build.</p></blockquote><div data-attrs=\"{&quot;url&quot;:&quot;https://newsletter.systemdesign.one/p/common-behavioral-interview-questions?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}\" data-component-name=\"CaptionedButtonToDOM\"><div><p>Share this post &amp; earn rewards for referrals.</p></div></div><h4><strong>The Problem with Pure Technical Answers</strong></h4><p>Many candidates show off their technical knowledge in technical interviews, and most get the technical answers right.</p><p>Let‚Äôs say 10 people interview:</p><p>7 of them answered the technical questions correctly. You‚Äôre one of those 7. So why should the interviewer pick you?</p><p>How? By sharing your real-world experience and behavioral skills.</p><p>While technical answers showcase that you have knowledge, they don‚Äôt paint a complete picture of your ability to succeed in a role.</p><p>For example, all engineers know what an idempotent API is. But how many can connect it to their experience in an interview and share real-world examples to boost the interviewer‚Äôs confidence in their skills? You stand out from other candidates by showing your experience and behavioral skills while you answer technical questions.</p><p>This also ensures that your interviewer does not downlevel you.</p><p>Let‚Äôs look at a couple of common technical questions‚Ä¶</p><p>I‚Äôll show you how to answer them in a way that also shows off your behavioral skills and experience.</p><h4><strong>Question: ‚ÄúWhat are microservices, and what are their advantages and disadvantages?‚Äù</strong></h4><p><strong>Purely Technical Approach</strong></p><blockquote><p><em>‚ÄúMicroservices are an architectural style where an application is built as a collection of small, independent services. The advantages include scalability, flexibility, and easier maintenance. Disadvantages include increased complexity and potential performance overhead due to network communication.‚Äù</em></p></blockquote><p>(This is just an example. You‚Äôll have your own version of a technical answer with much more depth to it!)</p><p><strong>Behavioral Skills Showcase Approach</strong></p><p>After you provide the technical answer, add your personal experience to it.</p><blockquote><p><em>‚ÄúIn fact, in one of my previous projects when I was consulting for a manufacturing company in 2022, I led a team that modernized our e-commerce platform by transitioning from a monolith to microservices.</em></p><p><em>We decided to make this shift because our monolithic application was becoming increasingly difficult to maintain and scale. For instance, deploying even small changes required testing the entire application, leading to a release cycle of 6 weeks.</em></p><p><em>To begin the transition, I initiated and facilitated an event storming session with stakeholders from development, operations, and business teams. This collaborative approach helped us identify natural service boundaries and ensured buy-in from all departments.</em></p><p><em>We started by extracting the product catalog service, as it was relatively self-contained. We faced several challenges, such as increased operational complexity and data consistency issues. I saw these as opportunities for the team to learn and grow. We invested time in upskilling, bringing in external experts for workshops on distributed systems and organizing internal knowledge-sharing sessions.</em></p><p><em>I‚Äôm happy to dive deep more into my experience. I‚Äôve seen firsthand in this project the advantages of microservices and the challenges that come along with it.‚Äù</em></p></blockquote><p>This response not only demonstrates technical knowledge but also showcases your experience and several behavioral skills:</p><ul><li><p>Leadership: Leading the modernization project</p></li><li><p>Communication: Facilitating sessions with various stakeholders</p></li><li><p>Problem-solving: Addressing challenges that arose during the transition</p></li><li><p>Learning mindset and adaptability: Learning and applying new technologies</p></li></ul><p>Now, let‚Äôs look into another question.</p><h4><strong>Question: ‚ÄúWhat factors would you consider when choosing between SQL and NoSQL databases?‚Äù</strong></h4><p><strong>Purely Technical Approach:</strong></p><blockquote><p><em>‚ÄúWhen choosing between SQL and NoSQL databases, several factors come into play.</em></p><p><em>Data structures are a primary consideration, with SQL being ideal for structured, relational data, while NoSQL is better suited for unstructured or semi-structured data.</em></p><p><em>Scalability needs often favor NoSQL, which typically scales horizontally more easily.</em></p><p><em>SQL databases offer stronger ACID compliance and excel at complex queries involving joins and transactions. However, NoSQL databases provide greater schema flexibility, allowing for more dynamic data models.</em></p><p><em>Performance requirements are also crucial, as NoSQL can offer faster read/write speeds for certain use cases.</em></p><p><em>Data consistency needs should be evaluated, with SQL providing immediate consistency and some NoSQL databases offering eventual consistency.</em></p><p><em>The choice ultimately depends on the specific requirements and constraints of the project at hand.‚Äù</em></p></blockquote><p>This is a good answer and will probably make the cut. But as I mentioned, most candidates will be able to provide this level of answer. You need to strive to go above and beyond.</p><p><strong>Behavioral Skills Showcase Approach:</strong></p><p>I understand you cannot have work experience for every technical question asked in an interview. And that is absolutely fine. Complement the technical answer above with how you would approach such a scenario.</p><blockquote><p><em>‚ÄúTo understand the requirements and constraints, I would organize a requirements gathering session with various stakeholders like the development team, product managers and, if possible, end-users. During this session, I would ask key questions such as:</em></p></blockquote><ul><li><p><em>How structured is the data? Do we need a fixed schema or flexibility for evolving structures?</em></p></li><li><p><em>What are our scalability requirements? What are the expected read/write ratios?</em></p></li><li><p><em>Do we need strong consistency for all operations, or is eventual consistency acceptable for some data?</em></p></li><li><p><em>What are our typical query patterns? Do we need complex joins and transactions?</em></p></li><li><p><em>How frequently will our data model change?</em></p></li></ul><blockquote><p><em>Once we have these answers, I would analyze them in the context of ACID (Atomicity, Consistency, Isolation, Durability) properties typically associated with SQL databases, and BASE (Basically Available, Soft state, Eventually consistent) properties often seen in NoSQL systems.</em></p><p><em>I would also consider the CAP theorem (Consistency, Availability, Partition tolerance) which states that in a distributed system, you can only have two of these three guarantees.</em></p><p><em>And most modern systems often benefit from a polyglot persistence approach, using different databases for different purposes within the same application.</em></p><p><em>PostgreSQL for user accounts and financial transactions, where ACID properties were crucial. MongoDB for storing product catalogs with varying attributes. Redis for caching and real-time analytics</em></p><p><em>This decision cannot be made in isolation. I would consider trade-offs of each approach, challenge assumptions and provide alternative viewpoints.‚Äù</em></p></blockquote><p>This response shows several behavioral skills:</p><ul><li><p>Analytical thinking: Systematically considering various factors</p></li><li><p>Stakeholder management: Involving different teams in the decision-making process</p></li><li><p>Communication: Organizing and facilitating requirements gathering and review sessions</p></li><li><p>Decision-making: Weighing pros and cons to arrive at a solution</p></li></ul><p>By answering technical questions in a way that showcases both your technical knowledge and behavioral skills, you present yourself as a well-rounded candidate who can not only do the job but also work effectively within a team and contribute to the company culture.</p><p>Companies are looking for more than just technical expertise. They want employees who can communicate effectively, work collaboratively, adapt to changing circumstances, and drive innovation.</p><p>So, as you prepare for your next technical interview, reflect not just on your technical accomplishments, but also on how you‚Äôve demonstrated these crucial behavioral skills in your work.</p><p>Now, let‚Äôs dive into understanding the STAR framework to prepare for your behavioral interviews‚Ä¶</p><p>If you‚Äôve been preparing for job interviews, you‚Äôve likely encountered the STAR format.</p><p>It‚Äôs a powerful framework for structuring responses to behavioral questions. However, many candidates use this technique incorrectly, resulting in weak, unconvincing answers.</p><p>In this section, I‚Äôll cover how to avoid common pitfalls and craft compelling STAR responses that will impress your interviewers.</p><p>As I explain the STAR format with an example and then go through more examples in the upcoming sections, I will adopt different personas.</p><p>I‚Äôll start with the persona of a Cloud Solutions Architect, as that‚Äôs my current role!</p><p>Let‚Äôs have a quick refresher of what STAR stands for:</p><ul><li><p>Situation: Context or background of your example</p></li><li><p>Task: Specific challenge or responsibility you faced</p></li><li><p>Action: Steps you took to address the task</p></li><li><p>Result: Outcomes of your actions</p></li></ul><p>Now, let‚Äôs examine each component, identify common mistakes, and learn how to do it right with an example‚Ä¶</p><h3><strong>Situation: Stop Being Vague</strong></h3><p>Situation sets the stage for your story.</p><p>It provides the context and background information necessary for the interviewer to understand the circumstances you were facing. When describing the situation, be specific about:</p><ul><li><p>Where you were working and what your role was</p></li><li><p>Relevant data/metrics to showcase the importance of the situation</p></li></ul><blockquote><p><em>‚ÄúI was working as a Cloud Solutions Architect, and we had to move our mission-critical workloads to the cloud.‚Äù</em></p></blockquote><p>This situation lacks specificity and fails to set the stage effectively. It doesn‚Äôt give the interviewer any meaningful context.</p><blockquote><p><em>‚ÄúI was working as a Senior Cloud Solutions Architect with a Fortune 500 manufacturing company. In Q1 2023, 80% of our mission-critical applications were running on aging on-premises infrastructure, causing frequent outages and limiting our ability to scale. Our CIO had set an aggressive goal to migrate 50% of these applications to the cloud within six months to improve reliability and reduce operational costs.‚Äù</em></p></blockquote><p>This approach works because it specifies the exact role and company, provides a clear timeframe, and offers relevant data and metrics that highlight the importance of the situation.</p><h3><strong>Task: Don‚Äôt Undersell the Challenge</strong></h3><p>Task describes the specific challenge, problem, or responsibility you were facing in a situation.</p><p>This component should clearly outline:</p><ul><li><p>What you needed to accomplish</p></li><li><p>Goals or objectives you were working towards</p></li><li><p>Urgency and importance of the task</p></li></ul><blockquote><p><em>‚ÄúThe task was to figure out how to move the applications to AWS within the given timeframe and make sure they worked properly.‚Äù</em></p></blockquote><p>This description undersells the complexity of the task and fails to convey its importance or urgency.</p><blockquote><p><em>‚ÄúThe task was to identify, prioritize and migrate critical applications to AWS within six months. This required assessing applications, designing a secure architecture, creating a migration plan, minimizing operational disruptions, ensuring high uptime, and reducing costs. The timelines were aggressive, as the urgency was high because our aging infrastructure was putting us at risk of major system failures.‚Äù</em></p></blockquote><p>This approach works because it breaks down the task into key components, emphasizes the urgency and importance of the challenge, and demonstrates the scope and complexity of what needs to be accomplished.</p><h3><strong>Action: Get Specific and Show Your Expertise</strong></h3><p>Action is the core of your response.</p><p>It details the steps you took to address the task or challenge. When describing your actions:</p><ul><li><p>Be specific about what you did. Use ‚ÄúI‚Äù statements to clarify your personal contributions.</p></li><li><p>Explain your thought process and decision-making</p></li><li><p>Highlight any skills or qualities you demonstrated</p></li></ul><blockquote><p><em>‚ÄúI looked at our applications and decided to start the migration with our core ERP system as it was most critical. Then I set up the AWS accounts and worked with security, database, networking and other teams to migrate the application. We had to make some application architecture changes to make the apps work in the cloud.‚Äù</em></p></blockquote><p>This description is vague, lacks detail, and does not demonstrate any specific skills or expertise.</p><blockquote><p><em>‚ÄúTo begin, I led a cross-functional team in conducting a thorough analysis of our application portfolio. We considered factors such as business criticality, dependencies, and architectural complexity to gain a complete understanding of our existing infrastructure.</em></p><p><em>Based on this assessment, I took the ownership to lead the migration of our core ERP system, which was critical to our manufacturing operations. This migration was also crucial to the overall goal as it would serve as a blueprint for future migrations.</em></p><p><em>I designed a multi-tiered AWS architecture for this application, ensuring high availability and scalability. Security was a top priority, so I collaborated closely with our security team to implement a robust model tailored to the ERP system‚Äôs requirements. I worked with the project manager to create a comprehensive project plan, including a phased approach to migrate different modules of the ERP system.</em></p><p><em>To streamline the migration process and reduce manual errors, I developed CloudFormation templates and leveraged AWS Migration Hub for automation. This significantly reduced migration time and improved consistency. Throughout the process, I worked closely with our database team to ensure data integrity and with our networking team to establish secure connectivity between our on-premises systems and AWS.</em></p><p><em>Additionally, I conducted several dry runs and extensive testing to minimize potential disruptions to our manufacturing operations.‚Äù</em></p></blockquote><p>In the STAR framework, the Action section is where you should invest the most detail and time.</p><p>Detailing your actions, explaining your choices, and highlighting your technical and leadership capabilities builds a powerful story. It shows your impact and value.</p><h3><strong>Result: Quantify Your Impact</strong></h3><p>Result is the conclusion of your story.</p><p>It describes the outcome of your actions and their impact. When discussing results:</p><ul><li><p>Be specific about what was achieved using quantifiable metrics when possible</p></li><li><p>Explain the positive impact on the company, team, or project</p></li><li><p>Mention any lessons learned or personal growth</p></li></ul><blockquote><p><em>‚ÄúWe managed to move few applications to the cloud within the 6 months. The application is working better in the cloud and we overall reduced the cost of infrastructure of running these applications.‚Äù</em></p></blockquote><p>This result lacks specificity and demonstrates no significant impact or value.</p><blockquote><p><em>‚ÄúWe successfully migrated our core ERP system to AWS in four months. The system‚Äôs response times decreased by 40%, and we improved scalability, handling a 200% increase in concurrent users during peak periods. We also reduced infrastructure costs for this application by 30%.</em></p><p><em>It took us more time than anticipated, but we learned a lot along the way. Based on the learnings, I created a blueprint, best practices document and SOP for other teams to migrate their respective applications. Using these documents, different teams have migrated 24 more applications so far.</em></p><p><em>Personally, this project deepened my expertise in large-scale cloud migrations and gave me the opportunity to work with multiple stakeholders and cross-functional teams.‚Äù</em></p></blockquote><p>This approach works because it shows clear, measurable wins. It explains the good impact on various business areas and highlights your personal growth.</p><p>Now that you understand how to structure your behavioral answers using the STAR format, let‚Äôs explore the key themes you should focus on‚Ä¶</p><p>Behavioral interviews can feel overwhelming because of their open-ended nature and the sheer volume of potential questions.</p><p>To streamline your preparation for your next tech company behavioral interview, I‚Äôve organized these questions into eight main themes:</p><h3><strong>1. Customer/User Focus Stories</strong></h3><p>These stories showcase your ability to prioritize and enhance the customer experience. They might include:</p><ul><li><p>Improving user experience</p></li><li><p>Handling customer complaints</p></li><li><p>Going above and beyond for clients</p></li></ul><p>: <em>‚ÄúGive an example of a time when you had to deal with a challenging customer or user issue.‚Äù</em></p><p><strong>What your answer should address:</strong> Describe the problem and why it was difficult to resolve, explain how you understood the customer‚Äôs needs, outline the steps you took to address the issue, and discuss the final resolution and how you ensured customer satisfaction.</p><p>The interviewers would like to hear about your ability to deliver results and handle challenges. Think about stories like:</p><ul><li><p>Achievements and accomplishments</p></li><li><p>Overcoming significant challenges</p></li><li><p>Innovative solutions or improvements</p></li></ul><p><em>‚ÄúTell me about a time when you significantly exceeded expectations on a project or task.‚Äù</em></p><p><strong>What your answer should address:</strong> Explain what the initial goals were and how you went above and beyond, describe the strategies you used to achieve results, and discuss how you measured your success.</p><p>Interviewers are interested in how you handle adversity and grow from experiences. Prepare stories that showcase:</p><ul><li><p>Projects that didn‚Äôt meet expectations</p></li><li><p>Mistakes with significant consequences</p></li><li><p>Failures to anticipate major problems or challenges</p></li></ul><p><em>‚ÄúTell me about a time when you failed to meet an important goal or deadline at work.‚Äù</em></p><p><strong>What your answer should address:</strong> Describe the situation and the factors that contributed to the failure, explain how you handled the aftermath, and discuss the lessons you learned and how you‚Äôve applied them since.</p><p>Interviewers want to assess your interpersonal skills and ability to navigate challenging situations. Prepare examples that showcase:</p><ul><li><p>Dealing with difficult colleagues or clients</p></li><li><p>Resolving team disagreements</p></li><li><p>Navigating workplace dynamics</p></li></ul><p><em>‚ÄúDescribe a situation where you had a conflict with a colleague or team member.‚Äù</em></p><p><strong>What your answer should address:</strong> Explain the source of the conflict and how you approached resolving it, describe the steps you took to maintain a professional relationship afterward, and discuss how this experience changed your approach to workplace conflicts.</p><h3><strong>5. Problem-Solving Stories</strong></h3><p>Interviewers aim to understand your analytical thinking and creative approach to challenges. Prepare examples that illustrate:</p><ul><li><p>Tackling complex challenges</p></li><li><p>Making decisions with limited information</p></li><li><p>Implementing process improvements</p></li></ul><p><em>‚ÄúGive an example of a complex problem you encountered at work that required an innovative solution.‚Äù</em></p><p><strong>What your answer should address:</strong> Explain what made this problem particularly challenging, walk through your problem-solving process, describe how you implemented your solution, and discuss the result and how you measured its success.</p><h3><strong>6. Learning/Growth Mindset Stories</strong></h3><p>Interviewers look for examples of your adaptability and commitment to continuous improvement. Share examples that demonstrate:</p><ul><li><p>Learning new skills quickly</p></li><li><p>Handling change or uncertainty</p></li><li><p>Embracing feedback for personal improvement</p></li></ul><p><em>‚ÄúDescribe a time when you had to learn a completely new skill or technology that was crucial for your role or a project.‚Äù</em></p><p><strong>What your answer should address:</strong> Explain the situation and why this new skill was necessary, describe the challenges you faced and how you overcame them, and discuss how you applied this new knowledge and what the outcome was.</p><p>These anecdotes showcase your ability to guide, influence, and develop others:</p><ul><li><p>Motivating and inspiring team members</p></li><li><p>Navigating conflicts or difficult decisions</p></li><li><p>Developing and mentoring others</p></li></ul><p><em>‚ÄúTell me about a time when you had to lead a team through a challenging situation or project.‚Äù</em></p><p><strong>What your answer should address:</strong> Describe the context and the specific leadership challenges you faced, explain how you approached motivating your team and keeping them aligned towards the goal, and discuss the project outcome and how this experience shaped your leadership style.</p><div data-attrs=\"{&quot;url&quot;:&quot;https://newsletter.systemdesign.one/p/common-behavioral-interview-questions?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}\" data-component-name=\"CaptionedButtonToDOM\"><div><p>Share this post &amp; earn rewards for referrals.</p></div></div><h3><strong>8. Time Management Stories</strong></h3><p>Interviewers are looking to assess your ability to organize, prioritize, and deliver under pressure. Consider examples that highlight:</p><ul><li><p>Balancing multiple responsibilities</p></li></ul><p><em> ‚ÄúDescribe a period when you had to manage multiple high-priority tasks simultaneously.‚Äù</em></p><p><strong>What your answer should address:</strong> Explain what the tasks were and why they were all critical, describe how you prioritized them and your time, discuss the tools or techniques you used to stay organized, and explain how successful you were in meeting your deadlines and what you would do differently if faced with a similar situation.</p><p>For each theme, prepare one or two well-developed stories using the STAR framework.</p><p>Know the underlying behavioral competencies you‚Äôre demonstrating with each story. Then you can adapt these stories to different questions you encounter. Also, map the stories to the core values of the company you are interviewing for.</p><blockquote><p><em>Want a free behavioral interview question bank with 40 questions in 8 themes? Subscribe to my newsletter, <a href=\"https://newsletter.bigtechcareers.com/\">Big Tech Careers</a>, and I‚Äôll send it in your welcome kit.</em></p></blockquote><p>Now, let‚Äôs examine a strong response from the Learning/Growth Mindset category.</p><p>Many companies value this theme. It shows how quickly you can learn new skills and adapt in a fast-paced environment‚Ä¶</p>","contentLength":39958,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/9cbd9776-19e8-49bd-b7ca-da811d09259e_1280x720.png","enclosureMime":"","commentsUrl":null},{"title":"I struggled with system design until I learned these 114 concepts","url":"https://newsletter.systemdesign.one/p/system-design-concepts","date":1770472735,"author":"Neo Kim","guid":34,"unread":true,"content":"<p>Some of these are foundational, and some are quite advanced. ALL of them are super useful to software engineers building scalable systems.</p><p>Curious to know how many were new to you:</p><ol><li><p>Latency vs Throughput vs Bandwidth,</p></li><li><p>Client-Server Architecture,</p></li><li><p>Load Balancing Algorithms,</p></li><li><p>Authentication vs Authorization,</p></li><li><p>Session-based vs Token-based Authentication,</p></li><li><p>OAuth/OAuth2/OpenID Connect,</p></li><li><p>High Availability vs Fault Tolerance,</p></li><li><p>Microservices Architecture,</p></li><li><p>Event-Driven Architecture,</p></li><li><p>Synchronous vs Asynchronous Communication.</p></li></ol><p>(‚Ä¶and many more in parts 2 &amp; 3!)</p><ul><li><p>What it is &amp; how it works--in simple words</p></li><li><p>A real-world analogy (if I found one)</p></li></ul><p> is the only AI code review tool that reflects your team‚Äôs standards and judgment, delivering thoughtful feedback that feels like it came from your best engineer.</p><blockquote><p>Scalability is the system‚Äôs ability to handle increased load without breaking.</p></blockquote><p>Vertical scaling means adding more power to your existing machine, such as a larger CPU, more RAM, or a faster disk. Horizontal scaling means adding more machines to distribute the work across multiple servers.</p><p>When traffic grows, vertical scaling upgrades a single machine, while horizontal scaling adds more machines to work together.</p><p>Vertical scaling is like upgrading from a small restaurant kitchen to a bigger one with industrial-grade equipment.</p><p>Horizontal scaling is like opening multiple restaurant locations instead of expanding one location.</p><p>Vertical scaling is simpler but hits a ceiling. You can only make one machine so powerful, and it becomes a single point of failure.</p><p>Horizontal scaling can grow infinitely, but it introduces complexity in coordinating multiple machines and keeping data consistent across them.</p><p>Use vertical scaling when you‚Äôre starting out or when your application isn‚Äôt designed for distribution. Switch to horizontal scaling when you need to handle millions of users, want high availability, or when vertical scaling becomes very expensive.</p><blockquote><p>Availability measures the percentage of time your system is operational &amp; accessible to users.</p></blockquote><p>It‚Äôs typically expressed as ‚Äúnines,‚Äù where 99.9% corresponds to about 8.76 hours of downtime per year, while 99.99% corresponds to only 52.6 minutes. Availability is achieved through redundancy, failover mechanisms, and the elimination of single points of failure.</p><p>Availability is like a 24/7 convenience store.</p><p>A store with 99% availability would be closed for 3.65 days per year. A store with 99.999% availability would only be closed for 5 minutes per year.</p><p>Higher availability requires more resources, such as redundant servers, load balancers, complex failover systems, and multi-region deployments. Each additional ‚Äúnine‚Äù gets exponentially more expensive.</p><p>You might also sacrifice consistency for availability (CAP theorem).</p><p>Customer-facing systems, e-commerce platforms, payment processing, or any service where downtime directly costs money or erodes user trust.</p><p>Yet internal tools or batch processing jobs can tolerate lower availability.</p><blockquote><p>Reliability is your system‚Äôs ability to perform its intended function correctly over time, even when things go wrong.</p></blockquote><p>A reliable system handles failures gracefully. If a server crashes, requests get rerouted. If data gets corrupted, backups restore it. Reliability includes fault tolerance, data durability, and consistent behavior under various conditions.</p><p>Reliability is like a car that starts every morning, even in winter‚Ä¶</p><p>It doesn‚Äôt just work 99% of the time--it safely takes you to the right destination. A highly available but unreliable system is like a taxi that always shows up but sometimes takes you to the wrong address.</p><p>Building reliable systems requires extensive testing, monitoring, error handling, retry logic, and redundancy. This increases development time &amp; operational complexity.</p><p>Prioritize reliability for financial transactions, healthcare systems, data pipelines where data loss is unacceptable, or any system where incorrect behavior is worse than being temporarily unavailable.</p><p>Remember, a personal blog doesn‚Äôt need the same reliability as a hospital patient monitoring system.</p><h2><strong>4. Latency vs Throughput vs Bandwidth</strong></h2><blockquote><p>Latency is the time it takes for a single request to travel from client to server and back, measured in milliseconds.</p><p>Throughput is how many requests your system can handle per unit of time, like requests per second.</p><p>Bandwidth is the maximum amount of data that can be transferred over a network connection in a given time, measured in Mbps or Gbps.</p></blockquote><p>These three metrics are related,,, but measure different aspects of performance.</p><ul><li><p>Latency is how long it takes one car to drive from point A to B.</p></li><li><p>Throughput is the number of cars that can complete the journey per hour.</p></li><li><p>Bandwidth is how many lanes a highway has.</p></li></ul><p>You can have an 8-lane highway with high latency over long distances, or a 2-lane road with low latency over short distances.</p><p>Optimizing for one doesn‚Äôt automatically improve the others‚Ä¶</p><p>You can increase throughput by adding more servers, but it won‚Äôt reduce latency. You can reduce latency by caching or using a CDN, but it doesn‚Äôt increase throughput.</p><p>Increasing bandwidth helps with large data transfers but doesn‚Äôt reduce latency.</p><p>Focus on low latency for real-time applications such as gaming, video calls, and trading platforms. While optimize throughput for high-traffic APIs and web services. And prioritize bandwidth for video streaming, file transfers, and data-intensive applications.</p><p>Most production systems need to balance all three‚Ä¶</p><h2><strong>5. Client-Server Architecture</strong></h2><blockquote><p>A model where clients, such as users‚Äô devices, browsers, or mobile apps, send requests to servers, which process those requests and send back responses.</p></blockquote><p>The server hosts the business logic, databases, and resources, while clients provide the user interface. This separation allows multiple clients to access the same server resources simultaneously.</p><p>Client-server is like a restaurant: you sit at a table, place your order with a waiter, and the waiter takes it to the kitchen.</p><p>The kitchen prepares your food and sends it back through the waiter. You don‚Äôt go into the kitchen yourself‚Ä¶there‚Äôs a clear separation of responsibilities.</p><p>This architecture centralizes control and data management, making it easier to maintain and secure. Yet the server could become a bottleneck and a single point of failure. If the server goes down, all clients lose access.</p><p>The server also needs to scale to handle increasing numbers of clients.</p><p>Web applications, mobile apps, email systems, and most modern software.</p><p>It‚Äôs the foundation of how the internet works‚Ä¶Consider alternatives such as peer-to-peer file sharing or edge computing when you need to reduce dependence on central servers.</p><blockquote><p>A database is an organized collection of structured data stored electronically and managed by a Database Management System (DBMS).</p></blockquote><p>Databases allow you to create, read, update, and delete data efficiently.</p><p>They handle concurrent access, ensure data integrity through transactions with ACID properties, and provide query languages to retrieve data. Databases can be relational, with tables organized as rows and columns, or non-relational, such as documents, key-value pairs, or graphs.</p><p>A database is like a highly organized library with a sophisticated cataloging system.</p><p>Instead of wandering through aisles hoping to find a book, you use the catalog to locate what you need instantly. The librarian ensures books don‚Äôt get lost, handles multiple people checking out books simultaneously, and maintains the organization system.</p><p>Databases provide powerful data management but introduce complexity:</p><p>They require careful schema design, indexing strategies, backup procedures, and monitoring. Poorly designed databases become bottlenecks. Plus, slow queries can bring down your entire application.</p><p>Different database types optimize for different use cases‚Ä¶so choosing the wrong one can ‚Äòhurt‚Äô performance.</p><p>Use databases whenever you need to persist data beyond application restarts, handle concurrent users accessing shared data, maintain data relationships, or query data in flexible ways.</p><p>Almost every production application needs a database‚Ä¶the question is which type fits your use case.</p><blockquote><p>SQL databases organize data in tables with predefined schemas, using rows and columns.</p></blockquote><p>They support complex queries, joins across tables, and ACID transactions. Examples: PostgreSQL &amp; MySQL.</p><blockquote><p>NoSQL databases use flexible schemas and store data as documents, key-value pairs, wide columns, or graphs.</p></blockquote><p>They prioritize scalability and flexibility over strict consistency. Examples: MongoDB, Redis, Cassandra, and Neo4j.</p><p>SQL is like a spreadsheet with strict columns‚Ä¶</p><p>Everyone must follow the same structure, but you can easily combine data from different sheets using formulas.</p><p>NoSQL is like a filing cabinet where each folder can contain different types of documents in different formats‚Ä¶more flexible, but harder to analyze across folders.</p><p>SQL databases offer strong consistency, complex querying, and enforced data integrity. They can scale vertically and horizontally, but distributing data across many machines is often complex because of joins and transactional guarantees.</p><p>While NoSQL databases are built to scale horizontally and handle flexible data models. They often trade strong consistency or full relational features for scale and high availability.</p><p>Most companies use both SQL for transactional data and NoSQL for flexibility and scalability.</p><ul><li><p>Use SQL for financial systems, e-commerce orders, user authentication, or anywhere you need ACID guarantees and complex queries across related data.</p></li><li><p>Use NoSQL for user profiles, product catalogs, real-time analytics, session storage, or when your schema changes frequently.</p></li></ul><p><em><strong>Reminder: this is a teaser of the subscriber-only post, exclusive to my golden members.</strong></em></p><p>When you upgrade, you‚Äôll get:</p><ul><li><p><strong>Full access to system design case studies</strong></p></li><li><p>FREE access to (coming) Design, Build, Scale newsletter series</p></li><li><p><strong>FREE access to (coming) popular interview question breakdowns</strong></p></li></ul><p>Get 10x the results you currently get with 1/10th the time, energy &amp; effort.</p>","contentLength":10057,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/e5da46f5-2df8-48bd-896b-4af2e5ab5b42_1280x720.png","enclosureMime":"","commentsUrl":null},{"title":"I struggled to code with AI until I learned this workflow","url":"https://newsletter.systemdesign.one/p/ai-coding-workflow","date":1770031839,"author":"Neo Kim","guid":33,"unread":true,"content":"<blockquote><p>Everyone talks about using AI to write code like it‚Äôs a vending machine:</p><p><em>‚ÄúPaste your problem, get a working solution.‚Äù</em></p></blockquote><p>The first time I tried it, I learned the hard way that this is not how it works in real projects‚Ä¶</p><p>The model would confidently suggest code that called functions that didn‚Äôt exist, assumed libraries we weren‚Äôt using, or skipped constraints that felt obvious to me. The output looked polished.</p><p>The moment I ran it‚Ä¶ It fell apart.</p><p>After enough trial and error, I stopped trying to ‚Äúprompt better‚Äù and started working differently. What finally made AI useful wasn‚Äôt a magic tool or a clever prompt. It was a simple loop that kept the model on a short leash and kept you in the driver‚Äôs seat:</p><p>This newsletter breaks that loop down step by step.</p><p>It‚Äôs written for software engineers who are new to AI coding tools and want a practical starting point: not a tour of every product on the market, but a repeatable method you can use tomorrow.</p><p>AI works best as an iterative loop, not a one-shot request. You steer. The model fills in the gaps. And because it does less guessing, you spend less time cleaning up confident mistakes.</p><p>I‚Äôm happy to partner with  on this newsletter. Code reviews usually delay feature deliveries and overload reviewers. And I genuinely believe CodeRabbit solves this problem.</p><p>He focuses on making AI more accessible by helping people learn practical AI skills for the industry alongside 500k+ fellow learners.</p><p>If you‚Äôre new to using AI for coding, this is the set of habits that prevents most pain.</p><ul><li><p><strong>Treat AI output like a draft, not an answer.</strong> Models can sound certain while being completely wrong, so anything that matters still gets reviewed and verified.</p></li><li><p><strong>Start with context, the way you‚Äôd brief a teammate.</strong> If you don‚Äôt share constraints, library versions, project rules, and intended behavior, the model will ‚Äòhappily‚Äô invent them for you.</p></li><li><p><strong>Ask for a plan before you ask for code.</strong> Plans are cheap to change. Code is expensive to unwind. I‚Äôll usually approve the approach first, then ask for small, step-by-step changes.</p></li><li><p><strong>Use reviews and tests as a safety net.</strong> I still do a normal pull request review and rely on tests to verify behavior and catch edge cases.</p></li></ul><p>Before we dive in, here‚Äôs the small vocabulary I‚Äôll use throughout.</p><p>It‚Äôs not exhaustive; it‚Äôs just enough to keep the rest of the article readable:</p><ul><li><p> (e.g., Cursor, VS Code + GitHub Copilot) is a code editor with AI built in. It can suggest completions, refactor functions, and generate code using your project files as context.</p></li><li><p> (e.g., ChatGPT, Claude, or Gemini) is a conversational AI you interact with in plain language. It‚Äôs useful when you‚Äôre still figuring out what to do: brainstorming approaches, explaining an error, comparing trade-offs, or sanity-checking a design before you write code.</p></li><li><p> tools (e.g., <a href=\"https://coderabbit.link/neo-jan\">CodeRabbit</a>) automatically review pull requests using AI, posting summaries and line-by-line suggestions.</p></li><li><p> (e.g., Perplexity) combines chat with web search. It‚Äôs what you reach for when you need to verify that a suggested API call is real, that a library feature exists in the version you‚Äôre using, or that you‚Äôre not about to copy-paste something that expired two releases ago.</p></li></ul><p>Before the workflow, it helps to be honest about what AI coding assistants are and aren‚Äôt.</p><p>They‚Äôre fantastic when the problem is well-scoped and sitting right in front of them. They‚Äôre unreliable the moment you assume they ‚Äúknow‚Äù what you didn‚Äôt explicitly provide. The workflow is basically a way to stay in the first zone and avoid the second.</p><p>When you give clear requirements, AI is great at drafting functions, refactoring code, scaffolding tests, and talking through error messages.</p><p>But it has a hard boundary: it only knows what it can see in the current context. It doesn‚Äôt remember your last chat; it doesn‚Äôt know your architecture or conventions, and it won‚Äôt reliably warn you when it‚Äôs guessing. It just keeps going confidently.</p><p>I‚Äôve seen AI call library functions that don‚Äôt exist, use syntax from the wrong version, and ignore constraints I assumed were obvious. The pattern was always the same: the AI didn‚Äôt know what I hadn‚Äôt told it, so it filled the gaps by inventing something plausible.</p><p>Once I understood this, three principles shaped how I work:</p><p><strong>1. Give more context than you think you need.</strong> Just like I‚Äôd brief a colleague who just joined the project, I brief the AI every time. If I don‚Äôt share the details, it invents them.</p><p><strong>2. Guide it with specific steps.</strong> AI struggles with ‚Äúbuild me a web app,‚Äù but does well with ‚Äúadd input validation for these fields, return a clear error message, and write a test that proves invalid input is rejected.‚Äù The more specific my request, the better the output.</p><p><strong>3. If it matters, verify it.</strong> Whenever the AI produces security-sensitive logic, a database migration, or an algorithm that must be correct, I review it myself and add tests that prove the behavior.</p><blockquote><p><em>A good way to hold all of this in your head is:</em></p><p>AI is a smart teammate who joined your project five minutes ago.</p><p>They can write quickly, but they don‚Äôt know your architecture, your conventions, or your constraints unless you tell them.</p><p>That‚Äôs why the mistakes look so predictable: the model isn‚Äôt ‚Äúbeing dumb,‚Äù it‚Äôs filling in gaps you didn‚Äôt realise you left open.</p></blockquote><p>Once I started seeing it that way, the fix wasn‚Äôt a better one-shot prompt.</p><p>It was a repeatable loop that forced me to brief the model, force clarity early, and keep changes small enough to verify.</p><p>I‚Äôm not sure if you're aware of this‚Ä¶</p><p>When you open a pull request,  can generate a summary of code changes for the reviewer. It helps them quickly understand complex changes and assess the impact on the codebase.</p><p>Speed up the code review process.</p><p>The loop is the same whether I‚Äôm fixing a bug, adding a feature, or cleaning up a messy module.</p><p>It keeps the AI from freelancing, and it keeps me from treating ‚Äúcode that looks plausible‚Äù as ‚Äúcode that‚Äôs ready to ship.‚Äù</p><ol><li><p> I share project background, constraints, and the relevant code so the AI isn‚Äôt guessing.</p></li><li><p> I ask for a strategy before any code gets written.</p></li><li><p> I generate or edit code one step at a time, so changes stay small and reviewable.</p></li><li><p> I carefully check the output and often use AI-assisted pull request reviews as a second set of eyes.</p></li><li><p> I run tests, and I‚Äôll often have AI generate new tests that lock in the intended behavior.</p></li><li><p> I debug failures, refine the request, and repeat until the change is solid.</p></li></ol><p>I use different tools at different points in the loop.</p><p>Each one is good at a specific job:</p><ul><li><p>An editor is good at working inside a repo,</p></li><li><p>A chat model is good at thinking in plain language,</p></li><li><p>And review/testing tools are good at catching things I‚Äôd miss when I‚Äôm tired.</p></li></ul><p>The rest of this newsletter breaks down each step.</p><blockquote><p>The most important step is the first one:</p><p>If the model is guessing about your setup, everything downstream becomes cleanup. So the workflow starts with context.</p></blockquote><p>Most AI mistakes in code have the same root cause.</p><p>The model is guessing in a vacuum. Someone pastes a function, types ‚Äúfix this,‚Äù and acts surprised when the suggestion ignores half the system.</p><p> is the fastest way to make the model hallucinate‚Ä¶</p><p>Without a project background and constraints, it has no choice but to fill gaps with whatever sounds right: ‚Äòfunctions that don‚Äôt exist, syntax from the wrong version, solutions that break conventions elsewhere in the repo‚Äô.</p><blockquote><p>So, for anything that is not small, I flip the default: documentation and rules go first. Code goes second.</p></blockquote><p>This is easiest with an AI editor that can automatically pull in files.</p><p>I use Cursor, which lets me highlight code, pull in other files from my project, and ask the AI to do specific work with all of that as context. The pleasant part is I can swap models on the fly: a fast one for quick edits, a heavier reasoning model when I need to solve a tricky bug.</p><p>VS Code with Copilot or Claude Code offers similar features if you prefer to stay in that ecosystem.</p><p>When a task is even , I load three kinds of context:</p><p>I keep an updated README for each project and start most AI sessions by attaching it with a simple opener:</p><pre><code>Read the README below to understand the project. Then I will give you a specific task.</code></pre><p>If the change touches something sensitive (like payments), I include the key files in that first message too. By the time I describe the change, the assistant has already seen the neighborhood.</p><p>I keep a rules file (sometimes called  or ) that bundles project scope, coding style, version constraints (for example, ‚Äúthis service runs on ‚Äù), and a few hard rules (‚Äúnever call this external API in development,‚Äù ‚Äúall dates must be UTC‚Äù).</p><p>Some tools support ‚Äúrules‚Äù or ‚Äúcustom instructions‚Äù that help me avoid repeating myself in every session.</p><h4><strong>3. Relevant source and signals</strong></h4><p>For bugs or features, I paste the function or file involved along with stack traces or logs.</p><p>A single error line is like a screenshot of one pixel. The assistant needs more than that if I want real reasoning instead of optimistic guessing.</p><p><strong>Here‚Äôs a reusable prompt pattern:</strong></p><pre><code>Read @README to understand the project scope, architecture, and constraints.\n\nRead @AGENTS.md to learn the coding style, rules, and constraints for this codebase.\n\nThen read @main.py, @business_logic_1.py, and @business_logic_2.py carefully.\n\nYour task is to update @business_logic_2.py to implement the following changes:\n\n1. &lt;change 1&gt;\n2. &lt;change 2&gt;\n3. &lt;change 3&gt;\n\nFollow the conventions in the README and AGENTS file.\n\nDo not modify other files unless strictly necessary and explain any extra changes you make.</code></pre><p>The structure stays the same every time: context, then rules, then a precise task.</p><p>I swap out the filenames and the change list, but the pattern holds.</p><p>One thing I learned the hard way: <em>more text isn‚Äôt always better</em>. The best briefings are short and focused. They explain what the project is for, how the main pieces fit together, and which rules actually matter. If I notice I‚Äôm pasting more than a human would reasonably read before starting work, I cut it down.</p><p>One final detail that matters: context should be ‚Ä¶ not dumped.</p><p>The best briefings are short and decisive, enough to prevent guessing, but not so much that the model loses the signal. If I‚Äôm pasting more than a human would reasonably read before starting, I cut it down.</p><h3><strong>Step 2: Plan Before You Code</strong></h3><blockquote><p>Context answers ‚Äúwhere am I?‚Äù</p><p>It doesn‚Äôt answer ‚Äúwhat should I build?‚Äù</p></blockquote><p>That‚Äôs where things usually go sideways.</p><p>If you let AI write code immediately, it often picks a strange approach, optimizes the wrong thing, or quietly ignores constraints.</p><p>I‚Äôve learned to force a two-step process: </p><p>I usually do the planning step in a chat model like Claude, ChatGPT, or Gemini. ChatGPT works well when the problem is fuzzy, and I need structured thinking. Once the design feels reasonable, I switch to an AI editor like Cursor or Claude Code in VS Code, where the implementation happens with the repo open.</p><p><strong>First: Ask for a plan only</strong></p><p>For any non-trivial change, I first describe the feature or bug in plain language. That initial exchange is just about getting the idea into a workable shape:</p><pre><code>Here is the feature I want to build and some context.\n\nHelp me design it.\n\nWhat needs to change?\n\nWhich modules are involved?\n\nWhat are the main steps?</code></pre><p>The key is to stop the AI from jumping straight into code. I‚Äôll often say explicitly, ‚ÄúDo not write any code until I say approved.‚Äù</p><p><strong>Then: Approve and implement in small steps</strong></p><p>Once the plan looks reasonable, I approve it and ask the AI to implement one step at a time.</p><p>This is where I usually switch from a chat model to an AI editor like Cursor or VS Code with Copilot, since the implementation happens inside the actual codebase. For each step, I ask the AI to explain what it‚Äôs about to change and propose the code for that step only.</p><p>Small steps are easier to review and easier to undo if something goes wrong.</p><p><strong>Here‚Äôs a prompt template I reuse:</strong></p><pre><code>You are a senior engineer helping me with a new change.\n\nFirst, read the description of the feature or bug:\n&lt;insert feature or bug description and any relevant context&gt;\n\nStep 1 ‚Äî Plan only:\n\n- Think step by step and outline a clear plan.\n- List the main steps you would take.\n- Call out important decisions or tradeoffs.\n- Mention edge cases we should keep in mind.\n\nStop after the plan. Do not write any code until I say ‚Äúapproved.‚Äù\n\n\nStep 2 ‚Äî Implement:\n\nOnce I say ‚Äúapproved,‚Äù implement the plan one step at a time:\n\n- For each step, explain what you are about to change.\n- Propose the code changes for that step only.\n- Write tests for that step where it makes sense.</code></pre><p>If the AI recommends a library or function I‚Äôve never seen, I‚Äôll verify it actually exists using a search assistant or official docs. Models sometimes hallucinate APIs that sound plausible but don‚Äôt exist.</p><p>This pattern is especially useful when I‚Äôm working in a new stack or unfamiliar codebase. Instead of reading docs for hours, I ask the AI to explain the stack, sketch a design, and then help me implement it. The AI explains before it writes, so I learn as I go.</p><p>It also helps when a change touches multiple parts of the system, since a plan lets me see the full scope before I make edits everywhere.</p><p>Same with subtle bugs I don‚Äôt fully understand. For a slow database query, instead of asking ‚Äúmake this faster,‚Äù I ask the AI to reason through why it might be slow and what options exist. Only after that reasoning do I ask for the actual fix.</p><p>Fixing a plan is cheaper than fixing a pile of code. The ‚Äúapproved‚Äù step forces me to agree with the approach before the AI starts typing.</p><h3><strong>Step 3: Lightweight Multi-Agent Coding</strong></h3><p>Once I got comfortable with planning before coding, I started using a simple trick that makes AI output more reliable: <em>I split the work into roles</em>.</p><p>This isn‚Äôt a complex ‚Äòagent system.‚Äô Most of the time, it‚Äôs the same AI model, just prompted differently for each job.</p><p>Sometimes I use different models for different roles: </p><ul><li><p>Claude or ChatGPT for the Planner role (where reasoning matters),</p></li><li><p>Then, a faster model for the Implementer role (where the task is already well-defined and speed matters more).</p></li></ul><p>In Cursor, I can switch models mid-task, which makes this easy.</p><p> Breaks down the task into steps and calls out edge cases. (This is what we covered in Step 2.)</p><p> Writes code strictly based on the approved plan. I prompt it with something like: <code>‚ÄúFollow the approved plan. Change only the files I list. Keep the change small. If something is unclear, ask before coding.‚Äù</code></p><p> Writes tests and edge cases. I prompt it with: <code>‚ÄúWrite a unit test for the happy path. Write at least two edge case tests. If this were a bug fix, write a regression test that would fail before the fix.‚Äù</code></p><p> Summarizes what changed and why. I prompt it with: <code>‚ÄúSummarize changes by file. Explain the logic in plain language. List what could break and how the tests cover it.‚Äù</code></p><p>Big prompts encourage messy answers.</p><p>When I ask the AI to plan, implement, test, and explain all at once, the output gets tangled. When I split roles, I get a checklist, then a small change, then tests, then an explanation. Each piece is easier to review.</p><p>Long chats also drift. After enough back-and-forth, the AI forgets earlier context or recycles bad ideas. Short, focused threads stay sharp.</p><blockquote><p><strong>Practical tip: summarise between steps.</strong></p></blockquote><p>When I finish one role, I ask for a short summary before moving to the next. Then I paste that summary into the next prompt. This keeps each step focused and prevents context from getting lost across a long conversation.</p><h3><strong>Step 4: Review the Output</strong></h3><p>AI-generated code needs extra review.</p><p>The model is confident even when it‚Äôs wrong, and subtle bugs hide easily in code that looks plausible. This is where I add a layer of automated review before merging anything.</p><p>One way to do this is with an AI code review tool like <a href=\"https://coderabbit.link/neo-jan\">CodeRabbit</a>, which integrates with GitHub and GitLab. When you open a pull request, it automatically reviews the diff and posts comments directly in the PR thread. This kind of tool catches issues that slip past manual reviews, especially when you‚Äôre tired or rushing.</p><p>A tool like <a href=\"https://coderabbit.link/neo-jan\">CodeRabbit</a> typically gives you two things:</p><ul><li><p>First, a summary of what changed, often with a file-by-file walkthrough. This helps confirm the pull request matches your intent before looking at the details.</p></li><li><p>Second, line-by-line comments with suggestions. These often flag missing error handling, edge cases, potential security issues, and logic bugs like off-by-one errors. It can also run the code through linters and security analyzers during the review.</p></li></ul><p>When you push more commits to the same PR, it reviews the new changes incrementally rather than repeating the entire review.</p><p><strong>An example pull request flow</strong></p><p>Here‚Äôs what a typical flow looks like:</p><ol><li><p>Open a PR with a small, focused change.</p></li><li><p>The AI review tool automatically posts comments.</p></li><li><p>Read the comments, fix real issues, and reply to anything that‚Äôs noise or missing context.</p></li><li><p>Then do a final human pass before merging.</p></li></ol><p>Not every comment requires action. Sort them into two buckets:</p><ul><li><p> logic errors, missing error handling, security issues</p></li><li><p> style preferences, naming suggestions, alternative approaches</p></li></ul><blockquote><p>If you‚Äôre unsure whether something matters, ask yourself: </p><ul><li><p>Would this likely cause a bug?</p></li><li><p>Or would this confuse someone reading the code later?</p></li></ul><p>If yes to either, fix it or add a test.</p></blockquote><p>AI review tools have the same limitations as other AI tools.</p><p>They sometimes flag things that aren‚Äôt problems or suggest patterns that don‚Äôt match the codebase. The goal is to catch obvious problems early, not to treat every comment as a mandate.</p><p>Always do a final human pass before merging.</p><p>Tests are part of the flow, not a later chore.</p><p>After any change that isn‚Äôt small, I ask for tests immediately. I don‚Äôt wait until the feature is complete. Tests serve both as verification and as documentation. If the AI can‚Äôt write a sensible test for the code it just produced, that‚Äôs often a sign the code itself is unclear‚Ä¶</p><p>I request different tests depending on the situation.</p><p>For new functions, I ask for unit tests that cover the happy path and edge cases. When I used AI to build a React component in a stack I barely knew, my immediate follow-up was, ‚ÄúNow write unit tests for this component.‚Äù The tests showed me what the component was supposed to do and how it handled different inputs.</p><p>For bug fixes, I ask for a regression test that would have failed before the fix. This proves the fix works and helps prevent the bug from returning later. For changes that touch multiple components or an endpoint, I ask for one minimal integration or end-to-end test.</p><p>I paste a short feature description and ask for a realistic user flow and a few edge cases.</p><pre><code>Write unit tests for this function.\n\nCover the happy path and at least two edge cases.</code></pre><pre><code>Write a regression test for this bug.\n\nThe test should fail before the fix and pass after.</code></pre><p><strong>For integration or end-to-end tests:</strong></p><pre><code>Write a minimal integration test for this feature.\n\nInclude one realistic user flow and a few edge cases.</code></pre><p><strong>For reviewing existing tests:</strong></p><pre><code>Review these tests.\n\nAre there obvious edge cases missing or any weak assertions?</code></pre><p>When I first started using AI for code, I would generate a function and move on.</p><p>Tests came later, if at all. Bugs shipped. And I didn‚Äôt always understand what the code was doing. Now I ask for tests right after the code. Reading the test often teaches me more than reading the function. It shows the inputs, the expected outputs, and the edge cases the code is supposed to handle.</p><p>If the generated test doesn‚Äôt make sense, I treat that as a signal. Either the code is unclear, or my prompt was incomplete. Either way, I go back before moving forward.</p><h3><strong>Step 6: Debug and Iterate</strong></h3><p>When something breaks‚Ä¶ I don‚Äôt just paste an error and hope.</p><p>I give the model the same information I‚Äôd give a colleague: the error, the function, and enough context to reason through the problem.</p><p>A single error line is rarely enough. The model needs more than that to produce a useful diagnosis.</p><ul><li><p>Error message or stack trace.</p></li><li><p>Function where the error occurs.</p></li><li><p>Relevant surrounding code or types.</p></li><li><p>What I expected to happen and what actually happened.</p></li></ul><p>I avoid pasting only the error with no code, dumping an entire file without pointing to the relevant section, or just saying ‚Äúit doesn‚Äôt work‚Äù without describing the failure.</p><p><strong>The prompt I use for debugging </strong>(I usually ask for both the explanation and the fix in one request):</p><pre><code>Here is the function and the error message.\n\nExplain why this is happening.\n\nThen rewrite the function using best practices, while keeping it efficient and readable.</code></pre><p>Asking for both gives me a diagnosis and a fix in one shot. It also helps me learn what went wrong, not just how to patch it.</p><p>If a fix doesn‚Äôt work and I keep saying ‚Äútry again‚Äù in the same thread, the suggestions usually get worse. The model circles the same wrong idea with slightly different words.</p><blockquote><p>My rule: if I‚Äôve asked twice and the answers are getting repetitive or worse, I stop.</p><p>I start a fresh chat, restate the problem with better context, and narrow the question.</p></blockquote><p>For example, instead of ‚Äúfix this function,‚Äù I ask, ‚Äúunder what conditions could this variable be null here?‚Äù Fresh context plus a smaller question beats a tired thread most of the time.</p><p>Sometimes I realize I don‚Äôt understand the problem well enough to evaluate the fix. When that happens, I stop asking for code and start asking for an explanation:</p><pre><code>Do not fix anything yet.\n\nExplain what this function does, step by step.\n\nThen list the most likely failure cases.</code></pre><p>Once I understand the logic, I go back to asking for a targeted fix.</p><p>This avoids the loop of accepting fixes I don‚Äôt understand and hoping one of them works.</p><p>brings instant code reviews directly to your terminal, seamlessly integrating with Claude Code, Cursor CLI, and other AI coding agents. While they generate code, CodeRabbit ensures it‚Äôs production-ready - catching bugs, security issues, and AI hallucinations before they hit your codebase.</p><h2><strong>Common Failure Modes and Guardrails</strong></h2><p>After enough cycles, I started noticing the same failures repeating.</p><p>Here‚Äôs a short checklist I keep in mind:</p><h4><strong>Context drift in long chats</strong></h4><p>Long conversations cause the model to forget earlier decisions.</p><p>The fix: keep conversations short and scoped. One chat for design, one for part A, one for part B. When a thread feels messy, ask the model to summarize where you are, then start a fresh chat with that summary at the top.</p><p>Models are trained on data up to a certain point.</p><p>They sometimes write code for an older version of a library or generate methods that don‚Äôt exist. For anything new or fast-moving, I assume the suggestion might be wrong and verify against official docs. I also ask the model to state its assumptions: ‚ÄúWhich version are you assuming?‚Äù</p><p>If the answer doesn‚Äôt match my setup, I rewrite it myself.</p><h4><strong>Off-rails debugging loops</strong></h4><p>Once a model gets stuck on a bad idea, it tends to dig deeper. It proposes variations of the same broken fix, sometimes reintroducing bugs from earlier attempts.</p><p>AI rarely produces well-structured code by default.</p><p>It‚Äôs good at ‚Äúsomething that runs,‚Äù less good at ‚Äúsomething I‚Äôll want to maintain in three months.‚Äù</p><p>I fix this by baking quality into the request: ask for tests, ask for a summary of what changed and why, and nudge toward structure (‚Äúrefactor this into smaller functions,‚Äù ‚Äúfollow the pattern in file X‚Äù).</p><p>This one has nothing to do with the model and everything to do with me.</p><p>If I let AI handle every decision, my own instincts start to dull. I push back by keeping important decisions human-owned, occasionally doing small tasks without AI, and asking the model to teach as well as do: explain its reasoning, compare approaches, and talk through trade-offs.</p><p>The goal is not just ‚Äúship faster‚Äù but ‚Äúship faster and understand what I shipped.‚Äù</p><p>The workflow I use comes back to a simple loop:</p><pre><code><strong>Context ‚Üí Plan ‚Üí Code ‚Üí Review ‚Üí Test ‚Üí Iterate</strong></code></pre><p>I give the model enough context to see the real problem.</p><ul><li><p>I ask it to plan before writing code.</p></li><li><p>I generate and edit in small steps.</p></li><li><p>I review the output, often with AI-assisted tools.</p></li><li><p>I ask for tests right away.</p></li></ul><p>And when something breaks, I debug, refine, and repeat until it works.</p><p>Tools and models will change. Pricing will change. New products will appear. What survives is your method: how you give context, how you break work into steps, when to use a model, and when to rely on yourself.</p><p>If this newsletter did its job, you now have a clearer picture of what coding with AI looks like in practice.</p><p>Some days it‚Äôs a sprint‚Ä¶ Some days it‚Äôs a wrestling match. But it has changed how I work. I ship features I wouldn‚Äôt have attempted before, and I feel less stuck when learning a new stack or working through an unfamiliar codebase.</p><p>The goal is not just to ship faster, but to ship faster and understand what I shipped.</p><p>Anyway, if you want to catch bugs, security flaws, and performance issues asyou write code‚Ä¶ try <a href=\"https://coderabbit.link/neo-jan\">CodeRabbit</a>.</p><p>It brings real-time, AI code reviews straight into VS Code, Cursor, and Windsurf.</p><p>I launched  (newsletter series exclusive to PAID subscribers).</p><p>When you upgrade, you‚Äôll get:</p><ul><li><p><strong>High-level architecture of real-world systems.</strong></p></li><li><p>Deep dive into how popular real-world systems actually work.</p></li><li><p><strong>How real-world systems handle scale, reliability, and performance.</strong></p></li><li><p>10x the results you currently get with 1/10th of your time, energy, and effort.</p></li></ul><h4>üö® Guest Authors Wanted: System Design &amp; AI Engineering</h4><ul><li><p>You‚Äôll get exposure to 200,000+ tech audience.</p></li><li><p>Along with hands-on support throughout the review &amp; editing process.</p></li></ul><p>Reply to this email with links to your prior work and a brief note on topics you‚Äôd like to write about.</p><p><strong>Want to reach 200K+ tech professionals at scale? </strong>üì∞</p><p>Thank you for supporting this newsletter.</p><p>You are now 200,001+ readers strong, very close to 201k. Let‚Äôs try to get 201k readers by 5 February. Consider sharing this post with your friends and get rewards.</p>","contentLength":26039,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/82fd5b97-da72-4489-b2e1-d50add2292cf_1280x720.png","enclosureMime":"","commentsUrl":null},{"title":"What a Supermarket Checkout Line Can Teach You About Message Queues","url":"https://newsletter.systemdesign.one/p/what-is-a-message-queue","date":1769862662,"author":"Neo Kim","guid":32,"unread":true,"content":"<ul><li><p><em>Block diagrams created using <a href=\"https://app.eraser.io/auth/sign-up?ref=neo\">Eraser</a>.</em></p></li></ul><blockquote><p>Picture your last grocery trip: you filled your cart &amp; headed to checkout.</p></blockquote><p>Then the big moment arrived‚Äîyou had to choose a line‚Ä¶Maybe you compared the number of items in other carts. Or you might have observed how quickly each cashier worked. Either way, you were making queue choices.</p><p>These are the same choices found in software systems.</p><p>In today‚Äôs newsletter, I‚Äôll teach you how message queues work by comparing them to waiting in grocery store queues. The read time is roughly the time most people spend in line.</p><p>By the end, you‚Äôll understand:</p><ul><li><p>How queue behavior affects performance</p></li><li><p>How to apply these ideas to build better systems</p></li></ul><p> is the AI code review that surfaces real issues and meaningful feedback instead of flooding your PRs with stylistic nitpicks and low-value comments.</p><p>The checkout lines are simple:</p><p>Customers come with their carts and wait. Eventually, they form a line. The first person in the line gets served first. The last one needs to wait for everyone in front of them. This is called <a href=\"https://en.wikipedia.org/wiki/FIFO_(computing_and_electronics)\">FIFO</a> (First-In-First-Out) ordering.</p><p>It‚Äôs simple, fair, and predictable.</p><p>Software message queues work in the same way.</p><p>Requests arrive &amp; wait in order. Think of an app like Instagram. When many users upload photos simultaneously, the app can‚Äôt process them all at once. So each photo upload becomes a message that will be processed later.</p><blockquote><p>There‚Äôs a hidden insight here:<strong> queues exist to absorb bursts in demand.</strong></p></blockquote><p>Use a queue when you can‚Äôt handle every request right now but still need to handle them later.</p><p>Queue mechanics are simple‚Ä¶</p><ul><li><p>New messages get placed at the back of the queue - this is called .</p></li><li><p>Processed ones leave from the front of the queue - this is called .</p></li></ul><p>This pattern of filling and emptying the queue is what makes it fair and predictable. Just like the supermarket checkout line.</p><p>Use queues to absorb sudden traffic spikes and keep track of what to process later.</p><p>In a supermarket, cashiers are responsible for handling customers‚Ä¶</p><p>Each cashier scans items, processes payments, and completes transactions. They work alone but share the same goal: move customers through checkout.</p><p>In software systems, servers work the same way‚Ä¶</p><p>They pull messages from queues and process them in turn. A queue growing faster than it‚Äôs getting processed is a signal to scale servers.</p><p>You can scale in two ways:</p><ul><li><ul><li><p>This means , so the work gets spread across workers</p></li><li><p>It‚Äôs like adding a new cashier in a supermarket; customers notice a new line opened and spread out</p></li></ul></li><li><ul><li><p>This means <strong>making the existing servers more powerful</strong></p></li><li><p>It‚Äôs like training cashiers in a supermarket; trained cashiers scan the items or process payments faster and serve more customers faster</p></li></ul></li></ul><p>But there‚Äôs a catch: <em>servers must confirm they finished processing.</em></p><p>At the supermarket, this is like a cashier calling ‚ÄúNext!‚Äù when ready. This is called an acknowledgment in software systems. Without it, the system can‚Äôt tell if a message succeeded or failed, so it has to be redelivered.</p><p>Match your processing power to demand by scaling out or scaling up servers.</p><p>Longer lines mean longer waits‚Ä¶</p><p>Too many customers during rush hour makes waits much longer,,, and customers get frustrated. They might leave their carts or choose a different store next time.</p><p>Long queues also hurt performance in software systems:</p><p>Too many requests slow things down. Think of Twitter during big events when millions of tweets flood in. Servers can‚Äôt keep up, so users experience slow responses or errors. This is very bad for the business.</p><blockquote><p><em>So how do you make sure you see issues before they happen?</em></p><p>‚ÄúOne approach is to use throughput and latency metrics.‚Äù</p></blockquote><p>Throughput means how many customers get handled per hour. Latency means how long it takes to process one customer.</p><p><strong>A good system has high throughput &amp; low latency.</strong></p><p>Store managers watch checkout lines to decide whether to open more lines.</p><p>Likewise, the engineers monitor queue length, throughput, and latency to make scaling decisions. It‚Äôs required to understand acceptable limits and scale before the system crashes.</p><ul><li><p>: system can‚Äôt handle enough requests at once</p></li><li><p> there aren‚Äôt enough servers, or the work isn‚Äôt shared evenly</p></li><li><p> add more servers or spread the work</p></li></ul><ul><li><p> requests take too long to finish</p></li><li><p> when code is slow, databases are lagging, or the network is busy</p></li><li><p>make the code faster, use caching, or improve the slow parts</p></li></ul><p>If queues keep growing, it means demand exceeds capacity. Use throughput and latency metrics to identify what to improve.</p><p>Ready for the next technique?</p><p>Supermarket express lines exist to speed up checkout for customers with fewer items.</p><p>They provide a faster option for quick trips and help the store increase throughput.</p><p>This is similar to software using <a href=\"https://learn.microsoft.com/en-us/azure/architecture/patterns/priority-queue\">priority queues,</a> where important messages are moved to the front instead of waiting in line. A priority queue assigns each message a level of importance. The system always processes the highest-priority task first, even if others arrived earlier.</p><p>Priority queues help systems improve performance, but they have downsides:</p><ul><li><p>Lower-priority work can get stuck if urgent jobs never finish</p></li><li><p>Priority queues are hard to debug since there‚Äôs no FIFO ordering</p></li><li><p>Managing priorities adds complexity in implementation/maintenance</p></li></ul><p>It‚Äôs a classic <strong>tradeoff between simplicity &amp; responsiveness</strong>. It‚Äôs best to use priority queues only when speed really matters, and to keep most workflows predictable and fair.</p><p>Priority queues ensure time-sensitive messages aren‚Äôt delayed by less critical work.</p>","contentLength":5492,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/238c5926-10c8-491a-94e8-f35427d4a7c0_1280x720.png","enclosureMime":"","commentsUrl":null}],"tags":["dev"]}