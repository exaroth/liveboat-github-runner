{"id":"CSXkJZ3MdFx","title":"Dev News","displayTitle":"Dev News","url":"","feedLink":"","isQuery":true,"isEmpty":false,"isHidden":false,"itemCount":52,"items":[{"title":"Single Responsibility Principle (SRP) In React: Write Focused Components","url":"https://thetshaped.dev/p/single-responsibility-principle-srp-in-react-write-focused-components","date":1739120242,"author":"/u/pepincho","guid":443,"unread":true,"content":"<p><a href=\"https://thetshaped.dev/p/solid-principles-writing-robust-and\" rel=\"\">SOLID Principles</a></p><p><a href=\"https://thetshaped.dev/p/solid-principles-writing-robust-and\" rel=\"\">SOLID</a></p><p><a href=\"https://thetshaped.dev/p/solid-principles-writing-robust-and\" rel=\"\">SOLID</a></p><p>By definition, the principle states:</p><blockquote><p><strong>‚ÄùA class should only have one reason to change.‚Äù</strong></p></blockquote><p>In other words, a class, function, or module should have a single responsibility.</p><p>Let‚Äôs first see how things look like when we violate the SRP in React and write not so good enough components.</p><p>The problem with this component is that it:</p><ol><li><p>handles data fetching for the products</p></li><li><p>manages the loading and error states </p></li><li><p>handles the form for adding a new product</p></li><li><p>takes care of the display and layout of the products</p></li></ol><p><strong>ProductsDashboard Component</strong><strong>harder to understand, maintain, debug, test, and reuse</strong></p><p><em>Be the Senior who delivers the standard for writing robust React Components.</em></p><p><strong>separate focused components</strong></p><ul><li><p><strong>Separate data handling from User Interface</strong></p></li><li><p><strong>Write small and focused components</strong></p></li><li><p><strong>Prefer composing a set of smaller components</strong></p></li><li><p><strong>Organize your components in terms of layers</strong></p></li></ul><p>That's all for today. I hope this was helpful. ‚úåÔ∏è</p><div><h2>How I can help you further?</h2><p><em><strong>Become the Senior React Engineer at your company! üöÄ</strong></em></p></div><p>I share daily practical tips to level up your skills and become a better engineer.</p><p><em>Thank you for being a great supporter, reader, and for your help in growing to 18.3K+ subscribers this week üôè</em></p><p><em>You can also hit the like ‚ù§Ô∏è button at the bottom to help support me or share this with a friend. It helps me a lot! üôè</em></p>","contentLength":1318,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1ilj86o/single_responsibility_principle_srp_in_react/"},{"title":"Installing operators and CRs in automated way?","url":"https://www.reddit.com/r/kubernetes/comments/1ilitg3/installing_operators_and_crs_in_automated_way/","date":1739119213,"author":"/u/Such_Relative_9097","guid":421,"unread":true,"content":"<p>Hi, maybe I‚Äôm wrong but I see some technologies officially provide their k8s installation with operators and CRs (being installed after) instead of official helm chart. We all know the cons/pros using helm‚Ä¶ and the advantages of operators.. but how the operator installation will work in automation? I mean, seem to be the CR yaml must be deployed after the operator yaml to function properly. In my case I do not mind using operators but I need an automated way to deploy them.. Maybe I grasp the concept all wrong‚Ä¶ how you guys tackle this? Which tools? (Ansible for instance) ‚Ä¶ my case is very specific one because I must provide to the customer a bundle of charts (umbrella) .. so I can‚Äôt even use ansible and etc.. ok I can create helm chart that will deploy the operator and the CR but it feels weird and definitely I need your opinion and guidance about the matter. Thank you ..</p>","contentLength":895,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"From Engineer to Principal Solutions Architect at AWS with Prasad Rao","url":"https://newsletter.eng-leadership.com/p/from-engineer-to-principal-solutions","date":1739118558,"author":"/u/gregorojstersek","guid":442,"unread":true,"content":"<p>Finding skilled developers is hard ‚Üí even for seasoned engineering leaders. Traditional hiring cycles can take months while critical features sit in the backlog.</p><p>Need to scale your team quickly or find specialized talent that's hard to source locally? They match you with developers from Europe and Latin America who integrate seamlessly into your workflow ‚Üí without the long hiring cycles or commitment of long-term contracts.</p><p>They don't just check r√©sum√©s, but put developers through a rigorous multi-step vetting process that assesses technical skills, problem-solving abilities, and communication.</p><p>Let‚Äôs get back to this week‚Äôs thought!</p><p>When we talk about career paths, all of our journeys are unique. There is no one single best path that works for all of us. It‚Äôs important that you find out what path you wish to pursue and work towards it.</p><p><a href=\"https://www.linkedin.com/in/kprasadrao/\" rel=\"\">Prasad Rao</a></p><p>Prasad has chosen the Architecture path and I can see why very clearly. He grew as an engineer early on but later moved to the role of a Pre-sales Engineer, which helped him with speaking in both business and technical terms, creating presentations, understanding clients and managing multiple stakeholders.</p><p>That particular set of skills is often hard to get from engineering roles alone, but it plays a crucial part in an Architect positions.</p><p>Now, let‚Äôs get into his journey, Prasad, over to you!</p><p>When engineers think about career growth, they often focus on two traditional paths: either advancing as an Individual Contributor (climbing from Senior to Staff Engineer and beyond) or transitioning into Engineering Management. </p><p>However, there are other powerful career paths that are sometimes overlooked.</p><p>In this article, I am sharing my journey of transitioning from an engineer to a Solutions Architect at AWS, offering insights into this alternative career trajectory.</p><p>My career began as a .NET Developer, where I gradually progressed to become a Senior Developer and then a Tech Lead. The year I graduated, I interviewed for a couple of Big Tech companies but never got beyond the initial coding rounds. I thought I wasn't made for Big Tech and made peace with it. </p><p>After a few initial job switches, I settled into a consulting company and started climbing the ladder. Unlike many others who choose the management track, I wanted to grow as an Individual Contributor (IC). However, many companies do not have a clearly defined IC growth path. The natural progression is to become a manager. I was looking for alternative opportunities.</p><p>Even though I was working for a consulting company, I was in a unique position as I was working on building a product for a financial services company. When the product was ready, they needed someone in the field to demo it to potential clients. I took the role, and that opened a whole new world of possibilities for me.</p><p>That's when I was first introduced to pre-sales activities. Instead of being an engineer on the product team, I would be part of the field team as a pre-sales engineer.</p><blockquote><p>Pro Tip: Don‚Äôt shy away from exploring lateral roles when an opportunity arises. Career growth is never linear.</p></blockquote><p>Frankly, before I started, I didn't know if such a role existed. As with any new role, there were pros and cons of being a pre-sales engineer. The pros were that I would be working more closely with customers onsite and traveling the world. The cons were that I would work on activities sometimes frowned upon by engineers - stakeholder management, customer interactions, gathering requirements, creating sales presentations, etc.</p><p>Frankly, it was stepping out of my comfort zone, but it helped me develop skills that I never knew would be so important in my career growth. </p><p>After a couple of years in this role working with multiple customers, I understood the importance of understanding customers' requirements and working backward to achieve them.</p><p>Being an engineer, I had mostly focused on completing the tasks assigned to me. I never focused on understanding the real business reasons behind the tasks. Other skills I learned in this role:</p><ul><li><p>Speaking both business and technical languages</p></li><li><p>Creating stellar technical presentations and product demonstrations</p></li><li><p>Understanding prospective clients' business needs and designing customized solutions</p></li><li><p>Collaborating with multiple stakeholders like sales representatives, client executives, business analysts, and product teams</p></li></ul><blockquote><p>Pro Tip: Spend time with your business stakeholders to understand the WHY behind the tasks you do on a daily basis.</p></blockquote><p>After a few years in the role of Pre-sales engineer, I got an opportunity to consult as a Senior Engineer/Tech Lead for a financial services customer on a digital transformation project. With improved business acumen and communication skills, I quickly became the go-to person for the customer. It was a development project, but my focus shifted to understanding the bigger picture.</p><p>As developers, we design and architect components, so we're already doing architecture work without realizing it. A key to transitioning to an architect role is viewing these individual components and systems through a wider lens.</p><p>To grow as an architect, you need to learn system design, distributed systems, and integration patterns. You also need to develop the mindset of considering scalability, performance, security, cost, and other factors. But those are technical skills that are relatively easy to pick up. The important thing to develop as an architect is perspective - while developers often focus deeply on specific components, architects maintain a holistic view of the entire system. For that, understanding the business requirements is essential.</p><p><a href=\"https://www.youtube.com/watch?v=yflW4BG7Ves\" rel=\"\">Thinking Like an Architect</a></p><p>In architecture, there is nothing defined as right or wrong - it's always a trade-off. There is a reason architects start their answers with \"It depends.\" It depends on the requirements. It depends on what you would like to achieve. It depends on what constraints you're working with. </p><p>Every architectural decision involves balancing multiple factors: scalability versus simplicity, performance versus maintainability, time-to-market versus perfect technical design, or cost versus capability.</p><p>Lastly, to grow as an architect, it is also important to develop a broad understanding of multiple technologies. This enables you to make informed decisions about choosing the right tools for specific problems.</p><blockquote><p>Pro Tip: Shift your focus to look at the big picture and have a holistic view. Architects learn to navigate the ambiguity in requirements and constraints.</p></blockquote><p>With 10+ years in the industry, I had gained enough experience in different roles - developer, tech lead, pre-sales engineer, and architect. I was looking for a new job when one of my seniors suggested I try for AWS.</p><p>I was reluctant, thinking that I would have to go through coding exercises. I was pretty hands-on, but solving LeetCode was not my cup of tea. To my surprise, I learned that coding rounds happen only for SDE roles. So if you are a naive person like me thinking that jobs at Big Tech are out of reach because of coding rounds, then please explore other roles.</p><p>I browsed through multiple roles to find one that matched my profile - 'Solutions Architect, Microsoft Developer Tools on AWS'. The job role mentioned experience required with .NET and Microsoft workload stack. In the role, I had to help customers migrate and modernize their Microsoft workloads on AWS.</p><p>My decade-long career was all in Microsoft technologies, but I had zero experience with AWS. I was pretty candid about that in my call with the recruiter, and still my profile got shortlisted. The entire interview process (8 rounds) was completely based on my experience and my learning ability with new technologies. No coding round whatsoever. </p><p>I'm not saying the interviews were easy or that I did not have to prepare. It took a lot of hard work to prepare for the interviews, but the diverse experience I had gained helped me position myself as a good fit for a Solutions Architect role, which requires both technical and consulting skills.</p><blockquote><p>Pro Tip: Don't let coding interviews discourage you from applying at MAANG+ companies. Explore jobs other than SDE roles and you'll be surprised at how different the interview processes are.</p></blockquote><p>Having spent 5 years in the Solutions Architect (SA) role at AWS and being promoted to Principal SA has given me enough insights into what is required to become a successful SA. Ask any experienced SA about what their day-to-day role looks like, and they would answer, \"Every day is different.\" And that's true.</p><p>Let me give you a glimpse of the different hats an SA wears in their role. It will not only help you understand what a typical day of an SA looks like but also the skills you should be developing if you aspire to become an SA.</p><ul><li><p><strong>cross-functional collaborators</strong></p></li></ul><p>So, one day I might spend a full day in whiteboarding sessions with customers, understanding their requirements and coming up with solutions using different AWS services. </p><p>Another day might find me glued to my computer, creating a proof of concept to showcase the capabilities of AWS services. Then there might be days when I speak at conferences, evangelizing AWS services. Or I might spend a full day conducting workshops and training sessions to upskill customers on AWS.</p><blockquote><p>Pro Tip: As every customer is different and every customer problem is unique, so is each day of a Solutions Architect. And that's what I like about the SA role.</p></blockquote><p><a href=\"https://www.youtube.com/@be-sa\" rel=\"\"> BeSA (Become a Solutions Architect)</a><a href=\"https://www.youtube.com/@be-sa\" rel=\"\"> BeSA YouTube channel</a></p><ul><li><p>Technical Track: AWS GenAI immersive hands-on workshops</p></li><li><p>Behavioural Track: Cracking the Solutions Architect Interview at AWS</p></li></ul><p><a href=\"https://www.linkedin.com/in/kprasadrao/\" rel=\"\">LinkedIn</a></p><p>We are not over yet! 2 more things.</p><a href=\"https://www.writeedge.ai/\" rel=\"\">WriteEdge</a><p><a href=\"https://x.com/mahdi\" rel=\"\">Mahdi</a></p><p>If you are someone looking to have discussions with like-minded people ‚Üí More than 468 people are already there!</p><p>Liked this article? Make sure to üíô click the like button.</p><p>Feedback or addition? Make sure to üí¨ comment.</p><p>Know someone that would find this helpful? Make sure to üîÅ share this post.</p><ul><li><p><a href=\"https://maven.com/gregor-ojstersek/senior-engineer-to-lead?promoCode=ENGLEADERSHIP\" rel=\"\">here</a></p></li><li><p><a href=\"https://calico-cabinet-fbf.notion.site/Sponsor-Engineering-Leadership-fa0579535d6f4422a6da350580a54546\" rel=\"\">here</a></p></li><li><p><a href=\"https://store.eng-leadership.com/\" rel=\"\">here</a></p></li><li><p><a href=\"https://calico-cabinet-fbf.notion.site/Work-with-Gregor-Ojstersek-1147b66fdc24809b86b1fb0467b60318\" rel=\"\">here</a></p></li></ul><p>If you wish to make a request on particular topic you would like to read, you can send me an email to info@gregorojstersek.com.</p><p>This newsletter is funded by paid subscriptions from readers like yourself.</p><p>If you aren‚Äôt already, consider becoming a paid subscriber to receive the full experience!</p><p>You are more than welcome to find whatever interests you here and try it out in your particular case. Let me know how it went! Topics are normally about all things engineering related, leadership, management, developing scalable products, building teams etc.</p>","contentLength":10518,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1ilik3a/from_engineer_to_principal_solutions_architect_at/"},{"title":"SysV init 3.14 released","url":"https://github.com/slicer69/sysvinit/releases/tag/3.14","date":1739117474,"author":"/u/gabriel_3","guid":434,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/linux/comments/1ili4vn/sysv_init_314_released/"},{"title":"DOKS vs GKE","url":"https://www.reddit.com/r/kubernetes/comments/1ilhsz1/doks_vs_gke/","date":1739116613,"author":"/u/Impossible-Night4276","guid":423,"unread":true,"content":"<p>I used GKE at my job but I'm starting a personal project now so I'm shopping around for a managed cluster</p><p>I can get a basic cluster on DOKS for $12/month while GKE charges about $100/month?</p><p>I understand the sentiment \"DigitalOcean is for hobbyists\" and \"GCP is for enterprises\" but why is that? What does GKE provide that DOKS doesn't?</p>","contentLength":333,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"What do you use for deployments?","url":"https://www.reddit.com/r/golang/comments/1ilh1a5/what_do_you_use_for_deployments/","date":1739114569,"author":"/u/stas_spiridonov","guid":332,"unread":true,"content":"<p>I have been working in companies with in-house built systems for builds and deployments, where all pf that stuff is maintained by separate infra teams. So I am honestly out of the loop of what normal people use to deploy their apps.</p><p>I am deploying to a bunch of hosts/VMs. I have several services, all in Go, so it is mostly a single binary file, sometimes a binary and a text config or a folder with js/css/images. I don‚Äôt have a problem of managing dependencies. My apps are stateful, they store data locally in files. Some apps Re web or grpc apps, some are async workers. I have a simple capistrano-like script which copies new artifacts to each host over ssh, updates a symlink and restarts the service. It works. But I am curious what tools do you use for that without reinventing a wheel?</p><p>I am trying to avoid any new dependency unless it is absolutely necessary. So if you mention a system, please also write what exactly problem you were trying to solve with it.</p>","contentLength":971,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Brainfly: A high-performance Brainf**k JIT and AOT compiler built on top of C# type system","url":"https://github.com/hez2010/Brainfly/blob/main/Intro.md","date":1739108814,"author":"/u/hez2010","guid":445,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1ilf1hy/brainfly_a_highperformance_brainfk_jit_and_aot/"},{"title":"Don't \"optimize\" conditional moves in shaders with mix()+step()","url":"https://iquilezles.org/articles/gpuconditionals/","date":1739104974,"author":"romes","guid":192,"unread":true,"content":"<div>\nIn this article I want to correct a popular misconception that's been making the rounds in computer graphics aficionado circles for a long time now. It has to do with branching in the GPUs. Unfortunately there are a couple of educational websites out there that are spreading some misinformation and it would be nice correcting that. I tried contacting the authors without success, so without further ado, here goes my attempt to fix things up:\nSo, say I have this code, which I actually published the other day:<div> snap45(  v )\n{\n     s = (v);\n     x = (v.x);\n     x&gt;?(s.x,):\n           x&gt;?s*():\n                      (,s.y);\n}</div>\nThe exact details of what it does don't matter for this discussion. All we care about is the two ternary operations, which as you know, implement conditional execution. Indeed, depending on the value of the variable , the function will return different results. This could be implemented also with regular  statements, and all that I'm going to say stays the same.<p>\nBut here's the problem - when seeing code like this, somebody somewhere will invariably propose the following \"optimization\", which replaces what they believe (erroneously) are \"conditional branches\" by arithmetical operations. They will suggest something like this:</p><div> snap45(  v )\n{\n     s = (v);\n     x = (v.x);\n\n     w0 = (,x);\n     w1 = (,x)*(-w0);\n     w2 = -w0-w1;\n\n     res0 = (s.x,);\n     res1 = (s.x,s.y)*();\n     res2 = (,s.y);\n\n     w0*res0 + w1*res1 + w2*res2;\n}</div>\nThere are two things wrong with this practice. The first one shows an incorrect understanding of how the GPU works. In particular, the original shader code had no conditional branching in it. Selecting between a few registers with a ternary operator or with a plain  statement does not lead to conditional branching; all it involves is a conditional move (a.k.a. \"select\"), which is a simple instruction to route the correct bits to the destination register. You can think of it as a bitwise AND+NAND+OR on the source registers, which is a simple combinational circuit. Again, there is no branching - the instruction pointer isn't manipulated, there's no branch prediction involved, no instruction cache to invalidation, no nothing.<p>\nFor the record, of course real branches do happen in GPU code, but those are not what's used by the GPU for small moves between registers like we have here. This is true for any GPU made in the last 20+ years. While I'm not an expert in CPUs, I am pretty sure this is true for them as well.</p><p>\nThe second wrong thing with the supposedly optimizer version is that it actually runs much slower than the original version. The reason is that the </p> function is actually implemented like this:<div> step(  x,  y )\n{\n     x &lt; y ?  : ;\n}</div>\nSo people using the step() \"optimization\" are using the ternary operation anyways, which produces the  or  which they will use to select the output, only wasting two multiplications and one or two additions. The values could have been conditionally moved directly, which is what the original shader code did.<p>\nBut don't take my word for it, let's look at the generated machine code for the relevant part of the shader I published:</p><div><div>\nGLSL<div> x&gt;?(s.x,):\n       x&gt;?s*():\n                  (,s.y);</div></div><div>\nAMD Compiler<div>     s0,      v3, , v1\n     v4, , v0\n     s1,   vcc, (v2), s0\n v3, 0, v3, vcc\n v0, v0, v4, vcc\n vcc, (v2), s1\n v1, v1, v3, vcc\n v0, 0, v0, vcc</div></div><div>\nMicrosoft Compiler<div>   r0.xy, l(, ), v0.xy\n   r0.zw, v0.xy, l(, )\n r0.xy, -r0.xyxx, r0.zwzz\n r0.xy, r0.xyxx\n  r1.xyzw, r0.xyxy, l4()\n   r2.xy, l(,), v0.xx  r0.z, l()\n r1.xyzw, r2.yyyy, r1.xyzw, r0.zyzy\n o0.xyzw, r2.xxxx, r0.xzxz, r1.xyzw</div></div></div>\nHere we can see that the GPU is not branching. Instead, according to the AMD compiler, it's performing the required comparisons ( and  - cmp=compare, gt=greater than, ngt=not greated than), and then using the result to mask the results with the bitwise operations mentioned earlier ( - cnd=conditional).<p>\nThe Microsoft compiler has expressed the same idea/implementation in a different format, but you can still see the comparison (</p> - \"lt\"=less than) and the masking or conditional move ( - mov=move, c=conditionally).<p>\nNot related to the discussion, but also note that the </p> call does not become a GPU instruction and instead becomes an instruction modifier, which is free.\nSo, if you ever see somebody proposing this<div> a = ( b, c, ( y, x ) );</div>\nas an optimization to\nthen please correct them for me. The misinformation has been around for 20 years / 10 GPU generation, and that's more than too long.</div>","contentLength":4492,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42990324"},{"title":"AI Code Generators Are Creating a Generation of ‚ÄúCopy-Paste Coders‚Äù ‚Äî Here‚Äôs How We Fix It","url":"https://medium.com/mr-plan-publication/ai-code-generators-are-creating-a-generation-of-copy-paste-coders-heres-how-we-fix-it-d49a3aef8dc2?sk=4f546231cd24ca0e23389a337724d45c","date":1739104183,"author":"/u/TerryC_IndieGameDev","guid":447,"unread":true,"content":"<p>You‚Äôre mentoring a junior developer. They‚Äôre breezing through tasks, their screen a blur of AI-generated code snippets. They meet every deadline, their GitHub commits glowing green. But then you ask them to explain  their code works. Silence. They fumble through jargon, their confidence crumbling like a house of cards.</p><p>This isn‚Äôt a hypothetical scenario. It‚Äôs happening in startups, corporate IT departments, and bootcamps worldwide. AI-powered tools like GitHub Copilot are reshaping coding ‚Äî but beneath the hype lies a crisis we‚Äôre too afraid to name: <strong>We‚Äôre raising a generation of developers who can‚Äôt think for themselves.</strong></p><p>Let‚Äôs be clear: AI code completion isn‚Äôt evil. For seasoned developers, it‚Äôs like having a tireless intern handle boilerplate code. But for juniors? It‚Äôs become the programming equivalent of GPS addiction.</p><p>I recently reviewed code from a junior who‚Äôd ‚Äúsolved‚Äù a complex sorting problem using Copilot. When I‚Ä¶</p>","contentLength":967,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1ildoun/ai_code_generators_are_creating_a_generation_of/"},{"title":"C++ on Steroids: Bjarne Stroustrup Presents Guideline-Enforcing 'Profiles' For Resource and Type Safety","url":"https://developers.slashdot.org/story/25/02/09/0636247/c-on-steroids-bjarne-stroustrup-presents-guideline-enforcing-profiles-for-resource-and-type-safety?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739102640,"author":"EditorDavid","guid":255,"unread":true,"content":"\"It is now 45+ years since C++ was first conceived,\" writes 74-year-old C++ creator Bjarne Stroustrup in an article this week for Communications of the ACM. But he complains that many developers \"use C++ as if it was still the previous millennium,\" in an article titled 21st Century C++ that promises \"the key concepts on which performant, type safe, and flexible C++ software can be built: resource management, life-time management, error-handling, modularity, and generic programming... \n\n\"At the end, I present ways to ensure that code is contemporary, rather than relying on outdated, unsafe, and hard-to-maintain techniques: guidelines and profiles.\"\n\nTo help developers focus on effective use of contemporary C++ and avoid outdated \"dark corners\" of the language, sets of guidelines have been developed. Here I focus on the C++ Core guidelines that I consider the most ambitious... My principal aim is a type-safe and resource-safe use of ISO standard C++. That is: \n\n- Every object is exclusively used according to its definition\n- No resource is leaked \nThis encompasses what people refer to as memory safety and much more. It is not a new goal for C++. Obviously, it cannot be achieved for every use of C++, but by now we have years of experience showing that it can be done for modern code, though so far enforcement has been incomplete... When thinking about C++, it is important to remember that C++ is not just a language but part of an ecosystem consisting of implementations, libraries, tools, teaching, and more. \nWG21 (and others) are working on \"profiles\" to enforce guidelines (though they're \"not yet available, except for experimental and partial versions\"). But Stroustrup writes that the C++ Core Guidelines \"use a strategy known as subset-of-superset.\"\n\n First: extend the language with a few library abstractions: use parts of the standard library and add a tiny library to make use of the guidelines convenient and efficient (the Guidelines Support Library, GSL).\n Next: subset: ban the use of low-level, inefficient, and error-prone features. \nWhat we get is \"C++ on steroids\": Something simple, safe, flexible, and fast; rather than an impoverished subset or something relying on massive run-time checking. Nor do we create a language with novel and/or incompatible features. The result is 100% ISO standard C++. Messy, dangerous, low-level features can still be enabled and used when needed. \nStroustrup writes that the C++ Core Guidelines focus on rules \"we hope that everyone eventually could benefit from.\"\n\nNo uninitialized variables\nNo range or nullptr violations\nNo resource leaks\nNo dangling pointers\nNo type violations\nNo invalidation\n\n\nBjarne Stroustrup answered questions from Slashdot readers in 2014...\n","contentLength":2744,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"This package helped us cut cloud costs in half while greatly improving our services response times","url":"https://github.com/viccon/sturdyc","date":1739102139,"author":"/u/Mysterious-Ad516","guid":335,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1ild5o1/this_package_helped_us_cut_cloud_costs_in_half/"},{"title":"Kubeconfig Operator: Create restricted kubeconfigs as custom resources","url":"https://www.reddit.com/r/kubernetes/comments/1ild0hg/kubeconfig_operator_create_restricted_kubeconfigs/","date":1739101547,"author":"/u/ASBroadcast","guid":420,"unread":true,"content":"<p>There recently was a post by the Reddit engineer <a href=\"https://www.reddit.com/u/keepingdatareal\">u/keepingdatareal</a> about their new SDK to build operators: <a href=\"https://www.reddit.com/r/RedditEng/comments/1gp11ui/open_source_of_achilles_sdk/\">Achilles SDK</a>. It allows you to specify Kubernetes operators as finite state machines. Pretty neat!</p><p>I used it to build a <a href=\"https://github.com/klaudworks/kubeconfig-operator\">Kubeconfig Operator.</a> It is useful for anybody who quickly wants to hand out limited access to a cluster without having OIDC in place. I also like to create a \"daily-ops\" kubeconfig to protect myself from accidental destructive operations. It usually has readonly permissions + deleting pods + creating/deleting portforwards.</p><p>Unfortunately, I can just add a single image but check out the repo's <a href=\"https://github.com/klaudworks/kubeconfig-operator\">README.md</a> to see a graphic of the operator's behavior specified as a FSM. Here is a sample Kubeconfig manifest:</p><pre><code> apiVersion: kind: Kubeconfig metadata: name: restricted-access spec: clusterName: local-kind-cluster # specify external endpoint to your kubernetes API. # You can copy this from your other kubeconfig. server: https://127.0.0.1:52856 expirationTTL: 365d clusterPermissions: rules: - apiGroups: - \"\" resources: - namespaces verbs: - get - list - watch namespacedPermissions: - namespace: default rules: - apiGroups: - \"\" resources: - configmaps verbs: - '*' - namespace: kube-system rules: - apiGroups: - \"\" resources: - configmaps verbs: - get - list - watchklaud.works/v1alpha1 </code></pre><p>If you like the operator I'd be happy about a Github star ‚≠êÔ∏è. The core logic is already fully covered by tests. So feel free to use it in production. Should any issue arise, just open a Github issue or text me here and I'll fix it.</p>","contentLength":1545,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Classic Data science pipelines built with LLMs","url":"https://github.com/Pravko-Solutions/FlashLearn/tree/main/examples","date":1739101178,"author":"galgia","guid":191,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42990036"},{"title":"Watchexec v2.3.0 ¬∑ with systemfd integration: `--socket`","url":"https://github.com/watchexec/watchexec/releases/tag/v2.3.0","date":1739100565,"author":"/u/passcod","guid":463,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/rust/comments/1ilcrw2/watchexec_v230_with_systemfd_integration_socket/"},{"title":"Testing errors","url":"https://bitfieldconsulting.com/posts/testing-errors","date":1739094784,"author":"/u/EightLines_03","guid":330,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1ilbffy/testing_errors/"},{"title":"RetroFab: Playable 3D simulations of vintage electronic games","url":"https://itizso.itch.io/retrofab","date":1739094635,"author":"todsacerdoti","guid":190,"unread":true,"content":"<div><div>( April 1980 - October 1980 )</div><div>In 1980 Nintendo released it's first series of handheld electronic games each featuring a dedicated LCD game with a bonus watch function. The silver metallic front plate gave the series it's name. </div></div><div><div>( January 1981 - April 1981 )</div><div>After the huge success of the Silver Series Nintendo released the next generation of it's Game &amp; Watch‚Ñ¢ handhelds the following year, featuring a new alarm function, color background-foils and a distinctive gold metallic front plate.  </div></div><div><div>( June 1981 - April 1982 )</div><div>Featuring a wide LCD screen and impressive line-up of timeless classics (including some of the first licenced titles) Nintendo's Wide Screen Series ranks among some of the most popular Game &amp; Watch‚Ñ¢ titles.  </div></div><div><div>( May 1982 - August 1989 )</div><div>In 1982 Nintendo introduced the innovative Multi Screen series whose most prominent feature was the use of two LCD screens in one foldable handheld with beautiful background-foil artwork and fine LCD elements.</div></div><div><div>( October 1982 - October 1991 )</div><div>Nintendo made further subtle improvements to the earlier Wide Screen series with a new box design featuring vivid artwork and a more colorful metallic front plate making the single screen LCD handhelds even classier.</div></div><div><div>( April 1983 - August 1983 )</div><div>Nintendo fulfilled the dream of many gamers to have their own mini arcade machine with the introduction of the Table Top Series which featured full color LCD graphics for the first time.</div></div><div><div>( August 1983 - September 1984 )</div><div>A few months after the introduction of the Table Top Series, Nintendo released a refinement of that technology in the form of the more portable Panorama Screen Series\\.</div></div><div><div>( July 1984 - November 1984 )</div><div>The Micro Vs. System introduced two-player gaming to the Game &amp; Watch‚Ñ¢ series by attaching two wired controllers to a foldable unit that featured a wide LCD screen.</div></div><div><div>( June 1986 - November 1986 )</div><div>The Crystal Screen series introduced a new wide format translucent LCD handheld featuring a transparent see-thru screen and innovative side-scrolling gameplay.</div></div><div><div>Featuring a colored LCD screen that no longer required an external light source (required by the Table Top and Panorama Screen series) and a new large portrait format LCD screen, the Super Color Series was perfectly suited for the two games released in this format.</div></div><div><div>Nintendo released a limited edition of it's Super Mario Bros handheld LCD game as a prize for winners of a competition it held in 1987. Only 10,000 copies were given away, making it the most rare of the 3 Game &amp; Watch versions of the game.</div></div>","contentLength":2511,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42989628"},{"title":"Minikube versus Kind: GPU Support","url":"https://www.reddit.com/r/kubernetes/comments/1ilb8v2/minikube_versus_kind_gpu_support/","date":1739093973,"author":"/u/MaximumNo4105","guid":422,"unread":true,"content":"<p>I come from a machine learning background with some, little, DevOps experience. I am trying to deploy a local Kubernetes cluster with NVIDIA GPU support.</p><p>I have so far been using Kind to do so, deploying three services and exposing them via an ingress controller locally, but I stumbled upon what seems to be an ongoing issue with providing GPU support to the containers when using kind. I have already set the container runtime to use NVIDIA's runtime. I have followed guides on installing NVIDIA plugin into the cluster, mounting the correct GPU devices paths, providing tolerations as to where a deployment which requires GPU access can be deployed to, I have tried everything, but still I am unable to access the GPUs from</p><p>Is this a known issue within the DevOps community?</p><p>If so, would switching to minikube make gaining access to the GPUs any easier? Has anyone got any experience deploying a minikube cluster locally and successfully gaining access to the GPUs?</p><p>I appreciate your help and time to read this.</p><p>Any help whatsoever is welcomed.</p>","contentLength":1042,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Clippy appreciation post","url":"https://www.reddit.com/r/rust/comments/1ilav8q/clippy_appreciation_post/","date":1739092310,"author":"/u/pnuts93","guid":467,"unread":true,"content":"<p>As a Rust amateur I just wanted to share my positive experience with Clippy. I am generally fond of code lints, but especially in a complex language with a lot of built-in functionalities as Rust, I found Clippy to be very helpful in writing clean and idiomatic code and I would highly recommend it to other beginners. Also, extra points for the naming</p>","contentLength":352,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Mathematics in the 20th century, by Michael Atiyah [pdf] (2002)","url":"https://marktomforde.com/academic/miscellaneous/images/atiyah20thcentury.pdf","date":1739091277,"author":"practal","guid":189,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42989419"},{"title":"IO_uring Zero-Copy Receive Support Ready For Linux 6.15 Networking","url":"https://www.phoronix.com/news/IO_uring-Zero-Copy-Receive-Net","date":1739089999,"author":"/u/unixbhaskar","guid":435,"unread":true,"content":"<p>Michael Larabel is the principal author of Phoronix.com and founded the site in 2004 with a focus on enriching the Linux hardware experience. Michael has written more than 20,000 articles covering the state of Linux hardware support, Linux performance, graphics drivers, and other topics. Michael is also the lead developer of the Phoronix Test Suite, Phoromatic, and OpenBenchmarking.org automated benchmarking software. He can be followed via <a href=\"https://twitter.com/MichaelLarabel\">Twitter</a>, <a href=\"https://www.linkedin.com/in/michaellarabel/\">LinkedIn</a>, or contacted via <a href=\"https://www.michaellarabel.com/\">MichaelLarabel.com</a>.</p>","contentLength":500,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/linux/comments/1ilacgo/io_uring_zerocopy_receive_support_ready_for_linux/"},{"title":"Modern-Day Oracles or Bullshit Machines","url":"https://thebullshitmachines.com/","date":1739089457,"author":"ctbergstrom","guid":188,"unread":true,"content":"<p>In a series of five- to ten-minute lessons, we will explain what these machines are, how they work, and how to thrive in a world where they are everywhere.</p><p>You will learn when these systems can save you a lot of time and effort. You will learn when they are likely to steer you wrong. And you will discover how to see through the hype to tell the difference. </p>","contentLength":358,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42989320"},{"title":"Have we ever considered allowing orphans in bin crates?","url":"https://www.reddit.com/r/rust/comments/1il9vnl/have_we_ever_considered_allowing_orphans_in_bin/","date":1739087992,"author":"/u/MengerianMango","guid":465,"unread":true,"content":"<p>The main reason for not allowing them is that a dep anywhere in your tree could add a trait and break everything, to put it simply. That's a good reason to disallow them in libs, but for bin crates that's not really a concern, and arguably the risk is something we should leave up to the application developer, the end user.</p><p>I'd also consider going a step further, since there will be commonly popular orphans. Perhaps they should also be allowed in first order dependencies of bin crates, to prevent people from vendoring/copy-pasting common orphans. The same logic of allowing user discretion applies to first order dependencies to a bin crate. It would be sorta weird to create a sort of bifurcation in the lib crates, but not really a huge issue since most don't need orphans anw.</p><p>This is an existing concept, allowing/semi-encouraging dirtiness and laziness in bin/app crates for the sake of productivity. Like how anyhow is bad in libs but ok if you're writing an app.</p>","contentLength":972,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"I think linux is actually easier to use than windows now","url":"https://www.reddit.com/r/linux/comments/1il9tes/i_think_linux_is_actually_easier_to_use_than/","date":1739087709,"author":"/u/petitlita","guid":438,"unread":true,"content":"<p>I had to reinstall windows on the one PC that I was (previously) running windows on, basically just for debugging windows programs and the 2 games that don't play well with linux. One is a ported browser game that still works in browser and the other is kinitopet where windows being required is kinda understandable. Found a disk for windows that came with a laptop and put it in, oops, I don't have TPM 2. Tried downloading windows 10. Mysterious driver issues that it refused to elaborate on, apparently I needed to find these drivers and put them on a USB without it giving me any information on what I was looking for. I got sick of dealing with it at this point since it really gave no information and I just wanted to play witcher, though I know if I had worked out the driver issues I would still need to work through getting a local account, debloating the OS, modifying the registry, etc, just to get it to run in a way any reasonable person would expect a normal computer to behave.</p><p>So I decide to just put endeavour OS on it instead (I have a recent nvidia GPU and I am lazy) and like, yeah it works well basically immediately, but what surprised me was how well it played with... everything. On windows, I spent 2 hours just fixing weird audio bugs with the steelseries wireless headset I have but it just works and connects immediately after I turn it on now. I didn't need to use their bloatware to turn off sidetone. The controller I use would require a bit of fiddling to connect when I turned it on on windows but on linux I just pick it up and it works. I install my games and they all (minux the aforementioned two) just work perfectly immediately. I don't get random video stuttering that I had on windows. WHEN did the linux experience become so seamless?</p><p>Edit: In case anyone is curious, in witcher I am getting 60fps (cap) when previously I was getting like 45 lol</p>","contentLength":1886,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Fluxcd useful features","url":"https://www.reddit.com/r/kubernetes/comments/1il9d9q/fluxcd_useful_features/","date":1739085759,"author":"/u/Upper-Aardvark-6684","guid":424,"unread":true,"content":"<p>I have been using fluxcd as gitops tool since 6 months at my job. The most useful features I found was the dependson and wait parameters that help me better manage dependencies. I want to know if there are more such features that I might have missed or not used and have been useful to you. Let me know how flux has helped you in your k8s deployments.</p>","contentLength":351,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Ohkami web framework v0.22 is out; runs on native, Cloudflare Workers, and AWS Lambda!","url":"https://github.com/ohkami-rs/ohkami","date":1739075879,"author":"/u/kanarus","guid":464,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/rust/comments/1il6sub/ohkami_web_framework_v022_is_out_runs_on_native/"},{"title":"How do I convince someone that Linux is, in fact, a \"normal operating system?\"","url":"https://www.reddit.com/r/linux/comments/1il6p1k/how_do_i_convince_someone_that_linux_is_in_fact_a/","date":1739075511,"author":"/u/FutureSuccess2796","guid":437,"unread":true,"content":"<p>EDIT: Want to clarify that the people who were telling me this were my parents and not a friend or just someone random. Just making note because I was vague about it prior. My bad!</p><p>I'll try to make this as quick as I possibly can: I finally decide to dive into the world of Linux and I LOVE it! Been using that more than Windows now on my laptop and I've also been experimenting with the terminal and installing some different applications to try out too. Now I'm extremely passionate about technology and learning new things, and I'm also someone who can get hyperfixated on a topic. And this time it was about the cool things I was working on using Ubuntu, which included installing and adding different applications' dependencies as well as trying out some other things to make my experience more decentralized. Well, that backfired because I was went off on and told that I need to just go back to \"a normal device and stop playing around with that USB all the time.\"</p><p>I tried to explain that Ubuntu is a normal operating system but was just a little different than Windows or Apple and that I installed it myself on my own USB. But that did nothing. And discussing decentralization made them start presuming that I was \"up to no good and that I would get into trouble with that command stuff,\" which is referencing the terminal and what it looks like when I install packages. Like, really, people? I get that not everybody's versed in computers, but you're literally assuming that something I'm passionate about must be troublesome because you're not familiar with it. </p><p>Any way to explain that I'm just being tech-savvy and using a regular operating system that just happens to look a little different? </p>","contentLength":1704,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Brain Hyperconnectivity in Children with Autism and Its Links to Social Deficits (2013)","url":"https://www.cell.com/cell-reports/fulltext/S2211-1247(13)00570-6","date":1739073244,"author":"stmw","guid":187,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42988303"},{"title":"Carbon is not a programming language (sort of)","url":"https://herecomesthemoon.net/2025/02/carbon-is-not-a-language/","date":1739061537,"author":"/u/cramert","guid":468,"unread":true,"content":"<p>\n              In case you‚Äôve not heard of it,  is Google‚Äôs experimental\n              <a href=\"https://github.com/carbon-language/carbon-lang\" target=\"_blank\">open-source</a> ‚ÄúC++-successor\n              language‚Äù. As a very rough first approximation, think Objective-C/Swift, Java/Kotlin, C/C++, C++/Carbon.\n              It is also frequently mentioned in the same breath as Herb Sutter‚Äôs Cppfront and Sean Baxter‚Äôs Circle (and\n              Rust, surprise surprise).\n            </p><p>\n              Like with any ‚Äòsuccessor language‚Äô, the overall goal includes (at the bare minimum) near-seamless\n              interoperability, as well as  improvements over the original language.\n              (Otherwise it can hardly be called a successor, duh.)\n            </p><p>\n              If you‚Äôve clicked on the article, you‚Äôre probably waiting for me to admit that I‚Äôm lying, and to tell you\n              that (in fact) Carbon  a programming language.\n            </p><p>\n              And yes, it‚Äôs true! Carbon is a programming language. (Or rather, it‚Äôs  to be a\n              programming language. Carbon is an experimental project and hasn‚Äôt hit its 0.1 release milestone yet. The\n              Carbon developers are very transparent about this.)\n            </p><p>\n              But in my humble opinion, thinking of Carbon as a ‚Äòprogramming language‚Äô is kind of missing the point. Let\n              me tell you how I think about Carbon, and why I think that it‚Äôs more interesting than most people give it\n              credit for:\n            </p><blockquote><p>\n                Carbon is a concentrated experimental effort to develop tooling that will facilitate automated\n                large-scale long-term migrations of existing C++ code to a modern, well-annotated programming language\n                with a modern, transparent process of evolution and governance model.\n              </p></blockquote><p>\n              The entirety of Carbon (the language, as well as the project) is built around making this goal possible.\n              (Disclaimer, I don‚Äôt speak for Carbon, take my words with a grain of salt.)\n            </p><p>In this post, I want to convince you of the following points:</p><ol><li>\n                Carbon is a project to investigate the possibility of a large-scale reduction of C++ technical debt via\n                automated code migration.</li><li>\n                Many so-called ‚Äòsuccessor languages‚Äô are . They don‚Äôt make\n                 an explicit goal, and generally build a layer of abstraction on top of\n                or rely on their host language.\n              </li><li>\n                All of this is downstream of Google‚Äôs disagreements with the C++ Standard Committee. In fact, while all\n                of this is about reducing technical debt, it‚Äôs also about reducing the organizational costs involved in\n                having to coordinate migrations and language evolution with the committee.\n              </li><li>Developing a new programming language is probably necessary to achieve the goals of the project.</li></ol><p>\n              I‚Äôd like to bring special attention to the point about governance: This isn‚Äôt just a technical issue. It‚Äôs\n              a governance issue. It‚Äôs a ‚ÄúWe just straight-up disagree on the future direction of the C++ programming\n              language.‚Äù sort of issue. I already went over these cultural disagreements in\n              <a href=\"https://herecomesthemoon.net/2024/11/two-factions-of-cpp/\" target=\"_blank\">a previous post</a>.\n            </p><p>\n              (The astute reader will note that you can evolve and govern your own programming language however you\n              want, without needing to deal with WG21 (aka the C++ Standard Committee, aka the authority that decides\n              what C++ .))\n            </p><p>\n              At this point I‚Äôd  to reach for the Herb Sutter ‚ÄúWe must minimize the need to change existing\n              code.‚Äù quote again,\n              but I‚Äôll instead just state the obvious:\n            </p><p>\n              A large-scale migration to a different programming language is  paradigm. As far as\n              changes to existing code go, it‚Äôs uncompromising. It‚Äôs an approach that‚Äôs only going to work for a subset\n              of people, and in fact,\n              <a href=\"https://github.com/carbon-language/carbon-lang/blob/trunk/docs/project/goals.md#legacy-compiled-libraries-without-source-code-or-ability-to-rebuild\" target=\"_blank\">Carbon‚Äôs goal document</a>\n              lists ‚ÄúWe consider it a non-goal to support legacy code for which the source code is no longer available‚Äù.\n            </p><p>\n              In other words, the language is not for everyone. That‚Äôs fine! I am still very interested in it. I care\n              about Carbon since I believe that it‚Äôs trying to solve the hardest problem C++ is currently facing.\n            </p><p>\n              This isn‚Äôt any  technical issue (there are many, many of those), no, and it‚Äôs not even a\n              broad concern such as memory safety.\n            </p><p>\n              It‚Äôs the problem of C++ slowly calcifying and struggling to modernize. It‚Äôs about ABI, about dozens of\n              tools but no agreed upon standards, and it‚Äôs about backwards compatibility. It‚Äôs about allowing existing\n              C++ code to , modernize and change, in spite of decades of technical debt, multiple\n              implementations, and many different users with different expectations and requirements.\n            </p><p>This is, in other words, an , and a .</p><p>\n              If you believe that certain multi-million line C++ codebases are still going to exist in twenty years,\n              <em>then you should understand the business case for Carbon</em>.\n            </p><h3>A short lesson in history</h3><p>\n              Let‚Äôs briefly summarize the backstory for those who haven‚Äôt kept track. You could (very roughly) say that\n              Google is developing Carbon due to conflicts with WG21, and disagreements about the future of the C++\n              language.\n            </p><p>\n              What matters is that Google contributed to WG21 for many years, and that it has a vested interest in the\n              future of the language, due to owning many,  million lines of C++ code. It‚Äôs hard to\n              overstate how critical C++ is for Google‚Äôs infrastructure, and for modern technology in general.\n            </p><p>\n              The short summary is that Google‚Äôs developers (not just Google‚Äôs, mind you) disagreed with other parts of\n              the committee about the\n              <a href=\"https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2020/p2137r0.html\" target=\"_blank\">future direction of the C++ language</a>. There are a lot of reasons for this, and\n              <a href=\"https://cor3ntin.github.io/posts/abi/\" target=\"_blank\">a lot of ink</a> has been spilled on the\n              topic. Eventually, after trying to work with WG21 for many years, Google basically threw in the towel.\n              (You cannot blame them. They tried hard, and the WG21 process is notoriously slow and frustrating.)\n            </p><p>\n              At this point, a lot of people might think that the core disagreement between Google and WG21 was about\n              ‚Äòmemory safety‚Äô, or something like that.\n            </p><p>\n              The current memory safety hype is a pretty big deal for C++, but the ball was already rolling several\n              years ago. All of this started with concerns about C++‚Äôs complexity\n              and .\n              It turns out that fixing certain issues would require backwards incompatible changes (bad!). Coordinating\n              this across the entire C++ ecosystem would be more or less impossible.\n            </p><p>\n              I‚Äôll not get into the details and instead point at Chandler Carruth‚Äôs\n              <a href=\"https://youtu.be/rHIkrotSwcc?t=1599\" target=\"_blank\">‚ÄòThere are no zero-cost abstractions‚Äô</a>\n              for an example: It pins down how first of all,  has a runtime overhead, and\n              second of all, how fixing this would require an ABI-break and a language change.\n            </p><p>\n              (That doesn‚Äôt mean Google doesn‚Äôt care about memory safety, of course. They do. But memory safety isn‚Äôt\n              what started the whole conflict, even though it‚Äôs currently carrying the torch. That‚Äôs why memory safety\n              is still relevant to all of this, especially since making C++ memory safe without compromising the vision\n              of the standard committee looks more or less impossible.)\n            </p><h2>Migration &amp; Language Evolution</h2><p>\n              First of all, that Carbon has  as one of its goals should be clear. The\n              Carbon people are\n              <a href=\"https://github.com/carbon-language/carbon-lang/blob/trunk/docs/project/goals.md#interoperability-with-and-migration-from-existing-c-code\" target=\"_blank\">very explicit about this</a>. It‚Äôs also a common theme in\n              <a href=\"https://youtu.be/omrY53kbVoA?t=634\" target=\"_blank\">their talks</a>.\n            </p><p>\n              This is, first and foremost, about moving  from the ‚ÄúWe mustn‚Äôt break existing code, so we\n              had to squeeze in this new feature/syntax in some awkward way .‚Äù approach to language\n              evolution. ( and the (proposed) reflection operator () are sending\n              their regards.)\n            </p><p>\n              This approach to language evolution kind of sucks. It‚Äôs not like the committee doesn‚Äôt\n               the problem, or doesn‚Äôt  to evolve the language. The committee is not\n              evil, and it‚Äôs not your enemy. C++ is just incredibly hard to evolve for all sorts of reasons, which would\n              honestly justify an article on their own (ABI, multiple implementations and the committee process, no\n              unified ecosystem, no editions or epochs system, no unified migration tooling, widespread dynamic linking,\n              etc.)\n            </p><p>Carbon‚Äôs goal is to move away from that.</p><p>\n              How? Via automated tooling, a well-defined process of language evolution with clear guarantees, etc.\n              Carbon is still highly experimental, so the details are still WIP. If I had to guess, I‚Äôd say they‚Äôre\n              planning to follow in the footsteps of other modern languages. As an example, consider how Rust manages:\n            </p><ul><li>\n                Have a new ‚Äôedition‚Äô every three years or so. Each edition is allowed to make certain breaking changes,\n                but modules from separate editions can be compiled and linked together.\n              </li><li>\n                Ship automated migration tooling with the language, which allows an automatic migration of code to the\n                new edition whenever possible.\n              </li><li>\n                If you want to eg. introduce a new keyword, you  it one edition ahead of time.\n                <a href=\"https://doc.rust-lang.org/book/appendix-01-keywords.html#raw-identifiers\" target=\"_blank\">Raw Identifier syntax</a>\n                allows migration and use of old code that still uses this keyword as an identifier.\n              </li></ul><p>In contrast to this, I don‚Äôt think there‚Äôs any feasible roadmap to get C++ to this state.</p><p>It‚Äôs only possible with an ecosystem split, and that‚Äôs exactly the point.</p><p>\n              Let me reiterate this. If there‚Äôs one thing you take from this article, it‚Äôs this here: The\n               is to make it possible to take existing C++ code and to put it onto a path\n              towards a modern, well-defined process for future evolution and changes.\n            </p><p>\n              This is the point. If you want to be cynical, it‚Äôs about cutting the dependency on the standard committee,\n              and it‚Äôs about allowing any forwards-looking, backwards-incompatible changes , without\n              having to worry about someone else‚Äôs ancient binaries from the 80s.\n            </p><p>\n              I just want to make clear that I believe that Carbon is radically different from\n              <a href=\"https://hsutter.github.io/cppfront/\" target=\"_blank\">Cpp2</a> (ie. Herb Sutter‚Äôs experimental\n              project to evolve C++).\n            </p><p>\n              The major difference is that Cpp2 tries to leverage the existing C++ language to its full extent, while\n              Carbon tries to minimize its dependency on C++ wherever possible.\n            </p><p>\n              Cpp2 takes the same approach C++ originally did: It transpiles its own code to the host language, and is\n              thus deeply and intrinsically linked to it. It reuses the C++ standard library with all of its problems,\n              it aims to maintain the C++ ecosystem instead of splitting it.\n            </p><p>\n              Perhaps most importantly, Cpp2 also cannot go  than C++: It cannot directly interface with\n              the compiler, since it‚Äôs written to be used by ‚Äúany standard-compliant C++20 compiler‚Äù.\n            </p><p>\n              It should be obvious that it‚Äôs basically impossible for Cpp2 to make meaningful reductions to C++‚Äôs\n              technical debt. Yes, it can be ‚ÄúC++, except with better defaults and syntax.‚Äù, but that‚Äôs all it can\n              feasibly be as long as full backwards compatibility is an explicit goal. Reducing C++‚Äôs technical debt on\n              a deeper level is  for Cpp2.\n            </p><p>\n              It  reduce the number of ways there are to initialize objects by simplifying syntax. It\n               make any changes that would require an ABI-break, it cannot add null-safety to the\n              language (eg.  can still be null,  can still be valueless), and\n              it can‚Äôt prevent your code from blowing up in exciting ways due to lifetime issues.\n              Carbon has the advantage that it  make these changes. (eg. Carbon is planning to move away\n              from exceptions, in favor of treating errors as values.)\n            </p><p>\n              Just to be clear, this is fine! I am not saying Cpp2 is bad, and I‚Äôm curious to see how the project\n              develops. I am just highlighting that Carbon and Cpp2 are <em>completely different projects</em> with\n              completely different scopes and goals.\n            </p><p>\n              It is written by Herb Sutter, someone who very clearly  C++ as it is, and who wants to make\n              it easier to use. It‚Äôs about having a new syntax, and making it  to apply best practices\n              to your C++ code.\n            </p><p>\n              This is a great idea, and a much less invasive proposal than Carbon. Carbon isn‚Äôt that. Carbon is about\n              <em>reworking the language from the ground up</em>. It‚Äôs about building a  language that can\n              support almost all of the same semantics, but is still critically different. It‚Äôs about reworking the\n              fundamentals, and building stronger abstractions.\n            </p><p>\n              So in short, Cpp2 works  C++, and Carbon is trying to  a better C++ from\n              scratch, while cutting its dependency on C++ almost completely.\n            </p><p>\n              Is Carbon feasible? I‚Äôll be honest, I have no clue. C++ code is  and this project is\n              (more or less) unprecedented. (Which is, again, why I am interested in it.)\n            </p><p>The reasons why I believe it  be technically feasible at all are simple:</p><ol><li>\n                Carbon doesn‚Äôt attempt to do the impossible: The goal is a tool-assisted migration of idiomatic code,\n                not a fully automated migration of  code. (What does ‚Äòidiomatic‚Äô mean? Who knows. Probably\n                something like ‚Äòwell-annotated and easy to handle for static analyzers‚Äô. Figuring out how to draw the\n                boundary of which code can be migrated is part of the project.)\n              </li><li>\n                Carbon is capable of leveraging its underlying tooling to do a  of the hard work. For\n                example, resolving C++ templates and function calls is handled by Clang and LLVM. This should not be\n                much of a surprise. Clang can be used as a library, and this is exactly what you‚Äôd expect it to excel\n                at. (Swift is\n                <a href=\"https://www.swift.org/documentation/cxx-interop/status/\" target=\"_blank\">already doing this for its C++ interop</a>.)\n              </li><li>\n                Carbon already demonstrated that its chosen abstractions are capable of supporting some pretty ‚Äúfun‚Äù C++\n                features.\n              </li></ol><p>Let me quickly substantiate some of that.</p><p>\n              So, here‚Äôs the thing. Carbon can\n              <em>convert your C++ to Carbon and then run it against the old test suite</em>. (Or that‚Äôs the plan, at\n              least.)\n            </p><p>(You do have a test suite, right?)</p><p>\n              If the code compiles and all tests pass, this should give you confidence in the resulting code\n              proportional to your confidence in your own test suite. (This is especially helpful for changes\n               the initial automated migration, even if it‚Äôs just clean-up work.)\n            </p><p>This approach is  for all sorts of reasons.</p><p>\n              First of all, it means that Carbon can leverage\n              <em>existing C++ test suites to test its own migration and interop capabilities</em>. This is great.\n            </p><p>\n              Second of all, it puts  burden on the user and sets a minimal bar for what Carbon means with\n              ‚Äòmigration of idiomatic C++‚Äô: You should  have some tests in your code. If you critically\n              depend on something, then you should have a test for it.\n            </p><h3>Generalization and unification of C++ features</h3><div><pre tabindex=\"0\"><code data-lang=\"cpp\"></code></pre></div><p>\n              If you have no idea what you‚Äôre looking at: This is legal C++. Calling  a ‚Äòpointer‚Äô is a\n              stretch, in practice it is just an  relative to the location of an object of this class in\n              memory.\n            </p><p>\n              Two funfacts: First, this can also be used to refer to methods. Second, this value can be null, and it‚Äôs\n              null-value is , since  would point to an actual field.\n            </p><p>\n              When I see a feature like this, my first question would be whether Carbon is even capable of\n               this specific type of behavior, and it turns out that, yes, they have thought about\n              this.\n            </p><p>\n              Carbon is building  on top of  (which can broadly be\n              understood as C++0x Concepts or Rust traits).\n            </p><p>\n              There‚Äôs a simple reason for that: Carbon wants to support  checked generics\n              (roughly, you‚Äôll know that a generic function can be instantiated without having to look into the body of\n              the function. This is not the case for templates.) As a consequence,  which\n              you can ‚Äúdo‚Äù with a value needs to be implemented as an interface, so that you can specify that an\n              incoming value fulfills this constraint.\n            </p><p>\n              Consequently,  are implemented via a so-called\n               interface, which (as far as I can tell) generalizes expressions of the form\n              , whether  is a field, a static member function, a method, a member access\n              pointer, or who knows what else. Any  which implements  (where\n               is the class of ) can be used as .\n            </p><p>\n              The pattern of unifying abstractions as interfaces gets used a lot: It turns out that deep within Carbon,\n              function calls are implemented as a synthesized type which implements some  interface.\n              This is used to unify functions, methods, lambdas, etc. Every single thing in Carbon which you can ‚Äúcall‚Äù\n              is just some value implementing the  interface.\n            </p><p>\n              Sorry, I‚Äôm basically just rehashing parts of Chandler Carruth‚Äôs (highly technical) talk here. For the full\n              picture, please just go and watch it. He‚Äôs a great speaker, and I don‚Äôt trust myself to get every\n              technical detail right.\n            </p><p>\n              The point is, if you‚Äôre wondering what the Carbon people are working on, then it‚Äôs this kind of stuff.\n              They‚Äôre building  which are general enough to to make all sorts of gnarly C++\n              semantics (eg. member access pointers) work, but have a  simpler underlying model. (eg. it\n              unifies everything that can be called,  gives you the ‚Äòconcept‚Äô/interface for free).\n            </p><p>\n              Is this going to work for the rest of the language? Who knows! C++ is complicated, probably too\n              complicated to manage. That‚Äôs the whole reason why Carbon even exists.\n            </p><h3>Digression: Why not Rust‚Ñ¢? Why not C++?</h3><p>\n              Rust is really just too different for an automated conversion of C++ code to Rust code to be feasible,\n              it‚Äôs as simple as that. I even\n              <a href=\"https://herecomesthemoon.net/2025/01/type-inference-in-rust-and-cpp/\" target=\"_blank\">wrote an article</a>\n              getting into the differences in type inference alone.\n            </p><p>\n              You have no class inheritance, no templates, no specialization, no ad-hoc function overloads, no implicit\n              conversions, and there‚Äôs still the whole deal with the borrow checker. Any conversion of modern\n              general-purpose C++ code to Rust basically amounts to a rewrite, which is just not something you can do\n              with classic automation tooling.\n            </p><p>\n              Carbon has the luxury of being able to support both templates  checked generics (ie. something\n              like Rust traits or C++0x concepts), and a way to migrate between them.\n            </p><p>\n              As for a C++-to-more-modern-C++-migration, it just doesn‚Äôt solve the question of language evolution.\n              You‚Äôre still heavily limited by what you can do, unless you also commit to a proper fork of C++ and\n              possibly Clang.\n            </p><p>\n              Which‚Ä¶might be viable, but makes it much harder to implement clean abstractions from the get-go. It also\n              doesn‚Äôt help that a fork runs a pretty severe risk of being ‚Äòusable‚Äô right from the get-go (meaning that\n              people will want to use it, and the boundary between C++ and Carbon will be muddier).\n            </p><p>\n              As I said, Carbon is a moonshot project to allow modern C++ codebases to evolve. (They might stop being\n              called ‚ÄúC++‚Äù in the process, but that‚Äôs probably fine. The only constant in life is change, or something\n              like that.)\n            </p><p>\n              The north star goal is, of course, that of a gradual but mostly automated migration of existing C++ code\n              to Carbon code, followed by  migrations to fix and improve this code using Carbon‚Äôs\n              modern, more powerful semantics (eg. null safety).\n            </p><p>\n              From this angle, and with the historical background in mind, let‚Äôs address the elephant in the room\n              and take a stab at describing how some people feel about Carbon, by rephrasing my interpretation of its\n              goals in the most cynical way possible. I‚Äôm deeply sorry to anyone who‚Äôs working on Carbon, since this is\n              going to feel like I‚Äôm twisting a proverbial knife:\n            </p><blockquote><p>\n                Carbon‚Äôs primary goal is a large-scale migration of Google‚Äôs enormous pile of (highly specific,\n                exception-less, Abseil and Protobuf-using, Clang-based, Bazel-built) C++ technical debt into a modern\n                language capable of supporting Google‚Äôs needs, and\n                <em>over whose governance Google is capable of exerting a significant amount of control.</em></p></blockquote><p>\n              There we go. Do\n              you see the elephant yet?\n            </p><p>\n              It‚Äôs pretty hard to miss since I highlighted it. (Sorry, I know that it‚Äôs the second time I made that\n              joke.)\n            </p><p>\n              This is about the least charitable way to phrase it, of course. I‚Äôm bringing this up for the obvious\n              reasons: Carbon is spearheaded by a big tech company, and people have various concerns.\n            </p><p>\n              These include the concern that Google trying to ‚Äôtake control‚Äô of C++ via a divide-and-conquer approach,\n              that Carbon will favor Google‚Äôs style of C++ at the expense of others, and the classic sentiment that\n              Carbon will eventually be abandoned and dropped (potentially hanging early adopters out in the dry).\n            </p><p>\n              As I already gestured at before, all of this is about , and by extension about governance.\n            </p><p>\n              As long as we‚Äôre willing to say that Carbon is about reducing the reliance on the C++ Standard Committee,\n              it‚Äôs pretty clear that that governance-shaped hole has to be filled , and that someone (or\n              some group of people) has to decide the future direction of the language.\n            </p><p>\n              I‚Äôll be honest, I can make no guarantees here. I am not working on Carbon, and the dynamics here are far beyond my scope.\n            </p><p>\n              I can point out that Carbon is an Apache-licensed open source project,\n              <a href=\"https://github.com/carbon-language/carbon-lang/blob/trunk/CONTRIBUTING.md\" target=\"_blank\">open for contributors right now</a>, and that it has an explicit ‚ÄúThe intent is that [‚Ä¶] Carbon remains a community-driven project, avoiding\n              situations where any single organization controls Carbon‚Äôs direction.‚Äù\n              <a href=\"https://github.com/carbon-language/carbon-lang/blob/trunk/docs/project/faq.md#how-does-carbon-make-decisions\" target=\"_blank\">disclaimer</a>\n              in its FAQ, but that‚Äôs not going to convince you if you‚Äôre worried about bad intentions.\n            </p><p>\n              So. What I  tell you is that I believe that putting governance of the language into the hands\n              of the open-source community is critical for Carbon‚Äôs long-term success, and that Carbon‚Äôs developers\n              understand this.\n            </p><p>\n              Whether Carbon will find widespread adoption depends on whether  trust\n              Carbon‚Äôs stewards to handle the language with enough responsibility that migrating their own C++ code to\n              Carbon seems like a safe offer.\n            </p><p>\n              This sort of trust is hard to establish as long as there‚Äôs a single owner,  if that\n              owner is Google.\n            </p><p>\n              Second: That Carbon finds any public adoption at all is also pretty important  the primary\n              goal was just to use it purely within Google. This might come as a surprise, but it‚Äôs pretty simple:\n              People who‚Äôre expected to use Carbon first need to learn Carbon. This is  easier\n              when Google can rely on a broad ecosystem of tutorials, libraries and discussion boards outside of its\n              intranet.\n            </p><p>\n              So in other words, for Carbon to become successful, it‚Äôs critical that there‚Äôs a public community, and\n              that enterprise users of C++  Carbon.\n            </p><p>These are huge incentives to push the language towards independent community ownership.</p><p>\n              Both of these points (trust by enterprise users and need for a public community) were\n               for <a href=\"https://go.dev/\" target=\"_blank\">Go</a> (which was also\n              spearheaded by Google), primarily due to Go‚Äôs simplicity, the fact that there was far less competition in\n              the programming language space when Go released, and the fact that it was a language for greenfield\n              projects. (That is, it didn‚Äôt require convincing ancient C++ coders to perform a massive migration and\n              rework their tool chain.)\n            </p><p>\n              My understanding is that\n              <a href=\"https://news.ycombinator.com/item?id=32153320\" target=\"_blank\">Carbon‚Äôs leads understand all of this</a>, and want the project to be community driven. For now, that‚Äôs more than good enough for me. For a\n              project this early in its life-cycle, it‚Äôs nice to see that they‚Äôre thinking about this at all, and have\n              made an explicit commitment to community ownership.\n            </p><h2>Conclusion: There is no free lunch.</h2><p>\n              The prospect of building a  to C++‚Äîarguably single most important programming language\n              currently in existence‚Äîsounds like it should be doomed to fail.\n            </p><p>\n              I‚Äôll repeat what I said before, and what should be common knowledge: C++ is an incredibly complex\n              programming language. It‚Äôs under-annotated, has multiple implementations (governed by a 2000+ page ISO\n              Standard document), carries four decades of technical baggage, is full of undefined behavior, and has a\n              frequently abused Turing-complete quasi-code-generation meta-programming language built into it.\n            </p><p>\n              All of that should make it near impossible to succeed C++. Complexity is in fact a form of job security.\n              So why am I still relatively confident in Carbon‚Äôs potential?\n            </p><p>Simple, it‚Äôs mainly since the priorities look correct to me. Carbon understands that</p><ol><li>\n                C++‚Äôs inability to evolve, modernize, deprecate, migrate and standardize is  critical issue\n                which the language is facing today.</li><li>\n                You cannot improve on this without making concessions. This goes both ways: There is old C++ code which\n                you will not be able to support. At the same time, there are C++ features which you  to\n                support, whether you want to or not.\n              </li><li>\n                This is a herculean task that requires a massive initial investment (a whole new programming language),\n                and a complete rethinking of tooling, communication, software engineering and language development\n                practices.\n              </li></ol><p>\n              The inability to evolve is an issue for people who‚Äôre just starting to learn C++, and who stumble into\n              every single footgun that hasn‚Äôt been taken care of over the past thirty years.\n            </p><p>\n              It‚Äôs an issue for people who care for high-quality code, readability or memory safety, and see no viable\n              path towards getting their C++ codebase into that state.\n            </p><p>\n              It‚Äôs an issue for <em>committee and compiler contributors</em>, who need to carefully consider how a new\n              feature will interact with <em>literally everything else</em> the language already supports.\n            </p><p>\n              You might disagree with that assessment. It might not be an issue . That‚Äôs\n              fine. C++ (for a given version, anyway) will stay exactly as it is. It‚Äôs not going to go away anytime\n              soon, and that‚Äôs a good thing. People depend on that. Critical infrastructure depends on that.\n            </p><p>\n              As for myself, I am incredibly glad to see that  is trying to take this bull by the horns,\n              and willing to face this charging billion lines-of-code mountain of complexity and technical debt head-on.\n            </p><p>\n              At last but not at least just since it would be  if we (humanity, as a whole)\n              could actually pull it off, and don‚Äôt need to pass tales warning people about the dangers of using\n               across the generations.\n            </p><p>\n              It might take a while, but that‚Äôs fine. This is a long-term project. It  to be a long-term\n              project to make this work. Once you start thinking about it from that perspective, everything makes a lot\n              more sense.\n            </p><p>\n              Remember, those millions of lines of C++ code are not going to go away anytime soon. They‚Äôll still be\n              there in a few decades. It‚Äôs either a large-scale migration (in some form or another), or nothing.\n            </p><p>\n              In the meantime, if you‚Äôre remotely interested, I‚Äôll reiterate that I highly recommend Carbon‚Äôs talks, eg.\n              <a href=\"https://youtu.be/bBvLmDJrzvI\" target=\"_blank\">this one</a>.\n            </p><p>\n              Writing this took significantly longer than expected. The total number of footnotes written and deleted is\n              about forty.\n            </p><p>Let me know if you got something out of it‚ÄîIt means a lot to me.</p><p>\n              Questions, suggestions, comments, writing advice, reading recommendations, music suggestions, pictures of\n              pets and basically anything else you can think of are all welcome via my contact e-mail at the bottom of\n              the page.\n            </p>","contentLength":31331,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/rust/comments/1il2b71/carbon_is_not_a_programming_language_sort_of/"},{"title":"I release Beta of my code editor Gladius","url":"https://www.reddit.com/r/rust/comments/1il108b/i_release_beta_of_my_code_editor_gladius/","date":1739057724,"author":"/u/njs5i","guid":466,"unread":true,"content":"<p>After several years of coding, I think I have \"good enough\" Beta release of my CLI, keyboard-only code editor Gladius. </p><p>I would like to especially thanks all contributors of the project so far.</p>","contentLength":192,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Is there a way to shutdown a gouroutine","url":"https://www.reddit.com/r/golang/comments/1ikyda1/is_there_a_way_to_shutdown_a_gouroutine/","date":1739050627,"author":"/u/Alone-Employ-1985","guid":333,"unread":true,"content":"<div><p>So i have a long function that runs as a goroutine for every http request i recieve for every id</p><p>I want to stop the already started goroutine if another request with same id is made</p></div>   submitted by   <a href=\"https://www.reddit.com/user/Alone-Employ-1985\"> /u/Alone-Employ-1985 </a>","contentLength":220,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Carbon is not a programming language (sort of)","url":"https://herecomesthemoon.net/2025/02/carbon-is-not-a-language/","date":1739050237,"author":"/u/SophisticatedAdults","guid":446,"unread":true,"content":"<p>\n              In case you‚Äôve not heard of it,  is Google‚Äôs experimental\n              <a href=\"https://github.com/carbon-language/carbon-lang\" target=\"_blank\">open-source</a> ‚ÄúC++-successor\n              language‚Äù. As a very rough first approximation, think Objective-C/Swift, Java/Kotlin, C/C++, C++/Carbon.\n              It is also frequently mentioned in the same breath as Herb Sutter‚Äôs Cppfront and Sean Baxter‚Äôs Circle (and\n              Rust, surprise surprise).\n            </p><p>\n              Like with any ‚Äòsuccessor language‚Äô, the overall goal includes (at the bare minimum) near-seamless\n              interoperability, as well as  improvements over the original language.\n              (Otherwise it can hardly be called a successor, duh.)\n            </p><p>\n              If you‚Äôve clicked on the article, you‚Äôre probably waiting for me to admit that I‚Äôm lying, and to tell you\n              that (in fact) Carbon  a programming language.\n            </p><p>\n              And yes, it‚Äôs true! Carbon is a programming language. (Or rather, it‚Äôs  to be a\n              programming language. Carbon is an experimental project and hasn‚Äôt hit its 0.1 release milestone yet. The\n              Carbon developers are very transparent about this.)\n            </p><p>\n              But in my humble opinion, thinking of Carbon as a ‚Äòprogramming language‚Äô is kind of missing the point. Let\n              me tell you how I think about Carbon, and why I think that it‚Äôs more interesting than most people give it\n              credit for:\n            </p><blockquote><p>\n                Carbon is a concentrated experimental effort to develop tooling that will facilitate automated\n                large-scale long-term migrations of existing C++ code to a modern, well-annotated programming language\n                with a modern, transparent process of evolution and governance model.\n              </p></blockquote><p>\n              The entirety of Carbon (the language, as well as the project) is built around making this goal possible.\n              (Disclaimer, I don‚Äôt speak for Carbon, take my words with a grain of salt.)\n            </p><p>In this post, I want to convince you of the following points:</p><ol><li>\n                Carbon is a project to investigate the possibility of a large-scale reduction of C++ technical debt via\n                automated code migration.</li><li>\n                Many so-called ‚Äòsuccessor languages‚Äô are . They don‚Äôt make\n                 an explicit goal, and generally build a layer of abstraction on top of\n                or rely on their host language.\n              </li><li>\n                All of this is downstream of Google‚Äôs disagreements with the C++ Standard Committee. In fact, while all\n                of this is about reducing technical debt, it‚Äôs also about reducing the organizational costs involved in\n                having to coordinate migrations and language evolution with the committee.\n              </li><li>Developing a new programming language is probably necessary to achieve the goals of the project.</li></ol><p>\n              I‚Äôd like to bring special attention to the point about governance: This isn‚Äôt just a technical issue. It‚Äôs\n              a governance issue. It‚Äôs a ‚ÄúWe just straight-up disagree on the future direction of the C++ programming\n              language.‚Äù sort of issue. I already went over these cultural disagreements in\n              <a href=\"https://herecomesthemoon.net/2024/11/two-factions-of-cpp/\" target=\"_blank\">a previous post</a>.\n            </p><p>\n              (The astute reader will note that you can evolve and govern your own programming language however you\n              want, without needing to deal with WG21 (aka the C++ Standard Committee, aka the authority that decides\n              what C++ .))\n            </p><p>\n              At this point I‚Äôd  to reach for the Herb Sutter ‚ÄúWe must minimize the need to change existing\n              code.‚Äù quote again,\n              but I‚Äôll instead just state the obvious:\n            </p><p>\n              A large-scale migration to a different programming language is  paradigm. As far as\n              changes to existing code go, it‚Äôs uncompromising. It‚Äôs an approach that‚Äôs only going to work for a subset\n              of people, and in fact,\n              <a href=\"https://github.com/carbon-language/carbon-lang/blob/trunk/docs/project/goals.md#legacy-compiled-libraries-without-source-code-or-ability-to-rebuild\" target=\"_blank\">Carbon‚Äôs goal document</a>\n              lists ‚ÄúWe consider it a non-goal to support legacy code for which the source code is no longer available‚Äù.\n            </p><p>\n              In other words, the language is not for everyone. That‚Äôs fine! I am still very interested in it. I care\n              about Carbon since I believe that it‚Äôs trying to solve the hardest problem C++ is currently facing.\n            </p><p>\n              This isn‚Äôt any  technical issue (there are many, many of those), no, and it‚Äôs not even a\n              broad concern such as memory safety.\n            </p><p>\n              It‚Äôs the problem of C++ slowly calcifying and struggling to modernize. It‚Äôs about ABI, about dozens of\n              tools but no agreed upon standards, and it‚Äôs about backwards compatibility. It‚Äôs about allowing existing\n              C++ code to , modernize and change, in spite of decades of technical debt, multiple\n              implementations, and many different users with different expectations and requirements.\n            </p><p>This is, in other words, an , and a .</p><p>\n              If you believe that certain multi-million line C++ codebases are still going to exist in twenty years,\n              <em>then you should understand the business case for Carbon</em>.\n            </p><h3>A short lesson in history</h3><p>\n              Let‚Äôs briefly summarize the backstory for those who haven‚Äôt kept track. You could (very roughly) say that\n              Google is developing Carbon due to conflicts with WG21, and disagreements about the future of the C++\n              language.\n            </p><p>\n              What matters is that Google contributed to WG21 for many years, and that it has a vested interest in the\n              future of the language, due to owning many,  million lines of C++ code. It‚Äôs hard to\n              overstate how critical C++ is for Google‚Äôs infrastructure, and for modern technology in general.\n            </p><p>\n              The short summary is that Google‚Äôs developers (not just Google‚Äôs, mind you) disagreed with other parts of\n              the committee about the\n              <a href=\"https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2020/p2137r0.html\" target=\"_blank\">future direction of the C++ language</a>. There are a lot of reasons for this, and\n              <a href=\"https://cor3ntin.github.io/posts/abi/\" target=\"_blank\">a lot of ink</a> has been spilled on the\n              topic. Eventually, after trying to work with WG21 for many years, Google basically threw in the towel.\n              (You cannot blame them. They tried hard, and the WG21 process is notoriously slow and frustrating.)\n            </p><p>\n              At this point, a lot of people might think that the core disagreement between Google and WG21 was about\n              ‚Äòmemory safety‚Äô, or something like that.\n            </p><p>\n              The current memory safety hype is a pretty big deal for C++, but the ball was already rolling several\n              years ago. All of this started with concerns about C++‚Äôs complexity\n              and .\n              It turns out that fixing certain issues would require backwards incompatible changes (bad!). Coordinating\n              this across the entire C++ ecosystem would be more or less impossible.\n            </p><p>\n              I‚Äôll not get into the details and instead point at Chandler Carruth‚Äôs\n              <a href=\"https://youtu.be/rHIkrotSwcc?t=1599\" target=\"_blank\">‚ÄòThere are no zero-cost abstractions‚Äô</a>\n              for an example: It pins down how first of all,  has a runtime overhead, and\n              second of all, how fixing this would require an ABI-break and a language change.\n            </p><p>\n              (That doesn‚Äôt mean Google doesn‚Äôt care about memory safety, of course. They do. But memory safety isn‚Äôt\n              what started the whole conflict, even though it‚Äôs currently carrying the torch. That‚Äôs why memory safety\n              is still relevant to all of this, especially since making C++ memory safe without compromising the vision\n              of the standard committee looks more or less impossible.)\n            </p><h2>Migration &amp; Language Evolution</h2><p>\n              First of all, that Carbon has  as one of its goals should be clear. The\n              Carbon people are\n              <a href=\"https://github.com/carbon-language/carbon-lang/blob/trunk/docs/project/goals.md#interoperability-with-and-migration-from-existing-c-code\" target=\"_blank\">very explicit about this</a>. It‚Äôs also a common theme in\n              <a href=\"https://youtu.be/omrY53kbVoA?t=634\" target=\"_blank\">their talks</a>.\n            </p><p>\n              This is, first and foremost, about moving  from the ‚ÄúWe mustn‚Äôt break existing code, so we\n              had to squeeze in this new feature/syntax in some awkward way .‚Äù approach to language\n              evolution. ( and the (proposed) reflection operator () are sending\n              their regards.)\n            </p><p>\n              This approach to language evolution kind of sucks. It‚Äôs not like the committee doesn‚Äôt\n               the problem, or doesn‚Äôt  to evolve the language. The committee is not\n              evil, and it‚Äôs not your enemy. C++ is just incredibly hard to evolve for all sorts of reasons, which would\n              honestly justify an article on their own (ABI, multiple implementations and the committee process, no\n              unified ecosystem, no editions or epochs system, no unified migration tooling, widespread dynamic linking,\n              etc.)\n            </p><p>Carbon‚Äôs goal is to move away from that.</p><p>\n              How? Via automated tooling, a well-defined process of language evolution with clear guarantees, etc.\n              Carbon is still highly experimental, so the details are still WIP. If I had to guess, I‚Äôd say they‚Äôre\n              planning to follow in the footsteps of other modern languages. As an example, consider how Rust manages:\n            </p><ul><li>\n                Have a new ‚Äôedition‚Äô every three years or so. Each edition is allowed to make certain breaking changes,\n                but modules from separate editions can be compiled and linked together.\n              </li><li>\n                Ship automated migration tooling with the language, which allows an automatic migration of code to the\n                new edition whenever possible.\n              </li><li>\n                If you want to eg. introduce a new keyword, you  it one edition ahead of time.\n                <a href=\"https://doc.rust-lang.org/book/appendix-01-keywords.html#raw-identifiers\" target=\"_blank\">Raw Identifier syntax</a>\n                allows migration and use of old code that still uses this keyword as an identifier.\n              </li></ul><p>In contrast to this, I don‚Äôt think there‚Äôs any feasible roadmap to get C++ to this state.</p><p>It‚Äôs only possible with an ecosystem split, and that‚Äôs exactly the point.</p><p>\n              Let me reiterate this. If there‚Äôs one thing you take from this article, it‚Äôs this here: The\n               is to make it possible to take existing C++ code and to put it onto a path\n              towards a modern, well-defined process for future evolution and changes.\n            </p><p>\n              This is the point. If you want to be cynical, it‚Äôs about cutting the dependency on the standard committee,\n              and it‚Äôs about allowing any forwards-looking, backwards-incompatible changes , without\n              having to worry about someone else‚Äôs ancient binaries from the 80s.\n            </p><p>\n              I just want to make clear that I believe that Carbon is radically different from\n              <a href=\"https://hsutter.github.io/cppfront/\" target=\"_blank\">Cpp2</a> (ie. Herb Sutter‚Äôs experimental\n              project to evolve C++).\n            </p><p>\n              The major difference is that Cpp2 tries to leverage the existing C++ language to its full extent, while\n              Carbon tries to minimize its dependency on C++ wherever possible.\n            </p><p>\n              Cpp2 takes the same approach C++ originally did: It transpiles its own code to the host language, and is\n              thus deeply and intrinsically linked to it. It reuses the C++ standard library with all of its problems,\n              it aims to maintain the C++ ecosystem instead of splitting it.\n            </p><p>\n              Perhaps most importantly, Cpp2 also cannot go  than C++: It cannot directly interface with\n              the compiler, since it‚Äôs written to be used by ‚Äúany standard-compliant C++20 compiler‚Äù.\n            </p><p>\n              It should be obvious that it‚Äôs basically impossible for Cpp2 to make meaningful reductions to C++‚Äôs\n              technical debt. Yes, it can be ‚ÄúC++, except with better defaults and syntax.‚Äù, but that‚Äôs all it can\n              feasibly be as long as full backwards compatibility is an explicit goal. Reducing C++‚Äôs technical debt on\n              a deeper level is  for Cpp2.\n            </p><p>\n              It  reduce the number of ways there are to initialize objects by simplifying syntax. It\n               make any changes that would require an ABI-break, it cannot add null-safety to the\n              language (eg.  can still be null,  can still be valueless), and\n              it can‚Äôt prevent your code from blowing up in exciting ways due to lifetime issues.\n              Carbon has the advantage that it  make these changes. (eg. Carbon is planning to move away\n              from exceptions, in favor of treating errors as values.)\n            </p><p>\n              Just to be clear, this is fine! I am not saying Cpp2 is bad, and I‚Äôm curious to see how the project\n              develops. I am just highlighting that Carbon and Cpp2 are <em>completely different projects</em> with\n              completely different scopes and goals.\n            </p><p>\n              It is written by Herb Sutter, someone who very clearly  C++ as it is, and who wants to make\n              it easier to use. It‚Äôs about having a new syntax, and making it  to apply best practices\n              to your C++ code.\n            </p><p>\n              This is a great idea, and a much less invasive proposal than Carbon. Carbon isn‚Äôt that. Carbon is about\n              <em>reworking the language from the ground up</em>. It‚Äôs about building a  language that can\n              support almost all of the same semantics, but is still critically different. It‚Äôs about reworking the\n              fundamentals, and building stronger abstractions.\n            </p><p>\n              So in short, Cpp2 works  C++, and Carbon is trying to  a better C++ from\n              scratch, while cutting its dependency on C++ almost completely.\n            </p><p>\n              Is Carbon feasible? I‚Äôll be honest, I have no clue. C++ code is  and this project is\n              (more or less) unprecedented. (Which is, again, why I am interested in it.)\n            </p><p>The reasons why I believe it  be technically feasible at all are simple:</p><ol><li>\n                Carbon doesn‚Äôt attempt to do the impossible: The goal is a tool-assisted migration of idiomatic code,\n                not a fully automated migration of  code. (What does ‚Äòidiomatic‚Äô mean? Who knows. Probably\n                something like ‚Äòwell-annotated and easy to handle for static analyzers‚Äô. Figuring out how to draw the\n                boundary of which code can be migrated is part of the project.)\n              </li><li>\n                Carbon is capable of leveraging its underlying tooling to do a  of the hard work. For\n                example, resolving C++ templates and function calls is handled by Clang and LLVM. This should not be\n                much of a surprise. Clang can be used as a library, and this is exactly what you‚Äôd expect it to excel\n                at. (Swift is\n                <a href=\"https://www.swift.org/documentation/cxx-interop/status/\" target=\"_blank\">already doing this for its C++ interop</a>.)\n              </li><li>\n                Carbon already demonstrated that its chosen abstractions are capable of supporting some pretty ‚Äúfun‚Äù C++\n                features.\n              </li></ol><p>Let me quickly substantiate some of that.</p><p>\n              So, here‚Äôs the thing. Carbon can\n              <em>convert your C++ to Carbon and then run it against the old test suite</em>. (Or that‚Äôs the plan, at\n              least.)\n            </p><p>(You do have a test suite, right?)</p><p>\n              If the code compiles and all tests pass, this should give you confidence in the resulting code\n              proportional to your confidence in your own test suite. (This is especially helpful for changes\n               the initial automated migration, even if it‚Äôs just clean-up work.)\n            </p><p>This approach is  for all sorts of reasons.</p><p>\n              First of all, it means that Carbon can leverage\n              <em>existing C++ test suites to test its own migration and interop capabilities</em>. This is great.\n            </p><p>\n              Second of all, it puts  burden on the user and sets a minimal bar for what Carbon means with\n              ‚Äòmigration of idiomatic C++‚Äô: You should  have some tests in your code. If you critically\n              depend on something, then you should have a test for it.\n            </p><h3>Generalization and unification of C++ features</h3><div><pre tabindex=\"0\"><code data-lang=\"cpp\"></code></pre></div><p>\n              If you have no idea what you‚Äôre looking at: This is legal C++. Calling  a ‚Äòpointer‚Äô is a\n              stretch, in practice it is just an  relative to the location of an object of this class in\n              memory.\n            </p><p>\n              Two funfacts: First, this can also be used to refer to methods. Second, this value can be null, and it‚Äôs\n              null-value is , since  would point to an actual field.\n            </p><p>\n              When I see a feature like this, my first question would be whether Carbon is even capable of\n               this specific type of behavior, and it turns out that, yes, they have thought about\n              this.\n            </p><p>\n              Carbon is building  on top of  (which can broadly be\n              understood as C++0x Concepts or Rust traits).\n            </p><p>\n              There‚Äôs a simple reason for that: Carbon wants to support  checked generics\n              (roughly, you‚Äôll know that a generic function can be instantiated without having to look into the body of\n              the function. This is not the case for templates.) As a consequence,  which\n              you can ‚Äúdo‚Äù with a value needs to be implemented as an interface, so that you can specify that an\n              incoming value fulfills this constraint.\n            </p><p>\n              Consequently,  are implemented via a so-called\n               interface, which (as far as I can tell) generalizes expressions of the form\n              , whether  is a field, a static member function, a method, a member access\n              pointer, or who knows what else. Any  which implements  (where\n               is the class of ) can be used as .\n            </p><p>\n              The pattern of unifying abstractions as interfaces gets used a lot: It turns out that deep within Carbon,\n              function calls are implemented as a synthesized type which implements some  interface.\n              This is used to unify functions, methods, lambdas, etc. Every single thing in Carbon which you can ‚Äúcall‚Äù\n              is just some value implementing the  interface.\n            </p><p>\n              Sorry, I‚Äôm basically just rehashing parts of Chandler Carruth‚Äôs (highly technical) talk here. For the full\n              picture, please just go and watch it. He‚Äôs a great speaker, and I don‚Äôt trust myself to get every\n              technical detail right.\n            </p><p>\n              The point is, if you‚Äôre wondering what the Carbon people are working on, then it‚Äôs this kind of stuff.\n              They‚Äôre building  which are general enough to to make all sorts of gnarly C++\n              semantics (eg. member access pointers) work, but have a  simpler underlying model. (eg. it\n              unifies everything that can be called,  gives you the ‚Äòconcept‚Äô/interface for free).\n            </p><p>\n              Is this going to work for the rest of the language? Who knows! C++ is complicated, probably too\n              complicated to manage. That‚Äôs the whole reason why Carbon even exists.\n            </p><h3>Digression: Why not Rust‚Ñ¢? Why not C++?</h3><p>\n              Rust is really just too different for an automated conversion of C++ code to Rust code to be feasible,\n              it‚Äôs as simple as that. I even\n              <a href=\"https://herecomesthemoon.net/2025/01/type-inference-in-rust-and-cpp/\" target=\"_blank\">wrote an article</a>\n              getting into the differences in type inference alone.\n            </p><p>\n              You have no class inheritance, no templates, no specialization, no ad-hoc function overloads, no implicit\n              conversions, and there‚Äôs still the whole deal with the borrow checker. Any conversion of modern\n              general-purpose C++ code to Rust basically amounts to a rewrite, which is just not something you can do\n              with classic automation tooling.\n            </p><p>\n              Carbon has the luxury of being able to support both templates  checked generics (ie. something\n              like Rust traits or C++0x concepts), and a way to migrate between them.\n            </p><p>\n              As for a C++-to-more-modern-C++-migration, it just doesn‚Äôt solve the question of language evolution.\n              You‚Äôre still heavily limited by what you can do, unless you also commit to a proper fork of C++ and\n              possibly Clang.\n            </p><p>\n              Which‚Ä¶might be viable, but makes it much harder to implement clean abstractions from the get-go. It also\n              doesn‚Äôt help that a fork runs a pretty severe risk of being ‚Äòusable‚Äô right from the get-go (meaning that\n              people will want to use it, and the boundary between C++ and Carbon will be muddier).\n            </p><p>\n              As I said, Carbon is a moonshot project to allow modern C++ codebases to evolve. (They might stop being\n              called ‚ÄúC++‚Äù in the process, but that‚Äôs probably fine. The only constant in life is change, or something\n              like that.)\n            </p><p>\n              The north star goal is, of course, that of a gradual but mostly automated migration of existing C++ code\n              to Carbon code, followed by  migrations to fix and improve this code using Carbon‚Äôs\n              modern, more powerful semantics (eg. null safety).\n            </p><p>\n              From this angle, and with the historical background in mind, let‚Äôs address the elephant in the room\n              and take a stab at describing how some people feel about Carbon, by rephrasing my interpretation of its\n              goals in the most cynical way possible. I‚Äôm deeply sorry to anyone who‚Äôs working on Carbon, since this is\n              going to feel like I‚Äôm twisting a proverbial knife:\n            </p><blockquote><p>\n                Carbon‚Äôs primary goal is a large-scale migration of Google‚Äôs enormous pile of (highly specific,\n                exception-less, Abseil and Protobuf-using, Clang-based, Bazel-built) C++ technical debt into a modern\n                language capable of supporting Google‚Äôs needs, and\n                <em>over whose governance Google is capable of exerting a significant amount of control.</em></p></blockquote><p>\n              There we go. Do\n              you see the elephant yet?\n            </p><p>\n              It‚Äôs pretty hard to miss since I highlighted it. (Sorry, I know that it‚Äôs the second time I made that\n              joke.)\n            </p><p>\n              This is about the least charitable way to phrase it, of course. I‚Äôm bringing this up for the obvious\n              reasons: Carbon is spearheaded by a big tech company, and people have various concerns.\n            </p><p>\n              These include the concern that Google trying to ‚Äôtake control‚Äô of C++ via a divide-and-conquer approach,\n              that Carbon will favor Google‚Äôs style of C++ at the expense of others, and the classic sentiment that\n              Carbon will eventually be abandoned and dropped (potentially hanging early adopters out in the dry).\n            </p><p>\n              As I already gestured at before, all of this is about , and by extension about governance.\n            </p><p>\n              As long as we‚Äôre willing to say that Carbon is about reducing the reliance on the C++ Standard Committee,\n              it‚Äôs pretty clear that that governance-shaped hole has to be filled , and that someone (or\n              some group of people) has to decide the future direction of the language.\n            </p><p>\n              I‚Äôll be honest, I can make no guarantees here. I am not working on Carbon, and the dynamics here are far beyond my scope.\n            </p><p>\n              I can point out that Carbon is an Apache-licensed open source project,\n              <a href=\"https://github.com/carbon-language/carbon-lang/blob/trunk/CONTRIBUTING.md\" target=\"_blank\">open for contributors right now</a>, and that it has an explicit ‚ÄúThe intent is that [‚Ä¶] Carbon remains a community-driven project, avoiding\n              situations where any single organization controls Carbon‚Äôs direction.‚Äù\n              <a href=\"https://github.com/carbon-language/carbon-lang/blob/trunk/docs/project/faq.md#how-does-carbon-make-decisions\" target=\"_blank\">disclaimer</a>\n              in its FAQ, but that‚Äôs not going to convince you if you‚Äôre worried about bad intentions.\n            </p><p>\n              So. What I  tell you is that I believe that putting governance of the language into the hands\n              of the open-source community is critical for Carbon‚Äôs long-term success, and that Carbon‚Äôs developers\n              understand this.\n            </p><p>\n              Whether Carbon will find widespread adoption depends on whether  trust\n              Carbon‚Äôs stewards to handle the language with enough responsibility that migrating their own C++ code to\n              Carbon seems like a safe offer.\n            </p><p>\n              This sort of trust is hard to establish as long as there‚Äôs a single owner,  if that\n              owner is Google.\n            </p><p>\n              Second: That Carbon finds any public adoption at all is also pretty important  the primary\n              goal was just to use it purely within Google. This might come as a surprise, but it‚Äôs pretty simple:\n              People who‚Äôre expected to use Carbon first need to learn Carbon. This is  easier\n              when Google can rely on a broad ecosystem of tutorials, libraries and discussion boards outside of its\n              intranet.\n            </p><p>\n              So in other words, for Carbon to become successful, it‚Äôs critical that there‚Äôs a public community, and\n              that enterprise users of C++  Carbon.\n            </p><p>These are huge incentives to push the language towards independent community ownership.</p><p>\n              Both of these points (trust by enterprise users and need for a public community) were\n               for <a href=\"https://go.dev/\" target=\"_blank\">Go</a> (which was also\n              spearheaded by Google), primarily due to Go‚Äôs simplicity, the fact that there was far less competition in\n              the programming language space when Go released, and the fact that it was a language for greenfield\n              projects. (That is, it didn‚Äôt require convincing ancient C++ coders to perform a massive migration and\n              rework their tool chain.)\n            </p><p>\n              My understanding is that\n              <a href=\"https://news.ycombinator.com/item?id=32153320\" target=\"_blank\">Carbon‚Äôs leads understand all of this</a>, and want the project to be community driven. For now, that‚Äôs more than good enough for me. For a\n              project this early in its life-cycle, it‚Äôs nice to see that they‚Äôre thinking about this at all, and have\n              made an explicit commitment to community ownership.\n            </p><h2>Conclusion: There is no free lunch.</h2><p>\n              The prospect of building a  to C++‚Äîarguably single most important programming language\n              currently in existence‚Äîsounds like it should be doomed to fail.\n            </p><p>\n              I‚Äôll repeat what I said before, and what should be common knowledge: C++ is an incredibly complex\n              programming language. It‚Äôs under-annotated, has multiple implementations (governed by a 2000+ page ISO\n              Standard document), carries four decades of technical baggage, is full of undefined behavior, and has a\n              frequently abused Turing-complete quasi-code-generation meta-programming language built into it.\n            </p><p>\n              All of that should make it near impossible to succeed C++. Complexity is in fact a form of job security.\n              So why am I still relatively confident in Carbon‚Äôs potential?\n            </p><p>Simple, it‚Äôs mainly since the priorities look correct to me. Carbon understands that</p><ol><li>\n                C++‚Äôs inability to evolve, modernize, deprecate, migrate and standardize is  critical issue\n                which the language is facing today.</li><li>\n                You cannot improve on this without making concessions. This goes both ways: There is old C++ code which\n                you will not be able to support. At the same time, there are C++ features which you  to\n                support, whether you want to or not.\n              </li><li>\n                This is a herculean task that requires a massive initial investment (a whole new programming language),\n                and a complete rethinking of tooling, communication, software engineering and language development\n                practices.\n              </li></ol><p>\n              The inability to evolve is an issue for people who‚Äôre just starting to learn C++, and who stumble into\n              every single footgun that hasn‚Äôt been taken care of over the past thirty years.\n            </p><p>\n              It‚Äôs an issue for people who care for high-quality code, readability or memory safety, and see no viable\n              path towards getting their C++ codebase into that state.\n            </p><p>\n              It‚Äôs an issue for <em>committee and compiler contributors</em>, who need to carefully consider how a new\n              feature will interact with <em>literally everything else</em> the language already supports.\n            </p><p>\n              You might disagree with that assessment. It might not be an issue . That‚Äôs\n              fine. C++ (for a given version, anyway) will stay exactly as it is. It‚Äôs not going to go away anytime\n              soon, and that‚Äôs a good thing. People depend on that. Critical infrastructure depends on that.\n            </p><p>\n              As for myself, I am incredibly glad to see that  is trying to take this bull by the horns,\n              and willing to face this charging billion lines-of-code mountain of complexity and technical debt head-on.\n            </p><p>\n              At last but not at least just since it would be  if we (humanity, as a whole)\n              could actually pull it off, and don‚Äôt need to pass tales warning people about the dangers of using\n               across the generations.\n            </p><p>\n              It might take a while, but that‚Äôs fine. This is a long-term project. It  to be a long-term\n              project to make this work. Once you start thinking about it from that perspective, everything makes a lot\n              more sense.\n            </p><p>\n              Remember, those millions of lines of C++ code are not going to go away anytime soon. They‚Äôll still be\n              there in a few decades. It‚Äôs either a large-scale migration (in some form or another), or nothing.\n            </p><p>\n              In the meantime, if you‚Äôre remotely interested, I‚Äôll reiterate that I highly recommend Carbon‚Äôs talks, eg.\n              <a href=\"https://youtu.be/bBvLmDJrzvI\" target=\"_blank\">this one</a>.\n            </p><p>\n              Writing this took significantly longer than expected. The total number of footnotes written and deleted is\n              about forty.\n            </p><p>Let me know if you got something out of it‚ÄîIt means a lot to me.</p><p>\n              Questions, suggestions, comments, writing advice, reading recommendations, music suggestions, pictures of\n              pets and basically anything else you can think of are all welcome via my contact e-mail at the bottom of\n              the page.\n            </p>","contentLength":31331,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1iky82v/carbon_is_not_a_programming_language_sort_of/"},{"title":"Jacksonpollock.org (2003)","url":"https://jacksonpollock.org/","date":1739049769,"author":"memalign","guid":186,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42986320"},{"title":"Tips for mathematical handwriting (2007)","url":"https://johnkerl.org/doc/ortho/ortho.html","date":1739042410,"author":"susam","guid":185,"unread":true,"content":"<p>Now that you‚Äôre majoring in one of the technical disciplines\n(engineering, science, or math), you‚Äôre going to be spending a\nsignificant amount of time communicating in writing with others.  You may find\nthat previously unimportant details, such as crossing your ‚Äôs,\nnow become essential ‚Äî not only so that others can understand you, but\nalso so that you can avoid mistaking your own 2 for\n and so on.  This is especially important if your\nhandwriting (like mine!) is less than perfect.\n\n</p><p>Before I continue, take a fresh look at our Roman alphabet, the digits, and\nthe Greek alphabet:\n\n</p><p>Notice that these mechanically typeset symbols are all clear and distinct\n(except that lowercase omicron and most of the uppercase Greek letters look\nlike Roman letters ‚Äî we don‚Äôt use these ‚Äúduplicates‚Äù).\n\n</p><p> When we write by hand, though, symbols can become ambiguous ‚Äî\nwe‚Äôre not machines, and things get a little loopy when we hurry.  In\nprose, surrounding letters can disambiguate a questionable letter ‚Äî e.g.\nyou can guess that the fourth letter of  has to be an .\nBut in mathematical expressions we mix symbols from different alphabets, in\ndifferent orders, so context can‚Äôt assist us ‚Äî and when we guess,\nwe often guess wrong.  So it now becomes very important that each letter be\nclearly recognizable on its own merits.\n\n</p><p>Here are samples, followed by the points I consider most important.\n\n</p>","contentLength":1405,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42985427"},{"title":"Need Your Suggestions -- Building a Syncthing-like System for Our Final Project","url":"https://www.reddit.com/r/golang/comments/1ikuyvg/need_your_suggestions_building_a_syncthinglike/","date":1739041802,"author":"/u/HunTTeR-47","guid":331,"unread":true,"content":"<p>My team and I are in our final semester of Computer Science, and we‚Äôre working on a file synchronization system inspired by Syncthing. We‚Äôre planning to include features like , , and  (Windows, Linux, and maybe Android).</p><p>We‚Äôd love to hear your thoughts on:</p><ul><li>: Are there any cool or efficient methods we should look into?</li><li>: What would make this system stand out or be more useful?</li><li>: Any tutorials, tools, or reading materials you‚Äôd recommend?</li></ul><p>If you‚Äôve worked on something similar or have ideas, we‚Äôd really appreciate your input! Thanks in advance for your help ‚Äì you‚Äôre awesome!</p>","contentLength":589,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Golang used to connect a PS1 to a PS4 by converting serial to websocket data","url":"https://www.youtube.com/watch?v=ODRqp4eJ-F0","date":1739039221,"author":"/u/Western-Hotel8723","guid":334,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1iktxui/golang_used_to_connect_a_ps1_to_a_ps4_by/"},{"title":"Show HN: Chez Scheme txtar port from Go","url":"https://git.sr.ht/~egtann/txtar/","date":1739039079,"author":"hellcow","guid":177,"unread":true,"content":"<p>txtar enables you to work with a simple text archive format compatible with\n<a href=\"https://golang.org/x/tools/txtar.\" rel=\"nofollow noopener\">https://golang.org/x/tools/txtar.</a> It concatenates files together and allows for\na top-level comment.</p><pre><code>Math implementation\n-- math.h --\n#ifndef MATH_H\n#define MATH_H\n\nint add(int a, int b);\n\n#endif\n-- math.c --\n#include \"math.h\"\n\nint add(int a, int b) {\n    return a + b;\n}\n</code></pre><p>This format is easy for humans to read and write by hand and is perfect for\ntest data.</p><div><pre>\n$makeinstall\n\n\n$</pre></div><p>If you want to remove the library from your system, simply run .</p><div><pre></pre></div><p>You can obtain these libraries and many more via Thunderchez:</p><div><pre>$gitclonehttps://github.com/ovenpasta/thunderchez\n\n\n$/path/to/thunderchez\n</pre></div><p>All the exports of this library are documented with type expectations. I\nencourage you to scan the implementation.</p><p>A few common example usecases are presented below for convenience:</p><p>To use this library, simply import :</p><h4><a href=\"https://git.sr.ht/~egtann/txtar/#construct-an-archive-from-a-list-of-filenames\" rel=\"nofollow noopener\">#</a>Construct an archive from a list of filenames</h4><div><pre></pre></div><h4><a href=\"https://git.sr.ht/~egtann/txtar/#write-text-to-an-archive-file\" rel=\"nofollow noopener\">#</a>Write text to an archive file</h4><div><pre></pre></div><h4><a href=\"https://git.sr.ht/~egtann/txtar/#retrieve-a-file-from-an-archive\" rel=\"nofollow noopener\">#</a>Retrieve a file from an archive</h4><div><pre></pre></div><p>Copyright (C) 2025 Evan Tann, ParaVoce LLC</p><p>This program is free software: you can redistribute it and/or modify it under\nthe terms of the GNU Affero General Public License as published by the Free\nSoftware Foundation, either version 3 of the License, or (at your option) any\nlater version.</p><p>This program is distributed in the hope that it will be useful, but WITHOUT ANY\nWARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A\nPARTICULAR PURPOSE. See the GNU Affero General Public License for more details.</p>","contentLength":1500,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42984962"},{"title":"Most Linux users dont allow the browser to collect data about their system. So, we won?","url":"https://www.reddit.com/r/linux/comments/1iktbzl/most_linux_users_dont_allow_the_browser_to/","date":1739037697,"author":"/u/ParamedicDirect5832","guid":439,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Can anyone ELI5 the general rust in linux kernel drama?","url":"https://www.reddit.com/r/linux/comments/1ikt1fq/can_anyone_eli5_the_general_rust_in_linux_kernel/","date":1739036983,"author":"/u/Nothos927","guid":436,"unread":true,"content":"<p>I only vaguely follow kernel dev but I've seen there's been another instance of drama over incorporating rust into the kernel that only seems to make complete sense if you already know what's going on.</p><p>As far as I can tell, roughly what's happened so far is:</p><ul><li>Linus (and other maintainers?) have traditionally been iffy on adding new languages like C++ to the kernel</li><li>However with rust becoming more popular and younger coders who learnt rust first it was decided to allow some small bits of rust in the mainline kernel codebase</li><li>A certain subset of maintainers were/are extremely opposed to rust code</li><li>There isn't actually much rust code there yet, what is there is mostly just the plumbing needed to get the rust code able to call existing functions safely. We are seeing more out of tree rust drivers being written that rely on these interfaces.</li></ul><p>So really I'm wondering how off the mark that assessment is and why some maintainers still have so much opposition? Is it ideological? Technical? It also seems like this entire thing is touching on broader issues with the kernel development process itself and stuff like tooling?</p>","contentLength":1118,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Writing a simple windows driver in Rust","url":"https://scorpiosoftware.net/2025/02/08/writing-a-simple-driver-in-rust/","date":1739035503,"author":"ingve","guid":184,"unread":true,"content":"<p>The Rust language ecosystem is growing each day, its popularity increasing, and with good reason. It‚Äôs the only mainstream language that provides memory and concurrency safety at compile time, with a powerful and rich build system (cargo), and a growing number of packages (crates).</p><p>My daily driver is still C++, as most of my work is about low-level system and kernel programming, where the Windows C and COM APIs are easy to consume. Rust is a system programming language, however, which means it plays, or at least can play, in the same playground as C/C++. The main snag is the verbosity required when converting C types to Rust. This ‚Äúverbosity‚Äù can be alleviated with appropriate wrappers and macros. I decided to try writing a simple WDM driver that is not useless ‚Äì it‚Äôs a Rust version of the ‚ÄúBooster‚Äù driver I demonstrate in my book (<a href=\"https://www.amazon.com/Windows-Kernel-Programming-Pavel-Yosifovich/dp/1977593372\" target=\"_blank\" rel=\"noreferrer noopener\">Windows Kernel Programming</a>), that allows changing the priority of any thread to any value.</p><p>To prepare for building drivers, consult <a href=\"https://github.com/microsoft/windows-drivers-rs\" target=\"_blank\" rel=\"noreferrer noopener\">Windows Drivers-rs</a>, but basically you should have a WDK installation (either normal or the <a href=\"https://learn.microsoft.com/en-us/legal/windows/hardware/enterprise-wdk-license-2022\" target=\"_blank\" rel=\"noreferrer noopener\">EWDK</a>). Also, the docs require installing <a href=\"https://llvm.org/\" target=\"_blank\" rel=\"noreferrer noopener\">LLVM</a>, to gain access to the <a href=\"https://clang.llvm.org/\" target=\"_blank\" rel=\"noreferrer noopener\">Clang </a>compiler. I am going to assume you have these installed if you‚Äôd like to try the following yourself.</p><p>We can start by creating a new Rust library project (as a driver is a technically a DLL loaded into kernel space):</p><p>We can open the booster folder in VS Code, and begin are coding. First, there are some preparations to do in order for actual code to compile and link successfully. We need a  file to tell cargo to link statically to the CRT. Add a  file to the root booster folder, with the following code:</p><div><pre title=\"\">fn main() -&gt; Result&lt;(), wdk_build::ConfigError&gt; {\n    std::env::set_var(\"CARGO_CFG_TARGET_FEATURE\", \"crt-static\");\n    wdk_build::configure_wdk_binary_build()\n}\n</pre></div><p>(Syntax highlighting is imperfect because the WordPress editor I use does not support syntax highlighting for Rust)</p><p>Next, we need to edit  and add all kinds of dependencies. The following is the minimum I could get away with:</p><div><pre title=\"\">[package]\nname = \"booster\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n[package.metadata.wdk.driver-model]\ndriver-type = \"WDM\"\n\n[lib]\ncrate-type = [\"cdylib\"]\ntest = false\n\n[build-dependencies]\nwdk-build = \"0.3.0\"\n\n[dependencies]\nwdk = \"0.3.0\"       \nwdk-macros = \"0.3.0\"\nwdk-alloc = \"0.3.0\" \nwdk-panic = \"0.3.0\" \nwdk-sys = \"0.3.0\"   \n\n[features]\ndefault = []\nnightly = [\"wdk/nightly\", \"wdk-sys/nightly\"]\n\n[profile.dev]\npanic = \"abort\"\nlto = true\n\n[profile.release]\npanic = \"abort\"\nlto = true\n</pre></div><p>The important parts are the WDK crates dependencies. It‚Äôs time to get to the actual code in . </p><p>We start by removing the standard library, as it does not exist in the kernel:</p><p>Next, we‚Äôll add a few  statements to make the code less verbose:</p><div><pre title=\"\">use core::ffi::c_void;\nuse core::ptr::null_mut;\nuse alloc::vec::Vec;\nuse alloc::{slice, string::String};\nuse wdk::*;\nuse wdk_alloc::WdkAllocator;\nuse wdk_sys::ntddk::*;\nuse wdk_sys::*;\n</pre></div><p>The  crate provides the low level interop kernel functions. the  crate provides higher-level wrappers.  is an interesting one. Since we can‚Äôt use the standard library, you would think the types like  are not available, and technically that‚Äôs correct. However,  is actually defined in a lower level module named , that can be used outside the standard library. This works because the only requirement for  is to have a way to allocate and deallocate memory. Rust exposes this aspect through a global allocator object, that anyone can provide. Since we have no standard library, there is no global allocator, so one must be provided. Then,  (and ) can work normally:</p><div><pre title=\"\">#[global_allocator]\nstatic GLOBAL_ALLOCATOR: WdkAllocator = WdkAllocator;\n</pre></div><p>This is the global allocator provided by the WDK crates, that use <a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/ddi/wdm/nf-wdm-exallocatepool2\" target=\"_blank\" rel=\"noreferrer noopener\"></a>and <a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/ddi/wdm/nf-wdm-exfreepool\" target=\"_blank\" rel=\"noreferrer noopener\"></a>to manage allocations, just like would do manually.</p><p>Next, we add two  crates to get the support for the allocator and a panic handler ‚Äì another thing that must be provided since the standard library is not included.  has a setting to abort the driver (crash the system) if any code panics:</p><div><pre title=\"\">extern crate wdk_panic;\nextern crate alloc;\n</pre></div><p>Now it‚Äôs time to write the actual code. We start with , the entry point to any Windows kernel driver:</p><div><pre title=\"\">#[export_name = \"DriverEntry\"]\npub unsafe extern \"system\" fn driver_entry(\n    driver: &amp;mut DRIVER_OBJECT,\n    registry_path: PUNICODE_STRING,\n) -&gt; NTSTATUS {\n</pre></div><p>Those familiar with kernel drivers will recognize the function signature (kind of). The function name is  to conform to the snake_case Rust naming convention for functions, but since the linker looks for , we decorate the function with the  attribute. You could use  and just ignore or disable the compiler‚Äôs warning, if you prefer.</p><p>We can use the familiar  macro, that was reimplemented by calling , as you would if you were using C/C++. You can still call , mind you, but  is just easier:</p><div><pre title=\"\">println!(\"DriverEntry from Rust! {:p}\", &amp;driver);\nlet registry_path = unicode_to_string(registry_path);\nprintln!(\"Registry Path: {}\", registry_path);\n</pre></div><p>Unfortunately, it seems  does not yet support a , so we can write a function named  to convert a  to a normal Rust string:</p><div><pre title=\"\">fn unicode_to_string(str: PCUNICODE_STRING) -&gt; String {\n    String::from_utf16_lossy(unsafe {\n        slice::from_raw_parts((*str).Buffer, (*str).Length as usize / 2)\n    })\n}\n</pre></div><p>Back in , our next order of business is to create a device object with the name ‚Äú\\Device\\Booster‚Äù:</p><div><pre title=\"\">let mut dev = null_mut();\nlet mut dev_name = UNICODE_STRING::default();\nstring_to_ustring(\"\\\\Device\\\\Booster\", &amp;mut dev_name);\n\nlet status = IoCreateDevice(\n    driver,\n    0,\n    &amp;mut dev_name,\n    FILE_DEVICE_UNKNOWN,\n    0,\n    0u8,\n    &amp;mut dev,\n);\n</pre></div><p>The  function converts a Rust string to a :</p><div><pre title=\"\">fn string_to_ustring&lt;'a&gt;(s: &amp;str, uc: &amp;'a mut UNICODE_STRING) -&gt; Vec&lt;u16&gt; {\n    let mut wstring: Vec&lt;_&gt; = s.encode_utf16().collect();\n    uc.Length = wstring.len() as u16 * 2;\n    uc.MaximumLength = wstring.len() as u16 * 2;\n    uc.Buffer = wstring.as_mut_ptr();\n    wstring\n}\n</pre></div><p>This may look more complex than we would like, but think of this as a function that is written once, and then just used all over the place. In fact, maybe there is such a function already, and just didn‚Äôt look hard enough. But it will do for this driver.</p><p>If device creation fails, we return a failure status:</p><div><pre title=\"\">if !nt_success(status) {\n    println!(\"Error creating device 0x{:X}\", status);\n    return status;\n}\n</pre></div><p> is similar to the  macro provided by the WDK headers.</p><p>Next, we‚Äôll create a symbolic link so that a standard  call could open a handle to our device:</p><div><pre title=\"\">let mut sym_name = UNICODE_STRING::default();\nlet _ = string_to_ustring(\"\\\\??\\\\Booster\", &amp;mut sym_name);\nlet status = IoCreateSymbolicLink(&amp;mut sym_name, &amp;mut dev_name);\nif !nt_success(status) {\n    println!(\"Error creating symbolic link 0x{:X}\", status);\n    IoDeleteDevice(dev);\n    return status;\n}\n</pre></div><p>All that‚Äôs left to do is initialize the device object with support for Buffered I/O (we‚Äôll use  for simplicity), set the driver unload routine, and the major functions we intend to support:</p><div><pre title=\"\">    (*dev).Flags |= DO_BUFFERED_IO;\n\n    driver.DriverUnload = Some(boost_unload);\n    driver.MajorFunction[IRP_MJ_CREATE as usize] = Some(boost_create_close);\n    driver.MajorFunction[IRP_MJ_CLOSE as usize] = Some(boost_create_close);\n    driver.MajorFunction[IRP_MJ_WRITE as usize] = Some(boost_write);\n\n    STATUS_SUCCESS\n}\n</pre></div><p>Note the use of the Rust  type to indicate the presence of a callback.</p><p>The unload routine looks like this:</p><div><pre title=\"\">unsafe extern \"C\" fn boost_unload(driver: *mut DRIVER_OBJECT) {\n    let mut sym_name = UNICODE_STRING::default();\n    string_to_ustring(\"\\\\??\\\\Booster\", &amp;mut sym_name);\n    let _ = IoDeleteSymbolicLink(&amp;mut sym_name);\n    IoDeleteDevice((*driver).DeviceObject);\n}\n</pre></div><p>We just call  and , just like a normal kernel driver would. </p><p>We have three request types to handle ‚Äì , , and . Create and close are trivial ‚Äì just complete the IRP successfully:</p><div><pre title=\"\">unsafe extern \"C\" fn boost_create_close(_device: *mut DEVICE_OBJECT, irp: *mut IRP) -&gt; NTSTATUS {\n    (*irp).IoStatus.__bindgen_anon_1.Status = STATUS_SUCCESS;\n    (*irp).IoStatus.Information = 0;\n    IofCompleteRequest(irp, 0);\n    STATUS_SUCCESS\n}\n</pre></div><p>The  is an  but it‚Äôs defined with a  containing  and . This seems to be incorrect, as  should be in a  with  (not ). Anyway, the code accesses the  member through the ‚Äúauto generated‚Äù union, and it looks ugly. Definitely something to look into further. But it works.</p><p>The real interesting function is the  handler, that does the actual thread priority change. First, we‚Äôll declare a structure to represent the request to the driver:</p><div><pre title=\"\">#[repr(C)]\nstruct ThreadData {\n    pub thread_id: u32,\n    pub priority: i32,\n}\n</pre></div><p>The use of  is important, to make sure the fields are laid out in memory just as they would with C/C++. This allows non-Rust clients to talk to the driver. In fact, I‚Äôll test the driver with a C++ client I have that used the C++ version of the driver. The driver accepts the thread ID to change and the priority to use. Now we can start with :</p><div><pre title=\"\">unsafe extern \"C\" fn boost_write(_device: *mut DEVICE_OBJECT, irp: *mut IRP) -&gt; NTSTATUS {\n    let data = (*irp).AssociatedIrp.SystemBuffer as *const ThreadData;\n</pre></div><p>First, we grab the data pointer from the  in the IRP, as we asked for Buffered I/O support. This is a kernel copy of the client‚Äôs buffer. Next, we‚Äôll do some checks for errors:</p><div><pre title=\"\">let status;\nloop {\n    if data == null_mut() {\n        status = STATUS_INVALID_PARAMETER;\n        break;\n    }\n    if (*data).priority &lt; 1 || (*data).priority &gt; 31 {\n        status = STATUS_INVALID_PARAMETER;\n        break;\n    }\n</pre></div><p>The  statement creates an infinite block that can be exited with a . Once we verified the priority is in range, it‚Äôs time to locate the thread object:</p><div><pre title=\"\">let mut thread = null_mut();\nstatus = PsLookupThreadByThreadId(((*data).thread_id) as *mut c_void, &amp;mut thread);\nif !nt_success(status) {\n    break;\n}\n</pre></div><p> is the one to use. If it fails, it means the thread ID probably does not exist, and we break. All that‚Äôs left to do is set the priority and complete the request with whatever status we have:</p><div><pre title=\"\">        KeSetPriorityThread(thread, (*data).priority);\n        ObfDereferenceObject(thread as *mut c_void);\n        break;\n    }\n    (*irp).IoStatus.__bindgen_anon_1.Status = status;\n    (*irp).IoStatus.Information = 0;\n    IofCompleteRequest(irp, 0);\n    status\n}\n</pre></div><p>The only remaining thing is to sign the driver. It seems that the crates support signing the driver if an INF or INX files are present, but this driver is not using an INF. So we need to sign it manually before deployment. The following can be used from the root folder of the project:</p><div><pre title=\"\">signtool sign /n wdk /fd sha256 target\\debug\\booster.dll\n</pre></div><p>The  uses a WDK test certificate typically created automatically by Visual Studio when building drivers. I just grab the first one in the store that starts with ‚Äúwdk‚Äù and use it.</p><p>The silly part is the file extension ‚Äì it‚Äôs a DLL and there currently is no way to change it automatically as part of cargo build. If using an INF/INX, the file extension does change to SYS. In any case, file extensions don‚Äôt really mean that much ‚Äì we can rename it manually, or just leave it as DLL. </p><p>The resulting file can be installed in the ‚Äúnormal‚Äù way for a software driver, such as using the  tool (from an elevated command window), on a machine with test signing on. Then  can be used to load the driver into the system:</p><div><pre title=\"\">sc.exe sc create booster type= kernel binPath= c:\\path_to_driver_file\nsc.exe start booster\n</pre></div><p>I used an existing C++ application that talks to the driver and expects to pass the correct structure. It looks like this:</p><div><pre title=\"\">#include &lt;Windows.h&gt;\n#include &lt;stdio.h&gt;\n\nstruct ThreadData {\n\tint ThreadId;\n\tint Priority;\n};\n\nint main(int argc, const char* argv[]) {\n\tif (argc &lt; 3) {\n\t\tprintf(\"Usage: boost &lt;tid&gt; &lt;priority&gt;\\n\");\n\t\treturn 0;\n\t}\n\n\tint tid = atoi(argv[1]);\n\tint priority = atoi(argv[2]);\n\n\tHANDLE hDevice = CreateFile(L\"\\\\\\\\.\\\\Booster\",\n\t\tGENERIC_WRITE, 0, nullptr, OPEN_EXISTING, 0,\n\t\tnullptr);\n\n\tif (hDevice == INVALID_HANDLE_VALUE) {\n\t\tprintf(\"Failed in CreateFile: %u\\n\", GetLastError());\n\t\treturn 1;\n\t}\n\n\tThreadData data;\n\tdata.ThreadId = tid;\n\tdata.Priority = priority;\n\tDWORD ret;\n\tif (WriteFile(hDevice, &amp;data, sizeof(data),\n\t\t&amp;ret, nullptr))\n\t\tprintf(\"Success!!\\n\");\n\telse\n\t\tprintf(\"Error (%u)\\n\", GetLastError());\n\n\tCloseHandle(hDevice);\n\n\treturn 0;\n}\n</pre></div><p>Here is the result when changing a thread‚Äôs priority to 26 (ID 9408):</p><p>Writing kernel drivers in Rust is possible, and I‚Äôm sure the support for this will improve quickly. The WDK crates are at version 0.3, which means there is still a way to go. To get the most out of Rust in this space, safe wrappers should be created so that the code is less verbose, does not have  blocks, and enjoys the benefits Rust can provide. Note, that I may have missed some wrappers in this simple implementation.</p><p>You can find a couple of more samples for KMDF Rust drivers <a href=\"https://github.com/microsoft/Windows-rust-driver-samples\" target=\"_blank\" rel=\"noreferrer noopener\">here</a>.</p>","contentLength":12934,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42984457"},{"title":"Show HN: FlashSpace ‚Äì fast, open-source, macOS Spaces replacement","url":"https://github.com/wojciech-kulik/FlashSpace","date":1739035163,"author":"wojciech-kulik","guid":176,"unread":true,"content":"<p>I've recently launched a new open-source project aimed at enhancing the experience of switching between Spaces/workspaces on macOS. The built-in Spaces feature is often slow and unfriendly. This project is designed to boost your productivity :). Enjoy!</p>","contentLength":252,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42984420"},{"title":"Mastering cross-database operations with PostgreSQL FDW","url":"https://packagemain.tech/p/mastering-cross-database-operations-with-postgres-fdw","date":1739035067,"author":"/u/der_gopher","guid":444,"unread":true,"content":"<p><a href=\"https://wiki.postgresql.org/wiki/Foreign_data_wrappers\" rel=\"\">PostgreSQL‚Äôs </a></p><p>In this post we will talk about:</p><ul><li><p>Setting up FDW to connect to external databases (ex: another PostgreSQL instance).</p></li><li><p>Importing foreign schemas.</p></li><li><p>Creating archival policies with stored procedures</p></li><li><p>Automating archival tasks with pg_cron</p></li></ul><blockquote><p><a href=\"https://dub.sh/focU0Kg\" rel=\"\">Multiplayer</a></p></blockquote><p>FDW is an extension that implements the SQL/MED standard, allowing PostgreSQL to interact with external data sources.</p><ul></ul><p>There is a lot of different FDW extensions that will let you connect to a variety of databases (relational, no-sql, files etc..)</p><ul><li><ul><li><p>Connects to other PostgreSQL databases (local or remote)</p></li><li><p>Supports read/write operations</p></li></ul></li><li><ul><li><p>Reads data from flat files (CSV, TSV, etc..)</p></li></ul></li><li><ul><li><p>Connects to MySQL/MariaDB databases</p></li><li><p>Supports basic queries and joins</p></li></ul></li></ul><p><a href=\"https://wiki.postgresql.org/wiki/Foreign_data_wrappers\" rel=\"\">here</a></p><p>As you can imagine, there are many use cases possible. </p><p>From reading files from your database, to getting cache keys from Redis and augment them from content stored in your PostgreSQL.</p><p><strong>The use case we will focus on, is an automatic archival from PostgreSQL to PostgreSQL.</strong></p><pre><code>-- Enable FDW   \nCREATE EXTENSION IF NOT EXISTS postgres_fdw;</code></pre><pre><code>-- Create a foreign server\nCREATE SERVER postgres_server FOREIGN DATA WRAPPER postgres_fdw\n   OPTIONS (host '{FOREIGN_HOST}', dbname '{FOREIGN_DB_NAME}');\n\n-- Map local PostgreSQL user to foreign server credentials\nCREATE USER MAPPING FOR postgres SERVER postgres_server\n   OPTIONS (user '{FOREIGN_USERNAME}', password '{FOREIGN_PASSWORD}');</code></pre><p>You might be tempted to import foreign schema from the other postgres into the ‚Äúpublic‚Äù schema of your current instance, however you can‚Äôt have 2 tables with the same name. </p><p>That‚Äôs why, I would suggest you create a separate schema, you can call it foreign_schema or whatever you wish:</p><pre><code>-- Create a new schema to import the tables into\nCREATE SCHEMA foreign_schema;\n\n-- Import all tables from the foreign postgreSQL database\nIMPORT FOREIGN SCHEMA public FROM SERVER postgres_server INTO foreign_scehma;\n\n-- You can also import only specific tables\nIMPORT FOREIGN SCHEMA public LIMIT TO ({TABLE1}, {TABLE2}) FROM SERVER postgres_server INTO foreign_schema;</code></pre><p>Now you can query your foreign database:</p><pre><code>SELECT * FROM foreign_schema.{TABLE1};</code></pre><p>The distant server is used as archive and the current db (the one you are connected to) is your live DB. </p><pre><code>CREATE TABLE IF NOT EXISTS transactions (\n    id uuid DEFAULT uuid_generate_v4(),\n    amount INT DEFAULT 0,\n    created_at   TIMESTAMPTZ DEFAULT NOW(),\n\n    PRIMARY KEY (id)\n); </code></pre><pre><code>CREATE OR REPLACE PROCEDURE archive_old_transactions()  \nLANGUAGE plpgsql  \nAS $$  \nBEGIN  \n  -- Move data older than 1 year to archive  \n  INSERT INTO foreign_schema.transactions  \n  SELECT * FROM public.transactions  \n  WHERE created_at &lt; NOW() - INTERVAL '1 year';  \n\n  -- Delete archived data from main table  \n  DELETE FROM public.transactions  \n  WHERE created_at &lt; NOW() - INTERVAL '1 year';  \nEND;  \n$$\n;  </code></pre><pre><code>-- Enable pg cron   \nCREATE EXTENSION IF NOT EXISTS pg_cron;</code></pre><pre><code>-- Run at 2 AM daily\nSELECT cron.schedule(\n  'archive_transactions',\n  '0 2 * * *',\n  'CALL archive_old_transactions()'\n); </code></pre><pre><code>CREATE VIEW combined_transactions AS (\n    WITH remote_data AS (\n      SELECT * FROM foreign_schema.transactions\n    ),\n    local_data AS (\n      SELECT * FROM public.transactions\n    )\n    SELECT * FROM remote_data\n    UNION ALL\n    SELECT * FROM local_data\n);</code></pre><p>You will notice that I didn‚Äôt simply do a UNION of two tables, I used CTE (Common Table Expressions) because it is crucial for optimizing queries with foreign tables. </p><p>Essentially, it containerizes the FDW query, because the query planner will have to ask the foreign database to execute its part, and the clearer this query is, the faster it will be.</p><ul><li><p>Containerize the FDW query to reduce data transfer</p></li><li><p>Filter data at the source </p></li><li><p>Minimize the returned row count </p></li></ul><p>Nothing forces you to have the exact same copy of foreign and local table, neither you have to force foreign keys or equivalent indexes. </p><p>It is probably recommended to create specific indexes in your foreign table that will match the query patterns they will be submitted to. Because you don‚Äôt query archive data the same way you might query live data. </p><p>The concept of archival is often to reclaim space, but if you were to need faster access to data from both the archive and the live DB then you could use Materialized views to ensure fast queries. </p><p>So if you query transactions from 2 years ago from now, until now. You necessarily have to query both tables.</p><pre><code>SELECT * FROM combined_transactions WHERE created_at BETWEEN(NOW() - INTERVAL '2 year', NOW()); </code></pre><ol></ol><p>PostgreSQL FDW transforms your database into a unified gateway for cross-database operations. By combining it with pg_cron and stored procedures, you can automate complex workflows like archival, reporting, and data synchronization without external tools. </p><blockquote><p><a href=\"https://dub.sh/focU0Kg\" rel=\"\">Multiplayer</a></p></blockquote>","contentLength":4730,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1iksa6k/mastering_crossdatabase_operations_with/"},{"title":"Securing Kubernetes Secrets & Disaster Recovery with SOPS and FluxCD ‚Äî My Journey","url":"https://www.reddit.com/r/kubernetes/comments/1ikrydu/securing_kubernetes_secrets_disaster_recovery/","date":1739034242,"author":"/u/mustybatz","guid":425,"unread":true,"content":"<div><p>I recently explored <strong>securing Kubernetes secrets and disaster recovery</strong> using  in a GitOps setup, and I thought this could be helpful for others working with Kubernetes (home labs or production).</p><ul><li>Encrypt and store secrets directly in Git with .</li><li>Automatically decrypt and deploy them using .</li><li>Disaster recovery using GitOps workflows + backup strategies with NAS and Velero.</li></ul><ul><li>Do you prefer  or ?</li><li>What‚Äôs your go-to strategy for persistent data backups?</li></ul><p>Let me know your thoughts or feedback! </p></div>   submitted by   <a href=\"https://www.reddit.com/user/mustybatz\"> /u/mustybatz </a>","contentLength":514,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Deck: An open-source cross-platform multiplayer card game engine in Flutter","url":"https://github.com/xajik/thedeck","date":1739029656,"author":"igor_st","guid":183,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42983699"},{"title":"We are destroying software","url":"https://antirez.com/news/145","date":1739026105,"author":"antirez","guid":222,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42983275"},{"title":"VSCode‚Äôs SSH agent is bananas","url":"https://fly.io/blog/vscode-ssh-wtf/","date":1738977932,"author":"zdyxry","guid":221,"unread":true,"content":"<p>We‚Äôre interested in getting integrated into the flow VSCode uses to do remote editing over SSH, because everybody is using VSCode now, and, in particular, they‚Äôre using forks of VSCode that generate code with LLMs. </p><div><p>‚Äùhallucination‚Äù is what we call it when LLMs get code wrong; ‚Äúengineering‚Äù is what we call it when people do.</p></div><p>LLM-generated code is <a href=\"https://nicholas.carlini.com/writing/2024/how-i-use-ai.html\" title=\"\">useful in the general case</a> if you know what you‚Äôre doing. But it‚Äôs ultra-useful if you can close the loop between the LLM and the execution environment (with an ‚ÄúAgent‚Äù setup). There‚Äôs lots to say about this, but for the moment: it‚Äôs a semi-effective antidote to hallucination: the LLM generates the code, the agent scaffolding runs the code, the code generates errors, the agent feeds it back to the LLM, the process iterates. </p><p>So, obviously, the issue here is you don‚Äôt want this iterative development process happening on your development laptop, because LLMs have boundary issues, and they‚Äôll iterate on your system configuration just as happily on the Git project you happen to be working in. A thing you‚Äôd really like to be able to do: run a closed-loop agent-y (‚Äúagentic‚Äù? is that what we say now) configuration for an LLM, on a clean-slate Linux instance that spins up instantly and that can‚Äôt screw you over in any way. You get where we‚Äôre going with this.</p><p>Anyways! I would like to register a concern.</p><p>Emacs hosts the spiritual forebearer of remote editing systems, a blob of hyper-useful Elisp called <a href=\"https://www.gnu.org/software/tramp/\" title=\"\">‚ÄúTramp‚Äù</a>. If you can hook Tramp up to any kind of interactive environment ‚Äî usually, an SSH session ‚Äî where it can run Bourne shell commands, it can extend Emacs to that environment.</p><p>So, VSCode has a feature like Tramp. Which, neat, right? You‚Äôd think, take Tramp, maybe simplify it a bit, switch out Elisp for Typescript.</p><p>Unlike Tramp, which lives off the land on the remote connection, VSCode mounts a full-scale invasion: it runs a Bash snippet stager that downloads an agent, including a binary installation of Node. </p><p>The agent runs over port-forwarded SSH. It establishes a WebSockets connection back to your running VSCode front-end. The underlying protocol on that connection can:</p><ul><li>Wander around the filesystem\n</li><li>Launch its own shell PTY processes\n</li></ul><p>In security-world, there‚Äôs a name for tools that work this way. I won‚Äôt say it out loud, because that‚Äôs not fair to VSCode, but let‚Äôs just say the name is murid in nature.</p><p>I would be a little nervous about letting people VSCode-remote-edit stuff on dev servers, and apoplectic if that happened during an incident on something in production. </p><p>It turns out we don‚Äôt have to care about any of this to get a custom connection to a Fly Machine working in VSCode, so none of this matters in any kind of deep way, but: we‚Äôve decided to just be a blog again, so: we had to learn this, and now you do too.</p>","contentLength":2855,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42979467"},{"title":"Google's 7-Year Slog To Improve Chrome Extensions Still Hasn't Satisfied Developers","url":"https://developers.slashdot.org/story/25/02/07/2246202/googles-7-year-slog-to-improve-chrome-extensions-still-hasnt-satisfied-developers?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1738977900,"author":"BeauHD","guid":289,"unread":true,"content":"The Register's Thomas Claburn reports: Google's overhaul of Chrome's extension architecture continues to pose problems for developers of ad blockers, content filters, and privacy tools. [...] While Google's desire to improve the security, privacy, and performance of the Chrome extension platform is reasonable, its approach -- which focuses on code and permissions more than human oversight -- remains a work-in-progress that has left extension developers frustrated.\n \nAlexei Miagkov, senior staff technology at the Electronic Frontier Foundation, who oversees the organization's Privacy Badger extension, told The Register, \"Making extensions under MV3 is much harder than making extensions under MV2. That's just a fact. They made things harder to build and more confusing.\" Miagkov said with Privacy Badger the problem has been the slowness with which Google addresses gaps in the MV3 platform. \"It feels like MV3 is here and the web extensions team at Google is in no rush to fix the frayed ends, to fix what's missing or what's broken still.\" According to Google's documentation, \"There are currently no open issues considered a critical platform gap,\" and various issues have been addressed through the addition of new API capabilities.\n \nMiagkov described an unresolved problem that means Privacy Badger is unable to strip Google tracking redirects on Google sites. \"We can't do it the correct way because when Google engineers design the [chrome.declarativeNetRequest API], they fail to think of this scenario,\" he said. \"We can do a redirect to get rid of the tracking, but it ends up being a broken redirect for a lot of URLs. Basically, if the URL has any kind of query string parameters -- the question mark and anything beyond that -- we will break the link.\" Miagkov said a Chrome developer relations engineer had helped identify a workaround, but it's not great. Miagkov thinks these problems are of Google's own making -- the company changed the rules and has been slow to write the new ones. \"It was completely predictable because they moved the ability to fix things from extensions to themselves,\" he said. \"And now they need to fix things and they're not doing it.\"","contentLength":2187,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Obscure islands I find interesting","url":"https://amanvir.com/obscure-islands","date":1738967011,"author":"venusgirdle","guid":182,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42978199"},{"title":"Show HN: ExpenseOwl ‚Äì Simple, self-hosted expense tracker","url":"https://github.com/Tanq16/ExpenseOwl","date":1738961818,"author":"import-base64","guid":175,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42977388"},{"title":"UK demands backdoor for encrypted Apple user data...","url":"https://www.youtube.com/watch?v=ozkg_iW9mNU","date":1738959621,"author":"Fireship","guid":419,"unread":true,"content":"<article>Try Brilliant free for 30 days https://brilliant.org/fireship You‚Äôll also get 20% off an annual premium subscription.\n\nThe United Kingdom is demanding Apple build a backdoor to access encrypted iCloud user data. Learn how end-to-end-encryption works and other tools that protect your digital privacy. \n\n#apple #tech #thecodereport \n\nüí¨ Chat with Me on Discord\n\nhttps://discord.gg/fireship\n\nüîó Resources\n\nMainstream Source https://www.washingtonpost.com/technology/2025/02/07/apple-encryption-backdoor-uk/\nFull Cryptography Tutorial https://youtu.be/NuyzuNBFWxQ\nApple Intelligence gone Wild https://youtu.be/7rXgVsIGvGQ\nTails OS in 100 Seconds https://youtu.be/mVKAyw0xqxw\n\nüî• Get More Content - Upgrade to PRO\n\nUpgrade at https://fireship.io/pro\nUse code YT25 for 25% off PRO access \n\nüé® My Editor Settings\n\n- Atom One Dark \n- vscode-icons\n- Fira Code Font\n\nüîñ Topics Covered\n\n- Why does the UK want Apple iCloud data?\n- What is a double rachet algorithm?\n- How does signal e2ee protocol work?\n- How do I keep browsing data private?\n- Best Linux distro for privacy</article>","contentLength":1076,"flags":null,"enclosureUrl":"https://www.youtube.com/v/ozkg_iW9mNU?version=3","enclosureMime":"","commentsUrl":null},{"title":"Do-nothing scripting: the key to gradual automation (2019)","url":"https://blog.danslimmon.com/2019/07/15/do-nothing-scripting-the-key-to-gradual-automation/","date":1738957696,"author":"tehnub","guid":181,"unread":true,"content":"<p>Every ops team has some manual procedures that they haven‚Äôt gotten around to automating yet. <a href=\"https://landing.google.com/sre/sre-book/chapters/eliminating-toil/\">Toil</a> can never be totally eliminated.</p><p>Very often, the biggest toil center for a team at a growing company will be its procedure for modifying infrastructure or its procedure for provisioning user accounts. Partial instructions for the latter might look like this:</p><ol><li>Create an SSH key pair for the user.</li><li>Commit the public key to Git and push to master.</li><li>Wait for the build job to finish.</li><li>Find the user‚Äôs email address in the employee directory.</li><li>Send the user their private key via 1Password.</li></ol><p>This is a relatively short example. Sometimes there are 20 steps in the process. Sometimes there are branches and special cases to keep track of as you go. Over time, these procedures can become unmanageably large and complex.</p><p>Procedures like this are frustrating because they‚Äôre focus-intensive yet require very little thought. They demand our full attention, but our attention isn‚Äôt rewarded with interesting problems or satisfying solutions ‚Äì just another checkbox checked. I have a word for a procedure like this: a .</p><p>We know that this procedure is ripe for automation. We can easily see how to automate any given step. And we know that a computer could carry out the instructions with far greater speed and accuracy than we can, and with less tendency toward <a href=\"https://risk-engineering.org/concept/Rasmussen-practical-drift\">practical drift</a>.</p><p>However, automating slogs sometimes feels like an all-or-nothing proposition. Sure, we could write a script to handle step 2, or step 5. But that wouldn‚Äôt  make the procedure any less cumbersome. It would lead to a proliferation of single-purpose scripts with different conventions and expectations, and you‚Äôd still have to follow a documented multi-step procedure for using those scripts.</p><p>This perception of futility is the problem we really need to solve in order to escape from these manual slogs. I‚Äôve found an approach that works pretty reliably: .</p><p>Almost any slog can be turned into a . A do-nothing script is a script that encodes the instructions of a slog, encapsulating each step in a function. For the example procedure above, we could write the following do-nothing script:</p><div><pre title=\"\">import sys\n\ndef wait_for_enter():\n    raw_input(\"Press Enter to continue: \")\n\nclass CreateSSHKeypairStep(object):\n    def run(self, context):\n        print(\"Run:\")\n        print(\"   ssh-keygen -t rsa -f ~/{0}\".format(context[\"username\"]))\n        wait_for_enter()\n\nclass GitCommitStep(object):\n    def run(self, context):\n        print(\"Copy ~/new_key.pub into the `user_keys` Git repository, then run:\")\n        print(\"    git commit {0}\".format(context[\"username\"]))\n        print(\"    git push\")\n        wait_for_enter()\n\nclass WaitForBuildStep(object):\n    build_url = \"http://example.com/builds/user_keys\"\n    def run(self, context):\n        print(\"Wait for the build job at {0} to finish\".format(self.build_url))\n        wait_for_enter()\n\nclass RetrieveUserEmailStep(object):\n    dir_url = \"http://example.com/directory\"\n    def run(self, context):\n        print(\"Go to {0}\".format(self.dir_url))\n        print(\"Find the email address for user `{0}`\".format(context[\"username\"]))\n        context[\"email\"] = raw_input(\"Paste the email address and press enter: \")\n\nclass SendPrivateKeyStep(object):\n    def run(self, context):\n        print(\"Go to 1Password\")\n        print(\"Paste the contents of ~/new_key into a new document\")\n        print(\"Share the document with {0}\".format(context[\"email\"]))\n        wait_for_enter()\n\nif __name__ == \"__main__\":\n    context = {\"username\": sys.argv[1]}\n    procedure = [\n        CreateSSHKeypairStep(),\n        GitCommitStep(),\n        WaitForBuildStep(),\n        RetrieveUserEmailStep(),\n        SendPrivateKeyStep(),\n    ]\n    for step in procedure:\n        step.run(context)\n    print(\"Done.\")\n</pre></div><p>This script doesn‚Äôt actually  any of the steps of the procedure. That‚Äôs why it‚Äôs called a do-nothing script. It feeds the user a step at a time and waits for them to complete each step manually.</p><p>At first glance, it might not be obvious that this script provides value. Maybe it looks like all we‚Äôve done is make the instructions harder to read. But the value of a do-nothing script is immense:</p><ul><li>It‚Äôs now much less likely that you‚Äôll lose your place and skip a step. This makes it easier to maintain focus and power through the slog.</li><li>Each step of the procedure is now encapsulated in a function, which makes it possible to replace the text in any given step with code that performs the action automatically.</li><li>Over time, you‚Äôll develop a library of useful steps, which will make future automation tasks more efficient.</li></ul><p>A do-nothing script doesn‚Äôt save your team any manual effort. It lowers the activation energy for automating tasks, which allows the team to eliminate toil over time.</p>","contentLength":4783,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42976698"},{"title":"Show HN: A website that heatmaps your city based on your housing preferences","url":"https://theretowhere.com/","date":1738952620,"author":"WiggleGuy","guid":174,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42975803"},{"title":"Cities can cost effectively start their own utilities","url":"https://kevin.burke.dev/kevin/norcal-cities-new-utility/","date":1738950940,"author":"kevinburke","guid":180,"unread":true,"content":"<p>PG&amp;E's rates are high enough that, even with the massive headache and expense\ninvolved, it's feasible for cities to create their own utility and undercut\nPG&amp;E's rates. When the savings per household are around $800-$1200 per\nyear, though, they should take it seriously.</p><p>Here are the basic components of how much it costs to get electricity to your\nhouse.</p><ul><li><p> The cost to actually generate the electricity in a power plant\nor utility-scale solar farm. This varies by time of day but typically costs\nabout 4 cents per kilowatt hour; you can see the current wholesale rate on <a href=\"https://www.caiso.com/todays-outlook/prices\">the\nCAISO website</a>.</p></li><li><p> How much it costs to move the power from the power source to\na local substation/transformer, over large transmission lines. PG&amp;E breaks this\nout in its detailed rate chart at about 4 cents per kilowatt hour.</p></li><li><p> How much to get the power from your local substation to your\nhouse over local power lines. In PG&amp;E's rate chart, they charge <em>20 cents per\nkilowatt hour</em> for this. That just does not match up with how much it actually\ncosts them to transmit power over local lines and keep the lines maintained.</p></li><li><p> Operations, maintenance, profit. This is where PG&amp;E is\nactually seeing large expenses, because their coverage area is massive, it\ncosts a lot of money to deliver power to rural customers, and they are also\nundertaking a massive project to underground utility lines in fire-prone areas.</p></li></ul><p>The high price and design of the electricity system have a number of bad\neffects:</p><ul><li><p>People really hate inflation. When utility bills spike, it makes people\nunhappy and also fuels the (not incorrect) perception that California is poorly\ngoverned.</p></li><li><p>Lower income people spend a higher percentage of their income on electricity,\nso higher utility bills disproportionately hurt them.</p></li><li><p>The net effect of charging higher rates to everyone to pay for undergrounding\nis that people who live in urban areas are paying more money to subsidize\nenergy transmission for people who live in $2 million houses in places like the\nBerkeley and Orinda hills. This makes no sense.</p></li><li><p>Higher rates for electricity make electricity less competitive vs. gasoline\nwhen people are considering a car purchase. It makes electricity less\ncompetitive vs. natural gas for heating a house, heating water, or choosing a\nlaundry machine. As gas is warming the planet and electricity is substantially\neasier to generate in abundance from renewable sources, it's just bad policy to\nhave high electricity rates.</p></li></ul><p>Let's walk through what this might look like for a particular city to undercut\nPG&amp;E's rates. I will pick Walnut Creek because it's a reasonably big city with\na good mix of detached homes and multifamily. Walnut Creek also has experience\nwith public ownership of amenities - the City operates a golf course and a\ndowntown parking garage with ground floor retail.</p><p>There are a number of particular problems with applying PG&amp;E's rates to Walnut\nCreek:</p><ul><li><p>Walnut Creek is an urban area with a compact footprint that has little acreage\nin a high severity wildfire zone. It has two transmission lines as well as a\nlocal transformer grid along Ygnacio Valley Road. It is very cheap to transmit\npower from power plants to Walnut Creek, and from transmission lines to every\nhouse in Walnut Creek.</p></li><li><p>Walnut Creek has an above average number of apartments. Apartments do not\nhave as much space for rooftop solar, and landlords don't have an incentive to\nprovide rooftop solar because they typically pass through utility costs. This\nmeans NEM1 and NEM2 subsidies ‚Äî <a href=\"https://lao.ca.gov/reports/2025/4950/Residential-Electricity-Rates-010725.pdf#page=8\">12% of the average non-solar bill</a>\n‚Äî disproportionately hurt Walnut Creek renters.</p></li><li><p>Local businesses have disproportionately high energy costs. Safeway and Whole\nFoods need to keep a row of refrigerators and freezers running 24/7. When they\npay PG&amp;E's rates to do that, those high energy costs are passed through as\nhigher food prices.</p></li></ul><p>Palo Alto's total electric consumption was 830 gigawatt hours in 2024 - 19% of\nthis usage was residential, and 81% was businesses and industry uses. Applying\nsome adjustments for Walnut Creek - our population is bigger, it's a bit hotter\nhere, and energy use has increased - let's say Walnut Creek uses about 1150\ngigawatt hours per year.</p><p>Palo Alto earned $172 million in revenue for 830 gigawatt hours, which is about\n20 cents per kilowatt hour.</p><p>Here's where Palo Alto's utility company spends money:</p><h4>Acquisition of the network and financing cost</h4><p>The first thing you need to do is buy out PG&amp;E's distribution network - all of\nthe power poles and local equipment that sits between the transmission lines and\npeople's houses. San Francisco proposed buying this for $2.5 billion in 2019;\nPG&amp;E rejected this offer for being too low. Adjusted for inflation and Walnut\nCreek's population, this is about $230 million, let's round up and say $350\nmillion. Let's also assume it costs $50 million in startup costs and one time\nexpenses to hire utility staff, buy equipment, marketing expense.</p><p>Cities with an AA credit rating can issue a 30 year loan at about 4% interest.\nBorrowing $400 million would cost about $23 million per year in interest and\nprincipal payments.</p><p>$23 million per year of financing cost spread across 1150 gigawatt hours is\nonly about 2 cents per kilowatt hour.</p><h4>Generation and distribution</h4><p>Palo Alto spent $114 million buying energy in 2024, about 14 cents per kilowatt\nhour. Let's assume Walnut Creek can get power for about 17 cents per kWh.</p><p>This covers customer service, financial management, billing, engineering work\nfor maintenance (tree trimming etc), and resource management. Palo Alto spent\n$65 million on these expenses in 2023. Let's assume Walnut Creek's costs are\nmuch higher at $90 million per year. This is about 8 cents per kilowatt hour.</p><p>Another $25 million per year is allocated for grid modernization,\nundergrounding, and reliability work. Let's assume this is $35 million per year\nfor Walnut Creek, which would be about 3 cents per kilowatt hour.</p><p>Adding this up, we get 30 cents per kilowatt hour, which is ten cents lower than\nPG&amp;E's base rate and about 15 cents lower than PG&amp;E's blended rate. At 1150\ngigawatt hours, <em>this would save Walnut Creek residential ratepayers about $23\nmillion per year in total, about $800 per ratepayer, and Walnut Creek businesses\nabout $92 million per year.</em> That is a  amount of money that could go\ntoward much more productive uses - paying higher salaries, lowering prices for\ngoods, spending more at local businesses.</p><p>Most elected officials would jump at the chance to mail every household a $800\ncheck every year. The next best thing is to put $800 back in their pocket.</p><h3>Other Benefits for Walnut Creek</h3><p>There are huge ancilliary benefits for Walnut Creek to running its own utility\nnetwork.</p><ul><li><strong>Green infrastructure investments:</strong> Walnut Creek has made sustainability a\nkey priority. Palo Alto owns a share in a hydroelectric dam, and Santa Clara\nowns a share in a geothermal plant. At a time when there are exciting new\ntechnologies that have the potential to reduce greenhouse gas emissions and\ndeliver clean, cheap energy to residents - things like Fervo Energy that <a href=\"https://www.washingtonpost.com/climate-environment/interactive/2024/fracking-geothermal-energy-plant-technology/\">use\nthe tech behind fracking to deliver geothermal power</a> - Walnut\nCreek can use its very low cost of capital to finance these investments. <strong>This\nis something PG&amp;E cannot do as effectively, because as a public utility with\nmassive amounts of debt and wildfire liability, their borrowing cost is much\nhigher.</strong> Public ownership would enable transformative green energy investments\nwith a low borrowing cost.</li></ul><ul><li><p><strong>Encouraging the green transition:</strong> A 25% reduction in the cost of\nelectricity relative to natural gas would make electric upgrades like heat pump\nwater heaters or electric cars much more financially prudent investments.</p></li><li><p> Like every city in California, Walnut Creek has boom\nand bust cycles. Utilities have much more stable revenues than cities. Walnut\nCreek could borrow from its utility in recessions, and loan money during booms.</p></li><li><p> Walnut Creek has a number of unincorporated\npockets (<a href=\"https://en.wikipedia.org/wiki/San_Miguel,_Contra_Costa_County,_California\">San Miguel CDP</a>, Shell Ridge CDP) that\nadministratively make little sense - they are served by different police,\nthey have different tax rules. If these homes could save $800 per year on\ntheir utility bill by joining Walnut Creek, this may provide an incentive to\nincorporate, which would ultimately lead to better governance.</p></li></ul><ul><li><p>Even if Walnut Creek doesn't ultimately pursue its own utility, just\ninvestigating the possibility may lead PG&amp;E to <em>offer concessions such as\nundergrounding the transmission line over downtown.</em> Because you can't\nbuild under a transmission line, this makes a 100 foot wide strip of very\nvaluable land undevelopable. St. Paul's would love to redevelop its parking\nlot under the transmission line for affordable housing, but can only develop\ntiny corners of the lot with the transmission line overhead. Undergrounding\nthe line would deliver huge benefits to Walnut Creek.</p></li><li><p><strong>Lowering the cost of urban living in safe places:</strong> PG&amp;E's current rate\nstructure has urban rate payers subsidize rural rate payers and people who live\nin wildfire zones in e.g. the Orinda Hills, who need substantial investment in\norder to receive power without sparking wildfires. This is bad policy - instead\nof subsidizing fire zones, it should be cheap to live in safe places and more\nexpensive to live in dangerous places. Lower cost of electricity would reverse\nthese trends.</p></li></ul><p>California is kneecapping its own climate transition with high electricity\nprices. The resulting inflation hurts our state's ability to retain a high\nclass, diverse workforce. Perversely, it also serves as a subsidy to wildfire\nzones at the expense of infill areas. It's time to reverse those trends and\ndeliver lower energy prices in places we want more Californians to live.</p><p><strong>What should I do if I want this to happen?</strong> Cities around the region are\ndoing \"priority setting\" exercises for 2025. Contact your Mayor or City\nCouncil and ask them to explore the possibility of creating their own utility,\npotentially partnering with other cities. I would probably select cities that do\nnot have large fire zones (ie, not Orinda or Moraga).</p>","contentLength":10023,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42975492"}],"tags":["dev"]}