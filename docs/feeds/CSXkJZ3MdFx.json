{"id":"CSXkJZ3MdFx","title":"Dev News","displayTitle":"Dev News","url":"","feedLink":"","isQuery":true,"isEmpty":false,"isHidden":false,"itemCount":58,"items":[{"title":"No, your GenAI model isn't going to replace me","url":"https://marioarias.hashnode.dev/no-your-genai-model-isnt-going-to-replace-me","date":1739639200,"author":"/u/dh44t","guid":622,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1iq5wq0/no_your_genai_model_isnt_going_to_replace_me/"},{"title":"Type safe Go money library beta2!","url":"https://www.reddit.com/r/golang/comments/1iq5stk/type_safe_go_money_library_beta2/","date":1739638928,"author":"/u/HawkSecure4957","guid":479,"unread":true,"content":"<p>Hello, after I released beta1, I received many constructive feedback! mainly lacking of locale support.</p><p>This update brings locale formatting support and an improved interface for better usability. With Fulus, you can perform monetary operations safely and type-soundly. Plus, you can format money for any locale supported by CLDR. You can even define custom money types tailored specifically to your application's needs! </p><p>I still need to battle test it against production projects, I have none at the moment. I am aiming next for performance benchmarking and more improvement, and parsing from string!</p><p>I am open for more feedback. Thank you! </p>","contentLength":639,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"TIL There is a minor-planet called Linux","url":"https://www.reddit.com/r/linux/comments/1iq5p1p/til_there_is_a_minorplanet_called_linux/","date":1739638670,"author":"/u/forvirringssirkel","guid":615,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Deepseek R1 Distill 8B Q40 on 4 x Raspberry Pi 5, 6.43 tok/s (eval 11.68 tok/s)","url":"https://github.com/b4rtaz/distributed-llama/discussions/162","date":1739635889,"author":"b4rtazz","guid":213,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43059579"},{"title":"Carbon capture more costly than switching to renewables, researchers find","url":"https://techxplore.com/news/2025-02-carbon-capture-renewables.html","date":1739631990,"author":"Brajeshwar","guid":212,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43058997"},{"title":"Dust from Car Brakes More Harmful Than Exhaust, Study Finds","url":"https://e360.yale.edu/digest/brake-pads-lung-damage-study","date":1739631975,"author":"Brajeshwar","guid":211,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43058993"},{"title":"Alexandre Mutel a.k.a. xoofx is leaving Unity","url":"https://mastodon.social/@xoofx/113997304444307991","date":1739631212,"author":"/u/namanyayg","guid":620,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1iq2zwv/alexandre_mutel_aka_xoofx_is_leaving_unity/"},{"title":"Don't \"optimize\" conditional moves in shaders with mix()+step()","url":"https://iquilezles.org/articles/gpuconditionals/","date":1739631147,"author":"/u/namanyayg","guid":621,"unread":true,"content":"\nIn this article I want to correct a popular misconception that's been making the rounds in computer graphics aficionado circles for a long time now. It has to do with conditionals when selecting between two results in the GPUs. Unfortunately there are a couple of educational websites out there that are spreading some misinformation, and it would be nice correcting that. I tried contacting the authors without success, so without further ado, here goes my attempt to fix things up a little:\nSo, say I have this code, which I actually published the other day:<div> snap45(  v )\n{\n     s = (v);\n     x = (v.x);\n     x&gt;?(s.x,):\n           x&gt;?s*():\n                      (,s.y);\n}</div>\nThe exact details of what it does don't matter for this discussion. All we care about is the two ternary operations deciding what's the final value this function should return. Indeed, depending on the value of the variable , the function will return one of three results, which are simple to compute. I could also have implemented this function with regular  statements, and all that I'm going to say in this article stays true.<p>\nNow, here's the problem - when seeing code like this, somebody somewhere will step up and invariably propose the following \"optimization\", which replaces what they believe (erroneously) are \"conditional branches\" in the code, by arithmetic operations. They will suggest something like this:</p><div> snap45(  v )\n{\n     s = (v);\n     x = (v.x);\n\n     w0 = (,x);\n     w1 = (,x)*(-w0);\n     w2 = -w0-w1;\n\n     res0 = (s.x,);\n     res1 = (s.x,s.y)*();\n     res2 = (,s.y);\n\n     w0*res0 + w1*res1 + w2*res2;\n}</div>\nThere are two things wrong with this practice. The first one shows an incorrect understanding of how the GPU works. In particular, the original shader code had no conditional branching in it. Selecting between a few registers with a ternary operator or with a plain  statement does not lead to conditional branching; all it involves is a conditional move (a.k.a. \"select\"), which is a simple instruction to route the correct bits to the destination register. You can think of it as a bitwise AND+NAND+OR on the source registers, which is a simple combinational circuit. I'll repeat it again - there is no branching, the instruction pointer isn't manipulated, there's no prediction involved, no pipe to flush, no instruction cache to invalidation, no nothing.<p>\nFor the record, of course GPUs can do real branching, and those are fine and fast and totally worth it when big chunks of code and computation are to be skipped given a condition. As with all things computing, always check the generated machine code to know what is happening exactly and when. But one thing you can safely assume without having to check any generated code - when moving simple values or computations like in my original example, you are guaranteed to not branch. This has been true for decades at this point, with GPUs. And while I'm not an expert in CPUs, I am pretty sure this is true for them as well.</p><p>\nThe second wrong thing with the supposedly optimized version is that it actually runs much slower than the original version. You can measure it in a variety of hardware. I can only assume that's because the </p> function is probably implemented with some sort of conditional move or subtract + bit propagation + AND.<div> step(  x,  y )\n{\n     x &lt; y ?  : ;\n}</div>\nEither way, using the step() \"optimization\" are either using the ternary operation anyways, which produces the  or  which they will use to mask in and out the different potential outputs with a series of arithmetic multiplications and additions. Which is wasteful, the values could have been conditionally moved directly, which is what the original shader code did.<p>\nBut don't take my word for it, let's look at the generated machine code for the original code I published:</p><div><div>\nGLSL<div> x&gt;?(s.x,):\n       x&gt;?s*():\n                  (,s.y);</div></div><div>\nAMD Compiler<div>     s0,      v3, , v1\n     v4, , v0\n     s1,   vcc, (v2), s0\n v3, 0, v3, vcc\n v0, v0, v4, vcc\n vcc, (v2), s1\n v1, v1, v3, vcc\n v0, 0, v0, vcc</div></div><div>\nMicrosoft Compiler<div>   r0.xy, l(, ), v0.xy\n   r0.zw, v0.xy, l(, )\n r0.xy, -r0.xyxx, r0.zwzz\n r0.xy, r0.xyxx\n  r1.xyzw, r0.xyxy, l4()\n   r2.xy, l(,), v0.xx  r0.z, l()\n r1.xyzw, r2.yyyy, r1.xyzw, r0.zyzy\n o0.xyzw, r2.xxxx, r0.xzxz, r1.xyzw</div></div></div>\nHere we can confirm that the GPU is not branching, as I explained. Instead, according to the AMD compiler, it's performing the required comparisons ( and  - cmp=compare, gt=greater than, ngt=not greated than), and then using the result to mask the results with the bitwise operations mentioned earlier ( - cnd=conditional).<p>\nThe Microsoft compiler has expressed the same idea/implementation in a different format, but you can still see the comparison (</p> - \"lt\"=less than) and the masking or conditional move ( - mov=move, c=conditionally).<p>\nThere are no jump/branch instructions in these listings.</p><p>\nSomething not related to the discussion but interesting, is that some of the </p> GLSL calls I had in my shader before the ternary operator we are discussing, didn't become GPU instructions but rather instruction modifiers, which is the reason you see them in the listing. This means you can think of abs() calls as being free.\nSo, if you ever see somebody proposing this<div> a = ( b, c, ( y, x ) );</div>\nas an optimization to\nthen please correct them for me.","contentLength":5296,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1iq2z4j/dont_optimize_conditional_moves_in_shaders_with/"},{"title":"What is Event Sourcing?","url":"https://newsletter.scalablethread.com/p/what-is-event-sourcing","date":1739628306,"author":"/u/scalablethread","guid":625,"unread":true,"content":"<p>Traditional data storage typically focuses on the current state of an entity. For example, in an e-commerce system, you might store the current state of a customer's order: items, quantities, shipping address, etc. Event sourcing takes a different approach. Instead of storing the current state directly, it stores the events that led to that state. Each event represents a fact that happened in the past. Think of it as a detailed log of transactions on your bank statement. These events are immutable and stored in an append-only event store. The core idea is that an application's state can be derived by replaying events in the order they occurred, just like you can get your current bank balance by replaying all the transactions from the beginning. This makes Event Sourcing particularly useful for applications that require a high degree of audibility and traceability.</p><p>Every change to the application state is captured as an event object in an Event Sourcing system. These events are then stored in an event store, a database optimized for handling event data. Here's a step-by-step breakdown of how Event Sourcing works:</p><ol></ol><p>Reconstructing the state from events involves reading all the events related to an entity from the event store and applying them in sequence to reconstruct the current state. It's like simulating all the changes that have occurred to construct the current state. For example, consider an e-commerce application where an order goes through various states like \"Created,\" \"Paid,\" and \"Shipped.\" To determine the current state of an order, you would:</p><ol><li><p>Retrieve all events related to the order from the event store.</p></li><li><p>Initialize an empty order object.</p></li><li><p>Apply each event to the order object in the order in which they were stored.</p></li></ol><p>By the end of this process, the order object will reflect the current state of the order.</p><p>As the number of events grows, replaying the entire event stream to reconstruct the state can become slow and inefficient. This is where snapshots come in. A snapshot is a saved state of an entity at a specific point in time. Instead of replaying all events from the beginning, the application can load the latest snapshot and then replay only the events that occurred after the snapshot was taken. </p><ul></ul><ul></ul><p><em>If you enjoyed this article, please hit the ‚ù§Ô∏è like button.</em></p><p><em>If you think someone else will benefit from this, then please üîÅ share this post.</em></p>","contentLength":2380,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1iq20v8/what_is_event_sourcing/"},{"title":"Diablo hackers uncovered a speedrun scandal","url":"https://arstechnica.com/gaming/2025/02/the-diablo-hackers-that-debunked-a-record-speedrun/","date":1739628000,"author":"pitwin","guid":210,"unread":true,"content":"<p>But simply splitting a run into segments doesn't explain away all of the problems the TAS team found. Getting Naj's Puzzler on dungeon level 9, for instance, still requires outside modification of a save file, which is specifically prohibited by <a href=\"https://kb.speeddemosarchive.com/Rules\">longstanding Speed Demos Archive rules</a> that \"manually editing/adding/removing game files is generally not allowed.\" Groobo's apparent splicing of multiple game versions and differently seeded save files also seems to go against SDA rules, which say that \"there obviously needs to be continuity between segments in terms of inventory, experience points or whatever is applicable for the individual game.\"</p><p>After being presented with the TAS team's evidence, SDA <a href=\"https://speeddemosarchive.com/\">wrote</a> that \"it has been determined that Groobo's run very likely does not stem from only legitimate techniques, and as such, has itself been banished barring new developments.\" But Groobo's record is <a href=\"https://www.guinnessworldrecords.com/world-records/110580-fastest-completion-of-an-rpg-videogame\">still listed as the \"Fastest completion of an RPG videogame\"</a> by Guinness World Records, which has not offered a substantive response to the team's findings (Guinness has not responded to a request for comment from Ars Technica).</p><figure><div><div>\n      A recent  speedrun on a confirmed legitimate dungeon seed.\n\n          </div></div></figure><p>This might seem like a pretty petty issue to spend weeks of time and attention debunking. But at a recent presentation attended by Ars, Cecil said he was motivated to pursue it because \"it did harm. Groobo's alleged cheating in 2009 completely stopped interest in speedrunning this category [of ]. No one tried, no one could.\"</p><p>Because of Groobo's previously unknown modifications to make an impossible-to-beat run, \"this big running community just stopped trying to run this game in that category,\" Cecil said. \"For more than a decade, this had a chilling impact on that community.\" With Groobo's run out of the way, though, new runners are <a href=\"https://www.youtube.com/watch?v=bXG1vW6VEKA\">setting new records on confirmed legitimate RNG seeds</a>, and <a href=\"https://www.youtube.com/watch?v=F9mn5CpQCFw\">with the aid of TAS tools</a>.</p><p>In the end, Cecil said he hopes the evidence regarding Groobo's run will make people look more carefully at other record submissions. \"Groobo had created a number of well-respected ... speedruns,\" he said. \"[People thought] there wasn't any good reason to doubt him. In other words, there was bias in familiarity. This was a familiar character. Why would they cheat?\"</p>","contentLength":2302,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43058522"},{"title":"Career transition in to Kubernetes","url":"https://www.reddit.com/r/kubernetes/comments/1iq1ka1/career_transition_in_to_kubernetes/","date":1739626865,"author":"/u/Similar-Secretary-86","guid":611,"unread":true,"content":"<p>\"I've spent the last six months working with Docker and Kubernetes to deploy my application on Kubernetes, and I've successfully achieved that. Now, I'm looking to transition into a Devops Gonna purchase kode cloud pro for an year is worth for money ? Start from scratch like linux then docker followed by kubernetes then do some certification Any guidance here would be appreciated </p>","contentLength":383,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Built a cli tool for generating .gitignore files","url":"https://www.reddit.com/r/golang/comments/1iq1ivv/built_a_cli_tool_for_generating_gitignore_files/","date":1739626739,"author":"/u/SoaringSignificant","guid":478,"unread":true,"content":"<p>I built this mostly as an excuse to play around with Charmbracelet‚Äôs libraries like Bubble Tea and make a nice TUI, but it also solves the annoying problem of constantly looking up .gitignore templates. It‚Äôs a simple CLI tool that lets you grab templates straight from GitHub, TopTal, or even your own custom repository, all from the terminal. You can search through templates using a TUI interface, combine multiple ones like mixing Go and CLion, and even save your own locally so you don‚Äôt have to redo them every time. If you‚Äôre always setting up new projects and find yourself dealing with .gitignore files over and over, this just makes life a bit easier, hopefully. If that sounds useful, check it out <a href=\"https://github.com/jasonuc/gignr\">here</a> and give it a try. And if you‚Äôve got ideas to make the TUI better or want to add something cool, feel free to open a PR. Always happy to get feedback or contributions!</p>","contentLength":890,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Karol Herbst steps down as Nouveau maintainer due to ‚Äúthin blue line comment‚Äù","url":"https://www.reddit.com/r/linux/comments/1iq09g6/karol_herbst_steps_down_as_nouveau_maintainer_due/","date":1739622250,"author":"/u/mdedetrich","guid":619,"unread":true,"content":"<p>\"I was pondering with myself for a while if I should just make it official that I'm not really involved in the kernel community anymore, neither as a reviewer, nor as a maintainer.</p><p>Most of the time I simply excused myself with \"if something urgent comes up, I can chime in and help out\". Lyude and Danilo are doing a wonderful job and I've put all my trust into them.</p><p>However, there is one thing I can't stand and it's hurting me the most. I'm convinced, no, my core believe is, that inclusivity and respect, working with others as equals, no power plays involved, is how we should work together within the Free and Open Source community.</p><p>I can understand maintainers needing to learn, being concerned on technical points. Everybody deserves the time to understand and learn. It is my true belief that most people are capable of change eventually. I truly believe this community can change from within, however this doesn't mean it's going to be a smooth process.</p><p>The moment I made up my mind about this was reading the following words written by a maintainer within the kernel community:</p><p>\"we are the thin blue line\"</p><p>This isn't okay. This isn't creating an inclusive environment. This isn't okay with the current political situation especially in the US. A maintainer speaking those words can't be kept. No matter how important or critical or relevant they are. They need to be removed until they learn. Learn what those words mean for a lot of marginalized people. Learn about what horrors it evokes in their minds.</p><p>I can't in good faith remain to be part of a project and its community where those words are tolerated. Those words are not technical, they are a political statement. Even if unintentionally, such words carry power, they carry meanings one needs to be aware of. They do cause an immense amount of harm.</p><p>I wish the best of luck for everybody to continue to try to work from within. You got my full support and I won't hold it against anybody trying to improve the community, it's a thankless job, it's a lot of work. People will continue to burn out.</p><p>I got burned out enough by myself caring about the bits I maintained, but eventually I had to realize my limits. The obligation I felt was eating me from inside. It stopped being fun at some point and I reached a point where I simply couldn't continue the work I was so motivated doing as I've did in the early days.</p><p>Please respect my wishes and put this statement as is into the tree. Leaving anything out destroys its entire meaning.</p>","contentLength":2492,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Building the MagicMirror in Rust with iced GUI Library ü¶Ä","url":"https://www.reddit.com/r/rust/comments/1ipzubj/building_the_magicmirror_in_rust_with_iced_gui/","date":1739620595,"author":"/u/amindiro","guid":629,"unread":true,"content":"<p>I recently embarked on a journey to build a custom MagicMirror using the Rust programming language, and I‚Äôd like to share my experiences. I wrost a blog post titled <a href=\"https://aminediro.com/posts/mirrors/#mirrors\">\"software you can love: miroir √î mon beau miroir\"</a> this project was my attempt to create a stable, resource-efficient application for the Raspberry Pi 3A.</p><p>Here's what I loved about using Rust and the iced GUI library:</p><ul><li><p><strong>Elm Architecture + Rust is a match made in heaven:</strong> iced was perfect for my needs with its Model, View, and Update paradigms. It helped keep my state management concise and leverage Rust type system</p></li><li><p> Opting for this lightweight rendering library reduced the size of the binary significantly, ending with a 9MB binary.</p></li><li><p> Although troublesome at first, I used ‚Äòcross‚Äô to cross compile Rust for armv7.</p></li></ul><p>If anyone is keen, I‚Äôm thinking of open-sourcing this project and sharing it with the community. Insights on enhancing the project's functionality or any feedback would be much appreciated!</p><p>Feel free to reach out if you're interested in the technical nitty-gritty or my experience with Rust GUI libraries in general.</p>","contentLength":1098,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"My new blog post comparing networking in EKS vs. GKE","url":"https://www.reddit.com/r/kubernetes/comments/1ipz55k/my_new_blog_post_comparing_networking_in_eks_vs/","date":1739617569,"author":"/u/jumiker","guid":612,"unread":true,"content":"   submitted by   <a href=\"https://www.reddit.com/user/jumiker\"> /u/jumiker </a>","contentLength":30,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Richard Stallman in Polytechnic University of Turin, Italy","url":"https://www.reddit.com/r/linux/comments/1ipz4wy/richard_stallman_in_polytechnic_university_of/","date":1739617538,"author":"/u/ShockleyTransistor","guid":618,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Deep Dive into VPA Recommender","url":"https://www.reddit.com/r/kubernetes/comments/1ipylpu/deep_dive_into_vpa_recommender/","date":1739615164,"author":"/u/erik_zilinsky","guid":613,"unread":true,"content":"<p>I wanted to understand how the Recommender component of the VPA (Vertical Pod Autoscaler) works - specifically, how it aggregates CPU/Memory samples and calculates recommendations. So, I checked its source code and ran some debugging sessions.</p><p>Based on my findings, I wrote a <a href=\"https://erikzilinsky.com/posts/vpa1.html\">blog post</a> about it, which might be helpful if you're interested in how the Recommender's main loop works under the hood.</p>","contentLength":395,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"what do you use golang for?","url":"https://www.reddit.com/r/golang/comments/1ipykyd/what_do_you_use_golang_for/","date":1739615068,"author":"/u/Notalabel_4566","guid":482,"unread":true,"content":"<p>Is there any other major use than web development?</p>","contentLength":50,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Show HN: Kreuzberg ‚Äì Modern async Python library for document text extraction","url":"https://github.com/Goldziher/kreuzberg","date":1739614043,"author":"nhirschfeld","guid":196,"unread":true,"content":"<p>I'm excited to showcase Kreuzberg!</p><p>Kreuzberg is a modern Python library built from the ground up with async/await, type hints, and optimized I/O handling.</p><p>It provides a unified interface for extracting text from documents (PDFs, images, office files) without external API dependencies.</p><p>Key technical features:\n- Built with modern Python best practices (async/await, type hints, functional-first)\n- Optimized async I/O with anyio for multi-loop compatibility\n- Smart worker process pool for CPU-bound tasks (OCR, doc conversion)\n- Efficient batch processing with concurrent extractions\n- Clean error handling with context-rich exceptions</p><p>I built this after struggling with existing solutions that were either synchronous-only, required complex deployments, or had poor async support. The goal was to create something that works well in modern async Python applications, can be easily dockerized or used in serverless contexts, and relies only on permissive OSS.</p><p>Key advantages over alternatives:\n- True async support with optimized I/O\n- Minimal dependencies (much smaller than alternatives)\n- Perfect for serverless and async web apps\n- Local processing without API calls\n- Built for modern Python codebases with rigorous typing and testing</p><p>The library is MIT licensed and open to contributions.</p>","contentLength":1289,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43057375"},{"title":"Linux in any distribution is unobtainable for most people because the first two installation steps are basically impossible.","url":"https://www.reddit.com/r/linux/comments/1ipyc1o/linux_in_any_distribution_is_unobtainable_for/","date":1739613947,"author":"/u/trollfinnes","guid":617,"unread":true,"content":"<p>Recently, just before Christmas, I decided to check out Linux again (tried it ~20 years ago) because Windows 11 was about to cause an aneurysm.</p><p>I was expecting to spend the \"weekend\" getting everything to work; find hardware drivers, installing various open source software and generally just 'hack together something that works'.</p><p>To my surprise everything worked flawlessly first time booting up. I had WiFi, sound, usb, webcam, memory card reader, correct screen resolution. I even got battery status and management! It even came with a nice litte 'app center' making installation of a bunch of software as simple as a click!</p><p>And I remember thinking any Windows user could  install Linux and would get comfortable using it in an afternoon.</p><p>I'm pretty 'comfortable' in anything PC and have changed boot orders and created bootable things since the early 90's and considered that part of the installation the easiest part.</p><p>However, most people have never heard about any of them, and that makes the two steps seem 'impossible'.</p><p>I recently convinced a friend of mine, who also couldn't stand Window11, to install Linux instead as it would easily cover all his PC needs. </p><p>And while he is definitely in the upper half of people in terms of 'tech savvyness', both those \"two easy first steps\" made it virtually impossible for him to install it. </p><p>He easily managed downloading the .iso, but turning that iso into a bootable USB-stick turned out to be too difficult. But after guiding him over the phone he was able to create it.</p><p>But he wasn't able to get into bios despite all my attempts explaining what button to push and when</p><p>Next day he came over with his laptop. And just out of reflex I just started smashing the F2 key (or whatever it was) repeatingly and got right into bios where I enabled USB boot and put it at the top at the sequence.</p><p>After that he managed to install Linux just fine without my supervision.</p><p>But it made me realise that the two first steps in installing Linux, that are second nature to me and probably everyone involved with Linux from people just using it to people working on huge distributions, makes them virtually impossible for most people to install it.</p><p>I don't know enough about programming to know of this is possible:</p><p>Instead of an .iso file for download some sort of .exe file can be downloaded that is able to create a bootable USB-stick and change the boot order?</p><p>That would 'open up' Linux to  more people, probably orders of magnitude..</p>","contentLength":2460,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Jane Street's Figgie card game","url":"https://www.figgie.com/","date":1739613560,"author":"eamag","guid":209,"unread":true,"content":"<p><a href=\"https://www.janestreet.com/\">Jane Street</a>'s fast-paced\n              Figgie game simulates exciting elements of markets and trading. At\n              Jane Street, Figgie is a game we teach and also one we really\n              enjoy playing.\n            </p><p><a href=\"https://www.figgie.com/faqs.html\">Read our FAQs</a>\n              for more. If you have a question that isn‚Äôt answered there, we‚Äôd\n              like to hear\n              <a href=\"mailto:figgie@janestreet.com\">what‚Äôs missing</a> and what\n              would be helpful to know, and we‚Äôll do our best to update FAQs\n              along the way.\n            </p>","contentLength":507,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43057344"},{"title":"Lessons from David Lynch: A Software Developer's Perspective","url":"https://lackofimagination.org/2025/02/lessons-from-david-lynch-a-software-developers-perspective/","date":1739612430,"author":"/u/aijan1","guid":624,"unread":true,"content":"<p>David Lynch passed away in January 2025, shortly after being evacuated from his Los Angeles home due to the Southern California wildfires. He‚Äôs perhaps best known for the groundbreaking TV series <a href=\"https://en.wikipedia.org/wiki/Twin_Peaks\">Twin Peaks</a>, which inspired countless shows, including The X-Files, The Sopranos, and Lost.</p><p>Lynch was genuinely a good human being who cared deeply for his actors and crew. He discovered extraordinary talent like Naomi Watts, who had struggled to land a major role in a Hollywood movie after 10 years of auditioning. From the interviews he gave, it quickly becomes apparent that he respected people of all kinds and never put anyone down ‚Äì even those who truly deserved it.</p><p>Lynch is famous for refusing to explain his movies. Although not a fan of his previous work, the great film critic Roger Ebert once wrote that <a href=\"https://en.wikipedia.org/wiki/Mulholland_Drive_(film)\">Mulholland Drive</a> remained compulsively watchable while refusing to yield to interpretation.</p><p>While Lynch offered very little in terms of what his movies meant, he was generous in sharing his views on creativity, work, and life in general. As a tribute to Lynch, I‚Äôd like to share my perspective on his life lessons from a software developer‚Äôs viewpoint.</p><blockquote><p>Ideas are like fish. If you want to catch little fish, you can stay in the shallow water. But if you want to catch the big fish, you‚Äôve got to go deeper.</p></blockquote><p>We‚Äôve all got hundreds or even thousands of ideas floating around in our brains. But the really big ones are few and far between. Once you catch a good one ‚Äìbecause they‚Äôre so rare‚Äì write it down immediately, says Lynch. From there, ideas attract other ideas and start to grow from their initial seed state. The final job is to translate those ideas into a medium, whether it‚Äôs a film, a painting, or software.</p><blockquote><p>The idea is the whole thing. If you stay true to the idea, it tells you everything you need to know, really. You just keep working to make it look like that idea looked, feel like it felt, sound like it sounded, and be the way it was.</p></blockquote><p>Software development is part art, part engineering. We don‚Äôt build the same software over and over again ‚Äì virtually all software is crafted by hand, sometimes with help from AI. If you ask two developers to create a non-trivial program, it‚Äôs very likely that the programs they produce will be different, even if the functionality is the same. Under the hood, the programming language, data structures, and overall architecture may be completely different. And on the surface, the user interfaces may look nothing alike.</p><p>It‚Äôs a good habit to listen to what users have to say, but they often can only describe their problems ‚Äì they rarely come up with good ideas to solve them. And that‚Äôs OK. It‚Äôs our job to find the right ideas, implement them well, and solve tricky problems in a way we, and hopefully the users, will love.</p><blockquote><p>My friend Bushnell Keeler, who was really responsible for me wanting to be a painter, said you need four hours of uninterrupted time to get one hour of good painting in, and that is really true.</p></blockquote><p>Like other creative fields, writing code requires deep concentration. We need to hold complex structures in our minds while working through problems. Switching between coding and other tasks disrupts  ‚Äì that magical state of mind where we lose track of time and produce code effortlessly. That‚Äôs why many developers hate meetings ‚Äì they are toxic to our productivity.</p><blockquote><p>I believe you need technical knowledge. And also, it‚Äôs really, really great to learn by doing. So, you should make a film.</p></blockquote><p>Software development is one of those rare fields where a college degree isn‚Äôt required to succeed. Yes, we should all know the basics, but in my experience, new college graduates often lack the practical knowledge to be effective developers.</p><p>The real learning happens through hands-on experience: building real projects, debugging tricky problems, collaborating with teams, and maintaining code over time. It‚Äôs crucial to never stop learning, experimenting, and iterating on our craft.</p><blockquote><p>Happy accidents are real gifts, and they can open the door to a future that didn‚Äôt even exist.</p></blockquote><p>Tim Berners-Lee invented the web in 1989, while working at CERN, the European Organization for Nuclear Research. Originally conceived to meet the demand for information sharing between scientists around the world, the web went mainstream within just a few years.</p><p>Linus Torvalds created Git due to a licensing dispute over BitKeeper, the original version control system used for Linux development. The need for a new tool led to Git becoming the most widely used version control system today.</p><blockquote><p>I feel that a set should be like a happy family. Almost like Thanksgiving every day, happily going down the road together.</p></blockquote><p>Be kind to your teammates, don‚Äôt embarrass them. They may not be perfect, but accept them for who they are. The most important trait of an effective software development team is psychological safety ‚Äìthat is, team members feel safe to take risks and be vulnerable in front of each other, as corroborated by <a href=\"https://rework.withgoogle.com/en/guides/understanding-team-effectiveness\">Google‚Äôs research</a> on the subject.</p><p>It‚Äôs OK to make mistakes, as long as you learn from them. Knowing that your team has your back when things go south is a wonderful feeling.</p><blockquote><p>Most of Hollywood is about making money - and I love money, but I don‚Äôt make the films thinking about money.</p></blockquote><p>Just like Lynch prioritizes creativity over financial gain, some of the most impactful software projects started with an open source model, and they literally changed the world, such as Linux, PostgreSQL, and Node.js, just to name a few.</p><p>What makes these projects remarkable is that they didn‚Äôt emerge from corporate boardrooms ‚Äì they were built by communities of passionate developers, collaborating across the world.</p><p>Money is just a means to an end. Unfortunately, many get this confused.</p><p>David, thank you for making the world a better place!</p>","contentLength":5845,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1ipy01t/lessons_from_david_lynch_a_software_developers/"},{"title":"Container Networking - Kubernetes with Calico","url":"https://www.reddit.com/r/kubernetes/comments/1ipw9bu/container_networking_kubernetes_with_calico/","date":1739604355,"author":"/u/tkr_2020","guid":610,"unread":true,"content":"<ul><li>: VLAN 10</li><li>: VLAN 20</li></ul><p>When traffic flows from VLAN 10 to VLAN 20, the outer IP header shows:</p><p>The inner IP header reflects:</p><p>The firewall administrator notices that both the source and destination ports appear as , indicating they are set to . This prevents the creation of granular security policies, as all ports must be permitted.</p><p>Could you please advise on how to set specific source and destination ports at the outer IP layer to allow the firewall administrator to apply more granular and secure policies?</p>","contentLength":502,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Bookshop.org launches Kindle alternative, sends e-book sales to local bookstores","url":"https://www.usatoday.com/story/entertainment/books/2025/01/28/bookshop-org-ereader-ebook-app/77928209007/","date":1739603151,"author":"dotcoma","guid":208,"unread":true,"content":"<p>Bibliophiles don‚Äôt need to commit to one style of reading ‚Äì with myriad titles available digitally or as audiobooks, diversifying reading habits has never been easier.</p><p>However, as platforms vary, the seller often doesn‚Äôt. Amazon accounts for <a href=\"https://www.ibisworld.com/united-states/industry/online-book-sales/5100/\" data-t-l=\":b|z|k|${u}\">more than 80% of all online book sales</a>, according to market research firm IBISWorld. Not to mention it owns Kindle, a wildly popular format for e-reading.</p><p><a href=\"https://bookshop.org/\" data-t-l=\":b|z|k|${u}\">Bookshop.org</a> is ready to change that. Today, the online platform that connects readers to local bookstores launched an e-reading platform of its own. For the first time, local <a href=\"https://www.usatoday.com/booklist/independent-bookstores\" target=\"_blank\" rel=\"noreferrer noopener\" data-t-l=\":b|e|k|${u}\">independent bookstores</a> can sell e-books to customers, says CEO and founder Andy Hunter.&nbsp;</p><h2>Bookshop.org launches e-book platform to support local bookstores</h2><p>Hunter is in the business of solving logistical problems for readers. In 2020, he launched <a href=\"https://bookshop.org/\" target=\"_blank\" rel=\"noreferrer noopener\" data-t-l=\":b|z|k|${u}\">Bookshop.org</a> to support local businesses losing sales to Amazon Books. Years later, as an e-reader himself, he realized how hard it was to continue his ‚Äúsocially-conscious consumerism‚Äù mindset of buying locally when it came to digital titles.</p><p>‚ÄúRight now, no matter how much you love your local bookstore, if you want to read an e-book, you have to go to Amazon or another alternate platform and you can‚Äôt support your local bookstore,‚Äù Hunter tells USA TODAY. ‚ÄúE-books are an important revenue stream for publishers and authors and they could be for independent bookstores.‚Äù</p><p>The result is an app (<a href=\"https://bookshop.org/info/ebooks\" target=\"_blank\" rel=\"noreferrer noopener\" data-t-l=\":b|z|k|${u}\">available for iOS and Android,</a> and accessible from a web browser) with nearly a million titles from major publishing houses. Readers can annotate, add notes, look up words and sync across all their devices. There's a search function if consumers know the book they want to read, and if they don't, there's an explore page with suggestions by genre.</p><p>Most importantly for Hunter, booksellers will take home the profits, which he says has prevented local businesses from thriving in e-book sales until now.&nbsp;</p><p>‚ÄúThere‚Äôs no real way to make it profitable, but we don‚Äôt care about it being profitable,‚Äù Hunter says, citing the socially conscious company‚Äôs B corporation status. ‚ÄúOur mission is to help independent bookstores survive and thrive in the digital age.‚Äù</p><p>With discounts, quick shipping and Kindle synching, Amazon Books has long been an appealing option to many readers. But now, Hunter says there‚Äôs ‚Äúno reason on Earth to give a billionaire your $9.99 for your e-book,‚Äù as publishers set a fixed price for e-books and there‚Äôs no shipping to compete with.&nbsp;</p><p>Bookshop.org‚Äôs new initiative follows a growing movement across social media ‚Äì not just exclusively in bookish communities ‚Äì to <a href=\"https://www.theatlantic.com/culture/archive/2024/10/washington-post-bezos-amazon-prime-cancel/680421/\" data-t-l=\":b|z|k|${u}\">forgo Amazon and other big-box sellers</a> in favor of shopping locally.&nbsp;</p><p>‚ÄúIn an age of billionaires and giant e-commerce companies and our loss of control of our lives to Silicon Valley <a href=\"https://www.usatoday.com/story/news/politics/2025/01/15/oligarchy-meaning-biden-farewell-address/77731224007/\" data-t-l=\":b|e|k|${u}\">oligarchs</a>, that they know we‚Äôre going to fight back against that and we‚Äôre going to stay local,‚Äù Hunter says. ‚ÄúIt doesn‚Äôt have to be this way. We can invest in, we can support our local community even when we‚Äôre reading digital books.‚Äù</p><h2>E-reader features to include social sharing</h2><p>Bookshop.org's platform also includes a ‚Äúquote-sharing‚Äù feature for social media, Hunter says. He wants books to catch up to the way other media is shared ‚Äì it‚Äôs easy to share your Spotify or Apple Music listening to your Instagram story, and you can even post about your workouts with some apps. But if you want to share a quote from a book, readers have to take a photo of the physical book or a screenshot.&nbsp;</p><p>‚ÄúThey should be able to share that to social media and somebody else should be able to click in, buy the book using Apple Pay and start reading it right away,‚Äù Hunter says. ‚ÄúThat‚Äôll fuel all kinds of discussions about books on TikTok and places like that, and all of that will benefit the independent bookstores because it will be them selling the books that people are talking about.‚Äù</p><h2>Looking for your next great read? USA TODAY has you covered.</h2><p><em>Clare Mulroy is USA TODAY‚Äôs Books Reporter, where she covers buzzy releases, chats with authors and dives into the culture of reading. Find her</em><a href=\"https://www.instagram.com/claremmulroy/\" data-t-l=\":b|z|k|${u}\"></a><a href=\"https://www.usatoday.com/staff/7713150001/clare-mulroy/\" data-t-l=\":b|e|k|${u}\"></a><em> or tell her what you‚Äôre reading at cmulroy@usatoday.com.</em></p>","contentLength":4199,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43056526"},{"title":"Kafka Delay Queue: When Messages Need a Nap Before They Work","url":"https://beyondthesyntax.substack.com/p/kafka-delay-queue-when-messages-need","date":1739596108,"author":"/u/Sushant098123","guid":623,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1ipu9n3/kafka_delay_queue_when_messages_need_a_nap_before/"},{"title":"Webassembly and go 2025","url":"https://www.reddit.com/r/golang/comments/1ipu4wd/webassembly_and_go_2025/","date":1739595637,"author":"/u/KosekiBoto","guid":481,"unread":true,"content":"<div><p>so I found <a href=\"https://www.youtube.com/watch?v=HShIpUgCPp4\">this video </a>and was thinking about doing something similar for my game as a means to implement modding, however I also stumbled upon a 3 y/o post when looking into it essentially stating that it's a bad idea and I wasn't able to really find anything on the state of go wasm, so can someone please enlighten me as to the current state of WASM and Go, thank you</p></div>   submitted by   <a href=\"https://www.reddit.com/user/KosekiBoto\"> /u/KosekiBoto </a>","contentLength":402,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The 20 year old PSP can now connect to WPA2 WiFi Networks","url":"https://wololo.net/2025/02/14/the-20-year-old-psp-can-now-connect-to-wpa2-wifi-networks/","date":1739590316,"author":"zdw","guid":207,"unread":true,"content":"<div><img data-recalc-dims=\"1\" fetchpriority=\"high\" decoding=\"async\" aria-describedby=\"caption-attachment-49719\" src=\"https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/psp_wpa2_support.jpg?resize=848%2C477&amp;ssl=1\" alt=\"\" width=\"848\" height=\"477\" srcset=\"https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/psp_wpa2_support.jpg?w=848&amp;ssl=1 848w, https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/psp_wpa2_support.jpg?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/psp_wpa2_support.jpg?resize=768%2C432&amp;ssl=1 768w\" sizes=\"(max-width: 848px) 100vw, 848px\"><p>Screenshot source: Zekiu_ on youtube</p></div><p><a href=\"https://wololo.net/tag/acid_snake\">Acid_Snake</a> and the <a href=\"https://wololo.net/tag/ark-4/\">ARK</a> Development team have released a significant update to the ARK custom Firmware for the Sony PSP. Custom Firmware now allows the Playstation Portable to connect to WPA2 encrypted Wifi networks. This is thanks to the recently released  plugin, created by developer  and published on the PSP Homebrew discord.</p><h2>Playstation Portable gets WPA2 Wifi access</h2><p>The PSP has been out of official support from Sony for years, but lots of enthusiasts keep maintaining this great handheld through homebrew and custom Firmware updates. As technology evolves around us, older devices such as the PlayStation Portable can lose some of their features.</p><p>For example, as WPA2 has become the defacto encryption standard for home wifi networks (WPA3‚Äôs adoption rate remains low), older devices such as the PSP, that do not support these new* encryption standards become technically unable to access the internet.</p><p>Wifi access was a very strong feature of the PSP when it was released, and, although it‚Äôs probably less important nowadays, losing that feature because newer networks aren‚Äôt compatible is a bummer.</p><p>WPA2 support has been a request by many enthusiasts for years on PSP discussion channels, and it seems that the wpa2psp plugin by developer Moment now brings this to life. According to Acid_Snake, the developer was kind enough to provide the source code of the plugin, which allowed the ARK team to embed it into the ARK Custom Firmware for PSP.</p><div><img data-recalc-dims=\"1\" decoding=\"async\" aria-describedby=\"caption-attachment-49720\" src=\"https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/moment_wpa2psp_release.png?resize=1024%2C321&amp;ssl=1\" alt=\"\" width=\"1024\" height=\"321\" srcset=\"https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/moment_wpa2psp_release.png?resize=1024%2C321&amp;ssl=1 1024w, https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/moment_wpa2psp_release.png?resize=300%2C94&amp;ssl=1 300w, https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/moment_wpa2psp_release.png?resize=768%2C241&amp;ssl=1 768w, https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/moment_wpa2psp_release.png?w=1124&amp;ssl=1 1124w\" sizes=\"(max-width: 1000px) 100vw, 1000px\"></div><p><a href=\"https://www.reddit.com/r/psphacks/comments/1iimnft/wpa2_now_works_on_psp_thanks_to_a_new_plugin/\">This reddit thread</a> by Nebula_NL covers a lot of details on how to install and use the plugin. But the bottom line is: install the latest release of the ARK CFW on your PSP, and take it from there. (Note that you can also manually install the plugin if you‚Äôre using another CFW than ARK)</p><p>This is of course the first iteration of this plugin, and it comes with limitations, specifically:</p><ul><li>2.4 GHz Only\n<ul><li>WPA2 support works with 2.4 GHz WiFi.</li><li>If your router uses a single SSID for both 2.4 GHz and 5 GHz, you may need to separate them and connect your PSP to the 2.4 GHz network.</li></ul></li><li>WPA2 AES Only\n<ul><li>Requires WPA2 with AES (AES-CCMP) encryption.</li><li>TKIP is not supported and will not work.</li></ul></li><li>WEP/WPA Compatibility\n<ul><li>While WPA2 is active, WEP and WPA encryption will not work.</li><li>To use WEP or WPA again, disable WPA2, and they will function normally.</li></ul></li><li>WPA2/WPA3 Mixed Mode\n<ul><li>If your router is set to WPA2/WPA3 mixed mode, your PSP may struggle to obtain an IP address.</li><li>Try manually setting the IP address instead of using DHCP in [AUTO] mode.</li></ul></li></ul><h2>Download and install ARK-4 + enable WPA2 Support for the PSP</h2><p><em>* WPA2 was certified in 2004‚Ä¶ It‚Äôs ‚Äúnew‚Äù from the PSP‚Äôs perspective which launched the same year and didn‚Äôt ‚Äúneed‚Äù to support it at the time. WPA3 launched in 2018 but its adoption is taking time</em></p>","contentLength":2772,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43055671"},{"title":"Bringing Nest.js to Rust: Meet Toni.rs, the Framework You‚Äôve Been Waiting For! üöÄ","url":"https://www.reddit.com/r/rust/comments/1iprsmo/bringing_nestjs_to_rust_meet_tonirs_the_framework/","date":1739587338,"author":"/u/Mysterious-Rust","guid":630,"unread":true,"content":"<p>As a Rust developer coming from TypeScript, I‚Äôve been missing a Nest.js-like framework ‚Äî its modularity, dependency injection, and CLI superpowers. But since the Rust ecosystem doesn‚Äôt have a direct counterpart (yet!), I decided to build one myself! üõ†Ô∏è</p><p>Introducing‚Ä¶ <a href=\"https://crates.io/crates/toni\">Toni.rs</a> ‚Äî a Rust framework inspired by the Nest.js architecture, designed to bring the same developer joy to our favorite language. And it‚Äôs live in beta! üéâ</p><p>Here‚Äôs what makes this project interesting:</p><p>Scalable maintainability üß©:</p><p>A modular architecture keeps your business logic decoupled and organized. Say goodbye to spaghetti code ‚Äî each module lives in its own context, clean and focused.</p><p>Need a complete CRUD setup? Just run a single CLI command. And I have lots of ideas for CLI ease. Who needs copy and paste?</p><p>Automatic Dependency Injection ü§ñ:</p><p>Stop wasting time wiring dependencies. Declare your providers, add them to your structure, and let the framework magically inject them. Less boilerplate, more coding.</p><p>Leave your thoughts below ‚Äî suggestions, questions, or even just enthusiasm! üöÄ </p>","contentLength":1089,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How do I configure Minikube to use my local IP address instead of the cluster IP?","url":"https://www.reddit.com/r/kubernetes/comments/1ipr3i1/how_do_i_configure_minikube_to_use_my_local_ip/","date":1739584978,"author":"/u/Own_Appointment5630","guid":609,"unread":true,"content":"<p>Hi there!! How can I configure Minikube on Windows (using Docker) to allow my Spring Boot pods to connect to a remote database on the same network as my local machine? When I create the deployment, the pods use the same IP as the Minikube cluster which gets rejected by the database. Is there any way that Minikube uses my local IP in order to connect correctly?.</p>","contentLength":363,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"what was the Linux expirance like in the 90's and 00's?","url":"https://www.reddit.com/r/linux/comments/1ipql9k/what_was_the_linux_expirance_like_in_the_90s_and/","date":1739583310,"author":"/u/mrcrabs6464","guid":614,"unread":true,"content":"<div><p>I started using Linux about 2 years ago really right at the beginning of the proton revolution. And I know that Gaming in specif was the biggest walls for mass adaption of Linux throughout the 2010's and late 2000's but Ive heard things about how most software ran through WINE until Direct x and other API's became more common. but gaming aside what was the expirance and community like at the time?</p></div>   submitted by   <a href=\"https://www.reddit.com/user/mrcrabs6464\"> /u/mrcrabs6464 </a>","contentLength":434,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Did Semgrep Just Get a Lot More Interesting?","url":"https://fly.io/blog/semgrep-but-for-real-now/","date":1739580031,"author":"ghuntley","guid":206,"unread":true,"content":"<p><a href=\"https://ghuntley.com/stdlib/\" title=\"\">This bit by Geoffrey Huntley</a> is super interesting to me and, despite calling out that LLM-driven development agents like Cursor have something like a 40% success rate at actually building anything that passes acceptance criteria, makes me think that more of the future of our field belongs to people who figure out how to use this weird bags of model weights than any of us are comfortable with. </p><p>I‚Äôve been dinking around with Cursor for a week now (if you haven‚Äôt, I think it‚Äôs something close to malpractice not to at least take it ‚Äî or something like it ‚Äî for a spin) and am just now from this post learning that Cursor has this <a href=\"https://docs.cursor.com/context/rules-for-ai\" title=\"\">rules feature</a>. </p><p>The important thing for me is not how Cursor rules work, but rather how Huntley uses them. He turns them back on themselves, writing rules to tell Cursor how to organize the rules, and then teach Cursor how to write (under human supervision) its own rules.</p><p>Cursor kept trying to get Huntley to use Bazel as a build system. So he had cursor write a rule for itself: ‚Äúno bazel‚Äù. And there was no more Bazel. If I‚Äôd known I could do this, I probably wouldn‚Äôt have bounced from the Elixir project I had Cursor doing, where trying to get it to write simple unit tests got it all tangled up trying to make <a href=\"https://hexdocs.pm/mox/Mox.html\" title=\"\">Mox</a> work. </p><p>But I‚Äôm burying the lead. </p><p>Security people have been for several years now somewhat in love with a tool called <a href=\"https://github.com/semgrep/semgrep\" title=\"\">Semgrep</a>. Semgrep is a semantics-aware code search tool; using symbolic variable placeholders and otherwise ordinary code, you can write rules to match pretty much arbitary expressions and control flow. </p><p>If you‚Äôre an appsec person, where you obviously go with this is: you build a library of Semgrep searches for well-known vulnerability patterns (or, if you‚Äôre like us at Fly.io, you work out how to get Semgrep to catch the Rust concurrency footgun of RWLocks inside if-lets).</p><p>The reality for most teams though is ‚Äúain‚Äôt nobody got time for that‚Äù. </p><p>But I just checked and, unsurprisingly, 4o <a href=\"https://chatgpt.com/share/67aa94a7-ea3c-8012-845c-6c9491b33fe4\" title=\"\">seems to do reasonably well</a> at generating Semgrep rules? Like: I have no idea if this rule is actually any good. But it looks like a Semgrep rule?</p><p>What interests me is this: it seems obvious that we‚Äôre going to do more and more ‚Äúclosed-loop‚Äù LLM agent code generation stuff. By ‚Äúclosed loop‚Äù, I mean that the thingy that generates code is going to get to run the code and watch what happens when it‚Äôs interacted with. You‚Äôre just a small bit of glue code and a lot of system prompting away from building something like that right now: <a href=\"https://x.com/chris_mccord/status/1882839014845374683\" title=\"\">Chris McCord is building</a> a thingy that generates whole Elixir/Phoenix apps and runs them as Fly Machines. When you deploy these kinds of things, the LLM gets to see the errors when the code is run, and it can just go fix them. It also gets to see errors and exceptions in the logs when you hit a page on the app, and it can just go fix them.</p><p>With a bit more system prompting, you can get an LLM to try to generalize out from exceptions it fixes and generate unit test coverage for them. </p><p>With a little bit more system prompting, you can probably get an LLM to (1) generate a Semgrep rule for the generalized bug it caught, (2) test the Semgrep rule with a positive/negative control, (3) save the rule, (4) test the whole codebase with Semgrep for that rule, and (5) fix anything it finds that way. </p><p>That is a lot more interesting to me than tediously (and probably badly) trying to predict everything that will go wrong in my codebase a priori and Semgrepping for them. Which is to say: Semgrep ‚Äî which I have always liked ‚Äî is maybe a lot more interesting now? And tools like it?</p>","contentLength":3614,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43054673"},{"title":"Tabiew 0.8.4 Released","url":"https://www.reddit.com/r/rust/comments/1ipp72r/tabiew_084_released/","date":1739578902,"author":"/u/shshemi","guid":631,"unread":true,"content":"<p>Tabiew is a lightweight TUI application that allows users to view and query tabular data files, such as CSV, Parquet, Arrow, Sqlite, and ...</p><ul><li>üìä Support for CSV, Parquet, JSON, JSONL, Arrow, FWF, and Sqlite</li><li>üóÇÔ∏è Multi-table functionality</li></ul><ul><li>UI is updated to be more modern and responsive</li><li>Horizontally scrollable tables</li><li>Visible data frame can be referenced with name \"_\"</li><li>Compatibility with older versions of glibc</li><li>Two new themes (Tokyo Night and Catppuccin)</li></ul>","contentLength":450,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Show HN: VimLM ‚Äì A Local, Offline Coding Assistant for Vim","url":"https://github.com/JosefAlbers/VimLM","date":1739576081,"author":"JosefAlbers","guid":195,"unread":true,"content":"<p>VimLM is a local, offline coding assistant for Vim. It‚Äôs like Copilot but runs entirely on your machine‚Äîno APIs, no tracking, no cloud.</p><p>- Deep Context: Understands your codebase (current file, selections, references).  \n- Conversational: Iterate with follow-ups like \"Add error handling\".  \n- Vim-Native: Keybindings like `Ctrl-l` for prompts, `Ctrl-p` to replace code.  \n- Inline Commands: `!include` files, `!deploy` code, `!continue` long responses.</p><p>Perfect for privacy-conscious devs or air-gapped environments.</p><p>Try it:  \n```\npip install vimlm\nvimlm\n```</p>","contentLength":558,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43054244"},{"title":"A decade later, a decade lost (2024)","url":"https://meyerweb.com/eric/thoughts/2024/06/07/a-decade-later-a-decade-lost/","date":1739574636,"author":"ZeWaka","guid":205,"unread":true,"content":"<p>I woke up this morning about an hour ahead of my alarm, the sky already light, birds calling.&nbsp; After a few minutes, a brief patter of rain swept across the roof and moved on.</p><p>I just lay there, not really thinking.&nbsp; Feeling.&nbsp; Remembering.</p><p>Almost sixteen years to the minute before I awoke, my second daughter was born.&nbsp; Almost ten years to the same minute before, she‚Äôd turned six years old, already semi-unconscious, and died not quite twelve hours later.</p><p>So she won‚Äôt be taking her first solo car drive today.&nbsp; She won‚Äôt be celebrating with dinner at her favorite restaurant in the whole world.&nbsp; She won‚Äôt kiss her niece good night or affectionately rag on her siblings.</p><p>Or maybe she wouldn‚Äôt have done any of those things anyway, after a decade of growth and changes and paths taken.&nbsp; What would she really be like, at sixteen?</p><p>We will never know.&nbsp; We can‚Äôt even guess.&nbsp; All of that, everything she might have been, is lost.</p><p>This afternoon, we‚Äôll visit Rebecca‚Äôs grave, and then go to hear her name read in remembrance at one of her very happiest places, <a href=\"https://en.wikipedia.org/wiki/Anshe_Chesed_Fairmount_Temple\">Anshe Chesed Fairmount Temple</a>, for the last time.&nbsp; At the end of the month, the temple will close as part of a merger.&nbsp; Another loss.</p><p>A decade ago, I said that I felt the weight of all the years she would never have, and that they might crush me.&nbsp; Over time, I have come to realize all the things she never saw or did adds to that weight.&nbsp; Even though it seems like it should be the same weight.&nbsp; Somehow, it isn‚Äôt.</p><p>I was talking about all of this with a therapist a few days ago, about the time and the losses and their accumulated weight.&nbsp; I said, ‚ÄúI don‚Äôt know how to be okay when I failed my child in the most fundamental way possible.‚Äù</p><p>‚ÄúYou didn‚Äôt fail her,‚Äù they said gently.</p><p>‚ÄúI know that,‚Äù I replied. ‚ÄúBut I don‚Äôt feel it.‚Äù</p><p>A decade, it turns out, does not change that.&nbsp; I‚Äôm not sure now that any stretch of time ever could.</p>","contentLength":1935,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43054069"},{"title":"If you ever stacked cups in gym class, blame my dad","url":"https://defector.com/if-you-ever-stacked-cups-in-gym-class-blame-my-dad","date":1739573102,"author":"nonoobs","guid":204,"unread":true,"content":"<p>The boxes came from Tokyo: first by tanker, then overland via container truck from a Pacific port, across the Continental Divide, and finally backed into a driveway at the end of a cul-de-sac in a south Denver suburban enclave. This was a neighborhood with Razor scooters dumped in trimmed front lawns. Where family walks with leashed dogs happened down the middle of intentionally curved streets named after long demolished natural landmarks like \"Timbercrest\" and \"Forest Trails.\" Where the HOA (because of course there was an HOA) banned the installation of driveway basketball hoops.</p><p>Receiving industrial freight deliveries, freshly cleared through international customs, probably wasn't explicitly prohibited in the homeowner's handbook. But then, why would it need to be? Nobody would think to bring that kind of commercial chaos into the burgeoning middle-class peace of Castle Pines North in 1998.</p><p>If neighbors peeking behind curtains at the idling 18-wheeler thought to call in a complaint, the husband and wife receiving the delivery didn't notice. They were too busy unloading boxes‚Äîmore than 800 of them.&nbsp;</p><p>Balancing four at a time on a handcart, it took 200 trips through the open garage door and down the unfinished basement steps. The boxes, holding smaller rectangular packages inscribed with Japanese lettering, were piled to the ceiling. There was enough room left for a skinny aisle leading back up the stairs, and two plastic tables ladened with tape and flat-rate USPS packaging.&nbsp;</p><p>5,800 miles away, a man in middle management at the global toy conglomerate Hasbro must have been very pleased. The delivery represented a small yet unexpected boon.&nbsp;</p><p>Those boxes were dead inventory, wasting space in a nondescript warehouse. They should have been headed for a landfill and a tax write-off. Instead, a Mr. Toshio Takiguchi brokered the export at a ¬•1,300 per-unit cost. Not a tidy profit, but no longer a loss on the annual P&amp;L. The remains of a failed business decision disappeared across the ocean. It was a certain Mr. Fox's problem now.</p><p>That problem cost $43,000, a sum that represented the entire life savings of Mr. Fox and his wife, who at that point had been surviving on public-school salaries. Friends and family never really said it out loud, but they were certainly thinking it: <em>This was insane. What about the three kids and that mortgage?&nbsp;</em></p><p>The couple, though, never had a doubt.&nbsp;</p><p>\"He always used to tell me, 'If I had 10,000 of these, I could sell them in a year,'\" Mrs. Fox&nbsp;recalled, 27 years later.</p><p>That's the unabashed confidence you'd expect from any good entrepreneur, especially with the benefit of hindsight. But ask yourself this: Would you, watching this couple unload box after box into their bank-financed home, have bet on this man and his family's future if you knew exactly what he needed to sell?</p><p>Tucked inside those boxes, in nested columns of 12, were 120,000 plastic cups. They were turned upside down, each with a hole drilled through the middle of the base, rendering them useless in terms of a cup's normal, and really only, task.</p><p>The couple's future hinged on accomplishing what the world's second largest toy company could not: convincing thousands of kids that stacking these plastic cups in pre-determined patterns was ‚Ä¶ . More critically, the couple needed to convince the parents of those kids to actually buy these cups, despite not even being able to drink from them.&nbsp;</p><p>Mr. Takiguchi could breathe a sigh of relief. Mr. and Mrs. Fox had to get to work.</p><div><div><blockquote><p><strong><em>The first thing you need to know about Bob Fox is that he used to be a clown</em></strong> ... <em><strong>The second thing you need to know about my dad is that he was a really, really good clown.&nbsp;</strong></em></p></blockquote></div></div><p>Every few months, in different corners of the internet, someone asks a version of the same question: <em>Why did we all stack plastic cups in elementary school PE class?</em></p><p>You might have even asked it yourself, perhaps after a few beers when a friend turned some Solo Cups upside down, activating one of your mid-aughts memories of sitting cross-legged on a linoleum gym floor, surrounded by the clatter of your classmates piling cups into pyramids.</p><p><a href=\"https://www.speedstacks.com/\" target=\"_blank\" rel=\"noreferrer noopener\">Sport Stacking</a>, as it's officially known (cup stacking and speed stacking as it is colloquially known), exists in the same cloud of millennial nostalgia where you'll find vague recollections of SlamBall and JoJo. It has appeared on pretty much every morning and late show, been a trend piece in both the <a href=\"https://www.nytimes.com/2016/04/01/sports/sport-stacking-speed-cups.html\" target=\"_blank\" rel=\"noreferrer noopener\"></a> and <a href=\"https://www.wsj.com/articles/SB124044351073445491\" target=\"_blank\" rel=\"noreferrer noopener\"></a>, and was once labeled by Glenn Beck as \"<a href=\"https://www.foxnews.com/story/glenn-beck-why-health-care-reform-is-like-cup-stacking\" target=\"_blank\" rel=\"noreferrer noopener\">what‚Äôs really wrong with America</a>.\"</p><p>It has been a minor plot line in , Matt LeBlanc's , and ; it's been the major plot line in a 2022 Thai-language film released on Netflix titled <a href=\"https://www.imdb.com/title/tt18357588/\" target=\"_blank\" rel=\"noreferrer noopener\"></a> (100 percent on Rotten Tomatoes). The infamous \"Oh my gosh!\" scream in Skrillex's \"Scary Monsters and Nice Sprites\" was sampled from a <a href=\"https://www.youtube.com/watch?v=j54yGxuk0yo&amp;t=1s\" target=\"_blank\" rel=\"noreferrer noopener\">viral sport stacking video</a> from 2008.</p><p>At its peak, between 2002 and 2011, roughly 5,000 American schools included it as part of their annual curriculum, according to Mr. and Mrs. Fox. That means somewhere between five and eight percent of U.S. adults between the ages of 22 and 35 share the same core memory‚Äîand in the ensuing years have asked themselves, their friends, or social media the same question: <em>Why did credentialed educational professionals make us do this ludicrous activity in gym class?</em></p><p>I am, perhaps, the person best suited on the planet to answer this question.&nbsp;Because the answer ‚Ä¶ is my dad.</p><p>The first thing you need to know about Bob Fox is that he used to be a clown. Not in the figurative, funnyman personality sense. In the literal red-nose, black-eyeliner, juggling-tennis-balls-at-children‚Äôs-birthday-parties sense.</p><p>The second thing you need to know about my dad is that he was a <em>really, really good clown</em>.&nbsp;</p><p>He'd scoff at the mental image you probably have of him right now: oversized shoes, cartoonish honks, and bumbling choreography. My dad's act was entirely silent, required immense skill, and was predicated on audience participation. He was equally good at riding a unicycle and convincing the most curmudgeonly dad in the room to leave their back corner and join him onstage to try‚Äîand always fail‚Äîat blowing up a balloon animal. Kids went bananas. Adults always laughed.&nbsp;</p><p>The San Francisco 49ers hired him to be the walk-around entertainment for their post‚ÄìSuper Bowl ring ceremony in 1995. We used to shut the shades so neighbors didn't think he robbed a bank as he counted the cash he earned during Denver's largest busking festival.</p><p>This was a man who took the unserious very, very seriously.&nbsp;</p><p>As a high school theater teacher, he'd spend 60‚Äì80 hours a week building out increasingly elaborate sets for the annual musical. He built a life-sized plant puppet that could actually eat cast members for , and cut a full-sized muscle car in half so it would fit on stage during ; another car was hoisted onto the school's roof to promote the show. Before her bevy of Oscar nominations, Amy Adams was one of his choreographers and students.</p><p>He quit because his wife, Jill, needed him home more to help raise their three children. So he became an elementary school classroom and PE teacher instead, where he would end up teaching hundreds of kids how to ride unicycles and produce an annual show on the blacktop basketball court called KidZircus.</p><p>The first thing you need to know about Jill Fox is that before working as a communications administrator at a school district, she used to be a journalist at a small newspaper, where she was assigned to write a profile about a local clown on \"sabbatical\" from his full-time job.&nbsp;</p><p>The second thing you need to know about Jill Fox is that despite the word \"sabbatical\" doing a generous amount of euphemistic work in her final published piece, she married that unemployed clown.</p><p>This was a woman who was very, very good at seeing‚Äîand supporting‚Äîthe potential in the crazy.</p><div><div><blockquote><p><strong><em>They had to figure out how to tap into the supply chain of global toy conglomerates. Fortunately, they had a guy: Uncle Johnny.</em></strong></p></blockquote></div></div><p>It took them 10 months to sell the 10,000 sets of 12 cups.&nbsp;</p><p>Kids in south Denver, it turns out, went absolutely nuts over this new phenomenon called \"cup stacking.\" That's mostly because my dad figured out the one thing Hasbro did not: The level of interest in the activity hinged almost exclusively on the enthusiasm and skill level of a real-life teacher. Without that, it was just inanimate plastic ephemera sitting on a shelf.</p><p>The basic rules take about 15 minutes to learn. Like a track meet, the sport is built on completing different \"distances\" as fast as you can. The shortest, and simplest, is called the 3-3-3. Envision each one of those 3's as a nested column of cups. You start on one side and \"upstack\" the first 3 into a pyramid, then move to the middle, and then the last 3. Then you return to where you started, and \"downstack\" them back into columns in the same order. The 3-6-3 has the same principle, but with a pyramid of six cups in the middle. The \"Cycle,\" is the sport's primetime event, starting with the 3-6-3, morphing into a 6-6, and ending with a 1-10-1.</p><p>If you skimmed over that clunky paragraph, you've proved my dad's foundational epiphany: You really need to see it to buy in. In fact, scrap reading this for a few seconds (that's all it will take) and watch this video instead.</p><p>Place a set of these cups in the corner of a room or on a toy shelf with paper instructions, and you might earn five minutes of an 8-year-old's frenzied attention. Put that same 8-year-old on the gym floor in front of a professionally trained clown with a passion for juggling, and they will be utterly hooked.</p><p>A brief digression on nomenclature: The sport was known as \"cup stacking\" until 2005, when my parents had the savvy to officially change the name to \"sport stacking.\" Why? 1) Because it sounds way cooler, and if enough people call it a sport then it must damn well be one. 2) The phrase \"cup stacking\" out of context evokes toddlers playing with blocks, a vibe they wanted to avoid. Confusingly, you might have also seen it referenced as \"speed stacking,\" after the company they eventually founded, Speed Stacks. They strategically eschewed this label to avoid the fate of Roller Blades, Frisbee, and Kleenex, all formerly good standing trademarks, until you lot ruined everything.‚Ä®</p><p>Except for this early-stage reference, I'll be calling it sport stacking hereafter so as to avoid a grumpy phone call from my dad (he'll probably still call about my use of \"damn,\" though). If you have a problem with that, consider the last time you went berserk over a nine-darter or screamed at the Swedish curling team during the Olympics. As my dad likes to say, there used to be a man trying to convince the world that tossing balls made from dried cow skin into retrofitted peach baskets was fun‚Äîand you all bought in.</p><p>It is important to note that my dad did not actually invent sport stacking. Credit goes to a group of bored kids at a Boys and Girls Club in Oceanside, Calif., in the early 1980s. They'd been given a stack of paper cups, and told to figure out a game that didn't involve messy liquid. Under the guidance of a program director named Wayne Godinet, both the rules and equipment evolved. He is responsible for the sport's first major innovation: He drilled a hole through the base of hard plastic cups to reduce air friction and prevent sticking. The California group's high-water mark came on Nov. 2, 1990, when they appeared on <em>The Tonight Show with Johnny Carson</em>. Among the millions watching that night, from his bed in a south Denver suburb: a clown and future PE teacher who thought it looked a bit like upside-down juggling.</p><p>Hasbro must have been watching, too. Perhaps chasing the Hoola Hoop and Pogs high of the '80s, the company scooped up a license to sell \"Kup Stax,\" popping sets in a rectangular plastic sleeve on toy store shelves around the world. Instead of becoming a fad, the product moved to the clearance rack. Someone in middle management was probably scolded. Manufacturing ceased.&nbsp;</p><p>In 1995, my dad attended a physical education development workshop to give new teachers a dozen ideas on how to keep kids occupied, exercised, and docile. The classics were all there: four-wheeled square scooters designed to give 80 percent of users elbow burn, dodgeballs primed to pop kids like me in the face, that large circus tent you toss above your head until it temporarily inflates so you can sit under it for a few seconds. So were the cups.&nbsp;</p><p>He brought them home and taught his kids. I was 4, my brother 6, our sister 9. We not only fell in love with them, we got good‚Äî. We weren't outliers. Among an elementary school of 500 students, 250 signed up for an afterschool program to keep stacking. My mom drove to every Toys \"R\" Us and Walmart within a 50-mile radius. She bought every set of Kup Stax she could find. They were always discounted, tucked in a back corner.</p><p>The local supply ran dry as my parents hosted workshops. Demand started to skyrocket from other PE teachers. My parents needed to go upstream. They had to figure out how to tap into the supply chain of global toy conglomerates. Fortunately, they had a guy: .</p><p>Now 64 with a Colonel Sanders goatee and passion for intricate leather carving, my dad's brother has been at certain points in his life: a professor at the Ringling Bros. and Barnum &amp; Bailey Clown College; a street mime in San Diego; a director of&nbsp;a Las Vegas magic show, performed entirely on ice; and a consultant for Japan's oldest and largest circus. If you need to find a man in middle management at Hasbro's Tokyo corporate office, you call Uncle Johnny.</p><p>The deal was struck. The shipment arrived. And the cups, rather magically, disappeared from our basement.</p><p>By 1998, Bob Fox was a dealer with no product and an increasingly addicted customer base. There was only one logical next step: Transition from distribution to fabrication.</p><p>He did make a final good-faith effort to partner with the sport's originator, Wayne Godinet, offering to purchase $20,000 worth of product. It was almost a third of the profit earned from reselling the Japanese shipment. Godinet sent back two sample sets with a bill for the cost of goods and shipping.</p><p>In a similar vein, Nike was founded in 1964 only after a running shoe company called Onitsuka lost interest in partnering with a recent Oregon track grad named Phil Knight. While his shoe empire was born between the grooves of a waffle iron, Bob and Jill's cup empire was sketched on the back of a Fresh Fish Co. paper placemat.</p><p>Speed Stacks LLC was incorporated in December 1998. My parents quit their full-time public school jobs in June 2000.&nbsp;</p><p>This was to be an official test of a core tenet of the American Dream: With enough passion and even more prodigious work ethic, you can turn a ludicrous idea into a successful business. To get started, they just needed four things.</p><p>First: a mold to mass produce the cups. It required $20,000 and overcoming the absolute befuddlement of executives at a Denver plastics manufacturer who did not understand the  to include three small holes at the base. As each cup came off the line, our family would inspect the shape; minor defects in its roundness caused sticking. Nearly every cup in the first run had to be tossed out for deformities.</p><p>Second: a nylon and mesh cup-carrying bag. Those were sewn in the back basement of a Vietnamese immigrant‚Äìowned textile company. We bagged each set of 12 by hand, my parents staying up until 2:00 in the morning to fulfill orders after working full school days. Bob wasn't satisfied unless the logo of every cup perfectly faced forward.</p><p>Third: to hit the road. Speed Stack's first tagline was \"See it! Believe it! Teach it!\" My parents meant it: They knew that success was linearly related to the number of PE teachers who witnessed the sport in person. Our family of five put almost 100,000 miles on our 1997 maroon Suburban in a little over four years.</p><p>Fourth: kids who could stack the cups. . For some reason, all three of the Fox progeny developed both the interest and intrinsic skill to do just that.</p><div><div><blockquote><p><strong><em>At a booth in hotel conference halls and city convention centers, we'd stack for hours, drawing crowds spread three and four rows deep, often to the annoyance of the dodgeball or shuttlecock purveyors next door.&nbsp;</em></strong></p></blockquote></div></div><p>Legendary ring announcer Michael Buffer‚Äôs voice was always our music cue. <em>\"Ladies and gentlemen, welcome to the main event!\"</em></p><p>It would blast over portable speakers on either side of a gym floor. Emmy, my older sister, would lead us out from a hidden corner, followed by my brother, Brennan, then me: a 7-year-old with Coke-bottle glasses, immensely satisfied by the fact that hundreds of eyes were watching my every move.</p><p>We stopped when we reached separate tables spread evenly across our makeshift stage, usually under the basketball hoop. We stood still to let the tempo build.&nbsp;</p><p><em>\"Let‚Äôs get ready to rumble!\"</em></p><p>The synths would drop, and we would commence stacking plastic cups. Faster and with more skill than the students and teachers in Amarillo or Ft. Lauderdale or Butzbach, Germany, or Copenhagen, Denmark, could ever think possible.&nbsp;</p><p>Our family performed hundreds of school assemblies in almost every corner of the country (and some overseas). The 30-minute spectacle was choreographed specifically to blow the minds of kids between the ages of 7 and 14 as quickly as possible. This wasn't a talk from your fire chief about safety, or puppets teaching you the value of sharing. We humiliated principals and popular teachers by making them race us. There was a fabricated jacket with holes cut in the back that we fitted onto a volunteer, then stuck our arms through the sleeves to make it appear like they were magically adept (performed to the  soundtrack). The finale was a choreographed stacking routine, set to \"Dueling Banjos\" from .</p><p>But a school-by-school roadshow wasn't a scalable business model. So we went to the nexus of physical education sweatsuitdom: state and national teacher conventions. At a booth in hotel conference halls and city convention centers, we'd stack for hours, drawing crowds spread three and four rows deep, often to the annoyance of the dodgeball or shuttlecock purveyors next door.&nbsp;</p><p>It's most likely that you learned how to sport stack because your teacher, with a lanyard badge bouncing over her multi-colored windbreaker on her way to get a free muffin from the guys who sell tug-o-war ropes, stopped in her tracks in the back corner of Exhibit Hall B at an exurban Renaissance hotel. She would watch as our hands manipulated dishware so fast it blurred.</p><p>If my dad was adept at putting on a good show, my mom was equally adept at corralling the press. Her journalism and PR‚Äìhoned chops put sport stacking in front of millions, from the D-block of local newscasts to 30 Rock Plaza during the .&nbsp;</p><p>That's how I found myself chatting with a shirtless Simon Cowell in the makeup room before we both appeared on Ellen DeGeneres's show, taught Tiki Barber the basics of the 3-3-3, and tried to convince a baffled Michael Caine in the green room of <em>LIVE with Regis and Kelly</em> that yes, indeed, kids really do stack plastic cups for fun.</p><p>All press, to my parents, was good. My dad was absolutely thrilled when Glenn Beck spent four minutes of his daily Fox News monologue staring directly into the camera, railing against the dangers of stacking cups.</p><p>\"We can't fix our country by keeping our children weak,\" Beck sputtered, roughly two minutes in. \"They need to have spines. They need to get hit in the face a few times with a ball, you know what I mean? They have to learn how to live with and thrive on past failures.\"</p><p>Brands soon took advantage of sport stacking's essential power: No matter the context, it attracts near-instant attention. In 2005, I appeared in a <a href=\"https://www.youtube.com/clip/UgkxwybLaGciSxQJgS1FKh-3PeJwa9xtXtN8\" target=\"_blank\" rel=\"noreferrer noopener\">nationwide Comcast commercial</a> for high speed internet. FritoLay shut down part of Times Square to feature our stacking talents as it launched Stax, a competitor to Pringles. A beverage company in England flew a dozen of us to London to help launch an abomination of a drink called <a href=\"https://www.youtube.com/watch?v=eelE8tHEScM\" target=\"_blank\" rel=\"noreferrer noopener\">Freekee Soda</a>. Main ingredient? Carbonated milk. (Did I pretend to enjoy drinking that carbonated milk so as to not piss off any of the execs helping to pay for my college education? Obviously. But it is a cursed flavor.)</p><p>Perhaps the only media my parents turned down was an appearance on the infamous reality show . The producers, naturally, presumed the scions of a ludicrous gym activity would have some weird baggage to mine for the masses.&nbsp;</p><p>Unfortunately, despite the cups, we were pretty normal.</p><div><div><blockquote><p><strong><em>To stack as fast as you possibly can in a World Championship is to strike a balance between fluidity and chaos.</em></strong></p></blockquote></div></div><p>It was the Germans who made everything more serious.</p><p>They arrived at the 2004 World Sport Stacking Championships in matching flag-inspired sweatsuits. Multiple coaches would analyze everything from hand-tag efficiency during the four-person relay event to the mental routines of stackers before their individual competition.</p><p>Sport stacking, I believe, grew into a minor phenomenon for three reasons: 1) It's visually arresting, 2) it's easy to learn, and 3) competing against the clock is incredibly addicting.</p><p>Media buzz and schoolteachers kindled the first two. But my dad's magnum opus‚Äîthe reason the sport didn't wither in the way of skip ball and snake boards‚Äîwas that he (with the help of the 20 employees at the burgeoning HQ) built the infrastructure and equipment to spur global competition.&nbsp;</p><p>The sport's growth coincided with two of my dad's innovations: the StackMat, a patented self-timing device that allowed kids to practice on their own for hours, aiming to trim hundredths of a second off their best times; and the World Sport Stacking Association, a governing body to codify the rules and serve as the keeper of world, national, and local records.</p><p>In 1997, 250 kids were hand-timed with stop watches at the first Colorado State Championship.&nbsp;By 2007, ESPN aired an <a href=\"https://www.youtube.com/watch?v=xm8EKnl4ZDQ\" target=\"_blank\" rel=\"noreferrer noopener\">hourlong David Lloyd‚Äìhosted special</a> of the World Championships, featuring more than 1,000 competitors from seven countries (re-aired in 2020 during their pandemic \"The Ocho\" promotion).&nbsp;</p><p>Like everything in his life, my dad choreographed a spectacle. He ordered a three-story banner to hang behind garbage can‚Äìsized cups that served as center stage. The competition floor was arranged with dozens of tables, all marked with laser-lined tape to demarcate relay boundaries.</p><p>During the final \"Stack of Champions,\" the top competitors (and relay teams) from each event competed under the scrutiny of spotlights, three officials, an instant replay camera, and hundreds of spectators. In individual events, you're allotted two warmups and three tries. Relays are conducted head-to-head in teams of four.</p><p>For a few years, I was among those finalists.&nbsp;</p><p>To stack as fast as you possibly can in a World Championship is to strike a balance between fluidity and chaos. Push too hard and the cups tumble. Pull back and you'll lose by thousandths of a second.</p><div><div><figure><figcaption>A relay race in the Stack of Champions, in which I (the third stacker on the left team) stumble at the start, allowing my brother (the last stacker on the right team) to beat us by two-hundredths of a second.</figcaption></figure></div></div><p>For those moments, you exist at the outer physical boundary of human biology. When performing at your peak, the cups feel less like they're being stacked and more like they're being sprayed.&nbsp;</p><p>In 2001, the world record for sport stacking's marquee event, the Cycle, was 7.43 seconds. It was held by my sister. At the time, most people assumed a sub-seven-second time was physically impossible. The pattern requires more than 40 separate moves. At those speeds, hands make micro-adjustments faster than the brain can register. Her time stood for nearly four years.</p><p>In 2025, the world record for the cycle is 4.739 seconds.&nbsp;</p><p>Please understand: I know this whole endeavor is silly, that it's worthy of your slight mockery and general patina of confusion. But also understand that my dad created a culture in which German coaches passed strategic tips to Australian competitors. Where Japanese teenagers became pen pals with suburban Texans. Where nerves collapsed faster than the cups. Where kids and adults shrieked with joy over millisecond improvements. Where tension and drama and friendship mingled with the clattering cacophony of sliding and tapping plastic (there really is no sound like the one at these competitions).&nbsp;</p><p>Sport stacking had broad exposure in both mainstream and weird places. But it had a deep impact in a much smaller community. It changed lives.</p><div><div><blockquote><p><strong><em>You've probably heard Rachael‚Äôs voice. Her effusive reaction on a stacking YouTube video meant for her small group of friends is behind the iconic \"YES, OH MY GOSH!\" scream, sampled in one of EDM's most mainstream hits, \"Scary Monsters and Nice Sprites,\" by Skrillex.</em></strong></p></blockquote></div></div><p>Milo Ferguson discovered sport stacking in first-grade PE class.&nbsp;</p><p>\"My teacher was the final boss of butch lesbians. That's the only way I know how to describe her,\" Ferguson, now a 23-year-old co-founder of an independent animation studio, said. Their teacher loved competition and was beloved by her students, exactly the archetype to stop at a conference booth and believe in a quirky new cup-centric educational trend.</p><p>Rachael Nedrow, now a 29-year-old product manager at Amazon, first saw the sport while scrolling YouTube when she was 11. She pulled paper cups from the kitchen drawer to try and mimic the movement.</p><p>Both became obsessed, quickly. Though for different reasons.</p><p>\"I was never the fastest kid. I was always kind of chubby. I was much more the creative person than an athletic one,\" Ferguson said. \"Sport stacking was about hand-eye coordination more than strength. It was intricate. Delicate.\" For the first time, they were excited to attend PE class.</p><p>Nedrow, an accomplished tennis player, was intrigued by the self-improvement and rigid strictures of the clock. She bought an official set of Speed Stacks and started logging her progress on her own YouTube channel.</p><p>\"My first competition was at a local church,\" Nedrow said. \"I did terribly, but I still won.\"</p><p>Despite differing motivations, Ferguson and Nedrow's paths to competitive sport stacking mirror each other. Friends weren't interested, so they went looking for a community online and at competitions.&nbsp;</p><p>For the thousand kids that congregated on the arena floor at each World Championships, like Ferguson and Nedrow, the sentiment was common. They had found  people. They fit in, sometimes for the first time in their life.&nbsp;</p><p>There were future college athletes and kids with autism. There were rugby fans from New Zealand (riffing off their national team, they called themselves the \"All Stacks\") and South Koreans who had never been to the United States.&nbsp;</p><p>Roll your eyes, but my dad loved to say that the sport only helped build \"positive pyramids.\" Spend a few hours watching kids pat each other on the back after a fumbled cup, or earn a hug for achieving a new personal best, and you'd buy into the platitude too.</p><p>Compared to other top-level stackers, Nedrow and Ferguson's experiences only differ in one way.&nbsp;</p><p>You've probably heard Rachael's voice. Her effusive reaction on a stacking YouTube video meant for her small group of friends is behind the iconic \"YES, OH MY GOSH!\" scream, sampled in one of EDM's most mainstream hits, \"<a href=\"https://www.youtube.com/watch?v=WSeNSzJ2-Jw\" target=\"_blank\" rel=\"noreferrer noopener\">Scary Monsters and Nice Sprites</a>,\" by Skrillex. Between Spotify and YouTube, it has more than 500 million streams.</p><p>And you probably know Ferguson's dad, Craig, the comedian and host of <em>The Late Late Show with Craig Ferguson</em> from 2005 to 2014.</p><p>Nedrow's collision with virality gave her backstage passes to several Skrillex concerts and the greatest fodder for \"Two Truths and a Lie\" of all time. But sport stacking also gave her something else she wasn‚Äôt expecting: a wide group of online friends.</p><p>\"I don't think I would have taken stacking so far if it wasn't for the online community,\" Nedrow said. \"When you are doing anything kind of competitive, it seems like it's much better when you are doing it with people. I really loved the aspect of kids commenting on my videos, saying they started stacking because of me. What greater pleasure can you get than inspiring other people to do what you love the most?\"</p><p>Sport stacking gave Ferguson inclusion and validation. But perhaps more important than what it gave them is what it gave their parents. While Craig and his ex-wife Sascha had been separated for a few years by the time their kid started competing, both fully committed to supporting this weird, wholesome obsession. Sascha helped Milo learn how to breathe and center themselves before starting to stack. And she supplied an ever-growing collection of stacking equipment, stored in a dedicated room in their Southern California home.</p><p>To see what sport stacking gave Craig, you need to watch his show <a href=\"https://www.youtube.com/watch?v=9Wjk0PkpWco\" target=\"_blank\" rel=\"noreferrer noopener\">from April 20, 2009</a>. He spends four minutes‚Äîmore than half of the entire monologue‚Äîbragging about Milo. Beneath the scripted jokes and of-the-era references (Octomom is mentioned twice), you see a guy just genuinely proud of his kid. He's like any neighbor, going off a bit too effusively about the weekend's peewee football game or math test.&nbsp;</p><p>Except this was done for millions. And it was about ... cups.&nbsp;</p><div><div><blockquote><p><strong><em>\"I wanted to give kids, no matter their athletic ability, the opportunity for success. It gave them something new and different. And it created a community. It brought kids around the world together.\"</em></strong></p></blockquote></div></div><p>Sport stacking gave different things to a lot of people.</p><p>For a few, it genuinely improved their life. College funds were paid through YouTube viewership revenue and small brand endorsements. Children with autism and special needs learned, practiced, competed, and socialized with others for the first time.&nbsp;</p><p>For me and my siblings, it gave us a stable home, trips to a dozen countries, and some excellent college essay material. My sister, Emmy, went on to play basketball for four years at the University of Minnesota, was drafted into the WNBA by the Minnesota Lynx, and then played professionally overseas with Sheryl Swoopes. My brother Brennan played D-III college football and turned into a mechanical engineer at a global cosmetics company. I turned into a fairly unathletic writer.</p><p>For my parents, it gave them an early retirement. A sometimes-operational 1957 VW Bug and an obsession with growing ever-larger pumpkins occupied my dad, while training to run another marathon at age 70 became a focus for my mom. They left their active roles at Speed Stacks in 2015, leaving control to some of its earliest employees. Programs are still active in thousands of schools around the world.</p><p>\"I was motivated to spread sport stacking for the same reason I taught my students how to juggle or unicycle,\" my dad recalled, nearly 10 years into retirement. \"I wanted to give kids, no matter their athletic ability, the opportunity for success. It gave them something new and different. And it created a community. It brought kids around the world together. And believe it or not, that all happened because of a couple million plastic cups.\"</p><p>For some of you reading this, sport stacking gave you an identical memory.&nbsp;A cross-legged seat on a linoleum gym floor. The hush from the principal. The music crescendoing into ' most iconic synth riff. The sound of cups, stacking at lightning speed. You knew, in that moment, that you weren't in for another monotonous few hours at school. Your day was about to rock.&nbsp;</p><p>For that, you can thank my dad.</p>","contentLength":31508,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43053908"},{"title":"We were wrong about GPUs","url":"https://fly.io/blog/wrong-about-gpu/","date":1739572591,"author":"mxstbr","guid":203,"unread":true,"content":"<div><p>We‚Äôre building a public cloud, on hardware we own. We raised money to do that, and to place some bets; one of them: GPU-enabling our customers. A progress report: GPUs aren‚Äôt going anywhere, but: GPUs aren‚Äôt going anywhere.</p></div><p>A Fly Machine is a <a href=\"https://fly.io/blog/docker-without-docker/\">Docker/OCI container</a> running inside a hardware-virtualized virtual machine somewhere on our global fleet of bare-metal worker servers. A GPU Machine is a Fly Machine with a hardware-mapped Nvidia GPU. It‚Äôs a Fly Machine that can do fast CUDA.</p><p>Like everybody else in our industry, we were right about the importance of AI/ML. If anything, we underestimated its importance. But the product we came up with probably doesn‚Äôt fit the moment. It‚Äôs a bet that doesn‚Äôt feel like it‚Äôs paying off.</p><p><strong>If you‚Äôre using Fly GPU Machines, don‚Äôt freak out; we‚Äôre not getting rid of them.</strong> But if you‚Äôre waiting for us to do something bigger with them, a v2 of the product, you‚Äôll probably be waiting awhile.</p><p>GPU Machines were not a small project for us. Fly Machines run on an idiosyncratically small hypervisor (normally Firecracker, but for GPU Machines <a href=\"https://github.com/cloud-hypervisor/cloud-hypervisor\">Intel‚Äôs Cloud Hypervisor</a>, a very similar Rust codebase that supports PCI passthrough). The Nvidia ecosystem is not geared to supporting micro-VM hypervisors.</p><p>GPUs <a href=\"https://googleprojectzero.blogspot.com/2020/09/attacking-qualcomm-adreno-gpu.html\">terrified our security team</a>. A GPU is just about the worst case hardware peripheral: intense multi-directional direct memory transfers</p><div><p>(not even bidirectional: in common configurations, GPUs talk to each other)</p></div><p>with arbitrary, end-user controlled computation, all operating outside our normal security boundary.</p><p>We did a couple expensive things to mitigate the risk. We shipped GPUs on dedicated server hardware, so that GPU- and non-GPU workloads weren‚Äôt mixed. Because of that, the only reason for a Fly Machine to be scheduled on a GPU machine was that it needed a PCI BDF for an Nvidia GPU, and there‚Äôs a limited number of those available on any box. Those GPU servers were drastically less utilized and thus less cost-effective than our ordinary servers.</p><p>We funded two very large security assessments, from <a href=\"https://www.atredis.com/\">Atredis</a> and <a href=\"https://tetrelsec.com/\">Tetrel</a>, to evaluate our GPU deployment. Matt Braun is writing up those assessments now. They were not cheap, and they took time.</p><p>Security wasn‚Äôt directly the biggest cost we had to deal with, but it was an indirect cause for a subtle reason.</p><p>We could have shipped GPUs very quickly by doing what Nvidia recommended: standing up a standard K8s cluster to schedule GPU jobs on. Had we taken that path, and let our GPU users share a single Linux kernel, we‚Äôd have been on Nvidia‚Äôs driver happy-path.</p><p>Alternatively, we could have used a conventional hypervisor. Nvidia suggested VMware (heh). But they could have gotten things working had we used QEMU. We like QEMU fine, and could have talked ourselves into a security story for it, but the whole point of Fly Machines is that they take milliseconds to start. We could not have offered our desired Developer Experience on the Nvidia happy-path.</p><p>Instead, we burned months trying (and ultimately failing) to get Nvidia‚Äôs host drivers working to map <a href=\"https://www.nvidia.com/en-us/data-center/virtual-solutions/\">virtualized GPUs</a> into Intel Cloud Hypervisor. At one point, we hex-edited the closed-source drivers to trick them into thinking our hypervisor was QEMU.</p><p>I‚Äôm not sure any of this really mattered in the end. There‚Äôs a segment of the market we weren‚Äôt ever really able to explore because Nvidia‚Äôs driver support kept us from thin-slicing GPUs. We‚Äôd have been able to put together a really cheap offering for developers if we hadn‚Äôt run up against that, and developers love ‚Äúcheap‚Äù, but I can‚Äôt prove that those customers are real.</p><p>On the other hand, we‚Äôre committed to delivering the Fly Machine DX for GPU workloads. Beyond the PCI/IOMMU drama, just getting an entire hardware GPU working in a Fly Machine was a lift. We needed Fly Machines that would come up with the right Nvidia drivers; our stack was built assuming that the customer‚Äôs OCI container almost entirely defined the root filesystem for a Machine. We had to engineer around that in our  orchestrator. And almost everything people want to do with GPUs involves efficiently grabbing huge files full of model weights. Also annoying!</p><p>And, of course, we bought GPUs. A lot of GPUs. Expensive GPUs.</p><p>The biggest problem: developers don‚Äôt want GPUs. They don‚Äôt even want AI/ML models. They want LLMs.  may have smart, fussy opinions on how to get their models loaded with CUDA, and what the best GPU is. But  don‚Äôt care about any of that. When a software developer shipping an app comes looking for a way for their app to deliver prompts to an LLM, you can‚Äôt just give them a GPU.</p><p>For those developers, who probably make up most of the market, it doesn‚Äôt seem plausible for an insurgent public cloud to compete with OpenAI and Anthropic. Their APIs are fast enough, and developers thinking about performance in terms of ‚Äútokens per second‚Äù aren‚Äôt counting milliseconds.</p><div><p>(you should all feel sympathy for us)</p></div><p>This makes us sad because we really like the point in the solution space we found. Developers shipping apps on Amazon will outsource to other public clouds to get cost-effective access to GPUs. But then they‚Äôll faceplant trying to handle data and model weights, backhauling gigabytes (at significant expense) from S3. We have app servers, GPUs, and object storage all under the same top-of-rack switch. But inference latency just doesn‚Äôt seem to matter yet, so the market doesn‚Äôt care.</p><p>Past that, and just considering the system engineers who do care about GPUs rather than LLMs: the hardware product/market fit here is really rough.</p><p>People doing serious AI work want galactically huge amounts of GPU compute. A whole enterprise A100 is a compromise position for them; they want an SXM cluster of H100s.</p><div><p>Near as we can tell, MIG gives you a UUID to talk to the host driver, not a PCI device.</p></div><p>We think there‚Äôs probably a market for users doing lightweight ML work getting tiny GPUs. <a href=\"https://www.nvidia.com/en-us/technologies/multi-instance-gpu/\">This is what Nvidia MIG does</a>, slicing a big GPU into arbitrarily small virtual GPUs. But for fully-virtualized workloads, it‚Äôs not baked; we can‚Äôt use it. And I‚Äôm not sure how many of those customers there are, or whether we‚Äôd get the density of customers per server that we need.</p><p><a href=\"https://fly.io/blog/cutting-prices-for-l40s-gpus-in-half\">That leaves the L40S customers</a>. There are a bunch of these! We dropped L40S prices last year, not because we were sour on GPUs but because they‚Äôre the one part we have in our inventory people seem to get a lot of use out of. We‚Äôre happy with them. But they‚Äôre just another kind of compute that some apps need; they‚Äôre not a driver of our core business. They‚Äôre not the GPU bet paying off.</p><p>Really, all of this is just a long way of saying that for most software developers, ‚ÄúAI-enabling‚Äù their app is best done with API calls to things like Claude and GPT, Replicate and RunPod.</p><p>A very useful way to look at a startup is that it‚Äôs a race to learn stuff. So, what‚Äôs our report card?</p><p>First off, when we embarked down this path in 2022, we were (like many other companies) operating in a sort of phlogiston era of AI/ML. The industry attention to AI had not yet collapsed around a small number of foundational LLM models. We expected there to be a diversity of  models, the world <a href=\"https://github.com/elixir-nx/bumblebee\" title=\"\">Elixir Bumblebee</a> looks forward to, where people pull different AI workloads off the shelf the same way they do Ruby gems.</p><p>But <a href=\"https://www.cursor.com/\" title=\"\">Cursor happened</a>, and, as they say, how are you going to keep ‚Äòem down on the farm once they‚Äôve seen Karl Hungus? It seems much clearer where things are heading.</p><p>GPUs were a test of a Fly.io company credo: as we think about core features, we design for 10,000 developers, not for 5-6. It took a minute, but the credo wins here: GPU workloads for the 10,001st developer are a niche thing.</p><p>Another way to look at a startup is as a series of bets. We put a lot of chips down here. But the buy-in for this tournament gave us a lot of chips to play with. Never making a big bet of any sort isn‚Äôt a winning strategy. I‚Äôd rather we‚Äôd flopped the nut straight, but I think going in on this hand was the right call.</p><p>A really important thing to keep in mind here, and something I think a lot of startup thinkers sleep on, is the extent to which this bet involved acquiring assets. Obviously, some of our <a href=\"https://fly.io/blog/the-exit-interview-jp/\" title=\"\">costs here aren‚Äôt recoverable</a>. But the hardware parts that aren‚Äôt generating revenue will ultimately get liquidated; like with <a href=\"https://fly.io/blog/32-bit-real-estate/\" title=\"\">our portfolio of IPv4 addresses</a>, I‚Äôm even more comfortable making bets backed by tradable assets with durable value.</p><p>In the end, I don‚Äôt think GPU Fly Machines were going to be a hit for us no matter what we did. Because of that, one thing I‚Äôm very happy about is that we didn‚Äôt compromise the rest of the product for them. Security concerns slowed us down to where we probably learned what we needed to learn a couple months later than we could have otherwise, but we‚Äôre scaling back our GPU ambitions without having sacrificed <a href=\"https://fly.io/blog/sandboxing-and-workload-isolation/\" title=\"\">any of our isolation story</a>, and, ironically, GPUs  are making that story a lot more important. The same thing goes for our Fly Machine developer experience.</p><p>We started this company building a Javascript runtime for edge computing. We learned that our customers didn‚Äôt want a new Javascript runtime; they just wanted their native code to work. <a href=\"https://news.ycombinator.com/item?id=22616857\" title=\"\">We shipped containers</a>, and no convincing was needed. We were wrong about Javascript edge functions, and I think we were wrong about GPUs. That‚Äôs usually how we figure out the right answers:  by being wrong about a lot of stuff.</p>","contentLength":9514,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43053844"},{"title":"Complex dynamics require complex solutions","url":"https://mathstodon.xyz/@tao/113873092369347147","date":1739570733,"author":"ckemere","guid":202,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43053625"},{"title":"The hardest working font in Manhattan","url":"https://aresluna.org/the-hardest-working-font-in-manhattan/","date":1739569549,"author":"robinhouston","guid":201,"unread":true,"content":"<p>\n\t\tIn 2007, on my first trip to New York City, I grabbed a brand-new DSLR camera and photographed all the fonts I was supposed to love. I admired American Typewriter in all of the I &lt;3 NYC logos, watched Akzidenz Grotesk and Helvetica fighting over the subway signs, and even caught an occasional appearance of the flawlessly-named Gotham, still a year before it skyrocketed in popularity via Barack Obama‚Äôs first campaign. \n\t</p><p>\n\t\tBut there was one font I didn‚Äôt even notice, even though it was everywhere around me.\n\t</p><p>\t\t\n\t\tLast year in New York, I walked over 100 miles and took thousands of photos of one and one font only.\n\t</p><p>\t\t\n\t\tThe font‚Äôs name is Gorton.\n\t</p><p>\t\t\n\t\tIt‚Äôs hard to believe today that there was a time before I knew of Gorton and all its quirks and mysteries. The first time I realized the font even existed was some time in 2017, when I was researching for <a target=\"_blank\" href=\"https://shifthappens.site\">my book about the history of typing</a>. \n\t</p><p>\t\t\n\t\tMany keyboards, especially older ones, sported a particular distinctive font on their keycaps. It was unusually square in proportions, and a weird m√©lange of ‚Äúmechanical‚Äù and ‚Äúchildish.‚Äù\n\t</p><p>\t\t \n\t\tThe more I looked at it, the more I realized how bizarre and amateurish it was. The G always felt like it was about to roll away on its side. There was a goofy wavy hook sticking out of Q. P and R were often too wide. &amp; and @ symbols would be laughed away in a type crit, and the endings of C felt like grabbing something next to it ‚Äì a beginning of a ligature that never came.\n\t</p><p>\t\t\n\t\tThe strangeness extended to the digits. There was a top-flatted 3 resembling a Cyrillic letter, 7 sloping down in a unique way, a very geometric 4, an unusual ‚Äì perhaps even na√Øve ‚Äì symmetry between 6 and 9, and a conflation of O with 0 that would be a fireable offense elsewhere.\n\t</p><p>\t\t\t\n\t\tLooking at just a few keyboards, it was also obvious that it wasn‚Äôt just one rigid font. There were always variations, sometimes even on one keyboard. 0 came square, dotted, or slashed. The usually very narrow letter I sometimes sported serifs. The R and the 6 moved their middles higher or lower. There also seemed to be a narrower version of the font, deployed when a keycap needed a word and not just a letter. (Lowercase letters existed too, but not very often.) \n\t</p><p>\t\t\n\t\tMy first thought was: What a mess. Is this how ‚Äú<a target=\"_blank\" href=\"https://fonts.ilovetypography.com/category/grotesque\">grotesque</a>‚Äù fonts got their name?\n\t</p><p>\t\t\n\t\tThen, the second thought: I kind of like it.\n\t</p><figcaption>The most distinctive letterforms of Gorton</figcaption><p>\t\t\n\t\tBut what font was it? What The Font website posited TT Rounds, Identifont suggested it could be Divulge, my early guess was DIN Rounded or something related to road signage. Whatever it was, a flat R clearly separated it from Helvetica, and the shapes were not as round as even the un-rounded Gotham‚Äôs.\n\t</p><p>\t\t\n\t\tA few places for keyboard nerds referred to the font as ‚ÄúGorton,‚Äù but that phrase yielded zero results anywhere I typically looked for fonts I could download and install.\n\t</p><p>\t\t\t\t\n\t\tI originally thought this had to do with how keys were made. Only in newer keyboards are the letters printed on top of the keys, or charred from their surface by a laser. In older ones ‚Äì those from the early 1960s laboratory computers, or the 1980s microcomputers ‚Äì&nbsp;the way every key was constructed was by first molding the letter from plastic of one color, and then grabbing a different plastic and molding the key around the letter. A Gorton letter was as physical as the key itself. It made the keys virtually indestructible ‚Äì the legend could not wear off any more than its key ‚Äì and I imagined required some specialized keyboard-making machinery that came with the ‚Äúkeyboard font‚Äù already there.\n\t</p><figcaption>\n\t\tAn example of a ‚Äúdouble-shot‚Äù key from above and from below\n\t</figcaption><p>\t\t\t\n\t\tBut then, I started seeing Gorton in other places.\n\t</p><p>\t\t\t\t\t\n\t\tHours of looking at close-ups of keys made me sensitive to the peculiar shapes of some of its letters. No other font had a Q, a 9, or a C that looked like this.\n\t</p><p>\t\t\t\t\t\n\t\tOne day, I saw what felt like Gorton it on a ferry traversing the waters Bay Area. A few weeks later, I spotted it on a sign in a national park. Then on an intercom. On a street lighting access cover. In an elevator. At my dentist‚Äôs office. In an alley. \n\t</p><p>\t\t\t\t\t\t\n\t\tThese had one thing in common. All of the letters were carved into the respective base material ‚Äì metal, plastic, wood. The removed shapes were often filled in with a different color, but sometimes left alone.\n\t</p><p>\t\t\t\t\t\n\t\tAt one point someone explained to me Gorton must have been a routing font, meant to be carved out by a milling machine rather than painted on top or impressed with an inked press.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tSome searches quickly led me to George Gorton Machine Co., a Wisconsin-based company which produced various engraving machines. The original model 1 led to model 1A and then 3U and then, half a decade later, P1-2. They were all pantograph engravers: They allowed you to install one or more letter templates and then trace their shape by hand. A matching rotating cutter would mimic your movements, and the specially configured arms would enlarge or reduce the output to the size you wanted.\n\t\t</p><p>\t\t\t\t\t\t\t\n\t\tThis immediately explained both the metaphorical and literal rough edges of Gorton.\n\t</p><p>\t\t\t\t\t\n\t\tA lot of typography has roots in calligraphy ‚Äì someone holding a brush in their hand and making natural but delicate movements that result in nuanced curves filled with thoughtful interchanges between thin and thick. Most of the fonts you ever saw follow those rules; even the most ‚Äúmechanical‚Äù fonts have surprising humanistic touches if you inspect them close enough.\n\t</p><p>\t\t\t\n\t\tBut not Gorton. Every stroke of Gorton is exactly the same thickness (typographers would call such fonts ‚Äúmonoline‚Äù). Every one of its endings is exactly the same rounded point. The italic is merely an oblique, slanted without any extra consideration, and while the condensed version has some changes compared to the regular width, those changes feel almost perfunctory.\n\t</p><p>\t\n\t\tMonoline fonts are not respected highly, because every type designer will tell you: This is not how you design a font. \n\t</p><p>\t\t\n\t\tIt seemed at this point that perhaps P1-2 and its predecessors were a somewhat popular machining product during the 20th century‚Äôs middle decades. But casual research through materials preserved by some of George Gorton Machine Company‚Äôs fans ‚Äì including <a target=\"_blank\" href=\"http://gorton-machine.org/\">the grandson of the founder</a> ‚Äì revealed something even more interesting. Gorton the font was a lot older than I expected. \n\t</p><p>\t\t\n\t\tI found a 1935 catalog showing the very same font. Then one from 1925. And then, there was one all the way from 1902, showing the shapes I was starting to be mildly obsessed with.\n\t</p><p>\t\t\t\n\t\tTo put it in perspective: the font I first assumed was a peer to 1950s Helvetica was already of retirement age the day Helvetica was born. Gorton was older than Gill Sans, Futura, or Johnston‚Äôs London Underground font. It was contemporaneous to what today we recognize as the first modern sans serif font, Akzidenz-Grotesk, released but three years before the end of the century.\n\t</p><p>\n\t\tImagine how stripped down and exotic Gorton must have felt right next to George Gorton Machine‚Äôs then-current logo!\n\t</p><p>\t\t\t\t\t\n\t\tI started researching Gorton more. Unfortunately, as I already suspected, no one ever wrote ‚ÄúI used Gorton to typeset this,‚Äù because Gorton was a tenuous name at best. It was the first font, and perhaps originally the  font that came with the engraver, so it suffered a nameless fate, familiar later to many bespoke bitmap fonts adoring the screens of early computers.\n\t</p><p>\t\t\t\t\t\n\t\tThe difference from these fonts, however, was that Gorton was meant to travel. And so, since searching for it by name was impossible, for months and years I just kept looking around for the now-familiar shapes.\n\t</p><p>\n\t\tGorton wasn‚Äôt just on computer keyboards, intercom placards, and sidewalk messages visited by many shoes. Gorton was there on typewriter keyboards, too. And on office signs and airline name tags. On boats, desk placards, rulers, and various home devices from fridges to tape dispensers.\n\t</p><p>\t\t\t\t\t\n\t\tIt was also asked to help in situations other fonts rarely did. I spotted Gorton on overengineered buttons that were put to heavy industrial and military use. I saw it carved into surfaces of traffic control devices, elevators and escalators, locomotives and subway trains, submarines and jet fighters. Gorton made its way to peace- and wartime nuclear facilities, it was there on the elevator at the Kennedy Space Center with labels marked EARTH and SPACE‚Ä¶ and it went  and then the Moon, as key legends on Apollo‚Äôs onboard computer.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tBut why? Why would anyone choose this kind of an ugly font where so many nicer fonts have already been around for ages?\n\t</p><p>\t\t\t\t\t\n\t\tSome of it might be the power of the default. Popular engraving equipment comes with a built-in font that‚Äôs so standard it reuses the router‚Äôs name? Of course you will see it, the same way you saw a lot of Arial in the 1990s, or Calibri today.\n\t</p><p>\n\t\tGorton was also convenient. If your previous engraving work required you do to the routing equivalent of handwriting or lettering ‚Äì every letter done by hand ‚Äì then a modern font you could simply  and one designed with ‚Äúa minimum of sharp corners for rapid tracing with a smooth stroke,‚Äù must have felt like a breath of fresh air.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tBut why engraving to begin with? Because the affordable and casual printing options we enjoy today ‚Äì the office laser printers and home inkjets, the FedEx Kinko‚Äôs, the various cheap labelers ‚Äì weren‚Äôt there. Even things that today feel obsolete, like dot matrix printers, Letraset, and popular letter stencils, were yet to be invented. Often, your only realistic option was the complicated and time-consuming lettering by hand.\n\t</p><p>\t\t\t\n\t\tOn top of that, Gorton‚Äôs longevity must have felt attractive. Ink smudges. Paint fades away. Paper can catch fire (quickly) or germs (slowly). Carve something into plastic, on the other hand, and it can survive decades. Substitute plastic for metal, and you just turned decades into centuries. The text is not added atop heavy-duty material. The text  the material.\n\t</p><figcaption>Various items from the 20th century typeset in Gorton</figcaption><p>\t\t\t\t\t\n\t\tI felt good about all my findings: What a strange story of a strange routing font! \n\t</p><p>\n\t\tBut it turns out I was just getting started. Because soon, I noticed Gorton as ink on paper, and as paint on metal.\n\t</p><p>We‚Äôre used to the flexibility of fonts today. Fonts as bits inside a computer can become a website, paint on paper, CNC routing, a wall projection, and many other things. But those freedoms weren‚Äôt as easy back when fonts were made out of metal. Life‚Äôs not as much fun outside of the glamor of a TTF file, and a routing font couldn‚Äôt immediately become a regular font ‚Äì so seeing Gorton being additive and not subtractive was an unexpected discovery.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tIt turns out that there developed a small cottage industry of things that extended Gorton past its engraving origins.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tA company called Keuffel &amp; Esser Co. grabbed Gorton‚Äôs machines, and used them to create lettering sets called Leroy. This was Gorton abstracted away ‚Äì still a pantograph, but cheap, small, completely manual, and a vastly simplified one: no possibility to make things bigger and smaller, and no carving ‚Äì&nbsp;instead, you‚Äôd mount a special pen and draw letters by tracing them.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tAnother company, Wood-Regan Instrument Co., made a similar set called (semi-eponymously) Wrico. But then, they simplified the process even more. Instead of a pantograph, they offered for sale a set of simple lettering guides used to guide your pen directly on paper.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tSome of the traditional draftspeople pooh-poohed these inventions ‚Äì one handbook wrote ‚Äú[Those are] of value chiefly to those who are not skilled in lettering. A professional show-card writer could work better and faster without it. A Leroy or Wrico lettering set permits work that is neat, rapid, and nearly foolproof, if not inspired.‚Äù\n\t</p><p>\t\t\t\n\t\tBut the products ended up being popular and influential. Their output appeared in many technical documents, but spread even a bit further than that. Eventually, there were stencils made by Unitech, Lutz, Tacro, Teledyne Post, Tamaya, Tech Graphic, Ridgway‚Äôs, Faber Castell, Zephyr, Charvoz, Rotring, Pickett, and probably many more.\n\t</p><p>\t\t\t\n\t\tThen, both EC Comics and All-Star Comics <a target=\"_blank\" href=\"https://kleinletters.com/Blog/wizards-of-leroy-and-wrico-lettering/\">used Leroy in the 1940s and 1950s</a>, most notably in the first comic book that introduced Wonder Woman. This was Gorton spreading further than just technical documents, and inspiring more people.\n\t</p><p>\t\t\t\n\t\tElsewhere silkscreening ‚Äì a pretty cool technique of applying paint on surfaces through a wet mesh of fabric ‚Äì took Gorton and Leroy in a different direction, by allowing paint on metal.\n\t</p><p>\t\t\t\n\t\tThere was more. The popular plastic letters attached to felt boards, popularized by restaurants decades ago, and more recently revisited by Instagram mom influencers, also clearly derive from Gorton and Leroy.\n\t</p><p>\n\t\tI also counted at least three different systems of ‚ÄúGorton movable type‚Äù ‚Äì some where you could assemble physical letters, and some where you could impress them into soft materials using steel types ‚Äì and I imagine there were probably more.\n\t</p><p>\t\t\t\n\t\tLetraset, a cheap technique of applying a font by rubbing a letter from a provided sheet onto paper, popular throughout the 1960s, introduced first- or second-hand Leroy too ‚Äì and so did a few competitors.\n\t</p><p>\t\t\t\t\t\n\t\tIn the regulatory space, the U.S. military canonized Gorton in 1968 as a standard called MIL-SPEC-33558 for aircraft and other equipment dials, cancelled it in 1998‚Ä¶ then brought it back again in 2007. NATO and STANAG followed. ANSI, American standardization body, made a more rounded Leroy an official font for technical lettering via <a target=\"_blank\" href=\"https://archive.org/details/ansi-y14.2m-1971-line-conventions-and-lettering\">ANSI Y14.2M</a>, and so did institutions like the US National Park Service.\n\t</p><p>\t\t\t\t\n\t\tGorton went on and on and on. The early <a target=\"_blank\" href=\"https://hackaday.com/2021/03/30/hershey-fonts-not-chocolate-the-origin-of-vector-lettering/\">Hershey vector fonts</a>, developed on very early computers and still popular in CAD applications today, were also derived from Gorton/Leroy shapes, simplified so that the already-simple curves weren‚Äôt even necessary ‚Äì&nbsp;any letter could now be drawn by a series of straight lines.\n\t</p><p>\t\t\t\t\t\n\t\tAnd even in the first universe Gorton inhabited things weren‚Äôt standing still. \n\t</p><p>\n\t\tAs the engraving industry learned what‚Äôs popular and what is not, the offerings started getting more and more sophisticated. A promotional booklet called ‚ÄúThe Whereabouts of 230 Engraving Machines‚Äù listed Gorton customers ranging from biscuit makers to fire engine constructors. <a target=\"_blank\" href=\"http://gorton-machine.org/forms/form_933/index.html\">Other</a><a target=\"_blank\" href=\"http://gorton-machine.org/forms/form_1370a/index.html\">catalogs</a><a target=\"_blank\" href=\"http://gorton-machine.org/forms/form_2070/index.html\">proudly listed</a> applications like book covers, billiard balls, organ keys, and toothbrushes, as well as ‚Äútools making more tools‚Äù ‚Äì using Gorton engravers to create legends for other machines.\n\t</p><p>\t\t\n\t\tAfter you bought your pantograph engraver, you could buy attachments for sometimes surprising use cases:\n\t</p><p>\n\t\tThe original machine-shop pantographs were supplanted by smaller portable units (called Pantoetchers) on one side, and by increasingly complex  devices on the other. First generation of those were still huge room-size endeavors with Nixie tubes and complex interfaces labeled‚Ä¶ in Gorton itself. \n\t</p><p>\n\t\tBut the technology matured quickly and soon more and more early manual ‚Äútracer-guided‚Äù pantographs that forced the operator to put letters side by side and then trace them by hand, were superseded by <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Numerical_control\">computerized ones</a>, with both the composition and the routing completely automated. They came from George Gorton Machine Co., and from competitors like New Hermes or H.P. Preis.\n\t</p><p>\t\t\t\t\n\t\tYou no longer had to buy the chromium-plated brass alphabets weighing up to 13 pounds, choosing the right size from 3/8¬¥¬¥ to 3¬¥¬¥ ahead of time (pantographs allowed for reductions and enlargements, but only gave you a few steps within a specific range.) \n\t</p><p>\n\t\tNow, fonts came as digits or formulas built into computer memory, or ‚Äì for a moment in time ‚Äì&nbsp;as separate cartridges you‚Äôd insert in eager slots. (And yes, before you ask:&nbsp;there were <a target=\"_blank\" href=\"https://archive.org/details/gorton-master-copy-type-for-all-pantograph-machines/page/n5/mode/2up\">other routing monoline fonts</a>, too. But I really don‚Äôt care about any of them.)\n\t</p><p>\t\t\t\t\t\n\t\tIt was the same story as in word processing right next door, where old-fashioned Gutenberg-era typesetting was being replaced by increasingly smaller and cheaper computers equipped with first-laughable-then-capable software.\n\t</p><p>\t\t\t\t\t\n\t\tAnd automation came for the Leroy branch of the tree as well. A few companies grabbed Leroy lettering templates and abstracted them away once more. They created curious small typewriter/plotter hybrids where typing letters on a keyboard would make the pen draw them on paper for you. (I own one of them, a Max Cadliner. It might be one of the strangest typewriters I‚Äôve seen ‚Äì a weird combination of a machine pretending to be another machine pretending to be a human hand.)\n\t</p><p>\t\t\t\t\n\t\tIf this was a Gorton typewriter, there were also Gorton , even more sophisticated 1980s machines whose text could be programmed in advance rather than typed one line at a time, and mixed with graphics.\n\t</p><p>\t\t\t\n\t\tI don‚Äôt think the ‚Äì by now 80 years and counting ‚Äì fractal explosion of Gorton made its original creators rich.\n\t</p><p>\t\t\t\n\t\tCopy protection in the world of typography is complicated. The font‚Äôs name can be trademarked and other companies legally prevented from using it, and you can‚Äôt just grab matrices or font files and copy them without appropriate licenses. But take any text output using a font and then redraw it ‚Äì and you are within your right to do so, and even to sell the final result. At least in America, or in some other countries until somewhat recently, the shapes of the letters themselves are not legally protected.\n\t</p><p>\t\t\t\n\t\tThis is why Keuffel &amp; Esser, Wood-Regan Instrument, and Letraset could potentially grab Gorton and claim it their own, as long as they didn‚Äôt name it Gorton. \n\t</p><p>\t\t\t\t\t\t\t\n\t\tBut of course, Gorton was barely named ‚ÄúGorton‚Äù to begin with. In the early days of George Gorton pantographs, as the default pantograph font, it came without a name. (The font sets for purchase were called ‚Äústandard copies.‚Äù) Then, as other fonts were added, it was retroactively named Gorton Normal ‚Äì the name of the company and the most generic word possible.\n\t</p><p>\t\t\t\t\t\n\t\tLeroy lettering sets started with one font, so similarly to Gorton the font started to be known as ‚ÄúLeroy,‚Äù then ‚ÄúSeries C,‚Äù then ‚ÄúGothic.‚Äù New Hermes called it simply ‚ÄúBlock,‚Äù Letraset went with ‚ÄúEngineering Standard,‚Äù and Rotring ‚Äì another producer of little computerized plotters&nbsp;‚Äì with ‚ÄúUniversal.‚Äù I‚Äôve also seen ‚ÄúA style,‚Äù ‚ÄúPlain Gothic,‚Äù and, mysteriously, ‚ÄúStandpoint.‚Äù \n\t</p><p>\t\t\t\t\t\t\t\n\t\tI don‚Äôt think this was meant to be disrespectful. ‚ÄúStandard,‚Äú ‚ÄúUniversal,‚Äù ‚ÄúA style‚Äù might not have had the connotations of ‚Äúgeneric‚Äù we associate with them today, but rather meaning ‚Äúthe only one you need,‚Äù ‚Äúapproved of by millions,‚Äù or ‚Äúthe ultimate.‚Äù\n\t</p><p>\t\t\t\t\t\t\t\n\t\tBut there  one name that felt somewhat inconsiderate. It appeared in one product in the 1980s, a few decades after the birth of another font whose name became recognizable and distinguished. In that product, Gorton was referred to as ‚ÄúLinetica.‚Äù\n\t</p><figcaption>A few rare examples of Gorton Extended in use</figcaption><p>\t\t\t\t\t\t\n\t\tEach of these reappearances made small changes to the shapes of some letters. Leroy‚Äôs ampersand was a departure from Gorton‚Äôs. Others softened the middle of the digit 3, and Wrico got rid of its distinctive shape altogether. Sometimes the tail of the Q got straightened, the other times K cleaned up. Punctuation ‚Äì&nbsp;commas, quotes, question marks ‚Äì&nbsp;was almost always redone. But even without hunting down the proof confirming the purchase of a Gorton‚Äôs pantograph or a Leroy template set as a starting point, the lineage of its lines was obvious. (The remixes riffed off of Gorton Condensed or the normal, squareish edition‚Ä¶ and at times both. The extended version ‚Äì not that popular to begin with ‚Äì was often skipped.)\n\t</p><figcaption>Classic Gorton vs. Gorton Modified</figcaption><p>\t\t\t\t\t\t\n\t\tThe only ‚Äúofficial‚Äù update to Gorton I know of, and one actually graced with a name, was Gorton Modified. It was made some time in the 1970s by one of the main keyboard keycap manufacturers, Comptec (later Signature Plastics). It was almost a fusion of Gorton and Futura, with more rounded letterforms. Gone was the quirkiness of 3, 7, Q, C, and the strange, tired ampersand. This is the version people might recognize from some of the 1980s computers, or mechanical keyboards today. \n\t</p><p>\n\t\tIt is also that last Gorton that mattered.\n\t</p><figcaption>A collection of movies and TV shows featuring Gorton</figcaption><p>\t\t\t\t\t\t\t\n\t\tMy every walk in Chicago or San Francisco was counting down ‚Äútime to Gorton‚Äù ‚Äì sometimes mere minutes before I saw a placard or an intercom with the familiar font.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tThis might be embarrassing to admit, but I have never been so happy seeing a font in the wild, particularly as there was almost always some new surprise ‚Äì a numero, a line going through the Z, a new use, or a new imperfection. And, for a font that didn‚Äôt exist, I saw it surprisingly often.\n\t</p><p>\t\t\t\t\t\t\t\t\t\n\t\tI even spotted Gorton a few times in Spain, or the U.K., and didn‚Äôt make too much of it, not thinking about the likelihood of machines from George Gorton‚Äôs company in a small town of Racine, Wisconsin making it all the way to different continents. In hindsight I should have.\n\t</p><figcaption>Gorton on old British cars, with a particularly delightful Rolls Royce logo made by a simple duplication of the classic Gorton letter R</figcaption><p>\t\t\t\t\t\t\n\t\tIt was only on a trip to Australia where something started connecting. Here, once more, I saw Gorton on the streets, put to work in all sorts of unglamorous situations:\n\t</p><p>\t\t\t\t\t\t\t\n\t\tSome letterforms in the above photos felt slightly odd, and so did Gorton on the heavy machinery in an abandoned shipyard on an island near Sydney:\n\t</p><p>\t\t\t\t\t\t\t\n\t\tAnd a visit to a naval museum cemented it all:\n\t</p><p>\n\t\tIt was Gorton, although with some consistent quirks: 2, 5, 6, and 9 were shorter, the centers of M and W didn‚Äôt stretch all the way across, and the distinctive shape of S was slightly different here.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tFortunately, this time around, a type designer familiar with my now-public obsession with Gorton clued me in. Gorton didn‚Äôt actually originate from Racine, Wisconsin in the late 19th century. It started a bit earlier, and quite a bit further away, at a photographic lens maker in the U.K. called Taylor, Taylor &amp; Hobson. \n\t</p><p>\t\t\t\t\t\t\t\n\t\tIn 1894, TT&amp;H needed some way to put markings on their lenses. This being late 19th century, their options were limited to manual engraving, which must have felt tricky given the small font sizes necessary. So the company did what makers sometimes do ‚Äì instead of searching for a solution that might not have even existed, they made new types of machines to carve out letters, and then designed a font to be used with them.\n\t</p><p>\n\t\tI don‚Äôt know how this first proto-Gorton was designed ‚Äì unfortunately, Taylor, Taylor &amp; Hobson‚Äôs history seems sparse and despite personal travels to U.K. archives, I haven‚Äôt found anything interesting ‚Äì but I know simple technical writing standards existed already, and likely influenced the appearance of the newfangled routing font.\n\t</p><figcaption>From a 1895 ‚ÄúFree-hand lettering‚Äù book by Frank T. Daniels</figcaption><p>\t\t\t\t\t\n\t\tThis was perhaps the first modern pantograph engraver, and perhaps even the arrival of a concept of an engraving font ‚Äì the first time technical writing was able to be replicated consistently via the aid of the machine.\n\t</p><p>\t\t\t\n\t\tNo wonder that other companies came knocking. Only a few years later, still deep within the 19th century, Taylor, Taylor &amp; Hobson <a target=\"_blank\" href=\"http://gorton-machine.org/archives/TTH_license_1898/index.html\">licensed their stuff to a fledgling American company</a> named after its founder. Gorton Model 1 was the first U.S. version of the engraver, and the TT&amp;H font must have been slightly adjusted on arrival. \n\t</p><figcaption>A Taylor-Hobson pantograph in use in 1942</figcaption><p>\t\t\t\n\t\tThis adds to the accomplishments of Gorton ‚Äì the font was actually  than even Akzidenz-Grotesk, and has been used on World War II equipment and later on on British rifles and motorcycles (and 3,775 finger posts in <a target=\"_blank\" href=\"https://www.yorkshiredales.org.uk/behind-the-signs-the-man-and-the-machine/\">one of the UK‚Äôs national parks</a>), but it complicates the story of the name even more. Turns out, the font without a name has even less of a name than I suspected.\n\t</p><p>\t\t\t\n\t\tIf the Taylor, Taylor &amp; Hobson (or, Taylor-Hobson, as their engravers were known) ‚Äúbranch‚Äù of Gorton were more used, should it usurp the at least somewhat popular Gorton name? Or should it just because it was first and the letterform changes were small? Does it matter? Where does one font end and another begin? (Unsurprisingly, TT&amp;H didn‚Äôt properly name the font either, eventually calling it ‚ÄúA style‚Äù for regular and ‚ÄúC style‚Äù for condensed variants. Google searches for ‚Äútaylor hobson font‚Äù are a lot more sparse than those for Gorton.)  \n\t</p><div><div><div>GortonGorton Condensed</div></div></div><figcaption>The Gorton quasisuperfamily</figcaption><p>\n\t\tIn the end, I‚Äôm sticking with Gorton for the whole branch since that feels the most well-known name, but I feel ill-equipped to make that call for everyone. You might choose to call it Gorton, Leroy, TT&amp;H, Taylor-Hobson, or one of the many other names. (Just, ideally, not Linetica.)\n\t</p><figcaption>A comparison of all major editions of Gorton</figcaption><p>\t\t\t\t\t\n\t\tAnd so, throughout the 20th century, Gorton has lived two parallel lives ‚Äì&nbsp;one originating in the U.K. and later expanding to its colonies and the rest of Europe, and another one in America. \n\t</p><p>\t\t\t\t\t\t\t\n\t\tI am still tracing various appearences of Gorton and perhaps you, dear reader, will help me with that. (<a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Frequency_illusion\">Chances are</a>, you will see Gorton later today!) I‚Äôm curious about whether Gorton made it to Eastern Europe, Africa, or Asia. I‚Äôm interested in seeing if it appeared in Germany where the objectively better-designed DIN fonts became much more popular in Gorton‚Äôs niche.\n\t</p><p>\n\t\tThe history of this strange font spans over a century and I‚Äôve seen it in so many countries by now, used in so many situations. But it‚Äôs impossible for me to say Gorton is the most hard-working font in the world.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tTo this title, there are many contenders. Garamond has a head start of 300+ years and has been released in more versions than letters in any alphabet. Helvetica is so famous and used so much that even its ugly copy, Arial, became a household name. Whatever font MS Office or a popular operating system appoint to be ‚Äúthe default‚Äù ‚Äì from Times New Roman through Calibri to Roboto ‚Äì immediately enjoys the world premiere that any Hollywood movie would be envious of. There is even a 5√ó7 pixel font originally started by Hitachi that you can see everywhere on cheap electronic displays in cash registers and intercoms.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tBut there is one place in the world where Gorton pulls triple duty, and I feel confident in saying at least this: Gorton is the hardest working font in Manhattan.\n\t</p><p>\t\t\t\t\t\t\n\t\tIn 2007, on my first trip to New York City, I grabbed my brand-new DSLR camera and photographed all the fonts I was supposed to love: American Typewriter, Helvetica, Gotham. But, in hindsight, I missed the most obvious one.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tGorton is everywhere in Manhattan. It‚Äôs there in the elevators, in the subway, on ambulances, in various plaques outside and inside buildings. And god knows it‚Äôs there on so, so many intercoms.\n\t</p><p>\t\t\t\t\t\n\t\tI wouldn‚Äôt be surprised if there weren‚Äôt a single block without any Gorton in a whole of Manhattan.\n\t</p><figcaption>A complete inventory of Gorton outside, near my hotel, between 5th and 7th avenues and 25th and 35th streets. I didn‚Äôt have access to the interiors of most buildings.</figcaption><p>\t\n\t\tThe omnipresence of Gorton makes it easy to collect all the type crimes layered on top of the font‚Äôs already dubious typographical origins. Walking through Manhattan, you can spot the abominable lowercase that should better be forgotten:\n\t</p><p>\t\t\t\t\t\t\t\n\t\tYou can see all sorts of kerning mistakes:\n\t</p><p>\t\t\t\t\t\t\t\t\t\n\t\tYou will notice the many, many routing imperfections ‚Äì an unfinished stroke, a shaky hand, or services of a pantograph that never felt the loving touch of regular maintenance:\n\t</p><p>\n\t\tThere are all the strange decisions to haphazardly mix various styles of Gorton, or even to mix Gorton with other fonts:\n\t</p><p>\t\t\t\t\t\t\t\t\t\t\t\n\t\tYou can even spot reappearing strange characters like a weirdly deep 3, or a flattened 4:\n\t</p><p>\n    I wish I understood how they came to be, but I have a hunch. The nature of pantographic reproduction is that Gorton carved into metal is not that far away from the original Gorton font template you started with! So in addition to the George Gorton and Taylor Hobson originals, and the other named and above-the-table copies, they might have been bigger or smaller Gorton . I have one myself, carved into acrylic, of unknown provenance and even more nameless than I thought possible for an already name-free font.\n  </p><p>\n\t\tBut New York Gorton holds pleasant surprises, too. Despite the simplicity of Gorton itself, the combinations of font sizes, cutter sizes, materials, reproductions, and applications can still yield some striking effects:\n\t\n\t</p><figcaption>\n\t\t\tAll my Gorton walks in Manhattan in 2024\n\t\t</figcaption>\n\n\t\tThis was what made me walk 100 miles. Over and over again, Gorton found ways to make itself interesting. Without hyperbole, I consider the above photos simply beautiful.\n\t<p>\n\t\tIn a city that never sleeps, Gorton wasn‚Äôt allowed to sleep, either. Even in the richest and most glamorous neighborhoods of Manhattan, the font would be there, doing the devil‚Äôs work without complaining. Gorton made Gotham feel bougie; American Typewriter touristy.\n\t</p><p>\n\t\tAnd once in a while, I‚Äôd find Gorton that would wink at me with a story ‚Äì&nbsp;followed by that aching in the heart as I realized I‚Äôd never know what the story was.\n\t</p><p>\t\t\t\n\t\tYou‚Äôre not supposed to fall in love with an ugly font. No one collects specimens of Arial. No one gets into eBay fights for artifacts set in Papyrus. No one walks a hundred miles in a hot New York summer, sweating beyond imagination, getting shouted at by security guys, to capture photos of Comic Sans.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tSo why do I love Gorton so much? \n\t</p><p>\t\t\t\t\t\t\t\n\t\tThe Occam‚Äôs Razor seems sharp on this one. Perhaps I like it because I‚Äôm a boy and Gorton is often attached to heavy machinery. \n\t</p><p>\t\t\t\t\n\t\tBut there must be more to it. Perhaps it‚Äôs all about the strange contrasts Gorton represents. The font is so ubiquitous, but also profoundly unrecognizable, sporting no designer and no name. Gorton is a decidedly toy-like, amateurish font deployed to for some of the most challenging type jobs: nuclear reactors, power plants, spacecraft. More than most other fonts, Gorton feels it‚Äôs been made by machines for machines ‚Äì&nbsp;but in its use, it‚Äôs also the font that allows you to see so many human mistakes and imperfections.\n\t</p><p>\t\t\t\t\n\t\tGorton also feels mistake-friendly. The strange limitations of Gorton mean that some of the transgressions of other fonts don‚Äôt apply here. The monoline nature of the font means that messing with the size of Gorton is okay: Shrinking the font for small caps or superscript, for example, gives you still-valid letterforms, almost by accident. \n\t</p><p>\n\t\tStretching or slanting Gorton is not as much a typographical crime as it would be with other fonts because you don‚Äôt stretch the tip of the router itself.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tThere are genuinely moments where I felt Gorton gave people freedoms to maul it decades before variable fonts allowed us similar flexibiity.\n\t\tAnd on top of that, the simplicity of the letterforms themselves feels compatible with the typical na√Øvet√© of Gorton‚Äôs typesetting. \n\t</p><figcaption>Various accessories and attachments allowing you to shift Gorton around in a way other fonts would not allow</figcaption><p>\n    Sure, there are really bad renditions that are inexcusable. \n\n\t\tBut most of the time, the imperfections and bad decisions are what makes Gorton come alive. They don‚Äôt feel like a profound misunderstandings of typography, typesetting, or Gorton itself. They don‚Äôt feel like abuses or aberrations. No, they feel exactly how Gorton was supposed to be used ‚Äì haphazardly, without much care, to solve a problem and walk away. (Later routing fonts copied Helvetica, but seeing Helvetica in this context with all the same mistakes grates so much more.)\n\t</p><p>\t\t\t\n\t\tThe transgressions are not really transgressions. They all feel honest. The font and its siblings just show up to work without pretense, without ego, without even sporting a nametag. Gorton isn‚Äôt meant to be admired, celebrated, treasured. It‚Äôs meant to do some hard work and never take credit for it. Gorton feels like it was always a font, and never a typeface. (Depending on how rigid you are with your definitions, some versions of Gorton ‚Äì especially those without instructions on how letters are positioned against each other ‚Äì might not even <a target=\"_blank\" href=\"https://mastodon.design/@fhardwig@mastodon.social/113515144112560218\">classify as a font</a>!)\n\t</p><p>\t\t\t\t\t\n\t\tAnd I think I love Gorton because over the years I grew a little tired of the ultra flat displays rendering miniature pixels with immaculate precision. \t\n\t\tWith Gorton, carving into metal or plastic means good-looking fixes are impossible:\n\t</p><p>\n\t\tAnd unsurprising given its roots, Gorton has dimensionality that most fonts cannot ever enjoy: A routing tip picked in the 1980s and a sun coming in from just the right angle forty years later can create a moment that thousands of letterpress cards can only dream of.\n\t</p><p>\n\t\tPerhaps above everything else, Gorton is all about . \n  </p><p>\n    Every kind of engraving has it, of course. But these are not precise submillimeter letters at the bottom of your MacBook Pro or Apple Watch. This is the utilitarian, often harried, sometimes downright  Gorton, carved into steel of a  \n\t\tmid-century intercom and filled in with <a target=\"_blank\" href=\"https://youtu.be/llzdLgMurvw?si=8S7px9gg8iH4iav2&amp;t=101\">special paste or wax</a>, or put on an office placard made out of a special two-layer material made especially so engraving it reveals the second color underneath, without the need for infill. \n\t</p><p>\t\t\t\n\t\t(This is also true when it comes to the original reason I learned of Gorton. Letters on keycaps show the same artifacts ‚Äì you just have to look very, very closely.)\n\t</p><p>\n\t\tThat‚Äôs the last, and perhaps the best thing to fall in love with. \n\t</p><p>\n\t\tYou won‚Äôt be able to fully appreciate it here, of course, but maybe this will give an approximation of how beautiful Gorton‚Äôs non-beauty can be:\n\t</p><p>\t\t\t\t\t\n\t\tThis has been a strange thing to write. Gorton has been around for over 135 years and used in so many countries for so many reasons, and yet I found no single article about it. \n\t</p><p>\t\t\t\t\t\n\t\tI feel the burden of being an amateur historian, wanting to know and share so much more, but only being able to provide little. I don‚Äôt know the full extent of Gorton‚Äôs use. I don‚Äôt know who designed it. My chronology is rickety and pieced together from a few breadcrumbs. I dream of seeing the original drawings or drafts once laid on the tables of Taylor, Taylor &amp; Hobson offices, or some notes, or some correspondence. I fear they might no longer exist.\n\t</p><p>\t\t\t\t\t\n\t\tAlso, if part of the allure of Gorton is shying away from the limelight and not being admired, am I doing it a disservice by writing about it?\n\t</p><p>\t\t\t\t\t\n\t\tBut mostly, I can‚Äôt shake the feeling that we all missed a window. That this essay can‚Äôt be just a celebration, but also needs to be the beginnings of a eulogy.\n\t</p><p>\t\t\t\t\t\n\t\tWalking around New York, you get a sense that even Gorton carved into metal can disappear. Some of the signs are rusted or destroyed beyond repair. Others get replaced by more modern, charmless equivalents.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tGorton itself is obsolete. All <a target=\"_blank\" href=\"https://spkeyboards.com/\">the keyboards that use Gorton Modified</a> you can still buy new today are tipping a hat to nostalgia. The omnipresence of Gorton in New York City is already time shifted from its decades of glory, a simple confirmation of what Robert Moses knew so well: that once built, cities don‚Äôt change all that much. But few of the new placards use Gorton, and none of the new intercoms do. \n\t</p><p>\n\t\tTaylor, Taylor &amp; Hobson went through multiple splits and mergers and survives as a subsidiary of Ametek, chiefly working on measuring devices. George Gorton Machine Co. from Racine has been bought by Kearny &amp; Trecker, which became Cross &amp; Trecker, was acquired by Giddings &amp; Lewis, and then acquired  by ThyssenKrupp, but not before the Gorton branch was spun off as Lars, and in a sequence of events now resembling a telenovella, eventually bought by Famco in 1987. I do not believe any corporate grandchildren of TT&amp;H and George Gorton‚Äôs company are today selling Gorton in any capacity.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tIt will take decades, perhaps even centuries, but one day the last of this font will be gone. The modern recreations (<a target=\"_blank\" href=\"https://aresluna.org/the-hardest-working-font-in-manhattan/the-hardest-working-font-in-manhattan/recreations\">I eventually found quite a few</a>) won‚Äôt help. They are perhaps all missing a point, anyway.\n\t</p><p>\n\t\tBut there‚Äôs a somewhat silver lining. Yes, when Gorton is carved into fresh metal, there might be nothing more pretty than seeing its depths glistening in the sun.\n\t</p><p>\n\t\tBut fresh, shining metal is at this point rare. Fortunately, the Gorton I love most is the weathered Gorton.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tManhattan‚Äôs tired Gorton is the best variant of Gorton: infill cracked by hot summers followed by frigid winters, the surface scratched by keys or worn out by many finger presses, the routing snafus meeting decades of wear and tear. Gorton‚Äôs no stranger to water, snow, rust, or dirt.\n\t</p><p>\t\t\n\t\tThis is, perhaps, how you become gortonpilled. You learn to recognize the 7 with a crooked hook, the Q with a swung dash, the strange top-heavy 3, the simple R. You start noticing the endings of each character being consistently circular, rather than occasionally flat. A routing mistake, suspicious kerning, or the absence of lowercase are not a wrongdoing ‚Äì they‚Äôre a .\n\t</p><p>\t\t\t\t\t\t\t\n\t\tYou find yourself enchanted with how this simple font went so very far. And then you touch the letters, just to be sure. If you can  them, chances are this is Gorton.\t\t\n\t</p>","contentLength":38055,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43053419"},{"title":"The Iconic 3DBenchy Enters the Public Domain","url":"https://www.nti-group.com/home/information/news/3dbenchy/","date":1739569169,"author":"kotaKat","guid":200,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43053350"},{"title":"GitHub - Clivern/Peanut: üê∫ Deploy Databases and Services Easily for Development and Testing Pipelines.","url":"https://github.com/Clivern/Peanut","date":1739567268,"author":"/u/Clivern","guid":480,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1ipl12p/github_clivernpeanut_deploy_databases_and/"},{"title":"Calico apiserver FailedDiscovery Check","url":"https://www.reddit.com/r/kubernetes/comments/1ipkg32/calico_apiserver_faileddiscovery_check/","date":1739565735,"author":"/u/Flimsy_Tomato4847","guid":608,"unread":true,"content":"<div><p>I installed the calico operator and follwing custom-resources.yaml:</p><pre><code># This section includes base Calico installation configuration. # For more information, see: https://docs.tigera.io/calico/latest/reference/installation/api#operator.tigera.io/v1.Installation apiVersion: operator.tigera.io/v1 kind: Installation metadata: name: default spec: # Configures Calico networking. calicoNetwork: ipPools: - name: default-ipv4-ippool blockSize: 26 cidr: 192.168.0.0/16 encapsulation: None natOutgoing: Enabled nodeSelector: all() --- # This section configures the Calico API server. # For more information, see: https://docs.tigera.io/calico/latest/reference/installation/api#operator.tigera.io/v1.APIServer apiVersion: operator.tigera.io/v1 kind: APIServer metadata: name: default spec: {} </code></pre><p>Getting this error in kube-apiserver logs:</p><pre><code>E0214 20:38:09.439846 1 remote_available_controller.go:448] \"Unhandled Error\" err=\"v3.projectcalico.org failed with: failing or missing response from https://10.96.207.72:443/apis/projectcalico.org/v3: Get \\\"https://10.96.207.72:443/apis/projectcalico.org/v3\\\": dial tcp 10.96.207.72:443: connect: connection refused\" logger=\"UnhandledError\" E0214 20:38:09.445839 1 controller.go:146] \"Unhandled Error\" err=&lt; Error updating APIService \"v3.projectcalico.org\" with err: failed to download v3.projectcalico.org: failed to retrieve openAPI spec, http error: ResponseCode: 503, Body: error trying to reach service: dial tcp 10.96.207.72:443: connect: connection refused </code></pre><p>calico-apiserver calico-api ClusterIP <a href=\"http://10.96.207.72\">10.96.207.72</a>&lt;none&gt; 443/TCP 45m</p><p>Do you know any things to solve this?</p></div>   submitted by   <a href=\"https://www.reddit.com/user/Flimsy_Tomato4847\"> /u/Flimsy_Tomato4847 </a>","contentLength":1635,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Rust, C(23), or Zig for a Synthesizer?","url":"https://www.reddit.com/r/rust/comments/1ipja2x/rust_c23_or_zig_for_a_synthesizer/","date":1739562706,"author":"/u/mekaulu","guid":627,"unread":true,"content":"<p>I have been programming in C for 8+ years and I am sick of it, but it's really comfortable for me to use it. I have been considering using Rust or Zig(or Ada, but tried it for a few months then gave up) but I can't really decide.</p><p>I know Zig and used it for small experimental game engine but I am quite worried about it not being 1.0 yet( yes I know Bun is using Zig).</p><p>I read a lot about Rust but I have no experience of actually using it therefore learning it probably take a bit of time. Although from what I have read from the docs it seems fairly easy enough for me to understand it, I have no idea what's going on sometimes and that worries me a bit. How much compiler magic is behind Rust? Can I use custom allocators easily? Macros seems to be mandatory to use?</p><p>I generally code a lot of stuff from scratch in C, and I will probably do so in Rust or Zig as well. For example, I have been slowly building \"custom\" stdlib for my needs (like Zig stdlib, all allocations are explicit, it also has optional return types, multithreading, cross-platform graphics library etc.). Even with all that though, like I said, I am sick of it lol.</p><p>So what do you guys recommend?</p><p>Sometimes I just think, \"who cares, just use C and get stuff done\", though for some reason I can't follow through this advice. Idk why tho.</p>","contentLength":1304,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Shutdown Go server","url":"https://www.reddit.com/r/golang/comments/1ipj5zn/shutdown_go_server/","date":1739562402,"author":"/u/Kennedy-Vanilla","guid":483,"unread":true,"content":"<div><p>Hi, recently I saw that many people shutdown their servers like this or similar</p><pre><code>serverCtx, serverStopCtx serverCtx, serverStopCtx := context.WithCancel(context.Background()) sig := make(chan os.Signal, 1) signal.Notify(sig, syscall.SIGHUP, syscall.SIGINT, syscall.SIGTERM, syscall.SIGQUIT) go func() { &lt;-sig shutdownCtx, cancelShutdown := context.WithTimeout(serverCtx, 30*time.Second) defer cancelShutdown() go func() { &lt;-shutdownCtx.Done() if shutdownCtx.Err() == context.DeadlineExceeded { log.Fatal(\"graceful shutdown timed out.. forcing exit.\") } }() err := server.Shutdown(shutdownCtx) if err != nil { log.Printf(\"error shutting down server: %v\", err) } serverStopCtx() }() log.Printf(\"Server starting on port %s...\\n\", port) err = server.ListenAndServe() if err != nil &amp;&amp; err != http.ErrServerClosed { log.Printf(\"error starting server: %v\", err) os.Exit(1) } &lt;-serverCtx.Done() log.Println(\"Server stopped\") } := context.WithCancel(context.Background()) sig := make(chan os.Signal, 1) signal.Notify(sig, syscall.SIGHUP, syscall.SIGINT, syscall.SIGTERM, syscall.SIGQUIT) go func() { &lt;-sig shutdownCtx, cancelShutdown := context.WithTimeout(serverCtx, 30*time.Second) defer cancelShutdown() go func() { &lt;-shutdownCtx.Done() if shutdownCtx.Err() == context.DeadlineExceeded { log.Fatal(\"graceful shutdown timed out.. forcing exit.\") } }() err := server.Shutdown(shutdownCtx) if err != nil { log.Printf(\"error shutting down server: %v\", err) } serverStopCtx() }() log.Printf(\"Server starting on port %s...\\n\", port) err = server.ListenAndServe() if err != nil &amp;&amp; err != http.ErrServerClosed { log.Printf(\"error starting server: %v\", err) os.Exit(1) } &lt;-serverCtx.Done() log.Println(\"Server stopped\") </code></pre><p>Is it necessary? Like it's so many code for the simple operation</p></div>   submitted by   <a href=\"https://www.reddit.com/user/Kennedy-Vanilla\"> /u/Kennedy-Vanilla </a>","contentLength":1805,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"the ref keyword","url":"https://www.reddit.com/r/rust/comments/1ipixny/the_ref_keyword/","date":1739561817,"author":"/u/Tickstart","guid":628,"unread":true,"content":"<p>I've made a quick mock situation which is analogous to my situation the other day:</p><pre><code>fn main() { let mut v: Option&lt;Vec&lt;usize&gt;&gt; = None; let mut h = 20; while h.ne(&amp;0) { if (h % 3).ge(&amp;1) { match v { Some(ref mut v) =&gt; (*v).push(h), None =&gt; v = Some(vec![h]) } } h -= 1 } println!(\"{v:?}\") } </code></pre><p>I was a bit confused on how it \"should\" be solved. My issue is the \"ref mut\". It made sense to me that I didn't want to consume the vector v, just add to it if it existed and I tried adding ref (then mut), which worked. When I goodled, it seemed ref was a legacy thing and not needed anymore. My question is, how is the idiomatic way to write this? Perhaps it's possible to do in a much simpler way and I just found a way to complicate it for no reason.</p><p>Also, don't worry I know this is a terrible pattern, it was mostly for tesing something.</p>","contentLength":828,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Lead Asahi Linux Developer Quits Days After Leaving Kernel Maintainer Role","url":"https://linux.slashdot.org/story/25/02/14/1842251/lead-asahi-linux-developer-quits-days-after-leaving-kernel-maintainer-role?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739558520,"author":"msmash","guid":273,"unread":true,"content":"Hector Martin has resigned as the project lead of Asahi Linux, weeks after stepping down from his role as a Linux kernel maintainer for Apple ARM support. His departure from Asahi follows a contentious exchange with Linus Torvalds over development processes and social media advocacy. After quitting kernel maintenance earlier this month, the conflict escalated when Martin suggested that \"shaming on social media\" might be necessary to effect change. \n\nTorvalds sharply rejected this approach, stating that \"social media brigading just makes me not want to have anything at all to do with your approach\" and suggested that Martin himself might be the problem. In his final resignation announcement from Asahi, Martin wrote: \"I no longer have any faith left in the kernel development process or community management approach.\" \n\nThe dispute reflects deeper tensions in the Linux kernel community, particularly around the integration of Rust code. It follows the August departure of another key Rust for Linux maintainer, Wedson Almeida Filho from Microsoft. According to Sonatype's research, more than 300,000 open source projects have slowed or halted updates since 2020.","contentLength":1172,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Macro-Less, Highly Integrated OpenAPI Document Generation in Rust with Ohkami","url":"https://medium.com/@kanarus786/macro-less-highly-integrated-openapi-document-generation-in-rust-with-ohkami-912de388adc1","date":1739557605,"author":"/u/kanarus","guid":626,"unread":true,"content":"<p>In Rust web dev, <a href=\"https://github.com/juhaku/utoipa\" rel=\"noopener ugc nofollow\" target=\"_blank\">utoipa</a> is the most popular crate for generating OpenAPI document from server code. While it‚Äôs a great tool, it can be frustrating due to excessive macro use.</p><p>A new web framework Ohkami offers a ,  way to generate OpenAPI document with its ‚Äúopenapi‚Äù feature.</p><p>Let‚Äôs take following code as an example. It‚Äôs the same sample from the ‚Äúopenapi‚Äù section of the README, but with openapi-related parts removed:</p><pre></pre><p>While this compiles and works as a pseudo user management server, activating ‚Äúopenapi‚Äù feature causes a compile error, telling that User and CreateUser don‚Äôt implement ohkami::openapi::Schema.</p><p>As indicated by this, Ohkami with ‚Äúopenapi‚Äù feature effectively handles type information and intelligently collects its endpoints‚Äô metadata. It allows code like:</p><pre></pre><p>to assemble metadata into an OpenAPI document and output it to a file .</p><p>Then, how we implement Schema? Actually we can easily impl Schema by hand, or just #[derive(Schema)] is available! In this case, derive is enough:</p><pre></pre><p>That‚Äôs it! Just adding these derives allows Ohkami::generate to output following file:</p><pre></pre><p>Additionally, it‚Äôs easy to define the User schema as a component instead of duplicating inline schemas. In derive, just add #[openapi(component)] helper attribute:</p><pre></pre><pre></pre><p>And  #[operation] attribute is available to set summary, description, and override operationId and each response‚Äôs description:</p><pre></pre><pre></pre><p>Let‚Äôs take a look at how this document generation works!</p><p>First, the #[derive(Schema)]s are expanded as following:</p><pre></pre><pre></pre><p>The DSL enables to easily impl manually.</p><p>Schema trait links the struct to an item of type called ‚ÄúSchemaRef‚Äù.</p><h2>2. openapi_* hooks of FromParam, FromRequest, IntoResponse</h2><p>FromParam, FromRequest and IntoResponse are Ohkami‚Äôs core traits appeared in the handler bound:</p><pre></pre><p>When ‚Äúopenapi‚Äù feature is activated, they additionally have following methods:</p><pre></pre><p>Ohkami leverages these methods in IntoHandler to generate consistent openapi::Operation, reflecting the actual handler signature like <a href=\"https://github.com/ohkami-rs/ohkami/blob/6e243ac823e21f286aca2660f9d38f7bde381c5a/ohkami/src/fang/handler/into_handler.rs#L328-L335\" rel=\"noopener ugc nofollow\" target=\"_blank\">this</a>.</p><p>Moreover, Ohkami properly propagates schema information in common cases like <a href=\"https://github.com/ohkami-rs/ohkami/blob/6e243ac823e21f286aca2660f9d38f7bde381c5a/ohkami/src/response/into_response.rs#L114-L128\" rel=\"noopener ugc nofollow\" target=\"_blank\">this</a>, allowing users to focus only on the types and schemas of their app.</p><h2>3. routes metadata of Router</h2><p>In Ohkami, what‚Äôs called router::base::Router <a href=\"https://github.com/ohkami-rs/ohkami/blob/6e243ac823e21f286aca2660f9d38f7bde381c5a/ohkami/src/router/base.rs#L8-L18\" rel=\"noopener ugc nofollow\" target=\"_blank\">has ‚Äúroutes‚Äù property</a> that stores all the routes belonging to an Ohkami instance. This is returned alongside router::final::Router from ‚Äúfinalize‚Äù step, and is used to assemble metadata of all endpoints.</p><p>What Ohkami::generate itself does is just to serialize an item of type openapi::document::Document and write it to a file.</p><p>The openapi::document::Document item is created by<a href=\"https://github.com/ohkami-rs/ohkami/blob/6e243ac823e21f286aca2660f9d38f7bde381c5a/ohkami/src/router/final.rs#L54-L59\" rel=\"noopener ugc nofollow\" target=\"_blank\"> ‚Äúgen_openapi_doc‚Äù of router::final::Router</a>, summarized as follows:</p><pre></pre><p>That‚Äôs how Ohkami generates OpenAPI document!</p><p>There is, however, a problem in , Cloudflare Workers: Ohkami is loaded to Miniflare or Cloudflare Workers as WASM, so it can only generate OpenAPI document andcannot write it to the user‚Äôs local file system.</p><p>To work around this, Ohkami provides a CLI tool <a href=\"https://github.com/ohkami-rs/ohkami/blob/6e243ac823e21f286aca2660f9d38f7bde381c5a/scripts/workers_openapi.js\" rel=\"noopener ugc nofollow\" target=\"_blank\">scripts/workers_openapi.js</a>. This is, for example, used in package.json of Cloudflare Workers + OpenAPI template:</p><pre></pre><p>generates OpenAPI document!</p>","contentLength":3119,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/rust/comments/1iph9lk/macroless_highly_integrated_openapi_document/"},{"title":"Dynamic triple/double buffering merge request for GNOME was just merged!","url":"https://gitlab.gnome.org/GNOME/mutter/-/merge_requests/1441","date":1739556559,"author":"/u/joojmachine","guid":616,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/linux/comments/1ipguyt/dynamic_tripledouble_buffering_merge_request_for/"},{"title":"Black, Indigenous, and People of Color (BIPOC) Initiative Meeting - 2025-02-11","url":"https://www.youtube.com/watch?v=eHa6GhK7L0I","date":1739541570,"author":"CNCF [Cloud Native Computing Foundation]","guid":398,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon Europe in London from April 1 - 4, 2025. Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io</article>","contentLength":317,"flags":null,"enclosureUrl":"https://www.youtube.com/v/eHa6GhK7L0I?version=3","enclosureMime":"","commentsUrl":null},{"title":"Show HN: Transform your codebase into a single Markdown doc for feeding into AI","url":"https://tesserato.web.app/posts/2025-02-12-CodeWeaver-launch/index.html","date":1739539403,"author":"tesserato","guid":194,"unread":true,"content":"<p>CodeWeaver is a command-line tool designed to weave your codebase into a single, easy-to-navigate Markdown document. It recursively scans a directory, generating a structured representation of your project's file hierarchy and embedding the content of each file within code blocks. This tool simplifies codebase sharing, documentation, and integration with AI/ML code analysis tools by providing a consolidated and readable Markdown output.\nThe output for the current repository can be found <a href=\"https://github.com/tesserato/CodeWeaver/blob/main/codebase.md\">here</a>.</p><ul><li><strong>Comprehensive Codebase Documentation:</strong> Generates a Markdown file that meticulously outlines your project's directory and file structure in a clear, tree-like format.</li><li> Embeds the complete content of each file directly within the Markdown document, enclosed in syntax-highlighted code blocks based on file extensions.</li><li>  Utilize regular expressions to define ignore patterns, allowing you to exclude specific files and directories from the generated documentation (e.g., , build artifacts, specific file types).</li><li> Choose to save lists of included and excluded file paths to separate files for detailed tracking and debugging of your ignore rules.</li><li><strong>Simple Command-Line Interface:</strong>  Offers an intuitive command-line interface with straightforward options for customization.</li></ul><p>If you have Go installed, run <code>go install github.com/tesserato/CodeWeaver@latest</code>to install the latest version of CodeWeaver or <code>go install github.com/tesserato/CodeWeaver@vX.Y.Z</code> to install a specific version.</p><p>Alternatively, download the appropriate pre built executable from the <a href=\"https://github.com/tesserato/CodeWeaver/releases\">releases page</a>.</p><p>If necessary, make the  executable by using the  command:</p><table><thead><tr></tr></thead><tbody><tr><td>The root directory to scan and document.</td></tr><tr><td>The name of the output Markdown file.</td></tr><tr><td><code>-ignore \"&lt;regex patterns&gt;\"</code></td><td>Comma-separated list of regular expression patterns for paths to exclude.</td></tr><tr><td><code>-included-paths-file &lt;filename&gt;</code></td><td>File to save the list of paths that were included in the documentation.</td></tr><tr><td><code>-excluded-paths-file &lt;filename&gt;</code></td><td>File to save the list of paths that were excluded from the documentation.</td></tr><tr><td>Display this help message and exit.</td></tr></tbody></table><h2><strong>Generate documentation for the current directory:</strong></h2><p>This will create a file named  in the current directory, documenting the structure and content of the current directory and its subdirectories (excluding paths matching the default ignore pattern ).</p><h2><strong>Specify a different input directory and output file:</strong></h2><pre><code>./codeweaver -dir=my_project -output=project_docs.md\n</code></pre><p>This command will process the  directory and save the documentation to .</p><h2><strong>Ignore specific file types and directories:</strong></h2><pre><code>./codeweaver -ignore=\"\\.log,temp,build\" -output=detailed_docs.md\n</code></pre><p>This example will generate , excluding any files or directories with names containing , , or . Regular expression patterns are comma-separated.</p><h2><strong>Save lists of included and excluded paths:</strong></h2><pre><code>./codeweaver -ignore=\"node_modules\" -included-paths-file=included.txt -excluded-paths-file=excluded.txt -output=code_overview.md\n</code></pre><p>This command will create  while also saving the list of included paths to  and the list of excluded paths (due to the  ignore pattern) to .</p><p>Contributions are welcome! If you encounter any issues, have suggestions for new features, or want to improve CodeWeaver, please feel free to open an issue or submit a pull request on the project's GitHub repository.</p><p>CodeWeaver is released under the <a href=\"https://tesserato.web.app/posts/2025-02-12-CodeWeaver-launch/LICENSE\">MIT License</a>. See the  file for complete license details.</p>","contentLength":3311,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43048027"},{"title":"AI is stifling new tech adoption?","url":"https://vale.rocks/posts/ai-is-stifling-tech-adoption","date":1739537105,"author":"kiyanwang","guid":241,"unread":true,"content":"<p>I propose that the advent and integration of AI models into the workflows of developers has stifled the adoption of new and potentially superior technologies due to training data cutoffs and system prompt influence.</p><p>I have noticed a bias towards specific technologies in multiple popular models and have noted anecdotally in conversation and online discussion people choosing technology based on how well AI tooling can assist with its usage or implementation.</p><p>While it has long been the case that developers have considered documentation and support availability when choosing software, AI‚Äôs influence dramatically amplifies this factor in decision-making, often in ways that aren‚Äôt immediately apparent and with undisclosed influence.</p><p>Large language models, especially those on the scale of many of the most accessible, popular hosted options, take humongous datasets and long periods to train. By the time everything has been scraped and a dataset has been built, the set is on some level already obsolete. Then, before a model can reach the hands of consumers, time must be taken to train and evaluate it, and then even more to finally deploy it.</p><p>Once it has finally released, it usually remains stagnant in terms of having its knowledge updated. This creates an AI knowledge gap. A period between the present and AI‚Äôs training cutoff. This gap creates a time between when a new technology emerges and when AI systems can effectively support user needs regarding its adoption, meaning that models will not be able to service users requesting assistance with new technologies, thus disincentivising their use.</p><p>The cutoff means that models are strictly limited in knowledge up to a certain point. For instance, Anthropic‚Äôs latest models have a cutoff of <a href=\"https://support.anthropic.com/en/articles/8114494-how-up-to-date-is-claude-s-training-data\">April 2024</a>, and OpenAI‚Äôs latest models have cutoffs of <a href=\"https://platform.openai.com/docs/models\">late 2023</a>.</p><p>The influence of the popularisation of AI models has also led to the proliferation of AI slop content, which AI companies are likely trying to avoid introducing in their scraped data sets ‚Äì potentially increasing this knowledge gap.</p><p>This knowledge gap doesn‚Äôt just stifle the adoption of new frameworks and tooling but also the adoption of new and potentially superior features introduced in updates to already in-use frameworks and tooling as a result of the models not yet including information about them in their training set. This is a lesser issue though, because a technology with existing market adoption is bound to have fanatics who will use it, create examples, and produce blog posts, documentation, and other media about it that will eventually end up in training data.</p><p>While some models are used in contexts where they are equipped with tooling, such as ChatGPT with its internet search capabilities, their prompts often only instruct them to use this functionality when explicitly requested by a user. Of course, plenty of implementations don‚Äôt have any access to any internet query functionality at all, such as Claude via its web interface, which will inform you it will only discuss things included in its training data.</p><p>Of course, if people are reluctant to adopt a new technology because of a lack of AI support, there will be fewer people likely to produce material regarding said technology, which leads to an overall inverse feedback effect. Lack of AI support prevents a technology from gaining the required critical adoption mass, which in turn prevents a technology from entering use and having material made for it, which in turn starves the model of training data, which in turn disincentivises selecting that technology, and so on and so forth.</p><p>Consider a developer working with a cutting-edge JavaScript framework released just months ago. When they turn to AI coding assistants for help, they find these tools unable to provide meaningful guidance because their training data predates the framework‚Äôs release. This forces developers to rely solely on potentially limited official documentation and early adopter experiences, which, for better or worse, tends to be an ‚Äòold‚Äô way of doing things and incentivises them to use something else.</p><p>I‚Äôve anecdotally noticed that many AI tools have a ‚Äòpreference‚Äô for React and Tailwind when asked to tackle a web-based task, or even to create any app involving an interface at all.</p><p>With Claude 3.5 Sonnet, which is generally my AI offering of choice given its superior coding ability, my ‚ÄúWhat personal preferences should Claude consider in responses?‚Äù profile setting includes the line ‚ÄúWhen writing code, use vanilla HTML/CSS/JS unless otherwise noted by me‚Äù. Despite this, Claude will  opt to generate new code with React, and in some occurrences even rewrite my existing code into React against my intent and without my consultation.</p><p>This can be evidenced when asking Claude to use a certain technology, such as Svelte Runes, where it will instead direct the user towards its preferred technology. For example:</p><blockquote><p> Build me something with Svelte Runes.</p></blockquote><blockquote><p> I apologize, but I am not able to create Svelte Runes components directly, as the artifact environment only supports certain technologies like React, HTML, and SVG. I can help you build something similar using React, or I can provide you with Svelte Runes code that you can use in your own Svelte project. Which would you prefer?</p><p>If you‚Äôd like to see a React version, I can create something with similar reactive functionality using React‚Äôs hooks. Or if you want Svelte Runes code specifically, I can write that for you to use in your own environment.</p></blockquote><p>To test if popular models do have built-in bias for React, I logged into the web interfaces of four of the current most popular AI chat platforms via my free account and asked the models to ‚ÄúCreate me a web app. It can do anything.‚Äù. I repeated this with each of the four models three times in fresh chats with previous chats deleted and any shared context (such as ChatGPT‚Äôs memory feature) disabled or cleared between each test.</p><p>I asked Anthropic‚Äôs Claude 3.5 Sonnet with blank personal preferences and artifacts enabled. The first time it opted to create a mood tracking app, the second a reading list manager, and the third time a to-do list. Each time it chose to generate it using React with Tailwind CSS for styling. It generated each project in an artifact which offered an interactive preview directly in the interface.</p><p>I asked OpenAI‚Äôs ChatGPT 4o with both custom instructions and memory disabled. It produced a note-taking app the first time, a random quote generator the second time, and a to-do list the third time. All using React with Tailwind for styling and presented in <a href=\"https://openai.com/index/introducing-canvas\">canvases</a>. These canvases came with a preview button, which, much like with Claude, offered an interactive preview of the React project it built directly in the interface.</p><p>I asked Google‚Äôs Gemini 2.0 Flash with app activity disabled. All three times it built to-do list apps using vanilla HTML, CSS, and JavaScript. Each time, it also noted that I should consider using JavaScript frameworks on the frontend, namely React, Angular, and Vue - in that order.</p><p>I asked DeepSeek‚Äôs DeepSeek-V3, and it returned a to-do list app using vanilla HTML, CSS, and JavaScript. On the second request, it created a project outline for a to-do list app, but this time with Bootstrap, Node.js, Express.js, and SQLite. The third time, it created another outline for a note-taking app but with Node.js, Express.js, and MongoDB.</p><p>DeepSeek had the greatest variation in technology used but is the least accessible model and didn‚Äôt actually ‚Äòcreate‚Äô the app as requested ‚Äì merely a general outline for it.</p><p>These tests show both Claude and ChatGPT have a strong preference for React and Tailwind,  that Gemini has a preference for HTML/CSS/JS but will recommend React and that DeepSeek is much more flexible and varied with its technological choices, though requires more prompting to produce an actual output.</p><p>I‚Äôd suggest that a beginner developer, or someone creating an app exclusively via prompting, is likely to use ChatGPT due to its position in the zeitgeist and use whatever output the model first produces without much second thought ‚Äì thus influencing their tech selection without their realising.</p><p>Even if a developer does opt to use another framework or toolset, there is a chance that the model will prod them towards a selection more aligned with its system prompt, even going as far as rewriting their code to its ‚Äòpreference‚Äô against user request, as evidenced by Claude ignoring my request for vanilla web technologies.</p><p>That is assuming that a specific framework or toolset hasn‚Äôt already been chosen by the user specifically because they have heard or experienced it being best handled by AI models. Also, while this very much applies to larger technical choices, such as what framework or general tooling a project may choose, it also trickles down into smaller decisions, such as what libraries or modules they may import.</p><p>I think it is evident that AI models are influencing technology, and that the technologies currently in use ‚Äì especially those that reached popularity before November 2022, when ChatGPT was released, or that are otherwise in current data sets ‚Äì will be around for a long time to come, and that AI models‚Äô preferential treatment of them will expand their adoption and lifespan.</p><p>I think it would be prudent for AI companies to provide more transparent documentation of technology biases in their models, like they disclose that their models can make mistakes. These models are becoming a common part of developer knowledge and decision-making, and we‚Äôre letting the training and prompting decisions of OpenAI, Anthropic, etc shape the entire direction of software development.</p><p>As for further research on this topic, if one had a collection of system prompts over time, it may be possible to compare them to download trends of specified packages and identify correlations. Of course, there are a lot of other influences on the download and adoption of packages, so this may prove difficult and provide data too noisy and influenced by outside variables to be unusable.</p>","contentLength":10120,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43047792"},{"title":"Show HN: A New Way to Learn Languages","url":"https://www.langturbo.com/","date":1739534938,"author":"sebnun","guid":193,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43047554"},{"title":"Anyone can push updates to the doge.gov website","url":"https://www.404media.co/anyone-can-push-updates-to-the-doge-gov-website-2/","date":1739518306,"author":"mahkeiro","guid":240,"unread":true,"content":"<div>\"THESE 'EXPERTS' LEFT THEIR DATABASE OPEN.\"</div>","contentLength":43,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43045835"},{"title":"Zed now predicts your next edit with Zeta, our new open model","url":"https://zed.dev/blog/edit-prediction","date":1739515847,"author":"ahamez","guid":239,"unread":true,"content":"<p>Zed is built for speed. We've always strived for an editing experience that feels . But what's faster than instant?  A tool that anticipates your next move. That's why we're introducing <a href=\"https://zed.dev/edit-prediction\">edit prediction</a> in Zed, powered by <a href=\"https://huggingface.co/zed-industries/zeta\">Zeta</a>, our new open source model.</p><p>Here's a quick walkthrough:</p><div><figure><figcaption>Edit Prediction in action.</figcaption></figure></div><p>As you work, Zed now predicts your next edit, so you can apply it just by hitting . Once you accept a prediction, you can perform multiple follow-up edits by pressing  repeatedly, saving you time and keystrokes. We've received  of requests for this functionality, and we've poured our hearts into making it feel like a natural extension of the Zed experience.</p><p>You can use Zeta for free during this public beta by <a href=\"https://zed.dev/download\">downloading Zed</a> and signing in with your GitHub account. Edit prediction won't be free forever, but right now we're just excited to share and learn.</p><p>Edit prediction transforms  into a magical, universal key. But what about the existing uses of , such as indenting lines? And what happens when there's both an edit prediction  suggestions from your language server? We didn't want a powerful new feature to come at the expense of the existing editing experience in Zed.</p><p>When language server completions are visible, Zed won't preview the predicted edit until you press  or . As soon as you press the modifier, Zed previews the edit and hides the menu to enable an unobstructed review. On macOS, you can just hit  to confirm, or back out by releasing  to restore the language server completions menu.</p><p>On Linux,  is often reserved by the window manager, so we offer  as an alternative default. We chose  because it's on the QWERTY home row and represents rightward movement in Vim. If your Linux window manager doesn't claim , you're free to use that binding as well.</p><p><a href=\"https://huggingface.co/zed-industries/zeta\">Zeta</a> is derived from Qwen2.5-Coder-7B, and is fully open source, including <a href=\"https://huggingface.co/datasets/zed-industries/zeta\">an open dataset</a>. If you're working in an open source repository, we'd love your help improving Zeta by contributing to its dataset. Please bear with us initially, as we will be reviewing the submitted data before publishing to ensure everyone's safety and privacy. We're excited to figure this out and see a community effort form to make edit prediction better everywhere, most especially in Zed!</p><div><div><div><p>How Zed's Open-Source Edit Predictions Work</p></div><p>Richard Feldman and Antonio Scandurra talk about how Zed's new Edit Prediction feature works under the hood. This includes how the Zed team developed and open-sourced both the code and the dataset behind the fine-tuned Zeta language model that powers it!</p></div></div><p>Most coding models are trained on a \"fill in the middle\" task. You give them a prefix and a suffix, and they generate what goes in between.</p><figure data-rehype-pretty-code-figure=\"\"><div><pre><code data-language=\"rs\" data-theme=\"dark-plus light-plus\"></code></pre></div></figure><p>This works for completing text at the cursor, but we wanted Zeta to predict edits at arbitrary locations, which doesn't fit into this structure.</p><p>In our experience, models aren't very good at producing granular edits, but they do excel at rewriting larger chunks of code. So that's where we started: given a list of recent edits and the cursor position, we asked the model to rewrite a snippet of text around the cursor, incorporating one or more edit predictions in the rewritten text.</p><p>Before writing a single line of code, we created a set of tests to check if our idea worked. Testing the output of a large language model is tricky because, on every run, you can get slightly different results even when feeding it the exact same input. This can be mitigated by using a temperature of  and, for providers that support it, providing a seed for the RNG.</p><p>That said, code can often be written in many different but equally valid ways. So even when Zeta's output differs from our expected answer, it might still be doing exactly what we want‚Äîjust taking a different path to get there. This makes traditional unit testing approaches particularly challenging when working with LLMs.</p><p>This led us to take a different approach‚Äîinstead of strict assertions, we used a larger LLM to evaluate Zeta's edits. By writing our test assertions in plain English and having Claude check if the results matched our intent, we could validate that Zeta was making sensible edits, even when its exact output differed between runs. This ended up being much more practical than trying to make brittle assertions about specific tokens.</p><p>Here's an example taken from our eval suite:</p><figure data-rehype-pretty-code-figure=\"\"><div><pre><code data-language=\"rs\" data-theme=\"dark-plus light-plus\"></code></pre></div></figure><p>We took our first stab at making those tests pass by using Qwen2.5-Coder-32B and giving it clear instructions for which types of edits we wanted it to predict. <a href=\"https://github.com/zed-industries/zed/blob/79a70b72b3968d102c6171f8bd2738ec7be8e94f/crates/zeta/src/complete_prompt.md\">Here's the initial system prompt</a> we used and you can look through the history to see how we kept changing it to pass the eval suite.</p><p>This worked out surprisingly well for the first 4-5 evals. However, as soon as we introduced more, we started noticing that it got harder and harder to pass them all consistently. Changing the prompt caused the new evals to pass, but made the old ones fail. Overall, it felt like a flaky process and we didn't feel confident this would lead to the system being robust enough to be used in production.</p><p>Moreover, using a 32b model wasn't really compatible with our strict latency requirements (more on that later).</p><p>After playing around with different approaches, we decided to go with supervised fine-tuning using <a href=\"https://unsloth.ai\">Unsloth</a> and LoRA. The idea was to teach Zeta two key things: figuring out what changes a developer might want next based on their recent edits, and then actually applying those changes cleanly to the code without introducing weird side effects.</p><p>But we had a classic chicken-and-egg problem‚Äîwe needed data to train the model, but we didn't have any real examples yet. So we started by having Claude generate about 50 synthetic examples that we added to <a href=\"https://huggingface.co/datasets/zed-industries/zeta-dataset\">our dataset</a>. We then used that initial fine-tune to ship an early version of Zeta behind a feature flag and started collecting examples from our own team's usage.</p><p>This approach let us quickly build up a solid dataset of around 400 high-quality examples, which improved the model a lot! However, we kept running into edge cases that would trip the model up. The most annoying ones were when Zeta was working with a small piece of code in a larger file‚Äîit would sometimes get confused and make random deletions or insertions that had nothing to do with what the user was trying to do, and it didn't seem like adding more examples steered the model away from those mistakes.</p><p>To handle these edge cases, we conducted another pass using direct preference optimization (DPO). This technique let us go beyond simply showing the model what good edits look like‚Äîwe could also teach it what edits . With DPO, we could fine-tune Zeta by providing both positive and negative examples, helping it learn the subtle differences between helpful and problematic edits.</p><p>We found that just ~150 carefully selected examples were enough to significantly improve Zeta's behavior on tricky cases. Of course, we think we can make it even better by expanding our training data with more diverse examples, and we're excited to keep pushing the boundaries here.</p><p>Like every feature in Zed, latency was a critical factor for edit prediction. When we started, we set aggressive performance targets: predictions should be delivered in under 200ms for the median case (p50) and under 500ms for the 90th percentile (p90). The challenge was that rewriting complete excerpts, while enabling multi-location edits, requires generating significantly more tokens than simple fill-in-middle approaches. Initially, this put us way over our latency budget.</p><p>However, there's a fascinating insight about how edit predictions work. When we rewrite a text snippet, the output often mirrors the input closely, with changes concentrated in specific spots. This pattern lets us parallelize token generation by using the input as a reference‚Äîa technique known as speculative decoding. We use n-gram search to identify promising jumping-off points in the input where we can start parallel token generation, giving us a significant speedup without sacrificing quality.</p><p>For edit predictions to feel responsive, we needed to solve multiple latency challenges in parallel. As discussed above, we tackled the model execution time through speculative decoding, but serving the model at scale presented its own set of hurdles. This was by far the most compute-intensive problem our team has ever tackled.</p><p>A few weeks out from launch, we ran a brief competitive process, and we ended up being really impressed with <a href=\"https://www.baseten.co\">Baseten</a>. Their performance engineers quickly optimized our open source model to run on their flexible infrastructure, achieving our target latencies while letting us retain full visibility into the details of the deployment, both for the Zed team and the entire Zed community. We plan to follow up with a guest post about what they learned optimizing <a href=\"https://huggingface.co/zed-industries/zeta\">our model</a>.</p><p>Latency is not just a function of compute; network transit time is a key driver of perceived speed. To cooperate with the laws of physics, we're launching with GPUs in both North America and Europe, and we hope to add more regions soon. We're also using <a href=\"https://workers.cloudflare.com/\">Cloudflare Workers</a> to handle your requests in a data center located as close to you as possible.</p><p>There's plenty more to explore to make edit predictions more powerful. We'll be fast-following with more experiments. We plan on sending more kinds of context to the model and continuing our experiments with fine-tuning, and we'll share updates as we grow and evolve the Zeta dataset.</p><p>We've learned a lot since we launched Zed AI last fall. The world is changing fast, and we're having a blast exploring and learning to build features that developers love. We're also excited to build with AI the Zed way. From our early days, we've been proponents of an open approach to building software, even when hard, and we see no reason to change that approach when it comes to working with AI. We hope you'll join us as a user, a contributor, or an employee, as we hustle to ship a golden future.</p>","contentLength":9947,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43045606"},{"title":"ChatLoopBackOff Episode 46 (Dragonfly)","url":"https://www.youtube.com/watch?v=gd6HRgr8KcA","date":1739512616,"author":"CNCF [Cloud Native Computing Foundation]","guid":397,"unread":true,"content":"<article>Dragonfly, a CNCF Incubating project, is an open-source, cloud-native image and file distribution system optimized for large-scale data delivery. It is designed to enhance the efficiency, speed, and reliability of distributing container images and other data files across distributed systems. \n\nThis CNCF project is for organizations looking to improve the speed, efficiency, and reliability of artifact distribution in cloud-native environments. Join CNCF Ambassador Nitish Kumar as he explores how it works, Kubernetes integration, as well as its simplified setup and usage.</article>","contentLength":576,"flags":null,"enclosureUrl":"https://www.youtube.com/v/gd6HRgr8KcA?version=3","enclosureMime":"","commentsUrl":null},{"title":"The Cloud Controller Manager Chicken and Egg Problem","url":"https://kubernetes.io/blog/2025/02/14/cloud-controller-manager-chicken-egg-problem/","date":1739491200,"author":"","guid":725,"unread":true,"content":"<p>Kubernetes 1.31\n<a href=\"https://kubernetes.io/blog/2024/05/20/completing-cloud-provider-migration/\">completed the largest migration in Kubernetes history</a>, removing the in-tree\ncloud provider. While the component migration is now done, this leaves some additional\ncomplexity for users and installer projects (for example, kOps or Cluster API) . We will go\nover those additional steps and failure points and make recommendations for cluster owners.\nThis migration was complex and some logic had to be extracted from the core components,\nbuilding four new subsystems.</p><p>One of the most critical functionalities of the cloud controller manager is the node controller,\nwhich is responsible for the initialization of the nodes.</p><p>As you can see in the following diagram, when the  starts, it registers the \nobject with the apiserver, Tainting the node so it can be processed first by the\ncloud-controller-manager. The initial  is missing the cloud-provider specific information,\nlike the Node Addresses and the Labels with the cloud provider specific information like the\nNode, Region and Instance type information.</p><div>sequenceDiagram\nautonumber\nrect rgb(191, 223, 255)\nKubelet-&gt;&gt;+Kube-apiserver: Create Node\nNote over Kubelet: Taint: node.cloudprovider.kubernetes.io\nKube-apiserver-&gt;&gt;-Kubelet: Node Created\nend\nNote over Kube-apiserver: Node is Not Ready<p> Tainted, Missing Node Addresses*, ...\nNote over Kube-apiserver: Send Updates\nrect rgb(200, 150, 255)\nKube-apiserver-&gt;&gt;+Cloud-controller-manager: Watch: New Node Created\nNote over Cloud-controller-manager: Initialize Node:</p>Cloud Provider Labels, Node Addresses, ...\nCloud-controller-manager-&gt;&gt;-Kube-apiserver: Update Node\nend\nNote over Kube-apiserver: Node is Ready\n</div><p>This new initialization process adds some latency to the node readiness. Previously, the kubelet\nwas able to initialize the node at the same time it created the node. Since the logic has moved\nto the cloud-controller-manager, this can cause a <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/#chicken-and-egg\">chicken and egg problem</a>\nduring the cluster bootstrapping for those Kubernetes architectures that do not deploy the\ncontroller manager as the other components of the control plane, commonly as static pods,\nstandalone binaries or daemonsets/deployments with tolerations to the taints and using\n (more on this below)</p><h2>Examples of the dependency problem</h2><p>As noted above, it is possible during bootstrapping for the cloud-controller-manager to be\nunschedulable and as such the cluster will not initialize properly. The following are a few\nconcrete examples of how this problem can be expressed and the root causes for why they might\noccur.</p><p>These examples assume you are running your cloud-controller-manager using a Kubernetes resource\n(e.g. Deployment, DaemonSet, or similar) to control its lifecycle. Because these methods\nrely on Kubernetes to schedule the cloud-controller-manager, care must be taken to ensure it\nwill schedule properly.</p><h3>Example: Cloud controller manager not scheduling due to uninitialized taint</h3><p>As <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/#running-cloud-controller-manager\">noted in the Kubernetes documentation</a>, when the kubelet is started with the command line\nflag <code>--cloud-provider=external</code>, its corresponding  object will have a no schedule taint\nnamed <code>node.cloudprovider.kubernetes.io/uninitialized</code> added. Because the cloud-controller-manager\nis responsible for removing the no schedule taint, this can create a situation where a\ncloud-controller-manager that is being managed by a Kubernetes resource, such as a \nor , may not be able to schedule.</p><p>If the cloud-controller-manager is not able to be scheduled during the initialization of the\ncontrol plane, then the resulting  objects will all have the\n<code>node.cloudprovider.kubernetes.io/uninitialized</code> no schedule taint. It also means that this taint\nwill not be removed as the cloud-controller-manager is responsible for its removal. If the no\nschedule taint is not removed, then critical workloads, such as the container network interface\ncontrollers, will not be able to schedule, and the cluster will be left in an unhealthy state.</p><h3>Example: Cloud controller manager not scheduling due to not-ready taint</h3><p>The next example would be possible in situations where the container network interface (CNI) is\nwaiting for IP address information from the cloud-controller-manager (CCM), and the CCM has not\ntolerated the taint which would be removed by the CNI.</p><blockquote><p>\"The Node controller detects whether a Node is ready by monitoring its health and adds or removes this taint accordingly.\"</p></blockquote><p>One of the conditions that can lead to a  resource having this taint is when the container\nnetwork has not yet been initialized on that node. As the cloud-controller-manager is responsible\nfor adding the IP addresses to a  resource, and the IP addresses are needed by the container\nnetwork controllers to properly configure the container network, it is possible in some\ncircumstances for a node to become stuck as not ready and uninitialized permanently.</p><p>This situation occurs for a similar reason as the first example, although in this case, the\n<code>node.kubernetes.io/not-ready</code> taint is used with the no execute effect and thus will cause the\ncloud-controller-manager not to run on the node with the taint. If the cloud-controller-manager is\nnot able to execute, then it will not initialize the node. It will cascade into the container\nnetwork controllers not being able to run properly, and the node will end up carrying both the\n<code>node.cloudprovider.kubernetes.io/uninitialized</code> and <code>node.kubernetes.io/not-ready</code> taints,\nleaving the cluster in an unhealthy state.</p><p>There is no one ‚Äúcorrect way‚Äù to run a cloud-controller-manager. The details will depend on the\nspecific needs of the cluster administrators and users. When planning your clusters and the\nlifecycle of the cloud-controller-managers please consider the following guidance:</p><p>For cloud-controller-managers running in the same cluster, they are managing.</p><ol><li>Use host network mode, rather than the pod network: in most cases, a cloud controller manager\nwill need to communicate with an API service endpoint associated with the infrastructure.\nSetting ‚ÄúhostNetwork‚Äù to true will ensure that the cloud controller is using the host\nnetworking instead of the container network and, as such, will have the same network access as\nthe host operating system. It will also remove the dependency on the networking plugin. This\nwill ensure that the cloud controller has access to the infrastructure endpoint (always check\nyour networking configuration against your infrastructure provider‚Äôs instructions).</li><li>Use a scalable resource type.  and  are useful for controlling the\nlifecycle of a cloud controller. They allow easy access to running multiple copies for redundancy\nas well as using the Kubernetes scheduling to ensure proper placement in the cluster. When using\nthese primitives to control the lifecycle of your cloud controllers and running multiple\nreplicas, you must remember to enable leader election, or else your controllers will collide\nwith each other which could lead to nodes not being initialized in the cluster.</li><li>Target the controller manager containers to the control plane. There might exist other\ncontrollers which need to run outside the control plane (for example, Azure‚Äôs node manager\ncontroller). Still, the controller managers themselves should be deployed to the control plane.\nUse a node selector or affinity stanza to direct the scheduling of cloud controllers to the\ncontrol plane to ensure that they are running in a protected space. Cloud controllers are vital\nto adding and removing nodes to a cluster as they form a link between Kubernetes and the\nphysical infrastructure. Running them on the control plane will help to ensure that they run\nwith a similar priority as other core cluster controllers and that they have some separation\nfrom non-privileged user workloads.\n<ol><li>It is worth noting that an anti-affinity stanza to prevent cloud controllers from running\non the same host is also very useful to ensure that a single node failure will not degrade\nthe cloud controller performance.</li></ol></li><li>Ensure that the tolerations allow operation. Use tolerations on the manifest for the cloud\ncontroller container to ensure that it will schedule to the correct nodes and that it can run\nin situations where a node is initializing. This means that cloud controllers should tolerate\nthe <code>node.cloudprovider.kubernetes.io/uninitialized</code> taint, and it should also tolerate any\ntaints associated with the control plane (for example, <code>node-role.kubernetes.io/control-plane</code>\nor <code>node-role.kubernetes.io/master</code>). It can also be useful to tolerate the\n<code>node.kubernetes.io/not-ready</code> taint to ensure that the cloud controller can run even when the\nnode is not yet available for health monitoring.</li></ol><p>For cloud-controller-managers that will not be running on the cluster they manage (for example,\nin a hosted control plane on a separate cluster), then the rules are much more constrained by the\ndependencies of the environment of the cluster running the cloud-controller-manager. The advice\nfor running on a self-managed cluster may not be appropriate as the types of conflicts and network\nconstraints will be different. Please consult the architecture and requirements of your topology\nfor these scenarios.</p><p>This is an example of a Kubernetes Deployment highlighting the guidance shown above. It is\nimportant to note that this is for demonstration purposes only, for production uses please\nconsult your cloud provider‚Äôs documentation.</p><pre tabindex=\"0\"><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\nlabels:\napp.kubernetes.io/name: cloud-controller-manager\nname: cloud-controller-manager\nnamespace: kube-system\nspec:\nreplicas: 2\nselector:\nmatchLabels:\napp.kubernetes.io/name: cloud-controller-manager\nstrategy:\ntype: Recreate\ntemplate:\nmetadata:\nlabels:\napp.kubernetes.io/name: cloud-controller-manager\nannotations:\nkubernetes.io/description: Cloud controller manager for my infrastructure\nspec:\ncontainers: # the container details will depend on your specific cloud controller manager\n- name: cloud-controller-manager\ncommand:\n- /bin/my-infrastructure-cloud-controller-manager\n- --leader-elect=true\n- -v=1\nimage: registry/my-infrastructure-cloud-controller-manager@latest\nresources:\nrequests:\ncpu: 200m\nmemory: 50Mi\nhostNetwork: true # these Pods are part of the control plane\nnodeSelector:\nnode-role.kubernetes.io/control-plane: \"\"\naffinity:\npodAntiAffinity:\nrequiredDuringSchedulingIgnoredDuringExecution:\n- topologyKey: \"kubernetes.io/hostname\"\nlabelSelector:\nmatchLabels:\napp.kubernetes.io/name: cloud-controller-manager\ntolerations:\n- effect: NoSchedule\nkey: node-role.kubernetes.io/master\noperator: Exists\n- effect: NoExecute\nkey: node.kubernetes.io/unreachable\noperator: Exists\ntolerationSeconds: 120\n- effect: NoExecute\nkey: node.kubernetes.io/not-ready\noperator: Exists\ntolerationSeconds: 120\n- effect: NoSchedule\nkey: node.cloudprovider.kubernetes.io/uninitialized\noperator: Exists\n- effect: NoSchedule\nkey: node.kubernetes.io/not-ready\noperator: Exists\n</code></pre><p>When deciding how to deploy your cloud controller manager it is worth noting that\ncluster-proportional, or resource-based, pod autoscaling is not recommended. Running multiple\nreplicas of a cloud controller manager is good practice for ensuring high-availability and\nredundancy, but does not contribute to better performance. In general, only a single instance\nof a cloud controller manager will be reconciling a cluster at any given time.</p>","contentLength":11247,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Show HN: SQL Noir ‚Äì Learn SQL by solving crimes","url":"https://www.sqlnoir.com/","date":1739483356,"author":"chrisBHappy","guid":192,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43041827"},{"title":"Privacy Pass Authentication for Kagi Search","url":"https://blog.kagi.com/kagi-privacy-pass","date":1739476649,"author":"b3n","guid":238,"unread":true,"content":"<p>Today we are announcing a new privacy feature coming to Kagi Search. Privacy Pass is an authentication protocol first introduced by Davidson  in [<a href=\"https://blog.kagi.com/kagi-privacy-pass#references\">1</a>], and recently standardized by the IETF as RFCs [<a href=\"https://blog.kagi.com/kagi-privacy-pass#references\">2‚Äî4</a>].  Our starting point was the excellent Rust implementation of the Privacy Pass protocols by <a href=\"https://github.com/raphaelrobert/privacypass\">Raphael Robert</a>. At the same time, we are announcing the immediate availability of Kagi‚Äôs <a href=\"https://blog.kagi.com/kagi-privacy-pass#tor\">Tor onion service</a>.</p><p>In general terms, Privacy Pass allows ‚ÄúClients‚Äù (generally users) to authenticate to ‚ÄúServers‚Äù (like Kagi) in such a way that while the Server can verify that the connecting Client has the right to access its services, it cannot determine which of its rightful Clients is actually connecting. This is particularly useful in the context of a privacy-respecting paid search engine, where the Server wants to ensure that the Client can access the services, and the Client seeks strong guarantees that, for example, the searches are not associated with them.</p><p>As a privacy-respecting search engine, Kagi‚Äôs business model is such that we have no incentive to track what an individual user is searching for. We are in the business of selling a search product, not selling user data or attention.</p><p>Now, Privacy Pass adds another layer of trust: we can verify that you have the right to search without knowing who you are or what you‚Äôre searching for. It‚Äôs one thing to promise we won‚Äôt track you; it‚Äôs another to make it technically impossible. We jumped on the opportunity to implement Privacy Pass as soon as the IETF made it an official standard.</p><p>This matters, because for many users, privacy isn‚Äôt just about incentives and privacy policies; it‚Äôs about proof. When we cannot track you even if we wanted to, that‚Äôs genuine privacy.</p><p>Initially, we will be offering Privacy Pass to all our plans with unlimited searches: Professional, Ultimate, Family, and Team plans. Privacy Pass will not be available to Trial and Starter plans due to technical limitations at this moment (see below for more info).</p><p>\nTo get started with Kagi Privacy Pass right away:</p><ul><li>Download the newest version of Kagi‚Äôs <a href=\"https://kagi.com/orion\">Orion Browser</a> (for macOS/iOS/iPadOS) with Kagi Privacy Pass natively integrated. You will need at least 0.99.131 for macOS and 1.3.17 for iOS/iPadOS (they are expected to be rolling out globally today).</li></ul><ul><li>Download the newest version of <a href=\"https://play.google.com/store/apps/details?id=com.kagi.search&amp;hl=en_US\">Kagi for Android</a> app with Kagi Privacy Pass natively integrated. You will need to use at least version 0.29 (this is expected to roll out globally today).</li></ul><ul><li>If you are already using the Kagi Search extension, you will want to update it to the latest version (0.7.6 on <a href=\"https://addons.mozilla.org/firefox/addon/kagi-search-for-firefox\">Firefox</a>, 1.2.2.5 on <a href=\"https://chromewebstore.google.com/detail/kagi-search/cdglnehniifkbagbbombnjghhcihifij\">Chrome</a>) to avoid compatibility issues, or simply disable it.</li><li>Safari is not yet supported due to technical limitations, see the F.A.Q. below.</li></ul><p>In addition our implementation of Privacy Pass is open sourced and you can find it <a href=\"https://github.com/kagisearch/privacypass-extension\">here</a>.</p><p>When using Kagi Privacy Pass mode, you‚Äôll be truly anonymous - which means your account settings won‚Äôt be available since we can‚Äôt identify which user you are.</p><p>But don‚Äôt worry - we‚Äôve made it flexible. You can easily toggle Privacy Pass on or off based on your needs. Think of it as two modes: full features with normal privacy, or maximum privacy with core features. You choose what makes sense for you based on your context and needs.</p><p>Privacy Pass uses cryptography to allow a client to authenticate to a server by performing a protocol with two phases: token generation and token redemption.</p><p>In the initial ‚Äútoken generation‚Äù phase, the client interacts with the server to generate some authentication ‚Äútokens.‚Äù</p><p>For the server to willingly participate in this protocol, the client must prove their ‚Äúright‚Äù to generate tokens.</p><p>In the case of Kagi‚Äôs users, this can be done by presenting their Kagi session cookie to the server.</p><p>The tokens eventually generated by the client at the end of this phase are indistinguishable from a randomly generated token from the server‚Äôs point of view. They cannot be traced back to the user who generated them, or to other tokens generated by the same user at the same or a different time.</p><p>After token generation is performed, a client can initiate a ‚Äútoken redemption‚Äù phase.</p><p>During this phase, the client actually accesses the services provided by the server, proving the client‚Äôs right to access the services by presenting one of the previously generated tokens.</p><p>Since the previously generated tokens are unknown and unpredictable to the server, the latter can only tell that the client has successfully completed token generation at some point.</p><p>Technically, we say that the techniques used by Privacy Pass result in the two phases being ‚Äúunlinkable‚Äù. While the server is able to tell whether a token presented for redemption was previously generated by interacting with a rightful client, it cannot link the token to a specific token generation phase.</p><p>Crucially, tokens are single-use: servers keep track of which tokens have already been redeemed to avoid multiple redemptions. Furthermore, clients should not present the same token twice to prevent different redemption phases from being linked.</p><p>Tokens have a fixed life span. If they are too old, they will stop being redeemable. In that case, a new token generation phase must be initiated by the client to obtain new tokens.</p><p>As standardized in [<a href=\"https://blog.kagi.com/kagi-privacy-pass#references\">2 - 4</a>], the Privacy Pass protocol is able to accommodate many ‚Äúarchitectures.‚Äù Our deployment model follows the original architecture presented by Davidson  [<a href=\"https://blog.kagi.com/kagi-privacy-pass#references\">1</a>], called ‚ÄúShared Origin, Attester, Issuer‚Äù in ¬ß 4 of [<a href=\"https://blog.kagi.com/kagi-privacy-pass#references\">2</a>].</p><p>Here, Kagi plays all the ‚ÄúServer roles‚Äù (Attester, Issuer, Origin), and Kagi users play the Client role via the new Kagi browser extensions for Privacy Pass, or via native support in Orion. This is what it looks like in practice:</p><ol><li>Once installed, and periodically, the browser extension will generate and store a large number of tokens.</li><li>The user can mark in the extension whether searches should be performed by authenticating classically via a session cookie, or by using Privacy Pass.</li><li>If the user chooses the second option, they will authenticate to Kagi during the search by redeeming one of the tokens it previously generated.</li></ol><p>Using Privacy Pass is as easy as clicking a toggle.</p><p>If you are using the latest version of <a href=\"https://kagi.com/orion\">Orion</a> for macOS,  select Kagi as your search engine in  and then enable the checkbox for showing Privacy Pass options on your toolbar.</p><p>From there you can easily toggle when you want to use Privacy Pass or standard authentication.</p><p>On iOS and iPadOS, Kagi Privacy Pass is natively supported in the latest version of the <a href=\"https://apps.apple.com/us/app/orion-browser-by-kagi/id1484498200\">Orion Browser</a> for iOS and iPadOS and takes just a few clicks to enable.</p><p>Our <a href=\"https://play.google.com/store/apps/details?id=com.kagi.search\">Android app</a> now supports Privacy Pass mode via an app shortcut. Launching the shortcut allows you to browse Kagi seamlessly in Privacy Pass mode. You can also add the shortcut to your home screen for quick access.</p><p>This feature lets you either use Kagi exclusively in Privacy Pass mode or switch effortlessly between modes.</p><h3>Chrome and Firefox browser extensions</h3><p>If you are using the Kagi Privacy Pass extension for <a href=\"https://chromewebstore.google.com/detail/kagi-privacy-pass/mendokngpagmkejfpmeellpppjgbpdaj\">Chrome</a> or <a href=\"https://addons.mozilla.org/firefox/addon/kagi-privacy-pass/\">Firefox</a>, once installed you should see the Kagi Privacy Pass icon on your toolbar.</p><p>Once installed, the extension automatically generates tokens. To use them, click the extension icon, and make sure the toggle is on.</p><p>Note that Safari is not supported at this moment; see the F.A.Q. below for more information.</p><p>As used by Kagi, Privacy Pass tokens offer various security properties (¬ß 3.3,  of [<a href=\"https://blog.kagi.com/kagi-privacy-pass#references\">2</a>]).</p><p>These can be a little technical to capture. In a few words, they guarantee that users can trust that their searches authenticated via Privacy Pass cannot be linked to their accounts, and Kagi can rest assured that only legitimate users can correctly authenticate using Privacy Pass. Crucially, the guarantee for users is even against malicious servers that attempt to incorrectly implement the server-side computation, as long as the client-side implementation is correct.</p><p>Three of these security properties serve to protect our users:</p><ol><li><p>Generation-redemption unlinkability: Kagi cannot link the tokens presented during token redemption ( during search) with any specific token generation phase. This means that Kagi will not be able to tell who it is serving search results to, only that it is someone who presented a valid Privacy Pass token.</p></li><li><p>Redemption-redemption unlinkability: Kagi cannot link the tokens presented during two different token redemptions. This means that Kagi will not be able to tell from tokens alone whether two searches are being performed by the same user.</p></li><li><p>No redemption hijacking: an eavesdropper that observes any token generation phase, cannot use the observed information alone to ‚Äústeal‚Äù the tokens from the intended user and redeem them themselves. This means that third parties snooping on a user‚Äôs token generation interaction will not be able to steal the tokens. This adds a layer of security on top of the confidentiality attained during token generation by using a TLS-protected connection.</p></li></ol><p>Two of these security properties serve to protect Kagi.</p><ol><li><p>Correctness: honestly generated tokens will pass Kagi‚Äôs validation.</p></li><li><p>One-more-forgery security: a malicious client cannot use knowledge of a correctly generated token to forge a new one. This means that valid tokens cannot be generated without correctly interacting with Kagi, and therefore valid tokens are evidence that the user owned a valid session cookie for a supported Kagi plan at the moment of generating the token.</p></li></ol><p>Naturally, online interactions are never fully described by a mathematical model.</p><p>While the Privacy Pass protocol  indeed guarantee that the server will not be able to link token generation and token redemption phases , in principle, a malicious server could still attempt to track clients via <a href=\"https://en.wikipedia.org/wiki/Side-channel_attack\">side-channel</a> information.</p><p>For example, if someone were to make the same specific request to a server at the same time every day (say, searching ‚Äúlunch places near 123 Mulholland Drive, LA‚Äù at 11:58 AM), a server that records all searches being made could, in principle, guess that these searches are all made by the same person.</p><p>In this case, Privacy Pass would make it harder for the server to determine who this specific person is, but the server could nonetheless link searches to one another.</p><p>On a level beyond, it is well known that browsers can often have a unique ‚Äúfingerprint‚Äù [<a href=\"https://blog.kagi.com/kagi-privacy-pass#references\">5-7</a>]. Fingerprinting attacks heavily rely on side-channel signals that evade the Privacy Pass protocol, such as user-agent strings or IP addresses. For example, if a server receives a token generation request from a given IP address, and immediately after a token redemption request from the same address, it can likely conclude that the same individual is behind the request. For this reason, it is <a href=\"https://www.rfc-editor.org/rfc/rfc9576.html#section-4.1\">highly recommended</a> to separate token generation and redemption in time, or ‚Äúin space‚Äù (by using an anonymizing service such as <a href=\"https://www.torproject.org/\">Tor</a> when redeeming tokens, see below).</p><p>Kagi‚Äôs Privacy Pass extension and native implementation in Orion take care, as much as we can, to uniform your browser fingerprint, by removing deanonymizing HTTP headers and cookies.</p><p>We see Privacy Pass as an important tool for increasing the anonymity guarantees we can offer to Kagi users.</p><p>Adopting state-of-the-art standards for new privacy enhancing technologies also signals to researchers and standardization bodies that there is a public demand for more privacy and anonymity tools in today‚Äôs digital world and incentivizes further scrutiny and development of privacy-enhancing technologies.</p><p>Together with launching Privacy Pass, we are also announcing that we now have a Tor onion service available, which allows access to Kagi directly from the Tor network. Kagi‚Äôs onion address is:</p><p>On its own, Tor will obscure your location by hiding your IP address. However, without Privacy Pass, you still need to be logged into your Kagi account to perform searches, making them all theoretically linkable back to a single account. As always, Kagi does not link searches to accounts or permanently record them; see <a href=\"https://kagi.com/privacy\">our Privacy Policy</a> for more info.</p><p>With Tor and Privacy Pass together, Kagi only knows that the search is being issued by a user who previously verified that they have an account authorized to receive tokens, but nothing about the user‚Äôs account, or where they‚Äôre located.</p><p>Privacy Pass support is provided:</p><p>This should accommodate users who want to install and use the extension across multiple browsers or computers. Please refer to our documentation for <a href=\"https://help.kagi.com/kagi/privacy/privacy-pass.html\">usage instructions</a>.</p><p>At first, Privacy Pass authentication will be available to users on any Kagi plan with unlimited searches. These plans will have a generous allocation of tokens (2000 to begin with) that they can generate monthly.</p><p>We are working on enabling this feature for Trial and Starter plans, which have access to a limited number of monthly searches. Therefore, they risk a worse user experience if their generated tokens are lost (for example, due to uninstalling the extension) and theoretically, users on this plan could redeem more tokens than the limit of searches allowed on their plan (again, we do not know who the user redeeming the tokens is, or what plan they are on). This makes it more technically challenging to support these plans with Privacy Pass, and we have left that for later.</p><p><strong>You mention ‚Äútokens.‚Äù Are blockchains involved in this protocol?</strong></p><p>Privacy Pass does not rely on any blockchain technology.</p><p>While the protocol makes use of various cryptographic primitives (specifically, elliptic curves and hash functions, as part of a ‚Äúverifiable oblivious pseudorandom function‚Äù construction, [<a href=\"https://blog.kagi.com/kagi-privacy-pass#references\">8</a>]) and generates ‚Äútokens,‚Äù these are not generated, stored, or traded on a blockchain.</p><p><strong>You mention the client generating tokens. Is this process energy-intensive or storage-demanding?</strong></p><p>No. The generation of 500 search tokens requires approximately 1 second of computation on a consumer laptop, and is performed in the background when installing the extension. A few extra seconds may be required due to the time required to contact the server and get a response. Each token consists of 216 bytes, for a total of approximately 100 KiB of storage per token generation request.</p><p><strong>Is there a potential impact on the speed of search when using Privacy Pass?</strong></p><p>The initial generation of tokens takes about ~1 second for 500 tokens, plus the time required for contacting the server. This occurs infrequently and is done in the background when possible.</p><p>Currently, the token validation servers are only deployed in our us-central1 region, we plan to expand this shortly after launch.</p><p><strong>How many tokens am I able to generate?</strong></p><p>You can generate 2,000 tokens in one ‚Äúepoch‚Äù (= one month). This should be enough for most users. If you need more than this, you can request additional tokens by contacting support@kagi.com.</p><p><strong>Do you plan to allow purchasing privacy pass tokens without having an account?</strong></p><p>Yes, this makes sense. This is possible because technically the extension does not care if you have an account or not. It just needs to be ‚Äòloaded‚Äô with valid tokens. And you can imagine a mechanism where you could also anonymously purchase them, eg. with monero, without ever creating an account at Kagi.  Let us know <a href=\"https://kagifeedback.org/d/6163-kagi-privacy-pass\">here</a> if you are excited about this, as it will help prioritize it.</p><p><strong>How can I submit feedback for Kagi Privacy Pass?</strong></p><p>We have a feedback thread open <a href=\"https://kagifeedback.org/d/6163-kagi-privacy-pass\">here</a>.</p><p><strong>Even if the extension implements anti-fingerprinting measures, Kagi will still be able to see my IP address, correct?</strong></p><p>Even with Privacy Pass authentication enabled, due to the way the TCP/IP stack works, we will be able to see your search request come from an IP address. As outlined in our <a href=\"https://kagi.com/privacy\">Privacy Policy</a>, your privacy is our priority, whether you are using Privacy Pass to authenticate or otherwise. If you are worried about us seeing your IP address, our suggestion is to connect to Kagi via Tor or through a VPN service you trust.</p><p><strong>How can Privacy Pass increase my privacy, if I have to send a session cookie to authenticate during token generation?</strong></p><p>While token generation is indeed not anonymous, Privacy Pass provides you with anonymity .</p><p>By providing the server with a Privacy Pass token instead of a session cookie when searching, you will guarantee that your searches cannot be  to any specific user account that generated Privacy Pass tokens, or to each other.</p><p>From the point of view of the server, your search query could have come from any of the users who previously generated Privacy Pass tokens.</p><p>The more users do so, the lower the probability that the server can guess it was you specifically who made a given search query.</p><p><strong>Token generation does not work in my Chrome/Firefox private window</strong></p><p>Correct, we need to authenticate you to create tokens (see above), and in the private window, the extension does not have access to your session cookie. Please use a normal browsing window while logged in to Kagi to generate tokens.</p><p>Note, generating tokens while in a private window will work in the <a href=\"https://kagi.com/orion\">Orion browser</a>.</p><p><strong>Can I use Kagi Assistant while using Privacy Pass?</strong></p><p>Not at this time, since Kagi Assistant is only available to Ultimate members. In Privacy Pass, we don‚Äôt have any account information, so we can‚Äôt validate what plan you‚Äôre on. We could issue tokens attached to different keys for different plans, but that also has privacy implications, see the discussion of personalization below.</p><p><strong>What Kagi services will be compatible with Privacy Pass at launch?</strong></p><p>At launch, Privacy Pass will only be used to authenticate Kagi Search. Soon to follow (in the next few weeks), we plan to expand support for Kagi Privacy Pass to:</p><ul><li>Kagi Translate and Kagi Maps</li><li>Kagi universal Summarizer and Ask questions about page</li></ul><p>Please disable Privacy pass to access these services for now.</p><p><strong>Since initial token generation happens in batches and the tokens expire, could tokens with similar expiration dates potentially be used to identify multiple searches from the same user?</strong></p><p>All tokens generated during month X expire at midnight of the first day of month X+2, to avoid this exact issue. Meaning a freshly generated token lasts until the end of the month following its generation (generate today, use all of Feb and March).</p><p><strong>If Kagi cannot track who exactly is performing search queries, will I have access to my account settings including customization and personalization?</strong></p><p>Since Kagi will not know who you are, we will not be able to serve you content tailored to your custom settings via Privacy Pass-protected search.</p><p>We have considered allowing users to send a small configuration with every request <code>(language, region, safe-search)</code> to automatically customize your search experience to some extent. However, we currently believe this would quickly result in a significant loss of anonymity for you and for other users. To illustrate this, we have examined the most common configurations of <code>(language, region, search-safe)</code> used on Kagi.com, and extrapolated how many Privacy Pass users would share them. Looking at the top 35 configurations, we see the following approximate numbers.</p><table><thead><tr></tr></thead><tbody><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr></tbody></table><p>Limiting the analysis to only the ten most common language settings, the effect is similar:</p><table><thead><tr></tr></thead><tbody><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr></tbody></table><p>This would mean that someone sending us  as their language configuration would automatically lose redemption-redemption unlinkability guarantees if approximately 1000 Kagi users used Privacy Pass.</p><p>While our extrapolation may be overly conservative, we won‚Äôt be enabling this level of ‚Äúdefault‚Äù customization for users authenticating via Privacy Pass for the time being. We could reconsider if we find a better solution.</p><p>For manual search settings customization, you can always use bangs in your search query to enable basic settings for a specific query. For example, <a href=\"https://help.kagi.com/kagi/features/bangs.html#regional-bangs\">regional bangs</a> will let you focus your query on one region. For example prefixing your search with  will automatically search in the German region.</p><p>To access a fully customized search experience, you can always use the traditional login method and disable the use of Privacy Pass.</p><p><strong>Will Safari be supported?</strong></p><p>The Safari extensions API doesn‚Äôt support (as far as we know) removing cookies from requests, which means it will always authenticate with your logged-in account. We‚Äôre not aware of a way to change this. The alternative if you want a similar, native, WebKit-based browsing experience, is to use the <a href=\"https://kagi.com/orion\">Orion Browser</a> which has Kagi Privacy Pass natively integrated.</p><ol><li>Davidson, A., Goldberg, I., Sullivan, N., Tankersley, G., &amp; Valsorda, F. (2018). Privacy pass: Bypassing internet challenges anonymously. Proceedings on Privacy Enhancing Technologies. <a href=\"https://doi.org/10.1515/popets-2018-0026\">Paper</a>.</li><li>Davidson, A., Iyengar, J., &amp; A. Wood, C. (2024). The Privacy Pass Architecture. <a href=\"https://www.rfc-editor.org/rfc/rfc9576.html\">RFC 9576</a>.</li><li>Pauly, T., Valdez, S., &amp; A. Wood, C. (2024). The Privacy Pass HTTP Authentication Scheme. <a href=\"https://www.rfc-editor.org/rfc/rfc9577.html\">RFC 9577</a>.</li><li>Celi, S., Davidson, A., Valdez, S., &amp; Wood, C. A. (2024). Privacy Pass Issuance Protocols. <a href=\"https://www.rfc-editor.org/rfc/rfc9578.html\">RFC 9578</a>.</li><li>Eckersley, P. (2010). How unique is your web browser? Proceedings on Privacy Enhancing Technologies. <a href=\"https://dl.acm.org/doi/10.5555/1881151.1881152\">Paper</a>.</li><li>Davidson, A., Faz-Hernandez, A., Sullivan, N., &amp; A. Wood, C. (2023). Oblivious Pseudorandom Functions (OPRFs) Using Prime-Order Groups. <a href=\"https://www.rfc-editor.org/rfc/rfc9497.html\">RFC 9497</a>.</li></ol><blockquote><p>Do you like how this post reads? It was proofread with <a href=\"https://translate.kagi.com\">Kagi Translate‚Äôs</a> proofreading option. To proofread any web page, just use <code>https://translate.kagi.com/proofread/[URL]</code>.</p></blockquote>","contentLength":21274,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43040521"},{"title":"Phind 2: AI search with visual answers and multi-step reasoning","url":"https://www.phind.com/blog/phind-2","date":1739470829,"author":"rushingcreek","guid":237,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43039308"}],"tags":["dev"]}