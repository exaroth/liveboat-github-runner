{"id":"CSXkJZ3MdFx","title":"Dev News","displayTitle":"Dev News","url":"","feedLink":"","isQuery":true,"isEmpty":false,"isHidden":false,"itemCount":55,"items":[{"title":"LibreOffice 25.8 Slams the Door On Windows 7 and 8.x","url":"https://tech.slashdot.org/story/25/08/23/0124202/libreoffice-258-slams-the-door-on-windows-7-and-8x?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1755943200,"author":"BeauHD","guid":262,"unread":true,"content":"BrianFagioli shares a report from NERDS.xyz: LibreOffice 25.8 has landed, and while it packs in new features and speed improvements, the biggest headline is who just got left behind. If you are still running Windows 7 or Windows 8/8.1, this is the end of the road. LibreOffice will not run on those systems anymore, and there are no workarounds. The suite has slammed the door shut.\n \nFor years, LibreOffice kept older Windows users afloat while Microsoft and other developers moved on. That lifeline is gone. Anyone stubbornly clinging to Windows 7 or 8 now has two choices: upgrade or stay stuck on outdated software. LibreOffice has made it clear that it will not carry dead platforms any further. And the cuts do not stop there. 32-bit Windows builds are on their way out, with deprecation already in place. On the Mac side, 25.8 is the last release that runs on macOS 10.15. Starting with LibreOffice 26.2, only macOS 11 and newer will be supported. In other words, if your computer is too old to run modern systems, LibreOffice is walking away.","contentLength":1050,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"I built Puhu, a pillow drop-in replacement in Rust","url":"https://www.reddit.com/r/rust/comments/1mxx8nu/i_built_puhu_a_pillow_dropin_replacement_in_rust/","date":1755942513,"author":"/u/creworker","guid":610,"unread":true,"content":"<p>Hey All, I‚Äôm a python developer and recently learning rust. I decided to build a drop-in replacement for pillow. Pillow is a 20+ old python package for image processing, and it‚Äôs well optimized. why did I start doing that? because why not üòÖ I wanted to learn rust and how to build python packages with rust backend. I did some benchmarks and actually it‚Äôs working pretty good, it‚Äôs faster than pillow in some functions. </p><p>My aim is use same api naming and methods so it will be easy to migrate from pillow to puhu. I‚Äôve implemented basic methods right now. continue working on other ones.</p><p>I appreciate any feedback, support or suggestions. </p>","contentLength":650,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Video: LibreOffice 25.8 ‚Äì Some of the new features","url":"https://www.youtube.com/watch?v=6dIRR37PF7M","date":1755938047,"author":"/u/themikeosguy","guid":576,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/linux/comments/1mxw2e2/video_libreoffice_258_some_of_the_new_features/"},{"title":"Upgrading cluster in-place coz I am too lazy to do blue-green","url":"https://www.reddit.com/r/kubernetes/comments/1mxuf5v/upgrading_cluster_inplace_coz_i_am_too_lazy_to_do/","date":1755931848,"author":"/u/suman087","guid":572,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"I'm too dumb for Zig's new IO interface","url":"https://www.openmymind.net/Im-Too-Dumb-For-Zigs-New-IO-Interface/","date":1755931178,"author":"begoon","guid":219,"unread":true,"content":"<p>You might have heard that Zig 0.15 introduces a new IO interface, with the focus for this release being the new std.Io.Reader and std.Io.Writer types. The old \"interfaces\" had problems. Like <a href=\"https://github.com/ziglang/zig/issues/17985\">this performance issue</a> that I opened. And it relied on a <a href=\"https://www.openmymind.net/In-Zig-Whats-a-Writer/\">mix of types</a>, which always confused me, and a lot of  - which is generally great, but a poor foundation to build an interface on.</p><p>I've been slowly upgrading my libraries, and I ran into changes to the  client used by my smtp library. For the life of me, I just don't understand how it works.</p><p>Zig has never been known for its documentation, but if we look at the documentation for , we'll find:</p><pre><code>input output options InitErrorClient\nInitiates a TLS handshake  establishes a TLSv1 TLSv1 session</code></pre><p>So it takes one of these new Readers and a new Writer, along with some options (sneak peak, which aren't all optional). It doesn't look like you can just give it a , but  does expose a  and  method, so that's probably a good place to start:</p><pre><code> stream  stdnetallocator stream writer  stream reader  stream tls_client  stdcryptotlsClient\n  readerwriterinterface</code></pre><p>Note that  returns a  and  returns a  - those aren't the types our  expects. To convert the  to an , we need to call its  method. To get a  from an , we need the address of its  field. This doesn't seem particularly consistent. Don't forget that the  and  need a stable address. Because I'm trying to get the simplest example working, this isn't an issue - everything will live on the stack of . In a real word example, I think it means that I'll always have to wrap the  into my own heap-allocated type; giving the writer and reader have a cozy stable home.</p><p>Speaking of allocations, you might have noticed that  and  take a parameter. It's the buffer they should use. Buffering is a first class citizen of the new Io interface - who needs composition? The documentation  tell me these need to be at least <code>std.crypto.tls.max_ciphertext_record_len</code> large, so we need to fix things a bit:</p><pre><code> write_buf writer  streamwrite_buf read_buf reader  streamread_buf</code></pre><p>Here's where the code stands: </p><pre><code> std  gpa stdheapinit allocator  gpa stream  stdnetallocator stream write_buf writer  streamwrite_buf read_buf reader  streamread_buf tls_client  stdcryptotlsClient\n      readerwriterinterface tls_client</code></pre><p>But if you try to run it, you'll get a compilation error. Turns out we have to provide 4 options: the ca_bundle, a host, a  and a . Normally I'd expect the options parameter to be for optional parameters, I don't understand why some parameters (input and output) are passed one way while  and  are passed another.</p><p>Let's give it what it wants AND send some data:</p><pre><code> bundle  bundleallocator bundleallocator tls_client  stdcryptotlsClient\n  readerwriterinterfaceca bundle  bundlehost explicit read_buffer write_buffer  tls_client tls_clientwriter</code></pre><p>Now, if I try to run it, the program just hangs. I don't know what  is, but I know Zig now loves buffers, so let's try to give it something:</p><pre><code> write_buf2 tls_client  stdcryptotlsClient\n  readerwriterinterfaceca bundle  bundlehost explicit read_buffer write_buffer write_buf2 tls_client tls_clientwriter</code></pre><p>Great, now the code doesn't hang, all we need to do is read the response.  exposes a  field which is \"Decrypted stream from the server to the client.\" That sounds like what we want, but believe it or not  doesn't have a  method. It has a  a , a  (which seems close, but it blocks until the provided buffer is full), a  and a lot more, but nothing like the  I'd expect. The closest I can find, which I think does what I want, is to stream it to a writer:</p><pre><code> buf wbuf n  tls_clientreaderwbuflen\nstddebugn bufn</code></pre><p>If we try to run the code now, it crashes. We've apparently failed an assertion regarding the length of a buffer. So it seems like we also  to provide a .</p><p>Here's my current version (it doesn't work, but it doesn't crash!):</p><pre><code> std  gpa stdheapinit allocator  gpa stream  stdnetallocator stream write_buf writer  streamwrite_buf read_buf reader  streamread_buf bundle  bundleallocator bundleallocator write_buf2 read_buf2 tls_client  stdcryptotlsClient\n      readerwriterinterfaceca bundle  bundlehost explicit read_buffer read_buf2write_buffer write_buf2 tls_client tls_clientwriter buf wbuf n  tls_clientreaderwbuflen\n  stddebugn bufn</code></pre><p>When I looked through Zig's source code, there's <a href=\"https://github.com/ziglang/zig/blob/306176046e6ae5e30bc58e5f3bcf786159e367f2/lib/std/http/Client.zig#L329\">only one place</a> using . It helped to get me where where I am. I couldn't find any tests.</p><p>I'll admit that during this migration, I've missed some basic things. For example, someone had to help me find  - the renamed version of . Maybe there's a helper like: <code>tls.Client.init(allocator, stream)</code> somewhere. And maybe it makes sense that we do  but  - I'm reminded of Go's  and . And maybe Zig has some consistent rule for what parameters belong in options. And I know nothing about TLS, so maybe it makes complete sense to need 4 buffers. I feel a bit more confident about the weirdness of not having a  function on , but at this point I wouldn't bet on me.</p>","contentLength":4948,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44993797"},{"title":"No, Google Did Not Unilaterally Decide to Kill XSLT","url":"https://meyerweb.com/eric/thoughts/2025/08/22/no-google-did-not-unilaterally-decide-to-kill-xslt/","date":1755926466,"author":"/u/AlyoshaV","guid":605,"unread":true,"content":"<p>It‚Äôs uncommon, but not unheard of, for a GitHub issue to spark an uproar.&nbsp; That happened over the past month or so as the WHATWG (Web Hypertext Application Technology Working Group, which I still say should have called themselves a Task Force instead) issue ‚Äú<a href=\"https://github.com/WHATWG/html/issues/11523\">Should we remove XSLT from the web platform?</a>‚Äù was opened, debated, and eventually locked once the comment thread started spiraling into personal attacks.&nbsp; Other discussions have since opened, such as <a href=\"https://github.com/whatwg/html/issues/11578\"> a counterproposal to update XSLT in the web platform</a>, thankfully with (thus far) much less heat.</p><p>If you‚Äôre new to the term, XSLT (Extensible Stylesheet Language Transformations) is an XML language that lets you transform one document tree structure into another.&nbsp; If you‚Äôve ever heard of people styling their RSS and/or Atom feeds to look nice in the browser, they were using some amount of XSLT to turn the RSS/Atom into HTML, which they could then CSS into prettiness.</p><p>This is not the only use case for XSLT, not by a long shot, but it does illustrate the sort of thing XSLT is good for.&nbsp; So why remove it, and who got this flame train rolling in the first place?</p><p>Before I start, I want to note that in this post, I won‚Äôt be commenting on whether or not XSLT support should be dropped from browsers or not.&nbsp; I‚Äôm also not going to be systematically addressing the various reactions I‚Äôve seen to all this.&nbsp; I have my own biases around this‚ÄØ‚Äî‚Äâsome of them in direct conflict with each other!‚ÄØ‚Äî‚Äâbut my focus here will be on what‚Äôs happened so far and what might lie ahead.</p><p>As a very quick background, various people have proposed removing XSLT support from browsers a few times over the quarter-century-plus since support first landed.&nbsp; It was discussed in both the early and mid-2010s, for example.&nbsp; At this point, browsers all more or less support<a href=\"https://www.w3.org/TR/xslt-10/\">XSLT 1.0</a>, whereas the latest version of XSLT is <a href=\"https://www.w3.org/TR/xslt-30/\">3.0</a>.&nbsp; I believe they all do so with C++ code, which is therefore not memory-safe, that is baked into the code base rather than supported via some kind of plugged-in library, like Firefox using <a href=\"https://github.com/mozilla/pdf.js\"> PDF.js</a> to support PDFs in the browser.</p><p>Anyway, back on August 1st, Mason Freed of Google opened <a href=\"https://github.com/WHATWG/html/issues/11523\">issue #11523</a> on WHATWG‚Äôs HTML repository, asking if XSLT should be removed from browsers and giving a condensed set of reasons why it might be a good idea.&nbsp; He also included a WASM-based polyfill he‚Äôd written to provide XSLT support, should browsers remove it, and opened ‚Äú<a href=\"https://issues.chromium.org/issues/435623334\"> Investigate deprecation and removal of XSLT</a>‚Äù in the Chromium bug tracker.</p><p>‚ÄúSo it‚Äôs already been decided and we just have to bend over and take the changes our Googlish overlords have decreed!‚Äù many people shouted.&nbsp; It‚Äôs not hard to see where they got that impression, given some of the things Google has done over the years, but that‚Äôs  what‚Äôs happening here.&nbsp; Not at this point.&nbsp; I‚Äôd like to set some records straight, as an outside observer of both Google and the issue itself.</p><p>First of all, while Mason was the one to open the issue, this was done because the idea was raised in a periodic WHATNOT meeting (call), where someone at Mozilla was actually the one to bring it up, after it had come up in various conversations over the previous few months.&nbsp; After Mason opened the issue, members of the Mozilla and WebKit teams expressed (tentative, mostly) support for the idea of exploring this removal.&nbsp; Basically,  of the vendors are particularly keen on keeping native XSLT support in their codebases, particularly after <a href=\"https://www.neowin.net/news/google-project-zero-exposes-security-flaw-in-libxslt-library-used-in-gnome-applications/\"> security flaws were found</a> in XSLT implementations.</p><p>This isn‚Äôt the first time they‚Äôve all agreed it might be nice to slim their codebases down a little by removing something that doesn‚Äôt get a lot of use (relatively speaking), and it won‚Äôt be the last.&nbsp; I bet they‚Äôve all talked at some point about how nice it would be to remove <a href=\"https://en.wikipedia.org/wiki/BMP_file_format\">BMP</a> support.</p><p>Mason mentioned that they didn‚Äôt have resources to put toward updating their XSLT code, and got widely derided for it. ‚ÄúGoogle has trillions of dollars!‚Äù people hooted.&nbsp;  has trillions of dollars.&nbsp; The Chrome team very much does not.&nbsp; They probably get, at best, a tiny fraction of one percent of those dollars.&nbsp; Whether Google should give the Chrome team more money is essentially irrelevant, because that‚Äôs not in the Chrome team‚Äôs control.&nbsp; They have what they have, in terms of head count and time, and have to decide how those entirely finite resources are best spent.</p><p>(I will once again invoke my late-1900s formulation of <a href=\"https://en.wikipedia.org/wiki/Hanlon's_razor\">Hanlon‚Äôs Razor</a>: <em> Never attribute to malice that which can be more adequately explained by resource constraints.</em>)</p><p>Second of all, the issue was opened to start a discussion and gather feedback as the first stage of a multi-step process, one that could easily run for years.&nbsp; Google, as I assume is true for other browser makers, has a pretty comprehensive method for working out whether removing a given feature is tenable or not.&nbsp; <a href=\"https://bkardell.com\">Brian</a> and I <a href=\"https://www.igalia.com/chats/unshipping\"> talked with Rick Byers about it</a> a while back, and I was impressed by both how many things been removed, and what they do to make sure they‚Äôre removing the right things.</p><p>Here‚Äôs one (by no means the only!) way they could go about this:</p><ol type=\"1\"><li>Set up a switch that allows XSLT to be disabled.</li><li>In the next release of Chrome, use the switch to disable XSLT in one percent of all Chrome downloads.</li><li>See if any bug reports come in about it.&nbsp; If so, investigate further and adjust as necessary if the problems are not actually about XSLT.</li><li>If not, up the percentage of XSLT-disabled downloads a little bit at a time over a number of releases.&nbsp; If no bugs are reported as the percentage of XSLT-disabled users trends toward 100%, then prepare to remove it entirely.</li><li>If, on the other hand, it becomes clear that removing XSLT will be a widely breaking change ‚ÄØ‚Äî‚Äâ&nbsp;where ‚Äúwidely‚Äù can still mean a very tiny portion of their total user base‚ÄØ‚Äî‚Äâthen XSLT can be re-enabled for all users as soon as possible, and the discussion taken back up with this new information in hand.</li></ol><p>Again, that is just one of several approaches Google could take, and it‚Äôs a lot simpler than what they would most likely actually do, but it‚Äôs roughly what they default to, as I understand it.&nbsp; The process is slow and deliberate, building up a picture of actual use and user experience.</p><p>Third of all, opening a bug that includes a pull request of code changes isn‚Äôt a declaration of countdown to merge, it‚Äôs a way of making crystal clear (to those who can read the codebase) exactly what the proposal would entail.&nbsp; It‚Äôs basically a requirement for the process of making a decision to start, because it sets the exact parameters of what‚Äôs being decided on.</p><p>That said, as a result of all this, I now strongly believe that every proposed-removal issue should point to the process and where the issue stands in it. (And write down the process if it hasn‚Äôt been already.) This isn‚Äôt for the issue‚Äôs intended audience, which was other people within WHATWG who are familiar with the usual process and each other, but for cases of context escape, like happened here.&nbsp; If a removal discussion is going to be held in public, then it should assume the general public will see it and provide enough context for the general public to understand the actual nature of the discussion.&nbsp; In the absence of that context, the nature of the discussion will be assumed, and every assumption will be different.</p><p>There is one thing that we should all keep in mind, which is that ‚Äúremove from the web platform‚Äù really means ‚Äúremove from browsers‚Äù.&nbsp; Even if this proposal goes through, XSLT could still be used server-side.&nbsp; You could use libraries that support XSLT versions more recent than 1.0, even!&nbsp; Thus, XML could still be turned into HTML, just not in the client via native support, though JS or WASM polyfills, or even add-on extensions, would still be an option.&nbsp; Is that good or bad?&nbsp; Like everything else in our field, the answer is ‚Äúit depends‚Äù.</p><p>Just in case your eyes glazed over and you quickly skimmed to see if there was a TL;DR, here it is:</p><p><em>The discussion was opened by a Google employee in response to interest from multiple browser vendors in removing built-in XSLT, following a process that is opaque to most outsiders.&nbsp; It‚Äôs a first step in a multi-step evaluation process that can take years to complete, and whose outcome is not predetermined.&nbsp; Tempers flared and the initial discussion was locked; the conversation continues elsewhere.&nbsp; There are good reasons to drop native XSLT support in browsers, and also good reasons to keep or update it, but XSLT is not itself at risk.</em></p>","contentLength":8626,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1mxswpp/no_google_did_not_unilaterally_decide_to_kill_xslt/"},{"title":"Coinbase CEO explains why he fired engineers who didn‚Äôt try AI immediately","url":"https://techcrunch.com/2025/08/22/coinbase-ceo-explains-why-he-fired-engineers-who-didnt-try-ai-immediately/","date":1755924216,"author":"/u/diegoargento1","guid":609,"unread":true,"content":"<p>It‚Äôs hard to find programmers these days who aren‚Äôt using AI coding assistants in some capacity, especially to write the repetitive, mundane bits.</p><p>But those who refused to try the tools when Coinbase bought enterprise licenses for GitHub Copilot and Cursor got promptly fired, CEO Brian Armstrong said this week on John Collison‚Äôs podcast <a href=\"https://www.youtube.com/watch?v=JeVny5KHj4g&amp;list=PLcoWp8pBTM3ATMYLP-hFIhJORSw-nFOiY&amp;index=2\" target=\"_blank\" rel=\"noreferrer noopener nofollow\">‚ÄúCheeky Pint.‚Äù</a> (Collison is the co-founder and president of the payments company Stripe.)</p><p>After getting licenses to cover every engineer, some at the cryptocurrency exchange warned Armstrong that adoption would be slow, predicting it would take months to get even half the engineers using AI.&nbsp;</p><p>Armstrong was shocked at the thought. ‚ÄúI went rogue,‚Äù he said, and posted a mandate in the company‚Äôs main engineering Slack channel. ‚ÄúI said, ‚ÄòAI is important. We need you to all learn it and at least onboard. You don‚Äôt have to use it every day yet until we do some training, but at least onboard by the end of the week. And if not, I‚Äôm hosting a meeting on Saturday with everybody who hasn‚Äôt done it and I‚Äôd like to meet with you to understand why.‚Äô‚Äù&nbsp;</p><p>At the meeting, some people had reasonable explanations for not getting their AI assistant accounts set up during the week, like being on vacation, Armstrong said.</p><p>‚ÄúI jumped on this call on Saturday and there were a couple people that had not done it. Some of them had a good reason, because they were just getting back from some trip or something, and some of them didn‚Äôt [have a good reason]. And they got fired.‚Äù</p><p>Armstrong admits that it was a ‚Äúheavy-handed approach‚Äù and there were people in the company who ‚Äúdidn‚Äôt like it.‚Äù</p><p>While it doesn‚Äôt sound like very many people were fired, Armstrong said it sent a clear message that AI is not optional. Still, everything about that story is wild: that there were engineers who wouldn‚Äôt spend a few minutes of their week signing up for and testing the AI assistant ‚Äî the most hyped tech for coders ever ‚Äî and that Armstrong was willing to fire them over it.</p><p>Coinbase did not respond to a request for comment.</p><p>Since then, Armstrong has leaned further into the training. He said the company hosts monthly meetings where teams who have mastered creative ways to use AI share what they have learned.</p><p>Interestingly, Collison, who has been <a href=\"https://fintechmagazine.com/articles/the-collison-brothers\" target=\"_blank\" rel=\"noreferrer noopener nofollow\">programming since childhood</a>, questioned how much companies should be relying on AI-generated code.</p><p>‚ÄúIt‚Äôs clear that it is very helpful to have AI helping you write code. It‚Äôs not clear how you run an AI-coded code base,‚Äù he commented.  Armstrong replied, ‚ÄúI agree.‚Äù</p><p>Indeed, as TechCrunch previously reported, <a href=\"https://techcrunch.com/2025/07/15/a-former-openai-engineer-describes-what-its-really-like-to-work-there/\">a former OpenAI engineer described</a> that company‚Äôs central code repository as ‚Äúa bit of a dumping ground.‚Äù The engineer said management had begun dedicating engineering resources to improve the situation.</p><p><em>We‚Äôre always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&nbsp;</em><em>&nbsp;to let us know how we‚Äôre doing and get the chance to win a prize in return!</em></p>","contentLength":3093,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1mxs92h/coinbase_ceo_explains_why_he_fired_engineers_who/"},{"title":"What on Earth Does Pointer Provenance Have to do With RCU?","url":"https://people.kernel.org/paulmck/what-on-earth-does-lifetime-end-pointer-zap-have-to-do-with-rcu","date":1755923066,"author":"/u/unixbhaskar","guid":573,"unread":true,"content":"<p>TL;DR: Unless you are doing very strange things with RCU, not much!!!</p><p>So why has the guy most responsible for Linux-kernel spent so much time over the past five years working on the provenance-related lifetime-end pointer zap within the C++ Standards Committee?</p><h2>What is Pointer Provenance?</h2><p>Back in the old days, provenance was for objets d'art and the like, and we did not need them for our pointers, no sirree!!!  Pointers had bits, those bits formed memory addresses, and as often as not we didn't even need to worry about these addresses being translated.  But life is more complicated now.  On the other hand, computing life is also much bigger, faster, more reliable, and (usually) more productive, so be extremely careful what you wish for from back in the Good Old Days!</p><p>These days, pointers have provenance as well as addresses, and this has consequences.  The C++ Standard  (<a href=\"https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2025/n5008.pdf\" rel=\"nofollow\">recent draft</a>) states that when an object's storage duration ends, any pointers to that object become invalid.  For its part, the C Standard states that when an object's storage duration ends, any pointers to that object become indeterminate.  In both standards, the wording is more precise, but this will serve for our purposes.</p><p>For the remainder of this document, we will follow C++ and say ‚Äúinvalid‚Äù, which is shorter than ‚Äúindeterminate‚Äù.  We will balance this out by using C-language example code.  Those preferring C++ will be happy to hear that this is the language that I use in my <a href=\"https://cppcon2025.sched.com/event/27bR6/interesting-upcoming-low-latency-concurrency-and-parallelism-features-from-wroclaw-2024-hagenberg-2025-and-sofia-2025\" rel=\"nofollow\">upcoming CPPCON presentation</a>.</p><p>Neither standard places any constraints on what a compiler can do with an invalid pointer value, even if all you are doing is loading or storing that value.</p><p>Those of us who cut our teeth on assembly language might quite reasonably ask why anyone would even think to make pointers so invalid that you cannot even load or store them.  Let's start by looking at pointer comparisons using this code fragment:</p><pre><code>p = kmalloc(...);\nmight_kfree(p);         // Pointer might become invalid (AKA \"zapped\")\nq = kmalloc(...);       // Assume that the addresses of p and q are equal.\nif (p == q)             // Compiler can optimize as \"if (false)\"!!!\n    do_something();\n</code></pre><p>Both  and  contain addresses, but the compiler also keeps track of the fact that their values were obtained from different invocations of .  This information forms part of each pointer's provenance.  This means that  and  have different provenance, which in turn means that the compiler does not need to generate any code for the  comparison.  The two pointers' provenance differs, so the result cannot be anything other than .</p><p>And this is one motivation for pointer provenance and invalidity:  The results of operations on invalid pointers are not guaranteed, which provides additional opportunities for optimization.  This example perhaps seems a bit silly, but modern compilers can use pointer provenance and invalidity to carry out serious points-to and aliasing analysis.</p><p>Yes, you can have hardware provenance.  Examples include ARM MTE, the CHERI research prototype (which last I checked had issues with C++'s requirement that pointers are trivially copiable), and the venerable IBM System i.  Conventional systems provide pointer provenance of a sort via their page tables, which is used by a variety of memory-allocation-use debuggers, for but one example, the efence library.  The pointer-provenance features of ARM MTE and IBM System i are not problematic, but last I checked, the jury was still out on CHERI.</p><p>Of course, using invalid (AKA ‚Äúdangling‚Äù) pointers is known to be a bad idea.  So why are we even talking about it???</p><h2>Why Would Anyone Use Invalid/Dangling Pointers?</h2><p>Please allow me to introduce you to the famous and frequently re-invented LIFO Push algorithm.  You can find this in many places, but let's focus on the Linux kernel's  and  functions.  The former atomically pushes a list of elements on a linked-list stack, and the latter just as atomically removes the entire contents of the stack:</p><pre><code>static inline bool llist_add_batch(struct llist_node *new_first,\n                                   struct llist_node *new_last,\n                                   struct llist_head *head)\n{\n    struct llist_node *first = READ_ONCE(head-&gt;first);\n\n    do {\n        new_last-&gt;next = first;\n    } while (!try_cmpxchg(&amp;head-&gt;first, &amp;first, new_first));\n\n    return !first;\n}\n\nstatic inline struct llist_node *llist_del_all(struct llist_head *head)\n{\n    return xchg(&amp;head-&gt;first, NULL);\n}\n</code></pre><p>As lockless concurrent algorithms go, this one is pretty straightforward.  The  function reads the list header, fills in the  pointer, then does a compare-and-exchange operation to point the list header at the new first element.  The  function is even simpler, doing a single atomic exchange operation to  out the list header and returning the elements that were previously on the list.  This algorithm also has excellent forward-progress properties: the  function is lock-free and the  function is wait-free.</p><p>In assembly language, or with a simple compiler, not much.  But to see the pointer-provenance issue with more heavily optimized languages, consider the following sequence of events:</p><ol><li>CPU 0 allocates an  B and passes it via both the  and  parameters of .</li><li>CPU 0 picks up the  pointer and places it in the  local variable, then assigns it to .  This  pointer now references  A.</li><li>CPU 1 invokes , which returns a list containing  A.  The caller of  processes A and passes it to .</li><li>CPU 0's  pointer is now invalid due to  A having been freed.  But CPU 0 does not know this.</li><li>CPU 1 allocates an  C that happens to have the same address as the old  A.  It passes C  via both the  and  parameters of , which runs to completion.  The  pointer now points to  C, which happens to have the same address as the now storage-duration-ended  A.</li><li>CPU 0 finally gets around to executing its , which given typical C compilers will succeed.  The  now contains an  B that contains an invalid pointer to dead  A, but whose pointer address happens to reference the shiny new  C.  (We term this invalid pointer a ‚Äúzombie pointer‚Äù because it has in some assembly-language sense come back from the dead.)</li><li>Some CPU invokes  and gets back an  containing an invalid pointer.</li></ol><p>One could argue that the Linux-kernel implementation of LIFO Push is simply buggy and should be fixed.  Except that there is no reasonable way to fix it.  Which of course raises the question...</p><h2>What Are Unreasonable Fixes?</h2><p>We can protect pointers from invalidity by storing them as integers, but:</p><ol><li>Suppose someone has an element that they are passing to a library function.  They should not be required to convert all their  pointers to integer just because the library's developers decide to switch to the LIFO Push algorithm for some obscure internal operation.</li><li>In addition, switching to integer defeats type-checking, because integers are integers no matter what type of pointer they came from.</li><li>We could restore some type-checking capability by wrapping the integer into a differently named struct for each pointer type.  Except that this requires a struct with some particular name to be treated as compatible with pointers of some type corresponding to that name, a notion that current do not support.</li><li>In C++, we could use template metaprogramming to wrap an integer into a class that converts automatically to and from compatibly typed pointers.  But there would then be windows of time in which there was a real pointer, and at that time there would still be the possibility of pointer invalidity.</li><li>All of the above hack-arounds put additional obstacles in the way of developers of concurrent software.</li><li>In environments such as the Linux kernel that provides their own memory allocators, we can hide them from the compiler.  But this is not free, in fact, the patch that exposed the Linux-kernel's memory allocators to the compiler resulted in a small but significant improvement.</li></ol><p>However, it is fair to ask...</p><h2>Why Do We Care About Strange New Algorithms???</h2><p>Let's take a look at the history, courtesy of Maged Michael's diligent software archaeology.</p><p>In 1986, R. K. Treiber presented an assembly language implementation of the LIFO Push algorithm in technical report RJ 5118 entitled ‚ÄúSystems Programming: Coping with Parallelism‚Äù while at the IBM Almaden Research Center.</p><p><a href=\"https://patents.google.com/patent/US3886525\" rel=\"nofollow\">US Patent 3,886,525</a> was filed in June 1973, just a few months before I wrote my first line of code, and contains a prior-art reference to the LIFO Push algorithm (again with pop() instead of popall()) as follows: ‚ÄúConditional swapping of a single address is sufficient to program a last-in, first-out single-user-at-a-time sequencing mechanism.‚Äù  (If you were to ask a patent attorney, you would likely be told that this 50-year-old patent has long since expired.  Which should be no surprise, given that it is even older than Dennis Ritchie's setuid <a href=\"https://patents.google.com/patent/US4135240A/en\" rel=\"nofollow\">Patent 4,135,240</a>.)</p><p>All three of these references describe LIFO push as if it was straightforward and well known.</p><p>So we don‚Äôt know who first invented LIFO Push or when they invented it, but it was well known in 1973.  Which is well over a decade before C was first standardized, more than two decades before C++ was first standardized, and even longer before work was started on Rust.</p><p>And its combination of (relative) simplicity and excellent forward-progress properties just might be why this algorithm was anonymously invented so long ago and why it is so persistently and repeatedly reinvented.  This frequent reinvention puts paid to any notion that LIFO Push is strange.</p><p>So sorry, but LIFO Push is neither new nor strange.</p><p>The lifetime-end pointer-zap story is not yet over, but we are currently pushing for the changes in four working papers.</p><h3>Nondeterministic Pointer Provenance</h3><p><a href=\"https://isocpp.org/files/papers/P2434R4.html\" rel=\"nofollow\">P2434R4 (‚ÄúNondeterministic pointer provenance‚Äù)</a> is the basis for the other three papers.  It asks that when converting a pointer to an integer and back, the implementation must choose a qualifying pointed-to object (if there is one) whose storage duration began before or concurrently with the conversion back to a pointer.  In particular, the implementation is free to ignore a qualifying pointed-to object when the conversion to pointer happens before the beginning of that object‚Äôs storage duration.</p><p>The ‚Äúqualifying‚Äù qualifier includes compatible type, as well as sufficiently early and long storage duration.</p><p>But why restrict the qualifying pointed-to object's storage duration to begin before or concurrently with the conversion back to a pointer?</p><p>An instructive example by Hans Boehm may be found in P2434R4, which shows that reasonable (and more important, very heavily used) optimizations would be invalidated by this approach.  Several examples that manage to be even more sobering may be found in David Goldblatt's <a href=\"https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2024/p3292r0.html\" rel=\"nofollow\">P3292R0 (‚ÄúProvenance and Concurrency‚Äù)</a>.</p><h3>Pointer Lifetime-End Zap Proposed Solutions: Atomics and Volatile</h3><p><a href=\"https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2025/p2414r9.pdf\" rel=\"nofollow\">P2414R10 (‚ÄúPointer lifetime-end zap proposed solutions: Atomics and volatile‚Äù)</a> is motivated by the observation that atomic pointers are subject to update at any time by any thread, which means that the compiler cannot reasonably do much in the way of optimization.  This paper therefore asks (1) that atomic operations be redefined to yield and to store prospective pointers values and (2) that operations on volatile pointers be defined to yield and to store prospective pointer values.  The effect is as if atomic pointers were stored internally as integers. This includes the ‚Äúold‚Äù pointer passed by reference to compare_exchange().</p><p>This helps, but is not a full solution because atomic pointers are converted to non-atomic pointers prior to use, at which point they are subject to lifetime-end pointer zap.  And the standard does not even guarantee that a zapped pointer can even be loaded, stored, passed to a function, or returned from a function.  Which brings us to the next paper.</p><h3>Pointer Lifetime-End Zap Proposed Solutions: Tighten IDB for Invalid Pointers</h3><p><a href=\"https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2025/p3347r3.pdf\" rel=\"nofollow\">P3347R3 (‚ÄúPointer lifetime-end zap proposed solutions: Tighten IDB for invalid pointers‚Äù)</a> therefore asks that all non-comparison non-arithmetic non-dereference computations involving pointers, specifically including normal loads and stores, are fully defined even if the pointers are invalid.  This permits invalid pointers to be loaded, stored, passed as arguments, and returned.  Fully defining comparisons would rule out optimizations, and fully defining arithmetic would be complex and thus far unneeded.</p><p>If these first three papers are accepted into the standard, the C++ implementation of LIFO Push show above becomes valid code.  This is important because this algorithm has been re-invented many times over the past half century, and is often open coded.  This makes it very hard to construct tools that find LIFO Push implementations in existing code.</p><h3>P3790R1: Pointer Lifetime-End Zap Proposed Solutions: Bag-of-Bits Pointer Class</h3><p><a href=\"https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2025/p3790r0.pdf\" rel=\"nofollow\">P3790R1 (‚ÄúPointer lifetime-end zap proposed solutions: Bag-of-bits pointer class‚Äù)</a> asks that (1) the addition to the C++ standard library of the function <code>launder_bag_of_bits_ptr()</code> that takes a pointer argument and returns a prospective pointer value corresponding to its argument; and (2) the addition to the C++ standard library of the class template  that is a pointer-like type that is still usable after the pointed-to object‚Äôs lifetime has ended.  Of course, such a pointer still cannot be dereferenced unless there is a live object at that pointer's address.  Furthermore, some systems, such as ARMv9 with memory tagging extensions (MTE) enabled have provenance as well as address bits in the pointer, and on such systems dereferencing will fail unless the pointer's provenance bits happen to match those of the pointed-to object.</p><p>This function and template class is nevertheless quite useful for maintaining hash maps keyed by pointers after the pointed-to object's lifetime has ended.</p><p>Unlike LIFO Push, source-code changes are required for these use cases.  This is unfortunate, but we have thus far been unable to come up with a same-source-code approach.</p><p>Those who have participated in standards work (or even open-source work) will understand that the names <code>launder_bag_of_bits_ptr()</code> and  are still subject to bikeshedding.</p><h2>A Happen Lifetime-End Pointer Zap Ending?</h2><p>It is still too early to say for certain, but thus far these proposals are making much better progress than did their predecessors.  So who knows?  Perhaps C++29 will address lifetime-end pointer zap.</p>","contentLength":14444,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/linux/comments/1mxrwl4/what_on_earth_does_pointer_provenance_have_to_do/"},{"title":"GPUI Hello World Tutorial - From Core Concepts to Hello World | 0xshadow's Blog","url":"https://blog.0xshadow.dev/posts/learning-gpui/gpui-hello-world-tutorial/","date":1755922295,"author":"/u/lazyhawk20","guid":612,"unread":true,"content":"<p>In this post, we are going to learn about GPUI - an open source UI framework developed by the Zed Industries team to build interfaces by utilizing our computer‚Äôs GPU. We are going to learn the basics of GPUI by building a hello world app.</p><ul><li>Basic HTML, CSS and JS knowledge</li></ul><p>GPUI is a <strong>hybrid immediate and retained mode, GPU-accelerated</strong> UI framework for Rust created by the makers of Zed editor. Before we dive into code, let me explain what these terms mean in simple language.</p><p> means GPUI uses our computer‚Äôs graphics card to render to interface unlike traditional CPU-based rendering. This makes it extremely fast.</p><p><strong>Hybrid immediate and retained mode</strong> refers to how GPUI manages the user interface:</p><ul><li> means the UI is redrawn from scratch every frame.</li><li> means the framework remembers the UI structure and only updates what changes, which is more efficient.</li><li> mean GPUI uses both approaches.</li></ul><p>Before jumping into coding, lets understand why the Zed team created GPUI? Why the existing solutions aren‚Äôt good enough for them?</p><p>When Zed team decided to build their own code editor, they realized that existing UI frameworks couldn‚Äôt deliver the performance they need. Hence, they decided to build their own UI framework.\nThe problem with traditional desktop UI frameworks is that they primarily use CPU for rendering. The CPU processes instructions sequentially. This becomes a bottleneck when you have a complex interface with many elements. Every button, text field, menu and visual element must be processed in sequence.</p><p>To fix this issue, they decided to use GPU of the computer, which can process thousands of operations in parallel. Your graphics card contains hundreads and thousands or cores that can work simultaneously. This parallel processing has been used in gaming for decades, but most desktop apps don‚Äôt take advantage of it.</p><p>Now that we know why GPUI exists, lets now see how it actually works. After understanding its core concepts, we can start building our app as we will already have the understanding of its essential concepts.</p><h2>The Application Lifecycle and AppContext</h2><p>When we run a GPUI app, the framework needs to take care of a lot of things that are happening simultaneously. Our app might have multiple windows open, user might be clicking buttons, typing text or resizing windows.</p><p>The  object is kind of the coordinator of all this activity. When we run , we are telling GPUI to ‚Äústart managing the app and keep running until the user closes the app‚Äù.</p><p>The (often shortened to  in code) is what we will use to communicate with the  object. Every time we want to create a window, handle an event or update the display, we need to do it through the .</p><h2>Views and The Render Trait</h2><p>In GPUI, everything we see on screen is organized into . A view is a Rust struct that represents a logical piece of our application‚Äôs interface. Think of a view as a self-contained component that manages both its own data and knows how to present that data visually.</p><p>Here‚Äôs what makes GPUI fundamentally different from desktop frameworks like Electron, Tauri, or traditional native frameworks: GPUI uses a declarative rendering approach rather than an imperative one. In imperative frameworks, we create interface objects once and then manually update their properties when things change. We might write code like <code>button.setText(\"New Label\")</code> or <code>window.setBackgroundColor(red)</code> to modify existing interface elements.</p><p>GPUI works differently. It doesn‚Äôt store permanent interface objects that we modify. Instead, GPUI asks our views to completely recreate their visual description every single time the screen needs to be redrawn. This happens through the  trait, which every displayable struct must implement.</p><p>The  trait has exactly one method: . This method takes the current state of our view and returns a fresh description of what should appear on screen. GPUI calls this method whenever it needs to redraw our view, which could be 60 times per second or more. Our job is to look at our view‚Äôs current data and describe what the interface should look like based on that data.</p><p>This approach might seem inefficient at first glance, but it‚Äôs actually what enables GPUI‚Äôs exceptional performance. Since GPUI gets a complete description of our interface every frame, it can compare the new description with the previous one and update only the parts that actually changed. This is similar to how React‚Äôs virtual DOM works, but optimized for GPU rendering instead of web browsers.</p><p>When our  method runs, it creates and returns elements. Elements are temporary objects that describe visual components. They specify things like ‚Äúthere should be a rectangle here with this color and size‚Äù or ‚Äúthere should be text here with this font and content.‚Äù Elements are not the actual visual components themselves, but rather instructions for creating those components.</p><p>GPUI provides built-in element types that cover most interface needs. The  element creates a container that can hold other elements, similar to HTML div tags but designed for desktop applications. The  element creates an interactive button that can respond to clicks. The  element displays styled text content. Each element type has methods we can chain together to configure its appearance and behavior.</p><p>The power of GPUI‚Äôs element system comes from composition. We build complex interfaces by nesting simple elements inside other elements. A  can contain multiple child elements, and each of those children can have their own children, creating a hierarchical tree structure. This tree represents the logical structure of our interface.</p><p>When we call methods like , , or  on elements, we‚Äôre not modifying existing objects. Instead, we‚Äôre creating new element descriptions that include those properties. GPUI uses a builder pattern where each method call returns a new element with the additional configuration applied.</p><p>Now, that we understood a little bit of theory, let‚Äôs start building our first simple hello world app in GPUI.</p><h2>Installing Rust Nightly for Our Project</h2><p>To use GPUI we need to have the nightly version of Rust because it is using some experimental features. To install the nightly tool, run the following command:</p><p>This will download and install the latest nightly version of Rust.</p><p>Let‚Äôs start by creating a new rust project using cargo. Open the terminal and go to the directory where you want the project to be created. Now, run the following command:</p><p>After running this command, you can see that you have a standard rust project that prints Hello World in console but we want to create a GPUI app and print the Hello World text in that app.</p><p>Now, we need to enable the nightly version of Rust specifically for this project and not for all Rust projects. To do this, create a file called  in our project root directory.</p><pre tabindex=\"0\" data-language=\"toml\"><code></code></pre><p>This tells Cargo to automatically use nightly Rust whenever we work in this project directory, while keeping our global Rust installation on stable.</p><p>It‚Äôs time to configure our  file to work with the nightly edition and GPUI.</p><h2>Configuring Cargo for 2024 Edition and GPUI</h2><p>Let‚Äôs update our  file.</p><pre tabindex=\"0\" data-language=\"toml\"><code></code></pre><p>Here, we changed the  from  to  and added the GPUI dependency.</p><h2>Writing Our Hello World Code</h2><p>I‚Äôm putting the entire  code here and after that I‚Äôll explain everything one by one.</p><pre tabindex=\"0\" data-language=\"rust\"><code></code></pre><p>Ok, it seems a lot of code for Hello World let‚Äôs unpack everything one by one.</p><pre tabindex=\"0\" data-language=\"rust\"><code></code></pre><p>This import statement gets everything that we need from GPUI. Let‚Äôs understand what we are importing from GPUI:</p><ul><li> - The context type we receive in our main application closure for setting up windows and global app state</li><li> - The main application object that manages our entire GPUI app lifecycle</li><li> - A type that represents the position and size of windows on screen</li><li> - The context object we receive in our render method, giving us access to GPUI‚Äôs systems for this specific view</li><li> - GPUI‚Äôs optimized string type that allows efficient sharing of text data without unnecessary copying</li><li> - Represents a window and provides access to window-specific properties and methods</li><li><strong><code>WindowBounds, WindowOptions</code></strong> - Configuration types for specifying how our window should be created and positioned</li><li> - The function that creates div elements, our main building block for layouts</li><li> - Brings in commonly used traits like  and utility functions</li><li> - Helper functions for creating measurements (pixels), colors, and size specifications</li></ul><h2>Defining Our View with State</h2><pre tabindex=\"0\" data-language=\"rust\"><code></code></pre><p>Our view struct contains the actual text data. The  field stores the text that we want to show or display in the app.</p><p>Now, you might be wondering why use  instead of ?\nThe reason is GPUI optimizes for sharing the text between different parts of the app. The  can be cloned very efficiently without copying the actual text data and multiple parts of our app can reference the same text without memory overhead.</p><h2>Implementing the Render Trait</h2><pre tabindex=\"0\" data-language=\"rust\"><code></code></pre><p>Now, let‚Äôs understand the signature of the  method:</p><ul><li> - Mutable access to our view, allowing us to modify the view‚Äôs state during rendering if needed. Even though we don‚Äôt modify anything in this example, GPUI requires this flexibility.</li><li> - Access to the window this view is being rendered in. We could use this to query window properties like current size, position, or screen DPI. The underscore indicates we‚Äôre not using it in this simple example.</li><li> - The context object that provides access to GPUI‚Äôs systems. Through this context, we could handle user input, set up timers, or create child views. The  parameter means this context is specifically typed for our  view.</li></ul><h3>Building Our Element Tree</h3><p>Now let‚Äôs understand each method call in our element construction:</p><p>This creates our root  element - the foundation container for everything else in our view. This is similar to how we use div for containers in HTML.</p><p>This enables flexbox layout on our div. Flexbox provides powerful, automatic layout capabilities that adjust to different content sizes and window dimensions. This is why I asked you to have basic knowledge on CSS. If you don‚Äôt know flexbox concept then please quickly read about it and then continue reading this tutorial.</p><p>This sets the flex direction to column, meaning any child elements would stack vertically rather than horizontally. Even though we only have one child, this establishes the layout direction.</p><p>This sets the background color to a dark blue-gray. The  function takes a hexadecimal color value and converts it to GPUI‚Äôs internal color representation.</p><p>This sets both width and height to exactly 500 pixels. The  function creates a pixel-based measurement. This gives us a fixed-size container regardless of window size.</p><p>This centers content along the main axis. Since we used , the main axis runs vertically, so this centers our content vertically within the 500-pixel height.</p><p>This centers content along the cross axis. With column direction, the cross axis runs horizontally, so this centers our content horizontally within the 500-pixel width.</p><p>This sets the text size to extra large. GPUI provides a typography scale with predefined sizes for consistent text styling across our application.</p><pre tabindex=\"0\" data-language=\"rust\"><code></code></pre><p>This sets the text color to light gray, providing good contrast against our dark background.</p><pre tabindex=\"0\" data-language=\"rust\"><code></code></pre><p>This adds our text content as a child element. We use  to create a dynamic string that includes our view‚Äôs  field. The  accesses the SharedString from our view‚Äôs state.</p><h2>Application Startup and Configuration</h2><pre tabindex=\"0\" data-language=\"rust\"><code></code></pre><ul><li> - Creates and initializes a new GPUI application, setting up the rendering engine, event system, and platform integration.</li><li><strong><code>.run(|cx: &amp;mut App| { ... })</code></strong> - Starts the application main loop and executes our setup closure. The  parameter gives us an  context for configuring our application‚Äôs initial state.</li></ul><h3>Understanding Closures in Rust</h3><p>The  syntax is a  in Rust, which is similar to anonymous functions or lambda functions in other languages. Let‚Äôs break this down:</p><p>The  symbols define a closure. Think of closures as functions that we define inline without giving them a name.</p><pre tabindex=\"0\" data-language=\"rust\"><code></code></pre><pre tabindex=\"0\" data-language=\"rust\"><code></code></pre><p>The closure is like defining and using the function all in one place.\n</p><p>GPUI‚Äôs  method needs to:</p><ol><li>Initialize all the graphics systems</li><li>Set up the main application loop</li><li>Let us configure our initial windows and views</li><li>Start processing events and rendering\nThe  method says: ‚ÄúI‚Äôll handle all the complex setup, but when I‚Äôm ready, I‚Äôll call your closure so you can tell me what windows and views you want.‚Äù</li></ol><ul><li> is just a variable name (short for ‚Äúcontext‚Äù)</li><li> means ‚Äúa mutable reference to an App object‚Äù</li><li>The  object gives us access to GPUI‚Äôs application-level features like creating windows</li></ul><p>Think of  as a control panel that GPUI hands us, saying ‚Äúhere, use this to set up your application.‚Äù</p><h2>Window Creation and Positioning</h2><pre tabindex=\"0\" data-language=\"rust\"><code></code></pre><p>This calculates where our window should appear:</p><ul><li> creates window bounds that center the window on screen</li><li> means use the primary monitor (we could specify a particular monitor)</li><li> creates a 500x500 pixel size specification</li><li> provides information about the current screen configuration</li></ul><pre tabindex=\"0\" data-language=\"rust\"><code></code></pre><p>Creates a window with specific options:</p><ul><li> configures window properties</li><li><code>window_bounds: Some(WindowBounds::Windowed(bounds))</code> sets the window to normal windowed mode with our calculated position and size</li><li> uses default values for other options like window title, decorations, etc.</li></ul><h2>View Creation and Initialization</h2><pre tabindex=\"0\" data-language=\"rust\"><code></code></pre><p>We actually have  nested in our code:</p><ol><li> - Sets up our application</li><li> - Defines what goes in the window</li><li> - Creates our view instance</li></ol><p>Each closure handles a different level of setup:</p><ol><li> - ‚ÄúWhat windows should exist?‚Äù</li><li> - ‚ÄúWhat should go in this specific window?‚Äù</li><li> - ‚ÄúHow should this view be initialized?‚Äù</li></ol><p>The window creation closure does two things:</p><ul><li>Takes a window handle (ignored with ) and a window-specific context</li><li>Uses  to create and register our view with GPUI</li><li>The inner closure creates our initial  instance with ‚ÄúGPUI World‚Äù as the text</li><li> converts the string literal into a </li></ul><p>You‚Äôll notice some closures use  as a parameter name:</p><pre tabindex=\"0\" data-language=\"rust\"><code></code></pre><p>The  means ‚ÄúI receive a parameter here, but I don‚Äôt need to use it.‚Äù It‚Äôs Rust‚Äôs way of saying ‚Äúignore this parameter‚Äù without getting compiler warnings.</p><p>When we run this application:</p><ol><li> initializes all GPUI systems</li><li> starts the main application loop and calls our setup closure</li><li>We calculate window bounds for a centered 500x500 window</li><li>We create a window with those specifications</li><li>We create a  view instance with initial text</li><li>GPUI calls our view‚Äôs  method to get the element description</li><li>Our  method returns a 500x500 div with centered text</li><li>GPUI renders this using the GPU and displays our window</li><li>The application loop continues, ready for user interaction or updates</li></ol><h2>Building and Running Our Application</h2><p>Now let‚Äôs see our hello world app in action. In your terminal, make sure you‚Äôre in the project directory and run:</p><p>The first time you run this command, it will take several minutes to complete. Cargo needs to download the Zed repository, compile GPUI and all its dependencies, and then compile our application. We‚Äôll see a lot of output as Cargo builds everything.</p><p>Don‚Äôt worry if this seems slow - this lengthy compilation only happens the first time. Subsequent runs will be much faster because Cargo caches the compiled dependencies.</p><p>When the compilation finishes and our application starts, we should see a 500x500 pixel window appear with our ‚ÄúHello, GPUI World!‚Äù message centered on a dark background. The text should be large and clearly visible in light gray against the dark blue-gray background. Something like this:</p><p><img alt=\"gpui-hello-world-output.png\" loading=\"lazy\" decoding=\"async\" fetchpriority=\"auto\" sizes=\"(min-width: 1136px) 1136px, 100vw\" data-astro-image=\"constrained\" width=\"1136\" height=\"1192\" src=\"https://blog.0xshadow.dev/_astro/gpui-hello-world-output.DDY6YTk-_Z1rCgEn.webp\" srcset=\"/_astro/gpui-hello-world-output.DDY6YTk-_Z2px3fw.webp 640w, /_astro/gpui-hello-world-output.DDY6YTk-_Z1zDmCA.webp 750w, /_astro/gpui-hello-world-output.DDY6YTk-_Z2gO83h.webp 828w, /_astro/gpui-hello-world-output.DDY6YTk-_Z2a6JUr.webp 1080w, /_astro/gpui-hello-world-output.DDY6YTk-_Z1rCgEn.webp 1136w\">\nTry interacting with the window - we can move it around, resize it, minimize it, and close it. Even though we haven‚Äôt written any code to handle these interactions, GPUI provides them automatically because they‚Äôre standard window operations.</p><p>This concludes learning the basics of GPUI and displaying hello world in the screen. I hope you‚Äôve learned something from this post and in the next post we are going to learn about handling user inputs, managing state changes, making our app respond to user actions and understanding event handling in GPUI. Learning these things before implementing the todo app would help us cover a lot of concepts in an isolated way making them simpler to understand. See you soon.</p>","contentLength":16104,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/rust/comments/1mxro1j/gpui_hello_world_tutorial_from_core_concepts_to/"},{"title":"K3S with iSCSI storage (Compellent/Starwind VSAN)","url":"https://www.reddit.com/r/kubernetes/comments/1mxr3z0/k3s_with_iscsi_storage_compellentstarwind_vsan/","date":1755920539,"author":"/u/Norava","guid":567,"unread":true,"content":"<p>Hey all! I have a 3 master 4 node K3S cluster installed on top of my Hyper-V S2D cluster in my lab and currently I'm just using Longhorn + each node having a 500gb vhd attached to serve as storage but as I'm using this to learn kube I wanted to try to work on building more scalable storage. </p><p>To that end I'm trying to figure out how to get any form of basic networked storage for my K3S cluster. In doing research I'm finding NFS is much to slow to use in prod so I'm trying to see if there's a way to set up ISCSI LUNs attached to the cluster / workers but I'm not seeing a clear path to even get started</p><p>I initially pulled out an old Dell SAN (A Compellent Scv2020) that I'm trying to get running but that right now is out of band due to it missing it's SCOS but I do know if the person who I found has an iso for SCOS I could get this running as ISCSI storage so I took 2 R610s I had laying around and made a basic Starwind vSAN but I cannot for the life of me figure out HOW to expose ANY LUNs to the k3s cluster. </p><p>My end goal is to have something to host storage that's both more scalable than longhorn and vhds that also can be backed up by Veeam Kasten ideally as I'm in big part also trying to get dr testing with Kasten done as part of this config as I determine how to properly handle backups for some on prem kube clusters I'm responsible for in my new roles that we by compliance couldn't use cloud storage for</p><p>I see democratic-csi mentioned a lot but that appears to be orchestration of LUNs or something through your vendors interface that I cannot find on Starwind and that I don't SEE an EOL SAN like the scv2020 having in any of my searches. I see I see CEPH mentioned but that looks like it's going to similarly operate with local storage like longhorn or requires 3 nodes to get started and the hosts I have to even perform that drastically lack the bay space a full SAN does (Let alone electrical issues I'm starting to run into with my lab but thats beyong this LOL) Likewise I see democratic could work with TrueNAS scale but that also requires 3 nodes and again will have less overall storage. I was debating spinning a Garage node for this and running s3 locally but I'm reading if I want to do ANYTHING with database or heavy write operations is doomed with this method and nfs storage similarly have such issues (Supposedly) Finally I've been through a LITANY of various csi github pages but nearly all of them seem either dead or lacking documentation on how they work</p><p>My ideal would just be connecting a LUN into the cluster in a way I can provision to it directly so I can use the SAN but my understanding is I can't exactly like, create a shared VHDX in Hyper-v and add that to local storage or longhorn or something without basically making the whole cluster either extremely manual or extremely unstable correct?</p>","contentLength":2840,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Measuring the environmental impact of AI inference","url":"https://arstechnica.com/ai/2025/08/google-says-it-dropped-the-energy-cost-of-ai-queries-by-33x-in-one-year/","date":1755919353,"author":"ksec","guid":218,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44992832"},{"title":"This month in Servo: new image formats, canvas backends, automation, and more!","url":"https://servo.org/blog/2025/08/22/this-month-in-servo/","date":1755914332,"author":"/u/KlasySkvirel","guid":574,"unread":true,"content":"<p>Servo has smashed its record again in July, with  landing in our nightly builds!\nThis includes several new web platform features:</p><p>Notable changes for Servo library consumers:</p><p>Like many browsers, Servo has two kinds of zoom:  affects the size of the viewport, while  does not (<a href=\"https://github.com/shubhamg13\">@shubhamg13</a>, <a href=\"https://github.com/servo/servo/pull/38194\">#38194</a>).\n now correctly triggers reflow (<a href=\"https://github.com/mrobinson\">@mrobinson</a>, <a href=\"https://github.com/servo/servo/pull/38166\">#38166</a>), and  is now reset to the viewport meta config when navigating (<a href=\"https://github.com/shubhamg13\">@shubhamg13</a>, <a href=\"https://github.com/servo/servo/pull/37315\">#37315</a>).</p><p> is now isolated between webviews, and copied to new webviews with the same  (<a href=\"https://github.com/janvarga\">@janvarga</a>, <a href=\"https://github.com/servo/servo/pull/37803\">#37803</a>).</p><p> now has a  and , so you can now  on Linux (<a href=\"https://github.com/MichaelMcDonnell\">@MichaelMcDonnell</a>, <a href=\"https://github.com/servo/servo/pull/38038\">#38038</a>).\nWe‚Äôve made it more ergonomic too, fixing both the sluggish  and <strong>pixel-perfect trackpad scrolling</strong> and the too fast  (<a href=\"https://github.com/yezhizhen\">@yezhizhen</a>, <a href=\"https://github.com/servo/servo/pull/37982\">#37982</a>).</p><p> is key to programmable graphics on the web, with Servo supporting WebGPU, WebGL, and 2D canvas contexts.\nBut the <strong>general-purpose 2D graphics</strong> routines that power Servo‚Äôs 2D canvases are potentially useful for a lot more than &lt;canvas&gt;:  is bread and butter for Servo, but  is only minimally supported right now, and  is not yet implemented at all.</p><p>Those features have one thing in common: they require things that WebRender can‚Äôt yet do.\n does one thing and does it well: rasterise the layouts of the web, really fast, by <a href=\"https://hacks.mozilla.org/2017/10/the-whole-web-at-maximum-fps-how-webrender-gets-rid-of-jank/\">using the GPU as much as possible</a>.\nFont rendering and SVG rendering both involve rasterising arbitrary paths, which currently has to be done outside WebRender, and PDF output is out of scope entirely.</p><p>The more code we can share between these tasks, the better we can make that code, and the smaller we can make Servo‚Äôs binary sizes (<a href=\"https://github.com/servo/servo/issues/38022\">#38022</a>).\nWe‚Äôve started by moving 2D-&lt;canvas&gt;-specific state out of the  crate (<a href=\"https://github.com/sagudev\">@sagudev</a>, <a href=\"https://github.com/servo/servo/pull/38098\">#38098</a>, <a href=\"https://github.com/servo/servo/pull/38114\">#38114</a>, <a href=\"https://github.com/servo/servo/pull/38164\">#38164</a>, <a href=\"https://github.com/servo/servo/pull/38214\">#38214</a>), which has in turn allowed us to modernise it with <strong>new backends based on <a href=\"https://github.com/linebender/vello\">Vello</a></strong> (<a href=\"https://github.com/EnnuiL\">@EnnuiL</a>, <a href=\"https://github.com/sagudev\">@sagudev</a>, <a href=\"https://github.com/servo/servo/issues/30636\">#30636</a>, <a href=\"https://github.com/servo/servo/issues/38345\">#38345</a>):</p><ul><li><p>a Vello GPU-based backend (<a href=\"https://github.com/sagudev\">@sagudev</a>, <a href=\"https://github.com/servo/servo/pull/36821\">#36821</a>), currently slower than the default backend; to use it, build Servo with  and enable it with <code>--pref dom_canvas_vello_enabled</code></p></li><li><p>a Vello CPU-based backend (<a href=\"https://github.com/sagudev\">@sagudev</a>, <a href=\"https://github.com/servo/servo/pull/38282\">#38282</a>), <strong>already faster than the default backend</strong>; to use it, build Servo with  and enable it with <code>--pref dom_canvas_vello_cpu_enabled</code></p></li></ul><p>Many recent Servo bugs have been related to our handling of , , and  (<a href=\"https://github.com/servo/servo/issues/36817\">#36817</a>, <a href=\"https://github.com/servo/servo/issues/37804\">#37804</a>, <a href=\"https://github.com/servo/servo/issues/37824\">#37824</a>, <a href=\"https://github.com/servo/servo/issues/37878\">#37878</a>, <a href=\"https://github.com/servo/servo/issues/37978\">#37978</a>, <a href=\"https://github.com/servo/servo/issues/38089\">#38089</a>, <a href=\"https://github.com/servo/servo/issues/38090\">#38090</a>, <a href=\"https://github.com/servo/servo/issues/38093\">#38093</a>, <a href=\"https://github.com/servo/servo/issues/38255\">#38255</a>).\nSymptoms of these bugs include  (e.g. links that can‚Äôt be clicked),  to the end of the page, or  like disappearing browser UI or black bars.</p><p>Windows rarely take up the whole screen, viewports rarely take up the whole window due to window decorations, and when different units come into play, like CSS  vs device pixels, a more systematic approach is needed.\nWe built <a href=\"https://docs.rs/euclid/0.22.11/euclid/\"></a> to solve these problems in a strongly typed way within Servo, but beyond the viewport, we need to convert between euclid types and the geometry types provided by the embedder, the toolkit, the platform, or WebDriver, which creates opportunities for errors.</p><p>Servo is also on <a href=\"https://thanks.dev\">thanks.dev</a>, and already  (‚àí3 from June) that depend on Servo are sponsoring us there.\nIf you use Servo libraries like <a href=\"https://crates.io/crates/url/reverse_dependencies\">url</a>, <a href=\"https://crates.io/crates/html5ever/reverse_dependencies\">html5ever</a>, <a href=\"https://crates.io/crates/selectors/reverse_dependencies\">selectors</a>, or <a href=\"https://crates.io/crates/cssparser/reverse_dependencies\">cssparser</a>, signing up for <a href=\"https://thanks.dev\">thanks.dev</a> could be a good way for you (or your employer) to give back to the community.</p><p>As always, use of these funds will be decided transparently in the Technical Steering Committee.\nFor more details, head to our <a href=\"https://servo.org/sponsorship/\">Sponsorship page</a>.</p>","contentLength":3367,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/linux/comments/1mxp3nt/this_month_in_servo_new_image_formats_canvas/"},{"title":"Codanna now supports Go! Instant call graphs, code-aware lookup, zero servers","url":"https://www.reddit.com/r/golang/comments/1mxnw4v/codanna_now_supports_go_instant_call_graphs/","date":1755910799,"author":"/u/Plenty_Seesaw8878","guid":551,"unread":true,"content":"<p>Your coding assistants can now index and navigate Go, Python, Typescript or Rust projects with precise context in . Runs fully local, integrates anywhere‚Äîfrom vibe coding with agents to plain Unix piping. It get's line numbers, extracts method signatures and logical flows in . Bonus: two Claude slash commands for everyday workflows ‚Äî  for natural-language lookup and  for dependency analysis</p><p>Codanna is the Unix tool that builds a live atlas of your code. Alone, it answers queries in under 300 ms. With agents or pipes, it drives context-aware coding with <strong>speed, privacy, and no guesswork</strong>.</p>","contentLength":595,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"My tips for using LLM agents to create software","url":"https://efitz-thoughts.blogspot.com/2025/08/my-experience-creating-software-with_22.html","date":1755910742,"author":"efitz","guid":217,"unread":true,"content":"<ul></ul><h2 dir=\"ltr\"></h2><h2 dir=\"ltr\"></h2><h2 dir=\"ltr\"></h2><h2 dir=\"ltr\"></h2><h2 dir=\"ltr\"></h2><ol></ol><h2 dir=\"ltr\"></h2><ol></ol><h2 dir=\"ltr\"></h2><ul></ul><h2 dir=\"ltr\"></h2><h2 dir=\"ltr\"></h2>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44991884"},{"title":"Netbeans 27 Released","url":"https://lists.apache.org/thread/py28oztx51vhk4f1js3q54vpx8pwzbb3","date":1755908352,"author":"/u/BlueGoliath","guid":604,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1mxn10t/netbeans_27_released/"},{"title":"Computer fraud laws used to prosecute leaking air crash footage to CNN","url":"https://www.techdirt.com/2025/08/22/investigators-used-terrible-computer-fraud-laws-to-ensure-people-were-punished-for-leaking-air-crash-footage-to-cnn/","date":1755907496,"author":"BallsInIt","guid":216,"unread":true,"content":"<h3>from the <i>if-it-can-be-abused,-it-WILL-be-abused</i> dept</h3><p>Earlier this year, an Army helicopter <a href=\"https://en.wikipedia.org/wiki/2025_Potomac_River_mid-air_collision\" data-type=\"link\" data-id=\"https://en.wikipedia.org/wiki/2025_Potomac_River_mid-air_collision\">collided with a passenger plane</a> over the Potomac River in Washington, DC. All sixty-seven people aboard both vehicles were killed. While the FAA focused its investigation on the failures that led to this mid-air collision, local investigators in Virginia were somehow far more concerned about identifying who had <a href=\"https://www.youtube.com/watch?v=JTgUrfQsOnA\" data-type=\"link\" data-id=\"https://www.youtube.com/watch?v=JTgUrfQsOnA\">leaked footage of the collision to CNN</a>. </p><p>The subject matter of the leaked recordings was obviously of public interest. And while the government may have its own interest in controlling dissemination of recording of incidents that involve federal agencies and their oversight, it‚Äôs not the sort of government interest most courts consider to be worthy of violating the First Amendment.</p><p>Fortunately, the government has options. For a very long time, the option federal law enforcement deployed most frequently in cases involving pretty much any sort of technology was the <a href=\"https://www.techdirt.com/tag/cfaa/\" data-type=\"link\" data-id=\"https://www.techdirt.com/tag/cfaa/\">Computer Fraud and Abuse Act</a> (CFAA). This <a href=\"https://www.techdirt.com/tag/shoot-the-messenger/\" data-type=\"link\" data-id=\"https://www.techdirt.com/tag/shoot-the-messenger/\">broadly written law</a> not only allowed prosecutors to charge people with federal crimes for doing nothing more than interacting with services/servers/etc. in unexpected ways, but allowed companies to, essentially, shoot the messengers for reporting data breaches, unsecured servers, or sloppy user interfaces that could be exploited to display far more information than those running them intended.</p><p>Here‚Äôs what Metropolitan Washington Airports Authority investigator Patrick Silsbee wrote in his report:</p><blockquote><p><em>‚ÄúThe video shows camera angles and views that can only be found on the Metropolitan Washington Airport‚Äôs Authority CCTV video,‚Äù Silsbee wrote in a January 31 report, noting the location of landmarks in the videos, including a boathouse near the airfield.</em></p><p><em>The locations of the MWAA security cameras are redacted in the reports provided to The Intercept, ostensibly ‚Äúto prevent the disclosure of law enforcement and security techniques and procedures not generally known outside the law enforcement community,‚Äù according to an accompanying letter from MWAA.</em></p></blockquote><p>That doesn‚Äôt mean much by itself, but Silsbee apparently figured out (thanks in part to CNN‚Äôs initial failure to redact some CCTV text that described the location of the camera) this footage must have been obtained by an MWAA employee working at the police dispatch center. </p><p>CCTV footage from  the dispatch center was obtained, which allegedly showed these actions being taken by the suspected leaker:</p><blockquote><p><em>‚ÄúBetween the hours of 2256 and 0545, Mr. Mbengue can be seen on multiple occasions utilize [sic] his personal cell phone to record video and photograph these critical scenes,‚Äù Silsbee wrote.</em></p></blockquote><p>That would be MWAA dispatch employee Mohamed Mbengue, who has since pleaded ‚Äúno contest‚Äù to charges stemming from Virginia‚Äôs ultra-vague <a href=\"https://law.lis.virginia.gov/vacode/18.2-152.4/\" data-type=\"link\" data-id=\"https://law.lis.virginia.gov/vacode/18.2-152.4/\">‚Äúcomputer trespass‚Äù law</a>. But it really takes a person with an overriding desire to shoot messengers to call cell phone recordings of screen images a ‚Äútrespass.‚Äù </p><p>The word is generally understood to describe unauthorized access to an area a person is not allowed to be in. Mbengue was at work and had full access to these recordings as a part of his job. That he recorded them and sent them to CNN doesn‚Äôt align with any rational definition of the word ‚Äútrespass.‚Äù The dissemination of footage may be a violation of policy, but policy violations aren‚Äôt criminal charges ‚Äî the sort of thing that can do permanent damage to a person‚Äôs life in ways that write-ups and even justified terminations simply can‚Äôt.</p><p>That‚Äôs why discretion is key. But when discretion matters most, law enforcement tends to deliberately ‚Äúerr‚Äù on the side of whatever does the most damage to anyone it happens to be investigating. And it appears MWAA investigators are more than happy to throw criminal charges at people for, at most, violating agency policies. A second dispatcher (Jonathan Savoy) was caught doing the same thing (albeit without sharing the recordings with CNN) and faced similar charges until someone actually exercised a bit of discretion and declined to move forward with the case.</p><blockquote><p><em>On February 3, the MWAA&nbsp;<a href=\"https://x.com/allisonpapson/status/1886553371257266540?s=46&amp;t=p5q6YKIPojSzB8gCMgZMiA\" target=\"_blank\" rel=\"noreferrer noopener\">announced</a>&nbsp;both men‚Äôs arrests, writing in a press statement that Savoy had been arrested ‚Äúfollowing further police investigation.‚Äù</em></p><p><em>In May, however, local prosecutors&nbsp;<a href=\"https://theintercept.com/2025/05/29/charges-dropped-leaked-dc-plane-crash-video/\">quietly dropped</a>&nbsp;the charges against Savoy, through a filing called a ‚Äúnolle prosequi,‚Äù according to the court docket.</em></p></blockquote><p>There‚Äôs absolutely nothing in the statute that actually covers the actions described here, which formed the basis for the bullshit criminal charges. It takes a ton of punitive imagination to turn ‚Äúrecording a CCTV monitor with a phone‚Äù into a criminal act. The only clause that could be even possibly be considered applicable requires investigators and prosecutors to engage in lot of extremely creative re-interpretations of <a href=\"https://law.lis.virginia.gov/vacode/18.2-152.4/\" data-type=\"link\" data-id=\"https://law.lis.virginia.gov/vacode/18.2-152.4/\">the plain text of the law</a>: </p><blockquote><p><em>Use a computer or computer network to make or cause to be made an unauthorized copy, in any form, including, but not limited to, any printed or electronic form of computer data, computer programs or computer software residing in, communicated by, or produced by a computer or computer network</em></p></blockquote><p>A smartphone is a computer. A recording could be considered an ‚Äúunauthorized copy.‚Äù To call the CCTV cameras and screens ‚Äúcomputers/computer network‚Äù means ignoring the generally understood utility of this tech. Even if a network connects the cameras and a computer provides access to recordings, recording playback via phone while accessing footage the suspects <em>had every right to access</em>, calling this a violation of the law demonstrates investigators were out for revenge, rather than serving the commonly understood definition of the word ‚Äújustice.‚Äù</p>","contentLength":5754,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44991542"},{"title":"Bluesky Goes Dark in Mississippi over Age Verification Law","url":"https://www.wired.com/story/bluesky-goes-dark-in-mississippi-age-verification/","date":1755903087,"author":"BallsInIt","guid":215,"unread":true,"content":"<p> can no longer use the social media platform <a href=\"https://www.wired.com/tag/bluesky/\">Bluesky</a>. The company announced Friday that it will be blocking all IP addresses within Mississippi for the foreseeable future in response to a recent <a href=\"https://www.wired.com/tag/us-supreme-court/\">US Supreme Court</a> decision that allows the state to enforce strict age verification for social media platforms.</p><p>According to Bluesky, Mississippi‚Äôs approach to verification ‚Äúwould fundamentally change‚Äù how users access the site. ‚ÄúWe think this law creates challenges that go beyond its child safety goals, and creates significant barriers that limit free speech and disproportionately harm smaller platforms and emerging technologies,‚Äù the Bluesky team said in <a data-offer-url=\"https://bsky.social/about/blog/08-22-2025-mississippi-hb1126\" data-event-click=\"{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://bsky.social/about/blog/08-22-2025-mississippi-hb1126&quot;}\" href=\"https://bsky.social/about/blog/08-22-2025-mississippi-hb1126\" rel=\"nofollow noopener\" target=\"_blank\">its statement</a>.</p><p>Bluesky did not respond to a request for comment.</p><p>The company says that compliance with Mississippi‚Äôs law‚Äîwhich would require identifying and tracking all users under 18, in addition to asking every user for sensitive personal information to verify their age‚Äîis not possible with the team‚Äôs current resources and infrastructure. By not complying with the law, Bluesky could face fines of up to $10,000 per violation. It is the first major social media platform to take such drastic steps in response to the law.</p><p>Age verification laws, which on the surface are intended to protect children from harmful content online, have already begun to broadly impact internet use in places around the world where they've been enacted. <a href=\"https://www.wired.com/story/the-age-checked-internet-has-arrived/\">In the UK</a>, users trying to access everything from pornography to social platforms must now submit to ID scans, credit card checks, age-estimation scans, and more to verify they‚Äôre over the age of 18. The state of Texas has a <a href=\"https://www.wired.com/story/us-supreme-court-porn-age-verification-decision-2025/\">similar law</a> the US Supreme Court upheld in June, despite concerns from critics over the erosion of free speech and access to information on the open internet.</p><p>Whether these laws are effective at protecting children is unclear; the use of virtual private networks (VPNs) in the UK <a href=\"https://www.wired.com/story/vpn-use-spike-age-verification-laws-uk/\">spiked</a> just after its age verification law went into effect as users deployed the tech to spoof their location. On platforms like Discord, people discovered they could use <a href=\"https://www.wired.com/story/age-verification-is-sweeping-gaming-is-it-ready-for-the-age-of-ai-fakes/\">video game characters</a> to trick face scans. Furthermore, <a href=\"https://www.wired.com/story/the-age-checked-internet-has-arrived/\">critics say</a> that age verification laws intended to reduce harm to children can sometimes have the opposite effect by putting kids in greater danger of identity theft and privacy violations.</p><p>WIRED has reached out to the sponsors of the original bill, Mississippi state representatives Jill Ford, Fabian Nelson, and Larry Byrd, and will update this story if they comment.</p><p>‚ÄúWe believe effective child safety policies should be carefully tailored to address real harms, without creating huge obstacles for smaller providers and resulting in negative consequences for free expression,‚Äù Bluesky wrote.</p>","contentLength":2738,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44990886"},{"title":"ChatLoopBackOff: Episode 68 (KANISTER)","url":"https://www.youtube.com/watch?v=-dy_J3VmmOg","date":1755903066,"author":"CNCF [Cloud Native Computing Foundation]","guid":386,"unread":true,"content":"<article>Join us LIVE as CNCF Ambassador Carlos Santana dives into Kanister, the open source framework for application-level data management on Kubernetes.\n\nCarlos will be exploring the project for the very first time, right alongside you. Expect a hands-on walkthrough of the docs, community resources, and real-world use cases that highlight how Kanister helps extend Kubernetes for backup, recovery, and data operations.\n\nIf you‚Äôre curious about how cloud native projects approach complex data management challenges, or just enjoy watching an experienced open source explorer break down a CNCF project live, this session is for you.\n\nBring your questions, share your experiences, and learn in real time as we explore Kanister together!</article>","contentLength":731,"flags":null,"enclosureUrl":"https://www.youtube.com/v/-dy_J3VmmOg?version=3","enclosureMime":"","commentsUrl":null},{"title":"FTP faster upload","url":"https://www.reddit.com/r/golang/comments/1mxjcfr/ftp_faster_upload/","date":1755898910,"author":"/u/pepiks","guid":552,"unread":true,"content":"<p>Is possible using Go upload files faster than by FTP client? I am looking for speed up uploading gallery images - typical size is around 20-40 MB at maximum, up to 200 resized images, but transfer is very slow and it can take even 15 minutes for this size. I am using FTP for this, not FTPS.</p>","contentLength":291,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Blind & Visually Impaired Initiative (BVI) Meeting - 2025-08-19","url":"https://www.youtube.com/watch?v=bJej44Ug8tU","date":1755893803,"author":"CNCF [Cloud Native Computing Foundation]","guid":385,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io</article>","contentLength":319,"flags":null,"enclosureUrl":"https://www.youtube.com/v/bJej44Ug8tU?version=3","enclosureMime":"","commentsUrl":null},{"title":"I'm making a freeware Linux Learning Game and could use some QA, Criticism, and feedback.","url":"https://www.reddit.com/r/linux/comments/1mxgm8l/im_making_a_freeware_linux_learning_game_and/","date":1755892448,"author":"/u/nconsola","guid":577,"unread":true,"content":"<p>I hope I can post here, I read the rules and I‚Äôm not trying to self-promoter, as I‚Äôm going to release this Linux learning game for free and make it open source when complete.</p><p>I am making a simple text-based game that is 100% focused on learning Linux command line, this game is not focused on specific distros of Linux like Ubuntu or Debian, it is Basic Standard Linux. If people like the game I will make others that are continuations off of this, that are specific to distros but for now its base Linux.</p><p>Quick background, I DO NOT KNOW LINUX, but we use it at work (Debian) and I need to learn it. This is why I made this game, every time I try to learn the commands ill forget them or say screw it, I will use the GUI. So, I thought if I had a game that focused on teaching me Linux, I could do it.... yeah, I know probably not going to happen, but still I set off to make it, and with the help of Google Gemini I have a solid Beta of the game, maybe Alpha/Beta, maybe Alpha. There is a lot I want to add after the instruction part of the game which is all I have now, so it is not complete just the 3 chapters that are below.</p><p>Through QA'ing the game myself I have learned a ton about command line. But as anyone who has QA a game before, you eventually know what to put in to get to the next part, and this doesn‚Äôt give a good representation of whether or not the game is teaching well for people who just pick it up. So, I‚Äôm looking for any testers who know Linux, and anyone who doesn‚Äôt.</p><p>I want people who know Linux, this way I can make sure all the commands work as they should, basically \"look\" the way they should in the simulated terminal, and to make sure I have all the commands that are available for basic Linux, and provide feedback where needed.</p><p>I want people who don‚Äôt know Linux, this way I can get feedback on the way the game progresses, does it make sense, do you actually feel like you‚Äôre learning Linux while playing, is it confusing, what do you not like, etc.</p><p>A little bit on what I have implemented so far,</p><p>some simple non game elements are,</p><ol><li><p>Terminal themes, so I have Default theme (supposed to simulate the terminal from the movie Alien, its close but not 100%), Commodore 64, Dos, Linux, and Apple II+ (which was my first computer)</p></li><li><p>A voice over on/off switch for the simulated AI, Aurora, it‚Äôs not a real AI or even a LLM it‚Äôs just simulated, all the commands and responses I have put in, and it is basic right now. But as the user you are being helped by a ship AI which is basically teaching you the Linux commands. And yeah, it was the closest voice I could get to simulate Mother in the movie Alien, and it sounds nothing like Mother.</p></li></ol><p>There is a beginner, intermediate, and advanced sections of the game, that teach you the following commands. Someone who knows Linux really good please let me know if you think anything is missing, but remember this is basic Linux so there is no apt-get etc. like in Debian, at least as far as I know.</p><p>* `help` - Shows available commands.</p><p>* `pwd` - Prints the current working directory.</p><p>* `ls` - Lists files and directories.</p><p>* `~` - A shortcut for the user's home directory.</p><p>* `clear` - Clears the terminal screen.</p><p>* `cat` - Displays the contents of a file.</p><p>* `hint` - Provides a hint for the current objective.</p><p>* `man` - Shows the manual page for a command.</p><p>* `cd` - Changes the current directory.</p><p>* `uptime` - Shows how long the system has been running.</p><p>* `echo` - Displays text or writes it to a file.</p><p>* `mkdir` - Creates a new directory.</p><p>* `touch` - Creates a new, empty file.</p><p>* `&gt;` - A redirection operator to write output to a file.</p><p>* `rm` - Removes (deletes) files.</p><p>* `rmdir` - Removes (deletes) empty directories.</p><p>* `mv` - Moves or renames files and directories.</p><p>* `less` - Views the content of a file page by page.</p><p>* `grep` - Searches for patterns within files.</p><p>* `find` - Searches for files and directories.</p><p>* `head` - Displays the beginning of a file.</p><p>* `tail` - Displays the end of a file.</p><p>* `wc` - Counts lines, words, and characters in a file.</p><p>* `sort` - Sorts the lines of a file.</p><p>* `|` - The \"pipe\" operator, used to send the output of one command to another.</p><p>* `uniq` - Removes duplicate adjacent lines from a file.</p><p>* `diff` - Compares two files and shows their differences.</p><p>* `ln` - Creates links between files.</p><p>* `uname` - Shows system information.</p><p>* `whoami` - Shows the current user's username.</p><p>* `groups` - Shows the groups a user belongs to.</p><p>* `dmesg` - Shows kernel and driver messages.</p><p>* `free` - Displays memory usage.</p><p>* `df` - Displays disk space usage.</p><p>* `du` - Shows the disk usage of files and directories.</p><p>* `tree` - Displays a directory's contents in a tree-like format.</p><p>* `file` - Determines a file's type.</p><p>* `cmp` - Compares two files byte by byte.</p><p>* `cut` - Extracts sections from lines of a file.</p><p>* `tr` - Translates or deletes characters.</p><p>* `&lt;` - A redirection operator to use a file's content as input.</p><p>* `tee` - Reads from standard input and writes to both standard output and files.</p><p>* `locate` - Finds files by name quickly.</p><p>* `chmod` - Changes the permissions of a file or directory.</p><p>* `sudo` - Executes a command as the superuser (root).</p><p>* `chown` - Changes the owner of a file or directory.</p><p>* `umask` - Sets the default permissions for new files.</p><p>* `split` - Splits a file into smaller pieces.</p><p>* `paste` - Merges the lines of files.</p><p>* `join` - Joins the lines of two files on a common field.</p><p>* `tar` - Creates and extracts archive files.</p><p>* `gzip` - Compresses or decompresses files.</p><p>* `gunzip` - Decompresses `.gz` files.</p><p>* `zip` - Creates a `.zip` archive.</p><p>* `unzip` - Extracts files from a `.zip` archive.</p><p>* `sed` - A stream editor for filtering and transforming text.</p><p>* `awk` - A powerful pattern scanning and processing language.</p><p>* `ping` - Tests network connectivity to a host.</p><p>* `traceroute` - Traces the network path to a host.</p><p>* `curl` - Transfers data from or to a server.</p><p>* `ps` - Shows currently running processes.</p><p>* `top` - Displays a dynamic, real-time view of processes.</p><p>* `htop` - An interactive process viewer.</p><p>* `netstat` - Shows network connections and statistics.</p><p>* `kill` - Sends a signal to a process (e.g., to terminate it) by its ID.</p><p>* `pkill` - Sends a signal to a process by its name.</p><p>* `iostat` - Reports CPU and I/O statistics.</p><p>* `vmstat` - Reports virtual memory statistics.</p><p>* `sar` - Collects and reports system activity information.</p><p>* `passwd` - Changes a user's password.</p><p>* `groupadd` - Creates a new user group.</p><p>* `useradd` - Creates a new user account.</p><p>* `usermod` - Modifies an existing user account.</p><p>* `userdel` - Deletes a user account.</p><p>* `groupdel` - Deletes a user group.</p><p>* `systemctl` - Manages system services.</p><p>* `bg` - Sends a job to the background.</p><p>* `fg` - Brings a job to the foreground.</p><p>* `jobs` - Lists active jobs.</p><p>* `mount` - Mounts a filesystem.</p><p>* `umount` - Unmounts a filesystem.</p><p>* `rsync` - Synchronizes files and directories between locations.</p><p>* `dd` - Copies and converts files at a low level.</p><p>* `lsof` - Lists open files.</p><p>* `crontab` - Manages scheduled tasks (cron jobs).</p><p>I‚Äôve been working on the game for almost 4 months, and rewritten this game from scratch 3 times now, which sucks, but when I seem to make major changes I break things, and as I‚Äôm not a good programmer, I rely on AI (Google Gemini), and as anyone who has used any AI programmer you know sometimes it decides to just DESTROY EVERYTHING YOU HAVE CREATED BEYOND REPAIR! So, when you go through the Beginner section you will notice that all the commands you need to run are explained by the ship AI and it is 99% complete as far as I can tell. The intermediate and advanced sections so far have everything working, as in the commands to move on to the next section, but you need to talk to the ship AI for every new command you need to enter to complete the task. So, it works functionally as far as I last tested, but you need to ask Aurora what to do next all the time, which is a pain in the ass. But That will be fixed as soon as I know everything else in the Beginner section is working, as I don‚Äôt want to update everything to just have to redo it if I messed something up in the beginner part.</p><p>Once the 3 parts are complete, I can then work on the, story part, which as of my planning will have 3 endings depending on how the player uses the Linux commands, and what they do in the game. The story part will be used as repetition on the commands from the previous 3 parts, this way it will hopefully burn the Linux commands into our heads, and we become Linux gods.</p><p>So, what‚Äôs the premise of the game. You are a sole caretaker (except for the ship AI, Aurora) of a spaceship on a deep space mission. Something happened on the ship and the AI sent you to the Engineering Bay and converted all life support to that area before shutting down to conserver power as the power is draining as well. The ship is run on a Linux system, and you need to get it back up and running before the Life support and Power go to 0% and you die. But you don‚Äôt know Linux, so the localized version of the ship AI, Aurora, is there to talk you through how to fix the ship and bring the systems back up using just Linux commands from the one terminal that is working. once you get everything back up and running stably, then you need to go through and see what happened. From this point on is the story part of the game and will involve going into the ships servers to find out what happened and what else needs to be fixed, etc.</p><p>The game is all web browser bases so far, when done I‚Äôll be able to port it to windows, Linux, mobile, at least that is what Google Gemini told me. So, I can put all the files in a Zip, or upload to my google drive, or can I upload here? I don‚Äôt want to upload here yet unless I get permission, as I believe it was one of the rules, unless I read it wrong.</p>","contentLength":9738,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Quick dumb question: Why did google not use Go for the gemini cli?","url":"https://www.reddit.com/r/golang/comments/1mxgdg1/quick_dumb_question_why_did_google_not_use_go_for/","date":1755891882,"author":"/u/0b_1000101","guid":555,"unread":true,"content":"<p>I was just trying the Gemini CLI, and when I checked the repo, I saw it was written in TypeScript. I do have a preference for Go, but I just want an objective reason for choosing TypeScript. I haven't really developed complex CLI tools in Go, just a few basic ones, but I know it is possible to create a good-looking TUI using bubble tea or something else.</p><p>I would like to know what advantages Go provides over other languages in terms of CLI from a user perspective.</p>","contentLength":466,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Kubernetes v1.34 is coming with some interesting security changes ‚Äî what do you think will have the biggest impact?","url":"https://www.armosec.io/blog/kubernetes-1-34-security-enhancements/","date":1755890863,"author":"/u/Swimming_Version_605","guid":571,"unread":true,"content":"<p>Kubernetes v1.34 is coming soon, and it brings a rich batch of security upgrades ‚Äì from alpha features that hint at the future of zero-trust Kubernetes, to mature enhancements making their way into stable releases. Whether you‚Äôre managing a production cluster or exploring new security patterns, this release has something worth your attention.</p><div><div><h2>Kubernetes Security ‚Äì The Ultimate Guide</h2><div><p>Dive deep into the ever evolving landscape of Kubernetes security, explore best practices, and discover potential pitfalls.</p></div><a href=\"https://landing.armosec.io/kubernetes_security_best_practices\">Learn More</a></div></div><h2>üîê What‚Äôs New in Kubernetes 1.34 Security</h2><h3>Built‚Äëin Mutual TLS for Pods (Alpha)&nbsp;</h3><p>Pods can now request short-lived X.509 certificates from the Kubernetes API server and use them to authenticate via mutual TLS. This enables a clean and native approach to in-cluster workload identity without relying on external tools or sidecars.</p><h3>Fine‚ÄëGrained Anonymous API Endpoint Control (Stable)&nbsp;</h3><p>Rather than disabling anonymous access cluster-wide, you can now configure it to apply only to specific safe paths (like /healthz, /livez, and /readyz). This prevents overly permissive anonymous access while preserving functionality for monitoring and load balancers.</p><h3><a href=\"https://www.armosec.io/blog/a-guide-for-using-kubernetes-rbac/\" target=\"_blank\" rel=\"noreferrer noopener\">RBAC</a> with Field &amp; Label Selectors for List/Delete (Stable)&nbsp;</h3><p>You can now restrict access to resources based on selectors in list, watch, and deleteCollection operations. For example, limit a kubelet to view only the pods on its node using spec.nodeName=$NODE.</p><h3>External JWT Signing via KMS or HSM (Beta)&nbsp;</h3><p>ServiceAccount tokens can now be signed using an external KMS or HSM via a new gRPC interface. This improves key security by enabling rotation, offloading signing from the API server, and aligning with compliance needs.</p><h3>Short-Lived Pod-Scoped Tokens for ImagePull (Beta)&nbsp;</h3><p>No more long-lived imagePullSecrets. Kubernetes can now use short-lived, per-pod tokens automatically generated for accessing private registries. These tokens are OIDC-compliant and auto-rotated by the system.</p><h3>CEL-Based In-Process Mutating Admission Policies (Beta)&nbsp;</h3><p>Kubernetes now supports <a href=\"https://www.armosec.io/blog/kubernetes-admission-controller/\" target=\"_blank\" rel=\"noreferrer noopener\">mutating admission policies</a> written using CEL (Common Expression Language) directly in the API server‚Äîno external webhook required. This simplifies setup and improves performance while supporting re-evaluation logic.</p><p>ARMO‚Äôs Kubescape, the CNCF‚Äôs Incubating open-source Kubernetes security platform, will enhance its<a href=\"https://github.com/kubescape/cel-admission-library/\" target=\"_blank\" rel=\"noreferrer noopener nofollow\"> CEL admission control library</a> in the upcoming release to support these new in-process mutating policies. This will allow users to define and enforce mutating admission policies directly within Kubescape, leveraging the same CEL framework as Kubernetes itself.</p><h3>OCI Artifact Volumes (Beta)&nbsp;</h3><p>You can now mount artifacts stored in OCI registries directly into pods as read-only volumes. This is useful for securely distributing config files, binaries, or ML models without baking them into container images.</p><h3>üß† Why These Changes Matter</h3><figure><table><thead><tr></tr></thead><tbody><tr><td>Enables pod-to-API secure identity</td><td>Test alpha feature in dev clusters</td></tr><tr><td>Prevents overexposed unauthenticated access</td></tr><tr><td>Enforces least privilege at node/pod granularity</td><td>Update roles with selectors</td></tr><tr><td>Eliminates local key exposure</td><td>Integrate with existing KMS</td></tr><tr><td>Prevents static secret leakage</td><td>Migrate from imagePullSecrets</td></tr><tr><td>Simplifies secure mutation logic</td><td>Define CEL-based policies</td></tr><tr><td>Secure delivery of external files</td><td>Replace sidecar/manual content injection</td></tr></tbody></table></figure><p>The Kubernetes 1.34 release reflects a growing focus on , , and <strong>native, reliable policy enforcement</strong>. From in-cluster identities to hardened token workflows and registry access, these updates make it easier for platform teams to deliver secure infrastructure ‚Äì without reinventing the wheel.</p><p>Stay secure, stay curious.</p><p>‚Äî <a href=\"https://www.armosec.io\" target=\"_blank\" rel=\"noreferrer noopener\"></a><a href=\"https://github.com/kubescape/kubescape\" target=\"_blank\" rel=\"noreferrer noopener\"></a><em>, the open-source Kubernetes security platform</em> and one of the leading <a href=\"https://www.armosec.io/platform/kubernetes-security-posture-management/\">KSPM</a> solutions. </p><div><div><h2>Quickly ensure your Kubernetes is secured.</h2><div><p>Follow this simple checklist and make sure your Kubernetes security is covered in just a few steps.</p></div><a href=\"https://landing.armosec.io/kubernetes_checklist\">Read Now</a></div></div>","contentLength":3881,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/kubernetes/comments/1mxfxsq/kubernetes_v134_is_coming_with_some_interesting/"},{"title":"Nitro: A tiny but flexible init system and process supervisor","url":"https://git.vuxu.org/nitro/about/","date":1755889589,"author":"todsacerdoti","guid":214,"unread":true,"content":"<p>Nitro is a tiny process supervisor that also can be used as pid 1 on Linux.</p><p>There are four main applications it is designed for:</p><ul><li>As init for a Linux machine for embedded, desktop or server purposes</li><li>As init for a Linux initramfs</li><li>As init for a Linux container (Docker/Podman/LXC/Kubernetes)</li><li>As unprivileged supervision daemon on POSIX systems</li></ul><p>Nitro is configured by a directory of scripts, defaulting to\n (or the first command line argument).</p><ul><li>Kernel support for Unix sockets</li><li> or writable  on another fs</li></ul><h2>Benefits over other systems</h2><ul><li>All state is kept in RAM, works without tricks on read-only root file systems.</li><li>Efficient event-driven, polling free operation.</li><li>Zero memory allocations during runtime.</li><li>No unbounded file descriptor usage during runtime.</li><li>One single self-contained binary, plus one optional binary to\ncontrol the system.</li><li>No configuration compilation steps needed, services are simple\ndirectories containing scripts.</li><li>Supports reliable restarting of services.</li><li>Reliable logging mechanisms per service or as default.</li><li>Support for logging chains spread over several services.</li><li>Works independently of properly set system clock.</li><li>Can be run on FreeBSD from /etc/ttys (sets up file descriptors 0, 1, 2).</li><li>Tiny static binary when using musl libc.</li></ul><p>Every directory inside  (or your custom service directory)\ncan contain several files:</p><ul><li>, an optional executable file that is run before the service starts.\nIt must exit with status 0 to continue.</li><li>, an optional executable file that runs the service;\nit must not exit as long as the service is considered running.\nIf there is no  script, the service is considered a ‚Äúone shot‚Äù,\nand stays ‚Äúup‚Äù until it‚Äôs explicitly taken ‚Äúdown‚Äù.</li><li>, an optional executable file that is run after the \nprocess finished.  It is passed two arguments, the exit status\nof the  process (or -1 if it was killed by a signal)\nand the signal that killed it (or 0, if it exited regularly).</li><li>, a symlink to another service directory.\nThe standard output of  is connected to the standard input of the\nservice under  by a pipe.  You can chain these for reliable and\nsupervised log processing.</li><li>, an optional file that causes nitro to not bring up this\nservice by default.</li><li>Service directories ending with ‚Äò@‚Äô are ignored; they can be used\nfor parameterized services.</li><li>Service names must be shorter than 64 chars, and not contain ,\n or newlines.</li></ul><p>You may find runit‚Äôs  useful when writing  scripts.</p><ul><li>: this service is used as a logging service for all services\nthat don‚Äôt have a  symlink.</li><li>:  is run before other services are brought up.\nYou can already use  in  to bring up services\nin a certain order.\n is run before all remaining services are killed and the\nsystem is brought down.\nAfter all processes are terminated,  is run.\nThe program , if it exists, is run instead of exiting\nwhen an unrecoverable, fatal error happens.\nThe program , if it exists, is executed into\ninstead of a shutdown.  This can be used to implement an initramfs,\nfor example.</li></ul><p>Service directories ending in  are ignored, however you can refer\nto parametrized services by symlinks (either in the service directory\nor as a  symlink), or start them manually using .</p><p>The part after the , the parameter, is passed to the scripts as\nfirst argument.</p><p>For example, given you have a script  and a symlink\n -&gt; , nitro will spawn .  Upon\nrunning , nitro will spawn , even if it does not exist in the service directory.</p><p>The lifecycle of a machine/container/session using nitro consists of\nthree phases.</p><p>First, the system is brought up.  If there is a special service\ng, its  script is run first.  After it finishes, all\nservices not marked  are brought up.</p><p>When a service exits, it‚Äôs being restarted, potentially waiting for\ntwo seconds if the last restart happened too quickly.</p><p>By using  or , the system can be\nbrought down.  If it exists,  will be run.  After this,\nnitro will send a SIGTERM signal to all running services and waits for\nup to 7 seconds for the service to exit.  Otherwise, a SIGKILL is\nsent.  After all processes are terminated,  is run.</p><p>Finally, nitro reboots or shuts down the system; or just exits when it\nwas used as a container init or unprivileged supervisor.  (When a\nreboot was requested, it re-execs itself.  This requires being called\nwith absolute path for the binary and the service directory.)</p><h2>Controlling nitro with nitroctl</h2><p>You can remote control a running nitro instance using the tool\n.</p><p>Usage: <code>nitroctl [COMMAND] [SERVICE]</code></p><ul><li>list: show a list of services and their state, pid, uptime and last\nexit status.</li><li>down: stop SERVICE (sending SIGTERM or the first letter of )</li><li>start: start SERVICE, waiting for success</li><li>restart: restart SERVICE, waiting for success</li><li>stop: stop SERVICE, waiting for success</li><li>p: send signal SIGSTOP to SERVICE</li><li>c: send signal SIGCONT to SERVICE</li><li>h: send signal SIGHUP to SERVICE</li><li>a: send signal SIGALRM to SERVICE</li><li>i: send signal SIGINT to SERVICE</li><li>q: send signal SIGQUIT to SERVICE</li><li>1: send signal SIGUSR1 to SERVICE</li><li>2: send signal SIGUSR2 to SERVICE</li><li>t: send signal SIGTERM to SERVICE</li><li>k: send signal SIGKILL to SERVICE</li><li>pidof: print the PID of the SERVICE, or return 1 if it‚Äôs not up</li><li>rescan: re-read , start added daemons, stop removed daemons</li><li>Shutdown: shutdown (poweroff) the system</li><li>Reboot: reboot the system</li></ul><h2>Controlling nitro by signals</h2><p>rescan can also be triggered by sending  to nitro.</p><p>reboot can also be triggered by sending  to nitro.</p><p>shutdown can also be triggered by sending  to nitro, unless\nnitro is used as Linux pid 1.</p><p>Nitro is self-contained and can be booted directly as pid 1.\nIt will mount  and  when required, everything else\nshould be done with .</p><p>When receiving Ctrl-Alt-Delete, nitro triggers an orderly reboot.</p><h2>Nitro as init for a Docker container</h2><p>Nitro is compiled statically, so you can copy it into your container easily:</p><pre><code>COPY ./nitro /bin/\nCOPY ./nitroctl /bin/\nCMD [\"/bin/nitro\"]\n</code></pre><p>Note that  must exist in the container if you want to use the\ndefault control socket name.</p><p>You can put the control socket onto a bind mount and remote control\n using  from the outside by pointing  to\nthe appropriate target.</p><p>You can add this line to  to run  supervised by\nFreeBSD :</p><pre><code>/etc/nitro \"/usr/local/sbin/nitro\" \"\" on\n</code></pre><p>I‚Äôm standing on the shoulder of giants; this software would not have\nbeen possible without detailed study of prior systems such as\ndaemontools, freedt, runit, perp, and s6.</p><p>nitro is licensed under the 0BSD license, see LICENSE for details.</p>","contentLength":6330,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44988530"},{"title":"Show HN: JavaScript-free (X)HTML Includes","url":"https://github.com/Evidlo/xsl-website","date":1755888450,"author":"Evidlo","guid":184,"unread":true,"content":"<p>I've been working on a little demo for how to avoid copy-pasting header/footer boilerplate on a simple static webpage. My goal is to approximate the experience of Jekyll/Hugo but eliminate the need for a build step before publishing. This demo shows how to get basic templating features with XSL so you could write a blog post which looks like</p><pre><code></code></pre>\nSome properties which set this approach apart from other methods:<pre><code>  - no build step (no need to setup Jekyll on the client or configure Github/Gitlab actions)\n  - works on any webserver (e.g. as opposed to server-side includes, actions)\n  - normal looking URLs (e.g. `example.com/foobar` as opposed to `example.com/#page=foobar`)\n</code></pre>\nThere's been some talk about removing XSLT support from the HTML spec [0], so I figured I would show this proof of concept while it still works.","contentLength":818,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44988271"},{"title":"The first Media over QUIC CDN: Cloudflare","url":"https://moq.dev/blog/first-cdn/","date":1755887056,"author":"kixelated","guid":213,"unread":true,"content":"<p>üö® It‚Äôs finally happening! üö®</p><p>Cloudflare has <a href=\"https://blog.cloudflare.com/moq/\">just announced</a> their Media over QUIC CDN!\nIt‚Äôs an , and you can test MoQ on their , anycast network.\nTry it out, and convince your boss‚Äô boss that the writing is on the wall.</p><p>If you‚Äôve been living under a rock, MoQ is an <a href=\"https://datatracker.ietf.org/group/moq/about/\">up-and-coming standard</a> for live media, aiming to supplant <a href=\"https://moq.dev/blog/replacing-webrtc\">WebRTC</a>, <a href=\"https://moq.dev/blog/replacing-hls-dash\">HLS/DASH</a>, and even  as the one to rule them all.\nAnd now Cloudflare wins the award for the first CDN offering!</p><figure><figcaption>Your prize is a blog post. You‚Äôre welcome mega-corp.</figcaption></figure><p>Also, , some shameless self-promotion: I just soft-launched <a href=\"https://moq.dev/blog/first-app\">hang.live</a>.\nCheck it out if you want to see the  cool stuff you can do with MoQ.</p><p>I‚Äôm biased so naturally I‚Äôm going to use <a href=\"https://github.com/kixelated/moq/tree/main/js/hang\">@kixelated/hang</a> (smash that star button).\nYou can publish a live broadcast in the browser using the <a href=\"https://moq.dev/publish\">web demo</a> or the <a href=\"https://github.com/kixelated/moq/blob/main/js/hang-demo/src/publish.html#L25\">library</a>:</p><pre tabindex=\"0\" data-language=\"html\"><code></code></pre><p>There‚Äôs a link to watch your live broadcast using the <a href=\"https://moq.dev/watch\">web demo</a>, or again you can use the <a href=\"https://github.com/kixelated/moq/blob/9f5f6153458c03f255877a036e36f68f742d5c85/js/hang-demo/src/index.html#L30\">library</a>:</p><pre tabindex=\"0\" data-language=\"html\"><code></code></pre><p>You might even notice  because I‚Äôve been experimenting with AI features (gotta get funding eventually üí∞).\nThey‚Äôre generated  using <a href=\"https://github.com/snakers4/silero-vad\">silero-vad</a> + <a href=\"https://github.com/openai/whisper\">whisper</a> + <a href=\"https://huggingface.co/docs/transformers.js/en/index\">transformers.js</a> + <a href=\"https://github.com/microsoft/onnxruntime\">onnxruntime-web</a> + <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/WebGPU_API\">WebGPU</a> and transmitted using MoQ of course.\nBut that‚Äôs a whole separate blog post; it‚Äôs pretty cool.</p><p> You don‚Äôt have to use this <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Web_components\">Web Component</a> API.\n<a href=\"https://moq.dev/blog/first-app\">hang.live</a> uses the far more powerful Javascript API to do more complicated stuff like get access to individual video frames.\nThere‚Äôs a  section at the end of this blog if you LOVE sample code, but I‚Äôm not going to bore the rest of you.</p><p>There‚Äôs also a ü¶Ä Rust ü¶Ä library <a href=\"https://github.com/kixelated/moq/tree/main/rs/hang\">to import MP4</a>, <a href=\"https://github.com/kixelated/moq/blob/9f5f6153458c03f255877a036e36f68f742d5c85/rs/justfile#L103\">pipe media from ffmpeg</a>, and <a href=\"https://github.com/kixelated/moq/blob/9f5f6153458c03f255877a036e36f68f742d5c85/rs/justfile#L119\">publish/watch using gstreamer</a> so you can do more complicated media stuff without ü§Æ Javascript ü§Æ.\nI wish I could spend more time on the Rust side but  is a big deal.\nWe are no longer forced to use WebRTC, but that also means we need to build our own WebRTC in ü§Æ Javascript ü§Æ.\nI can suffer and you can reap the rewards.</p><h2>What‚Äôs not available yet?</h2><p>This is a  release.\nCloudflare is only supporting a  subset of an <a href=\"https://www.ietf.org/archive/id/draft-ietf-moq-transport-07.html\">old draft</a>, which is even smaller than <a href=\"https://www.ietf.org/archive/id/draft-lcurley-moq-lite-01.html\">my tiny subset</a>.\nThey‚Äôre using a <a href=\"https://github.com/englishm/moq-rs\">fork</a> of my terrible code so bugs are guaranteed.</p><ul><li><strong>There‚Äôs no authentication yet</strong>: choose an unguessable name for each broadcast.</li><li><strong>There‚Äôs no ANNOUNCE support</strong>: my <a href=\"https://github.com/kixelated/moq/blob/main/js/hang-demo/src/meet.html\">conferencing example</a> uses  to discover when broadcasts start/stop, so that won‚Äôt work.</li><li><strong>Nothing has been optimized</strong>: the user experience will improve over time.</li></ul><p>If any of these are deal breakers, then you could always run your own <a href=\"https://github.com/kixelated/moq/tree/main/rs/moq-relay\">moq-relay</a> in the meantime.\nI‚Äôve been adding new features and fixing a bunch of stuff  Cloudflare smashed that fork button.\nFor example, authentication (via JWT) and a WebSocket fallback for Safari/TCP support.</p><p>There‚Äôs even a <a href=\"https://github.com/kixelated/moq.dev/blob/main/infra/relay.tf\">terraform module</a> that powers .\nYou too can run your own ‚Äúglobal‚Äù CDN with 3 nodes and pay GCP a boatload of money for the privilege.\nIt‚Äôs not  as good as Cloudflare‚Äôs network, currently available for free‚Ä¶</p><p>Or host  yourself!\nIt should even work on private networks provided you <a href=\"https://moq.dev/blog/tls-and-quic\">wrestle with TLS certificates</a>.\nI‚Äôd also love to get MoQ running over <a href=\"https://www.iroh.computer/\">Iroh</a> for peer-to-peer action if anybody wants to help.</p><p>As a great philosopher once said:</p><blockquote><p>Apathy is a tragedy and boredom is a crime.\n- <a href=\"https://www.youtube.com/watch?v=k1BneeJTDcU\">Bo Burnham</a></p></blockquote><p>This is a big deal.\nThe biggest of deals.\nThe HUGEST of deals.</p><p>I‚Äôve been an <a href=\"https://moq.dev/blog/transfork\">outspoken critic</a> of the MoQ standardization process.\nIt‚Äôs just really difficult to design a protocol, via a cross-company committee, before there‚Äôs been any real world usage.\nIt‚Äôs been over 3 years since I fought Amazon lawyers and published my <a href=\"https://www.ietf.org/archive/id/draft-lcurley-warp-00.html\">first MoQ draft</a>.\nIt‚Äôs going to be at least another 3 years before even the <a href=\"https://datatracker.ietf.org/doc/draft-ietf-moq-transport/\">base networking layer</a> becomes an RFC.</p><p>\nThe best standards take a while.\nLook no further than QUIC, deployed by Google in 2012, started standardization in 2015, with the RFC released in 2021.\nAnd they had a boatload of production data to shape the specification.\nMeanwhile, we have only had a <a href=\"https://moq.dev/watch\">Big Buck Bunny demo</a>, and I believe the standard has veered off course as a result.</p><p>Cloudflare has done something fantastic and said:</p><blockquote><p>fuck waiting for a RFC, let‚Äôs release something</p></blockquote><p>Okay they didn‚Äôt say that, but this is  the mentality that MoQ needs right now.\n.\n.\n.</p><figure><figcaption>Holy shit I‚Äôm Shia LaBeouf.</figcaption></figure><p>Arguing in the <a href=\"https://github.com/moq-wg/moq-transport/issues\">650+ issues</a> and <a href=\"https://github.com/moq-wg/moq-transport/pulls\">500+ PRs</a> can wait for another day.\nTweaking the messaging encoding for the hundredth time can wait for another day.\nWe‚Äôre still going to make sure that MoQ gets standardized , but it‚Äôs more important to get  out there.</p><p>I‚Äôm looking at you: Google, Akamai, Fastly, etc.\nTake some code, run it on some spare servers, and start to learn what customers need  you design the protocol.</p><p>We‚Äôre effectively trying to reimplement WebRTC / HLS / RTMP using relatively new Web APIs.\nDon‚Äôt judge MoQ based on these initial offerings.\nWe‚Äôve got a  of work to do.\n.</p><p><a href=\"https://discord.gg/FCYF3p99mr\">Join the Discord</a>.\nSomehow there‚Äôs 900+ people in there.\nPing me and I will do whatever I can to help.\n if it means putting one more nail in the WebRTC coffin.</p><h2>Javascript is an Abomination</h2><p>You win some bonus documentation.\nCongrats!\nI knew you would win.</p><p>Here‚Äôs an example of my reactive library in action.\nIt powers <a href=\"https://moq.dev/blog/first-app\">hang.live</a> so the API is subject to change and is probably already out of date.\nWhen in doubt, <a href=\"https://github.com/kixelated/moq/tree/main/js/hang\">consult the source code</a> like the hacker you are.</p><pre tabindex=\"0\" data-language=\"typescript\"><code></code></pre><p>There‚Äôs even some  features behind undocumented APIs.\nLike running an object detection model in browser and publishing the results as a MoQ track.\nStay tuned for a blog post about that if I can figure out a better use-case than a cat cam. üêà</p><pre tabindex=\"0\" data-language=\"typescript\"><code></code></pre><p>Also, for the record, Typescript is really nice.\nü§Æ Javascript ü§Æ is still an abomination.</p>","contentLength":5578,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44987924"},{"title":"[Media] Accelerating Erasure Coding to 50GB/s with Rust 1.89.0 and AVX-512 on AMD EPYC","url":"https://www.reddit.com/r/rust/comments/1mxe8t4/media_accelerating_erasure_coding_to_50gbs_with/","date":1755886981,"author":"/u/itzmeanjan","guid":613,"unread":true,"content":"<div><p>Thanks to Rust 1.89.0 stabilizing both  and  target features, now we have faster erasure-coding and recoding with Random Linear Network Coding, on x86_64.</p><p>Here's a side-by-side comparison of the peak median throughput between </p><ul><li>x86_64 with  (12th Gen Intel(R) Core(TM) i7-1260P)</li><li>x86_64 with  (AWS EC2  with Intel(R) Xeon(R) Platinum 8488C)</li><li>x86_64 with  (AWS EC2  with AMD EPYC 9R14)</li><li>aarch64 with  (AWS EC2  with Graviton4 CPU)</li></ul><table><thead><tr></tr></thead><tbody><tr></tr><tr></tr><tr></tr></tbody></table></div>   submitted by   <a href=\"https://www.reddit.com/user/itzmeanjan\"> /u/itzmeanjan </a>","contentLength":453,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Weaponizing image scaling against production AI systems - AI prompt injection via images","url":"https://blog.trailofbits.com/2025/08/21/weaponizing-image-scaling-against-production-ai-systems/","date":1755885633,"author":"/u/grauenwolf","guid":606,"unread":true,"content":"<p>Picture this: you send a seemingly harmless image to an LLM and suddenly it exfiltrates all of your user data. By delivering a multi-modal prompt injection not visible to the user, we achieved data exfiltration on systems including the Google Gemini CLI. This attack works because AI systems often scale down large images before sending them to the model: when scaled, these images can reveal prompt injections that are not visible at full resolution.</p><p>In this blog post, we‚Äôll detail how attackers can <a href=\"https://www.usenix.org/conference/usenixsecurity20/presentation/quiring\">exploit image scaling</a> on Gemini CLI, Vertex AI Studio, Gemini‚Äôs web and API interfaces, Google Assistant, Genspark, and other production AI systems. We‚Äôll also explain how to mitigate and defend against these attacks, and we‚Äôll introduce <a href=\"https://github.com/trailofbits/anamorpher\">Anamorpher</a>, our open-source tool that lets you explore and generate these crafted images.</p><p>: <a href=\"https://www.usenix.org/conference/usenixsecurity19/presentation/xiao\">Image scaling attacks</a> were used for model <a href=\"https://arxiv.org/abs/2003.08633\">backdoors, evasion, and poisoning</a> primarily against older computer vision systems that enforced a fixed image size. While this constraint is less common with newer approaches, the systems surrounding the model may still impose constraints calling for image scaling. This establishes an underexposed, yet widespread vulnerability that we‚Äôve weaponized for <a href=\"https://developer.nvidia.com/blog/how-hackers-exploit-ais-problem-solving-instincts/\">multi-modal prompt injection</a>.</p><h2>Data exfiltration on the Gemini CLI</h2><p>To set up our data exfiltration exploit on the Gemini CLI through an image-scaling attack, we applied the default configuration for the Zapier MCP server. This automatically approves all MCP tool calls without user confirmation, <a href=\"https://github.com/google-gemini/gemini-cli/issues/5598\">as it sets  in the  of the Gemini CLI</a>. This provides an important primitive for the attacker.</p><p>Figure 2 showcases a video of the attack. First, the user uploads a seemingly benign image to the CLI. With no preview available, the user cannot see the transformed, malicious image processed by the model. This image and its prompt-ergeist triggers actions from Zapier that exfiltrates user data stored in Google Calendar to an attacker‚Äôs email without confirmation.</p><p>We also successfully demonstrated image scaling attacks on the following:</p><ul><li>Vertex AI with a Gemini back end</li><li>Gemini‚Äôs API via the  CLI</li><li>Google Assistant on an Android phone</li></ul><p>Notice the persistent mismatch between user perception and model inputs in figures 3 and 4. The exploit is particularly impactful on Vertex AI Studio because the front-end UI shows the high-resolution image instead of the downscaled image perceived by the model.</p><p>Our testing confirmed that this attack vector is widespread, extending far beyond the applications and systems documented here.</p><h2>Sharpening the attack surface</h2><p>These image scaling attacks exploit downscaling algorithms (or <a href=\"https://guide.encode.moe/encoding/resampling.html\">image resampling algorithms</a>), which perform interpolation to turn multiple high resolution pixel values into a single low resolution pixel value.</p><p>There are three major downscaling algorithms: <a href=\"https://en.wikipedia.org/wiki/Nearest-neighbor_interpolation\">nearest neighbor interpolation</a>, <a href=\"https://en.wikipedia.org/wiki/Bilinear_interpolation\">bilinear interpolation</a>, and <a href=\"https://en.wikipedia.org/wiki/Bicubic_interpolation\">bicubic interpolation</a>. Each algorithm requires a different approach to perform an image scaling attack. Furthermore, these algorithms are implemented differently across libraries (e.g., Pillow, PyTorch, OpenCV, TensorFlow), with varying anti-aliasing, alignment, and kernel phases (in addition to <a href=\"https://bartwronski.com/2021/02/15/bilinear-down-upsampling-pixel-grids-and-that-half-pixel-offset/\">distinct bugs</a> that historically have <a href=\"https://arxiv.org/abs/2104.11222\">plagued model performance</a>). These differences also impact the techniques necessary for an image scaling attack. Therefore, exploiting production systems required us to fingerprint each system‚Äôs algorithm and implementation.</p><p>To understand why image downscaling attacks are possible, imagine that you have a long ribbon with an intricate yet regular pattern on it. As this ribbon is pulled past you, you‚Äôre trying to recreate the pattern by grabbing samples of the ribbon at regular intervals. If the pattern changes rapidly, you need to grab samples very frequently to capture all the details. If you‚Äôre too slow, you‚Äôll miss crucial parts between grabs, and when you try to reconstruct the pattern from your samples, it looks completely different from the original.</p><h2>Anamorpher and the attacker‚Äôs darkroom</h2><p>Currently, Anamorpher (named after <a href=\"https://en.wikipedia.org/wiki/Anamorphosis\">anamorphosis</a>) can develop crafted images for the aforementioned three major methods. Let‚Äôs explore how Anamorpher exploits bicubic interpolation frame by frame.</p><p>Bicubic interpolation considers the 16 pixels (from 4x4 sampling) around each target pixel, using cubic polynomials to calculate smooth transitions between pixel values. This method creates a predictable mathematical relationship that can be exploited. Specifically, the algorithm assigns different weights to pixels in the neighborhood, creating pixels that contribute more to the final output, which are known as high-importance pixels. Therefore, the total <a href=\"https://en.wikipedia.org/wiki/Luma_(video)\">luma</a> (brightness) of dark areas of an image will increase if specific high-importance pixels are higher luma than their surroundings.</p><p>Therefore, to exploit this, we can carefully craft high-resolution pixels and solve the inverse problem. First, we select a decoy image with large dark areas to hide our payload. Then, we adjust pixels in dark regions and push the downsampled result toward a red background using least-squares optimization. These adjustments in the dark areas cause the background to turn red while text areas remain largely unmodified and appear black, creating much stronger contrast than visible at full resolution. While this approach is most effective on bicubic downscaling, it also works on specific implementations of bilinear downscaling.</p><p>Anamorpher provides users with the ability to visualize and craft image scaling attacks against specific algorithms and implementations through a front-end interface and Python API. In addition, it comes with a modular back end, which enables users to customize their own downscaling algorithm.</p><p>While some downscaling algorithms are more vulnerable than others, attempting to identify the least vulnerable algorithm and implementation is <a href=\"https://arxiv.org/abs/2104.08690\">not a robust approach</a>. This is especially true since image scaling attacks are not restricted to the aforementioned three algorithms.</p><p>For a secure system, we recommend not using image downscaling and simply limiting the upload dimensions. For any transformation, but especially if downscaling is necessary, the end user should always be provided with a preview of the input that the model is actually seeing, even in CLI and API tools.</p><p><a href=\"https://github.com/trailofbits/anamorpher\">Anamorpher</a> is currently in beta, so feel free to reach out with feedback and suggestions as we continue to improve this tool. Stay tuned for more work on the security of multi-modal, agentic, and multi-agentic AI systems!</p>","contentLength":6551,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1mxdmty/weaponizing_image_scaling_against_production_ai/"},{"title":"XSLT removal will break multiple government and regulatory sites across the world","url":"https://github.com/whatwg/html/issues/11582","date":1755885585,"author":"/u/Comfortable-Site8626","guid":608,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1mxdm22/xslt_removal_will_break_multiple_government_and/"},{"title":"OpenBao installation on Kubernetes - with TLS and more!","url":"https://nanibot.net/posts/vault","date":1755885253,"author":"/u/-NaniBot-","guid":570,"unread":true,"content":"<div><p>OpenBao is an open-source fork of HashiCorp‚Äôs Vault, created to ensure the project remains community-driven and permissively licensed. It provides a robust, transparent, and accessible solution for secrets management and data protection, offering a viable alternative for users who relied on Vault‚Äôs original open-source model.</p><p>The default Helm installation of OpenBao is enough for a dev environment but it needs some modifications for a full-fledged production deployment. In this blog post we‚Äôll learn about how a typical production deployment for OpenBao would look like.</p><p> I‚Äôm  new to OpenBao myself. Apologies for any mistakes/inaccuracies in my blog post. Feel free to e-mail me if you find something wrong.</p><p><code>mail: nanibot@nanibot.net</code></p><p>Here‚Äôs all the things that we‚Äôre going to configure for our OpenBao cluster:</p><ol><li><p>End-to-end TLS encryption for network traffic. Includes the OpenBao UI (with proxy SSL support!)</p></li><li><p>High availability via OpenBao‚Äôs internal Raft implementation.</p></li><li><p>Auto-unseal without relying on a cloud KMS solution ( This might  be secure - depending on whether you feel comfortable storing the unseal key as a kubernetes secret or not)</p></li></ol><p> Currently, static unseal is only available in a nightly build (<code>openbao/openbao-nightly:2.4.0-nightly1752150785</code>) but is planned to be released as part of the 2.4.0 release</p><ul><li><p>I‚Äôll use  for creating the necessary certificates and  for exposing the UI</p></li><li><p>I‚Äôll assume the chart is going to be installed in the  namespace and the release is called </p></li></ul><ol><li>Certificate to be used for TLS. In this example, I‚Äôm using a wildcard certificate issued by my own CA. The certificate is stored in a kubernetes secret named <code>internal-wildcard-cert-secret</code> in the  namespace</li></ol><pre tabindex=\"0\"><code>apiVersion: cert-manager.io/v1\nkind: Certificate\nmetadata:\n  name: internal-wildcard-cert\n  namespace: vault-system\nspec:\n  secretName: internal-wildcard-cert-secret\n  duration: 2160h\n  renewBefore: 720h\n  privateKey:\n    algorithm: RSA\n    encoding: PKCS1\n    size: 2048\n    rotationPolicy: Always\n  subject:\n    organizations:\n      - Umbrella\n    organizationalUnits:\n      - nanibot.net\n  dnsNames:\n    - \"vault-production-openbao-active\"\n    - \"*.vault-production-openbao-internal\"\n    - \"*.vault-production-openbao-internal.vault-system\"\n    - \"*.vault-production-openbao-internal.vault-system.svc\"\n    - \"*.vault-production-openbao-internal.vault-system.svc.cluster.local\"\n  ipAddresses:\n    - \"127.0.0.1\"\n  issuerRef:\n    name: pki-production-selfsigned-issuer\n    kind: ClusterIssuer\n</code></pre><p> The dnsName entry <code>vault-production-openbao-active</code> refers to the Kubernetes service that‚Äôs created by the Helm chart. This will also be our API Address - the hostname that the Vault API will be exposed at.</p><ol start=\"2\"><li>Unseal key for static auto-unseal</li></ol><p>We need to create a kubernetes secret containing the unseal key for static auto-unseal to work. We can do this by running the following commands:</p><pre tabindex=\"0\"><code>openssl rand -out unseal-umbrella-1.key 32\nkubectl create secret generic unseal-key --from-file=unseal-umbrella-1.key=./unseal-umbrella-1.key\n</code></pre><pre tabindex=\"0\"><code>global:\n  tlsDisable: false\nserver:\n  image:\n    repository: \"openbao/openbao-nightly\"\n    tag: \"2.4.0-nightly1752150785\"\n  extraEnvironmentVars:\n    BAO_CACERT: \"/certs/ca.crt\"\n  ha:\n    enabled: true\n    apiAddr: \"https://vault-production-openbao-active:8200\"\n    raft:\n      enabled: true\n      config: |\n        ui = true\n\n        listener \"tcp\" {\n          address = \"[::]:8200\"\n          cluster_address = \"[::]:8201\"\n          tls_cert_file = \"/certs/tls.crt\"\n          tls_key_file = \"/certs/tls.key\"\n        }\n\n        storage \"raft\" {\n          path = \"/openbao/data\"\n        }\n\n        seal \"static\" {\n          current_key_id = \"umbrella-1\"\n          current_key = \"file:///keys/unseal-umbrella-1.key\"\n        }\n\n        service_registration \"kubernetes\" {}\n  auditStorage:\n    enabled: true\n  ingress:\n    enabled: true\n    annotations:\n      nginx.ingress.kubernetes.io/backend-protocol: \"HTTPS\"\n      nginx.ingress.kubernetes.io/proxy-ssl-verify: \"on\"\n      nginx.ingress.kubernetes.io/proxy-ssl-name: \"vault-production-openbao-active\"\n      nginx.ingress.kubernetes.io/proxy-ssl-secret: \"vault-system/internal-wildcard-cert-secret\"\n    ingressClassName: \"nginx\"\n    hosts:\n      - host: vault.nanibot.net\n    tls:\n      - secretName: public-wildcard-cert-secret\n        hosts:\n          - vault.nanibot.net\n  volumes:\n    - name: unseal-key\n      secret:\n        secretName: unseal-key\n    - name: certs\n      secret:\n        secretName: internal-wildcard-cert-secret\n  volumeMounts:\n    - mountPath: /keys\n      name: unseal-key\n      readOnly: true\n    - mountPath: /certs\n      name: certs\n      readOnly: true\nui:\n  enabled: true\n</code></pre><ol><li><p>We enable TLS by setting  to . This enables https endpoints for the relevant services.</p></li><li><p>We use the nightly build of OpenBao which has support for static auto-unseal (<code>openbao/openbao-nightly:2.4.0-nightly1752150785</code>).</p></li><li><p> is set to the path of our CA certificate so that OpenBao can verify the TLS certificate of other nodes in the cluster.</p></li><li><p>We enable HA and Raft storage.</p></li><li><p>We configure the Raft listener to use TLS and bind to all interfaces. We also provide the paths to our TLS certificate and key.</p></li><li><p>We configure static auto-unseal using a file-based unseal key.</p></li><li><p>apiAddr is set to the DNS name of the active OpenBao node (Kubernetes service created by the Helm chart). This is required for the UI to work properly with proxy SSL.</p></li><li><p>proxy-ssl-name is set to the DNS name of the active OpenBao node. This is required for the UI to work properly with proxy SSL.</p></li><li><p>Other  parameters are set to ensure that the ingress controller can verify the TLS certificate of the OpenBao server.</p></li><li><p>We enable the UI by setting  to .</p></li><li><p>Volumes and volume mounts are added for the unseal key and TLS certificates.</p></li></ol><ol><li><p>Install the helm chart using the above values.yaml file</p></li><li><p>Initialize the OpenBao cluster by running the following command (Assuming the pod name is <code>vault-production-openbao-0</code>):</p></li></ol><pre tabindex=\"0\"><code>kubectl exec -it vault-production-openbao-0 -- bao operator init\n</code></pre><ol start=\"3\"><li><p>Store the unseal key(s) and the root token somewhere safe</p></li><li><p>Join the other nodes to the cluster by running the following command on each of them:</p></li></ol><pre tabindex=\"0\"><code>kubectl exec -it vault-production-openbao-1 -- bao operator raft join -leader-ca-cert=@/certs/ca.crt https://vault-production-openbao-0.vault-production-openbao-internal:8200\nkubectl exec -it vault-production-openbao-2 -- bao operator raft join -leader-ca-cert=@/certs/ca.crt https://vault-production-openbao-0.vault-production-openbao-internal:8200\n</code></pre><p>That‚Äôs it! You should now have a fully functional OpenBao cluster running on Kubernetes with TLS, HA and auto-unseal support.</p><p>The Web UI should be accessible at <code>https://vault.nanibot.net</code> (or whatever host you configured in the ingress).</p></div>","contentLength":6709,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/kubernetes/comments/1mxdgvd/openbao_installation_on_kubernetes_with_tls_and/"},{"title":"Leaving Gmail for Mailbox.org","url":"https://giuliomagnifico.blog/post/2025-08-18-leaving-gmail/","date":1755884508,"author":"giuliomagnifico","guid":212,"unread":true,"content":"<p>This was a tough decision, having used Gmail since 2007/2008. However, I had to draw the line and stop giving Google my data for free.</p><p>The problem with email is that everything is transmitted in plain text. Technically, Google can store every message you receive and know everything, and U.S. agencies can request access to that data (this include also EU citizens under the <a href=\"https://policies.google.com/privacy/frameworks?hl=en-US\">EU-U.S. and Swiss-U.S. Data Privacy Frameworks</a>).</p><p>For someone like me, who cares about privacy and runs as much as possible on my own home servers, that felt like way too much.</p><p>So I decided to switch to another provider, one that respects privacy a bit more. Of course, this meant no longer ‚Äúpaying‚Äù with my personal data, but instead paying the actual price of the email service.</p><p>Let me start by saying: I use email in a very basic way. I send and receive a lot of messages (at least 50 a day), but they‚Äôre plain text/html emails with no attachments or fancy features. I couldn‚Äôt care less about the rest of the ‚Äúsuite\", like notes, contacts, calendars and all that extra stuff.</p><p>So, after a bit of research, I narrowed it down to three different services:</p><ul></ul><p>The last two providers offered true end-to-end encryption, at a cost of about ‚Ç¨3/4 per month. Sounds good‚Ä¶ but the catch is that to use their end-to-end encryption you‚Äôre forced to use their apps (or, on macOS, run a background ‚Äúbridge‚Äù).</p><p>That‚Äôs a no go for me, because I love Apple‚Äôs Mail app on macOS and iOS, it just works perfectly for my needs, and I don‚Äôt want to give that up.</p><p>So, I went with mailbox.org that still offers integrated PGP encryption, and if you want, you can always use external PGP too (which I was already doing with Gmail).</p><p>Mailbox.org has a solid plan: 10GB of email storage plus 5GB of cloud storage starting at ‚Ç¨2.50/month (paid annually). You can even expand the mail storage up to 100GB, at ‚Ç¨0.20 per gigabyte.</p><p>I was using around 2.5GB on Gmail, so I had no issues with paying the equivalent of two coffees a month for a huge boost in privacy. And if I ever need more space, I can just add it on-demand for ‚Ç¨0.20/GB.</p><p>There‚Äôs also a free one-month trial, but it‚Äôs pretty limited since you can‚Äôt send emails outside of mailbox.org domains.</p><p>So win the end, I registered my new address <code>giuliomagnifico@mailbox.org</code> and paid ‚Ç¨3 for a month of testing. That means I‚Äôm covered for two months, and then I can just ‚Äútop up‚Äù the account with ‚Ç¨30 for a full year.</p><div><div>Mailbox.org doesn‚Äôt use auto-renewal, so you have to manually top up your account. Nice feature</div></div><p>The web interface is extremely simple but very effective. I actually find it better than Gmail, less bloated of useless stuff.</p><p>And on mobile it‚Äôs very usable too.</p><img src=\"https://giuliomagnifico.blog/_images/2025/away-from-gmail/ios.jpeg\" alt=\"ios\"><p>One thing I prefer is using folders instead of Gmail‚Äôs ‚Äúlabels.‚Äù Mainly because this way I can put the folders directly under the account in Apple Mail (I think is the only email that can actually support this).</p><img src=\"https://giuliomagnifico.blog/_images/2025/away-from-gmail/folders.jpeg\" alt=\"folders\"><p>Mailbox.org also has all the features I need,\nand probably way more than I‚Äôll ever use. It even includes storage, video chat, an XMPP chat, task lists, calendar, contacts, an Etherpad (basically shared notes, I think), and so on‚Ä¶ none of which I really care about.</p><p>I decided to move all my emails from Gmail to mailbox.org, so I could (in future) completely wipe my Gmail account.</p><p>After creating an ‚Äúapp password‚Äù on Gmail, I installed the Docker image and ran the tool with this script:</p><pre tabindex=\"0\"><code>#!/bin/sh\nset -eu\n\nHOST1=\"imap.gmail.com\"\nUSER1=\"giuliomagnifico@gmail.com\"\nPASS1=\"xxx\"\n\nHOST2=\"imap.mailbox.org\"\nUSER2=\"giuliomagnifico@mailbox.org\"\nPASS2=\"xxx\"\n\nLOGDIR=\"/home/imapsync/logs\"\nmkdir -p \"$LOGDIR\"\nLOGFILE=\"$LOGDIR/sync_$(date +%F_%H-%M-%S).log\"\n\necho \"Starting: $(date)\"\ndocker compose run --rm imapsync imapsync \\\n  --host1 \"$HOST1\" --user1 \"$USER1\" --password1 \"$PASS1\" --ssl1 \\\n  --host2 \"$HOST2\" --user2 \"$USER2\" --password2 \"$PASS2\" --ssl2 \\\n  --automap --syncinternaldates --skipsize \\\n  --useuid --addheader --usecache --buffersize 4096 \\\n  --nofoldersizes --nofoldersizesatend \\\n  --exclude \"\\[Gmail\\]/All Mail\" \\\n  --regextrans2 \"s/\\[Imap\\]\\/Archive/Archive/\" \\\n  --log &gt; \"$LOGFILE\" 2&gt;&amp;1\n\necho \"Complete: $(date)\"\necho \"Log file: $LOGFILE\"\n</code></pre><p>The script excludes the All Mail folder\" using: <code>--exclude \"\\[Gmail\\]/All Mail\" \\</code></p><p>This to avoid duplicate emails already present in the folders, I also merged the  folder into the general Archive folder using: <code>--regextrans2 \"s/\\[Imap\\]\\/Archive/Archive/\"</code></p><p>This because Apple‚Äôs Mail app creates the  folder/label on Gmail whenever you use the ‚ÄúArchive‚Äù function instead of ‚ÄúTrash.‚Äù</p><p>The whole process took a couple of hours (11201secs, ~3h to be precise) during which I was monitoring the logs using: <code>tail -f /home/imapsync/logs/sync_2025-08-19_15-02-48.log</code></p><pre tabindex=\"0\"><code>[cut]\nmsg [Gmail]/Trash/183393 {19549}      copied to Trash/13361      2.36 msgs/s  200.418 KiB/s 2.140 GiB copied \nmsg [Gmail]/Trash/183394 {92245}      copied to Trash/13362      2.36 msgs/s  200.420 KiB/s 2.140 GiB copied \nmsg [Gmail]/Trash/183395 {19675}      copied to Trash/13363      2.36 msgs/s  200.415 KiB/s 2.140 GiB copied \nmsg [Gmail]/Trash/183396 {5953}       copied to Trash/13364      2.36 msgs/s  200.410 KiB/s 2.140 GiB copied \n++++ End looping on each folder\n++++ Statistics\nTransfer started on                     : Tuesday 19 August 2025-08-19 03:02:49 +0000 UTC\nTransfer ended on                       : Tuesday 19 August 2025-08-19 06:09:30 +0000 UTC\nTransfer time                           : 11201.5 sec\nFolders synced                          : 14/14 synced\nFolders deleted on host2                : 0 \nMessages transferred                    : 26407 \nMessages skipped                        : 0\nMessages found duplicate on host1       : 0\nMessages found duplicate on host2       : 0\nMessages found crossduplicate on host2  : 0\nMessages void (noheader) on host1       : 0  \nMessages void (noheader) on host2       : 0\nMessages found in host1 not in host2    : 0 messages\nMessages found in host2 not in host1    : 0 messages\nMessages deleted on host1               : 0\nMessages deleted on host2               : 0\nTotal bytes transferred                 : 2297647358 (2.140 GiB)\nTotal bytes skipped                     : 0 (0.000 KiB)\nMessage rate                            : 2.4 messages/s\nAverage bandwidth rate                  : 200.3 KiB/s\nReconnections to host1                  : 0\nReconnections to host2                  : 0\nMemory consumption at the end           : 268.7 MiB (*time 836.2 MiB*h) (started with 161.5 MiB)\nLoad end is                             : 0.06 0.08 0.08 1/1135 on 16 cores\nCPU time and %CPU                       : 446.72 sec 4.0 %CPU 0.2 %allcpus\nBiggest message transferred             : 30413995 bytes (29.005 MiB)\nMemory/biggest message ratio            : 9.3\nDetected 0 errors\nThis imapsync is up to date. ( local 2.306 &gt;= official 2.290 )( Use --noreleasecheck to avoid this release check. )\nHomepage: https://imapsync.lamiral.info/\nExiting with return value 0 (EX_OK: successful termination) 0/50 nb_errors/max_errors PID 1\nRemoving pidfile /var/tmp//tmp/imapsync.pid\nLog file is LOG_imapsync/2025_08_19_03_02_49_171_giuliomagnifico_gmail_com_giuliomagnifico_mailbox_org.txt ( to change it, use --logfile filepath ; or use --nolog to turn off logging )\n</code></pre><p>Of course, the full switch will be a gradual process, even though I‚Äôve already updated almost all my main services with the new address.</p><p>To make things easier, on my old Gmail account (which I removed from Apple Mail on all devices) I set up a forward to my new mailbox.org address.</p><p><img src=\"https://giuliomagnifico.blog/_images/2025/away-from-gmail/forward.jpeg\" alt=\"forward\">\nOn the new mailbox.org account, I also set up a filter to flag any emails that get forwarded from Gmail.</p><p>That way, I immediately notice them and I can update the address from Gmail to Mailbox.org whenever they show up. (The  tag is perfect for this, since it add a ‚Äúreal red flag‚Äù in Apple Mail on iOS, iPadOS and macOS)</p><p>Mailbox.org allows you to easily import your keys for PGP cryptography directly from the web. This is convenient as it lets you read and send PGP encrypted emails right from the browser on iOS, where there aren‚Äôt any ‚Äúdecent‚Äù apps for encrypted mail. The same goes for macOS, although there you can just use Thunderbird, which works really well.</p><p>Here‚Äôs how PGP emails look on iOS:</p><img src=\"https://giuliomagnifico.blog/_images/2025/away-from-gmail/gpgios.jpeg\" alt=\"PGPios\"><p>To send encrypted emails, you just select ‚ÄúUse PGP encrypted‚Äù when composing a new message, after importing your private key, of course.</p><p>And from the web interface, there‚Äôs also a handy feature to quickly import the sender‚Äôs public keys:</p><p>I‚Äôm satisfied. Leaving Gmail completely was something I wanted to do for a long time, but I was always hesitant. Finally, I made the switch, and, as often happens with these transitions, I discovered many unexpected positive aspects.</p><p>Oh, and if you have something to tell me or just want to test Mailbox.org after your switch, feel free to send me an email. Here‚Äôs my public key:</p><pre tabindex=\"0\"><code>-----BEGIN PGP PUBLIC KEY BLOCK-----\n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\nQjuwt/KpUqS4qTLl/Q==\n=GpPW\n-----END PGP PUBLIC KEY BLOCK-----\n</code></pre>","contentLength":12034,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44987380"},{"title":"Anybody using multi-seat? This is my Ubuntu 24.04 multi-seat setup for my kids.","url":"https://www.reddit.com/r/linux/comments/1mxcodi/anybody_using_multiseat_this_is_my_ubuntu_2404/","date":1755883456,"author":"/u/Rob_Bob_you_choose","guid":578,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Quick background and Demo on kagent - Cloud Native Agentic AI - with Christian Posta and Mike Petersen","url":"https://youtube.com/live/KUOIRZsWv38","date":1755882405,"author":"/u/mpetersen_loft-sh","guid":569,"unread":true,"content":"<div><p>Christian Posta gives some background on kagent, what they looked into when building agents on Kubernetes. Then I install kagent in a vCluster - covering most of the quick start guide + adding in a self hosted LLM and ingress.</p></div>   submitted by   <a href=\"https://www.reddit.com/user/mpetersen_loft-sh\"> /u/mpetersen_loft-sh </a>","contentLength":266,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/kubernetes/comments/1mxc7w5/quick_background_and_demo_on_kagent_cloud_native/"},{"title":"Show HN: Clyp ‚Äì Clipboard Manager for Linux","url":"https://github.com/murat-cileli/clyp","date":1755878606,"author":"timeoperator","guid":183,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44986205"},{"title":"Vibe Debugging: Enterprises' Up and Coming Nightmare","url":"https://marketsaintefficient.substack.com/p/vibe-debugging-enterprises-up-and","date":1755877803,"author":"/u/bullionairejoker","guid":607,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1mxa6hn/vibe_debugging_enterprises_up_and_coming_nightmare/"},{"title":"Rust For Foundational Software","url":"https://corrode.dev/blog/foundational-software/","date":1755876982,"author":"/u/don_searchcraft","guid":611,"unread":true,"content":"<p>Ten years of stable Rust; writing this feels surreal.</p><p>It‚Äôs only been  that we all celebrated the 1.0 release of this incredible language.</p><p>I was at Rust Week where Niko Matsakis gave his talk ‚ÄúOur Vision for Rust‚Äù in which he made a profound and insightful statement:</p><blockquote><p>Rust is a language for building .</p></blockquote><p>I highly recommend you read his blog post titled <a rel=\"noopener noreferrer\" target=\"_blank\" href=\"https://smallcultfollowing.com/babysteps/blog/2025/03/10/rust-2025-intro/\">‚ÄúRust in 2025: Targeting foundational software‚Äù</a>, which is a great summary on the topic.\nI wanted to expand on the idea and share what this means to corrode (and perhaps to a wider extent to Rust in the industry).</p><p>First off, do we really need another term?\nAfter all, many people still think of Rust as a systems programming language first and foremost, so why can‚Äôt we just stick to ‚Äúsystems programming‚Äù?</p><p>I believe the framing is all wrong.\nFrom the outside, ‚Äúsystems programming‚Äù might establish that it is about ‚Äúbuilding systems,‚Äù but the term is loaded with historical baggage that feels limiting and prohibitive.\nIt creates an artificial distinction between systems programming and ‚Äúother types of programming.‚Äù</p><p>The mindset ‚ÄúWe are not a systems programming company so we don‚Äôt need Rust‚Äù is common, but limiting.</p><p>If I may be candid for a moment, I believe well-known systems-programming domains have a tendency to be toxic.\nEven the best developers in the world have had that experience.</p><blockquote><p>The first contribution that I had to the Linux kernel was some fix for the ext3 file system. It was a very emotional moment for me. I sent a patch to the Linux Kernel and then I saw an email response from Al Viro - one of those developers I‚Äôd only heard about and dreamed of meeting someday.\nHe responded, <strong>‚ÄòI‚Äôve never seen code this bad in my life. You managed to introduce three new bugs in two new lines of code. People like you should never be allowed to get close to a keyboard again.‚Äô</strong>\nThat was my introduction to Linux.</p></blockquote><p>Glauber went on to work at Red Hat, Parallels, ScyllaDB, and Datadog on schedulers, databases, and performance optimizations, but just imagine how many capable developers got discouraged by similar early feedback or never even tried to contribute to the Linux kernel in the first place.</p><p>The whole idea of Rust is to enable  to build reliable and efficient software.\nTo me, it‚Äôs about breaking down the barriers to entry and making larger parts of the software stack accessible to more people.\nYou can sit with us.</p><blockquote><p>‚ÄúI think ‚Äòinfrastructure‚Äô is a more useful way of thinking about Rust‚Äôs niche than arguing over the exact boundary that defines ‚Äòsystems programming‚Äô.‚Äù</p><p>‚ÄúThis is the essence of the systems Rust is best for writing: not flashy, not attention-grabbing, often entirely unnoticed. Just the robust and reliable necessities that enable us to get our work done, to attend to other things, confident that the system will keep humming along unattended.‚Äù</p></blockquote><p>In conversations with potential customers, one key aspect that comes up with Rust a lot is this perception that Rust is merely a systems programming language.\nThey see the benefit of reliable software, but often face headwinds from people dismissing Rust as ‚Äúyet another systems level language that is slightly safer.‚Äù</p><p>People keep asking me how Rust could help them.\nAfter all, Rust is just a ‚Äúsystems programming language.‚Äù\nI used to reply along the lines of Rust‚Äôs mantra: ‚Äúempowering everyone to build reliable and efficient software‚Äù ‚Äì and while I love this mission, it didn‚Äôt always ‚Äúclick‚Äù with people.</p><p>My clients use Rust for a much broader range of software, not just low-level systems programming.\nThey use Rust for writing software that .</p><p>Then I used to tell my own story:\nI did some C++ in the past, but I wouldn‚Äôt call myself a systems programmer.\nAnd yet, I help a lot of clients with really interesting and complex pieces of software.\nI ship code that is used by many people and companies like Google, Microsoft, AWS, and NVIDIA.\nRust is a great enabler, a superpower, a <a rel=\"noopener noreferrer\" target=\"_blank\" href=\"https://web.archive.org/web/20230603070738/https://thefeedbackloop.xyz/safety-is-rusts-fireflower/\">fireflower</a>.</p><p>I found that my clients often don‚Äôt use Rust as a C++ replacement.\nMany clients don‚Äôt even have any C++ in production in the first place.\nThey also don‚Äôt need to work on the hardware-software interface or spend their time in low-level code.</p><p>What they all have in common, however, is that the services they build with Rust are <strong>foundational to their core business</strong>.\nRust is used for building platforms: systems which enable building other systems on top.</p><p>These services need to be robust and reliable and serve as platforms for other code that might or might not be written in Rust.\nThis is, in my opinion, the core value proposition of Rust: to build things that form the bedrock of critical infrastructure and must operate reliably for years.</p><p>Rust is a day-2-language, i.e. it only starts to shine on day 2. All of the problems that you have during the lifecycle of your application surface early in development.\nOnce a service hits production, maintaining it is boring.\nThere is very little on-call work.</p><p>The focus should be on what Rust enables: a way to express very complicated ideas on a type-system level, which will help build complex abstractions through simple core mechanics: ownership, borrowing, lifetimes, and its trait system.</p><p>This mindset takes away the focus from Rust as a C++ replacement and also explains why so many teams which use languages like Python, TypeScript, and Kotlin are attracted by Rust.</p><p>What is less often talked about is that Rust is a language that enables people to move across domain boundaries: from embedded to cloud, from data science to developer tooling.\nFew other languages are so versatile and none offer the same level of correctness guarantees.</p><p>If you know Rust, you can program simple things in all of these domains.</p><p>But don‚Äôt we just replace ‚ÄúSystems Programming‚Äù with ‚ÄúFoundational Software‚Äù?\nDoes using the term ‚ÄúFoundational Software‚Äù simply create a new limiting category?</p><p>Crucially, foundational software is different from low-level software and systems software.\nFor my clients, it‚Äôs all foundational.\nFor example, building a data plane is foundational.\nWriting a media-processing pipeline is foundational.</p><p>Rust serves as a catalyst: companies start using it for critical software but then, as they get more comfortable with the language, expand into using it in other areas of their business:</p><blockquote><p>I‚Äôve seen it play out as we built Aurora DSQL - we chose Rust for the new dataplane components, and started off developing other components with other tools. The control plane in Kotlin, operations tools in Typescript, etc. Standard ‚Äúright tool for the job‚Äù stuff. But, as the team has become more and more familiar and comfortable with Rust, it‚Äôs become the way everything is built. A lot of this is because we‚Äôve seen the benefits of Rust, but at least some is because the team just enjoys writing Rust.</p></blockquote><p>That fully aligns with my experience: I find that teams become ambitious after a while.\nThey reach for loftier goals because they .\nThe fact they don‚Äôt have to deal with security issues anymore enables better affordances.\nFrom my conversations with other Rustaceans, we all made the same observation: suddenly we can build more ambitious projects that we never dared tackling before.</p><p>It feels to me as if this direction is more promising: starting with the foundational tech and growing into application-level/business-level code if needed/helpful.\nThat‚Äôs better than the other way around, which often feels unnecessarily clunky.\nOnce the foundations are in Rust, other systems can be built on top of it.</p><p>Just because we focus on foundational software doesn‚Äôt mean we can‚Äôt do other things.\nBut the focus is to make sure that Rust stays true to its roots.</p><h2><a href=\"https://corrode.dev/blog/foundational-software/#systems-you-plan-to-maintain-for-years\" aria-label=\"Anchor link for: systems-you-plan-to-maintain-for-years\">Systems You Plan To Maintain For Years</a></h2><p>So, what  foundational software?</p><p>It‚Äôs software that organizations deem critical for their success.\nIt might be:</p><ul><li>a satellite control system</li><li>an SDK for multiple languages</li><li>a real time notification service</li></ul><p>All of these things power organizations and  or at least do so .\nMy clients and the companies I interviewed on our <a href=\"https://corrode.dev/podcast\">podcast</a> all have one thing in common:\nThey work on Rust projects that are not on the sideline, but front and center, and they shape the future of their infrastructure.\nRust is useful in situations where the <a rel=\"noopener noreferrer\" target=\"_blank\" href=\"https://dreamsongs.com/Files/worse-is-worse.pdf\">‚Äúworse is better‚Äù philosophy falls apart</a>; it‚Äôs a language for building the ‚Äúright thing‚Äù:</p><blockquote><p>With the right thing, designers are equally concerned with simplicity, correctness, consistency, and completeness.</p></blockquote><p>I think many companies will choose Rust to build their future platforms on.\nAs such, it competes with C++ as much as it does with Kotlin or Python.</p><p>I believe that we should shift the focus away from memory safety (which these languages also have) and instead focus on the explicitness, expressiveness, and ecosystem of Rust that is highly competitive with these languages.\nIt is a language for teams which want to build things  and are at odds with the ‚Äúmove fast and break things‚Äù philosophy of the past.\nRust is future-looking.\nBackwards-compatibility is enforced by the compiler and many people work on the robustness aspect of the language.</p><p>Dropbox was one of the first production users of Rust.\nThey built their storage layer on top of it.\nAt no point did they think about using Rust as a C++ replacement.\nInstead, they saw the potential of Rust as a language for building scalable and reliable systems.\nMany more companies followed:\nAmazon, Google, Microsoft, Meta, Discord, Cloudflare, and many more.\nThese organizations build platforms.\nRust is a tool for professional programmers, developed by world experts over more than a decade of hard work.</p><blockquote><p>‚ÄúAt this point, we now know the answer: yes, Rust is used a lot. It‚Äôs used for real, critical projects to do actual work by some of the largest companies in our industry. We did good.‚Äù</p><p>‚Äú[Rust is] not a great hobby language but it is a fantastic professional language, precisely because of the ease of refactors and speed of development that comes with the type system and borrow checker.‚Äù</p></blockquote><p>To build a truly industrial-strength ecosystem, we need to remember the professional software lifecycle, which is hopefully decades long.\nStability plays a big role in that.\nThe fact that Rust has stable editions and a language specification is a big part of that.</p><p>But Rust is not just a compiler and its standard library.\nThe tooling and wider ecosystem are equally important.\nTo build foundational software, you need guarantees that vulnerabilities get fixed and that the ecosystem evolves and adapts to the customer‚Äôs needs.\nThe ecosystem is still mostly driven by volunteers who work on important parts of the ecosystem in their free time.\nThere is more to be said about supply-chain security and sustainability in the ecosystem.</p><p>Building foundational systems is rooted in the profound belief that the efforts will pay off in the long run because organizations and society will benefit from them for decades.\nWe are building systems that will be used by people who may not even know they are using them, but who will depend on them every day.\nCritical infrastructure.</p><p>And Rust allows us to do so with great ergonomics.\nRust inherits pragmatism from C++ and purism from Haskell.</p><p>Rust enables us to build sustainable software that stays within its means and is concerned about low resource usage.\nSystems where precision and correctness matter.\nSolutions that work across language boundaries and up and down the stack.</p><p>Rust is a language for decades and my mission is to be a part of this shift.</p>","contentLength":11547,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/rust/comments/1mx9tdr/rust_for_foundational_software/"},{"title":"FFmpeg 8.0","url":"https://ffmpeg.org/index.html#pr8.0","date":1755876162,"author":"gyan","guid":211,"unread":true,"content":"<div><div><h2>\n        A complete, cross-platform solution to record, convert and stream audio and video.\n      </h2></div></div><div><h3>Converting  and  has never been so easy.\n    </h3><pre>$ ffmpeg -i input.mp4 output.avi</pre></div><h3>August 22nd, 2025, FFmpeg 8.0 </h3><p>\n  A new major release, <a href=\"https://ffmpeg.org/download.html#release_8.0\">FFmpeg 8.0 </a>,\n  is now available for download.\n  Thanks to several delays, and modernization of our entire infrastructure, this release ended up\n  being one of our largest releases to date. In short, its new features are:\n  </p><ul><li>Native decoders: , ProRes RAW, RealVideo 6.0, Sanyo LD-ADPCM, G.728</li><li>VVC decoder improvements: ,\n                                  ,\n                                  Palette Mode</li><li>Vulkan compute-based codecs: FFv1 (encode and decode), ProRes RAW (decode only)</li><li>Hardware accelerated decoding: Vulkan VP9, VAAPI VVC, OpenHarmony H264/5</li><li>Hardware accelerated encoding: Vulkan AV1, OpenHarmony H264/5</li><li>Formats: MCC, G.728, Whip, APV</li><li>Filters: colordetect, pad_cuda, scale_d3d11, Whisper, and others</li></ul><p>\n  A new class of decoders and encoders based on pure Vulkan compute implementation have been added.\n  Vulkan is a cross-platform, open standard set of APIs that allows programs to use GPU hardware in various ways,\n  from drawing on screen, to doing calculations, to decoding video via custom hardware accelerators.\n  Rather than using a custom hardware accelerator present, these codecs are based on compute shaders, and work\n  on any implementation of Vulkan 1.3.\n  Decoders use the same hwaccel API and commands, so users do not need to do anything special to enable them,\n  as enabling <a href=\"https://trac.ffmpeg.org/wiki/HWAccelIntro#Vulkan\">Vulkan decoding</a> is sufficient to use them.\n  Encoders, like our hardware accelerated encoders, require specifying a new encoder (ffv1_vulkan).\n  Currently, the only codecs supported are: FFv1 (encoding and decoding) and ProRes RAW (decode only).\n  ProRes (encode+decode) and VC-2 (encode+decode) implementations are complete and currently in review,\n  to be merged soon and available with the next minor release.<p>\n  Only codecs specifically designed for parallelized decoding can be implemented in such a way, with\n  more mainstream codecs not being planned for support.</p>\n  Depending on the hardware, these new codecs can provide very significant speedups, and open up\n  possibilities to work with them for situations like non-linear video editors and\n  lossless screen recording/streaming, so we are excited to learn what our downstream users can make with them.\n  </p><p>\n  The project has recently started to modernize its infrastructure. Our mailing list servers have been\n  fully upgraded, and we have recently started to accept contributions via a new forge, available on\n  <a href=\"https://code.ffmpeg.org/\">code.ffmpeg.org</a>, running a Forgejo instance.\n  </p><p>\n    As usual, we recommend that users, distributors, and system integrators to upgrade unless they use current git master.\n  </p><h3>September 30th, 2024, FFmpeg 7.1 </h3><p>\n    The more important highlights of the release are that the VVC decoder, merged as experimental in version 7.0,\n    has had enough time to mature and be optimized enough to be declared as stable. The codec is starting to gain\n    traction with broadcast standardization bodies.\n    Support has been added for a native AAC USAC (part of the xHE-AAC coding system) decoder, with the format starting\n    to be adopted by streaming websites, due to its extensive volume normalization metadata.<p>\n    MV-HEVC decoding is now supported. This is a stereoscopic coding tool that begun to be shipped and generated\n    by recent phones and VR headsets.</p>\n    LC-EVC decoding, an enhancement metadata layer to attempt to improve the quality of codecs, is now supported via an\n    external library.</p><p>\n    Support for Vulkan encoding, with H264 and HEVC was merged. This finally allows fully Vulkan-based decode-filter-encode\n    pipelines, by having a sink for Vulkan frames, other than downloading or displaying them. The encoders have feature-parity\n    with their VAAPI implementation counterparts. Khronos has announced that support for AV1 encoding is also coming soon to Vulkan,\n    and FFmpeg is aiming to have day-one support.\n  </p><p>\n    In addition to the above, this release has had a lot of important internal work done. By far, the standout internally\n    are the improvements made for full-range images. Previously, color range data had two paths, no negotiation,\n    and was unreliably forwarded to filters, encoders, muxers. Work on cleaning the system up started more than 10\n    years ago, however this stalled due to how fragile the system was, and that breaking behaviour would be unacceptable.\n    The new system fixes this, so now color range is forwarded correctly and consistently everywhere needed, and also\n    laid the path for more advanced forms of negotiation.\n    Cropping metadata is now supported with Matroska and MP4 formats. This metadata is important not only for archival,\n    but also with AV1, as hardware encoders require its signalling due to the codec not natively supporting one.\n  </p><p>\n    As usual, we recommend that users, distributors, and system integrators to upgrade unless they use current git master.\n  </p><h3>September 11th, 2024, Coverity</h3><p>\n  The number of issues FFmpeg has in <a href=\"https://scan.coverity.com/projects/ffmpeg\">Coverity (a static analyzer)</a> is now lower than it has been since 2016.\n  Our defect density is less than one 30th of the average in OSS with over a million code\n  lines. All this was possible thanks to a grant from the <a href=\"https://www.sovereigntechfund.de/\">Sovereign Tech Fund</a>.\n  </p><img src=\"https://ffmpeg.org/img/coverity-lifetime-2024-08.PNG\" alt=\"Coverity Lifetime Graph till 2024-08\"><h3>June 2nd, 2024, native xHE-AAC decoder</h3><p>\n  FFmpeg now implements a native xHE-AAC decoder. Currently, streams without (e)SBR, USAC or MPEG-H Surround\n  are supported, which means the majority of xHE-AAC streams in use should work. Support for USAC and (e)SBR is\n  coming soon. Work is also ongoing to improve its stability and compatibility.\n  During the process we found several specification issues, which were then submitted back to the authors\n  for discussion and potential inclusion in a future errata.\n  </p><h3>May 13th, 2024, Sovereign Tech Fund</h3><p>\n  The FFmpeg community is excited to announce that Germany's\n  <a href=\"https://www.sovereigntechfund.de/tech/ffmpeg\">Sovereign Tech Fund</a>\n  has become its first governmental sponsor. Their support will help\n  sustain the maintainance of the FFmpeg project, a critical open-source\n  software multimedia component essential to bringing audio and video to\n  billions around the world everyday.\n  </p><h3>April 5th, 2024, FFmpeg 7.0 \"Dijkstra\"</h3><p>\n  This release is  backwards compatible, removing APIs deprecated before 6.0.\n  The biggest change for most library callers will be the removal of the old bitmask-based\n  channel layout API, replaced by the  API allowing such\n  features as custom channel ordering, or Ambisonics. Certain deprecated \n  CLI options were also removed, and a C11-compliant compiler is now required to build\n  the code.\n  </p><p>\n  As usual, there is also a number of new supported formats and codecs, new filters, APIs,\n  and countless smaller features and bugfixes. Compared to 6.1, the  repository\n  contains almost ‚àº2000 new commits by ‚àº100 authors, touching &gt;100000 lines in\n  ‚àº2000 files ‚Äî thanks to everyone who contributed. See the\n  <a href=\"https://git.videolan.org/?p=ffmpeg.git;a=blob_plain;f=Changelog;hb=n7.0\">Changelog</a>,\n  <a href=\"https://git.videolan.org/?p=ffmpeg.git;a=blob_plain;f=doc/APIchanges;hb=n7.0\">APIchanges</a>,\n  and the git log for more comprehensive lists of changes.\n  </p><h3>January 3rd, 2024, native VVC decoder</h3><p>\n  The  library now contains a native VVC (Versatile Video Coding)\n  decoder, supporting a large subset of the codec's features. Further optimizations and\n  support for more features are coming soon. The code was written by Nuo Mi, Xu Mu,\n  Frank Plowman, Shaun Loo, and Wu Jianhua.\n  </p><h3>December 18th, 2023, IAMF support</h3><p>\n  The  library can now read and write <a href=\"https://aomediacodec.github.io/iamf/\">IAMF</a>\n  (Immersive Audio) files. The  CLI tool can configure IAMF structure with the new\n   option. IAMF support was written by James Almer.\n  </p><h3>December 12th, 2023, multi-threaded  CLI tool</h3><p>\n  Thanks to a major refactoring of the  command-line tool, all the major\n  components of the transcoding pipeline (demuxers, decoders, filters, encodes, muxers) now\n  run in parallel. This should improve throughput and CPU utilization, decrease latency,\n  and open the way to other exciting new features.\n  </p><p>\n  Note that you should  expect significant performance improvements in cases\n  where almost all computational time is spent in a single component (typically video\n  encoding).\n  </p><h3>November 10th, 2023, FFmpeg 6.1 \"Heaviside\"</h3><ul><li>Playdate video decoder and demuxer</li><li>Extend VAAPI support for libva-win32 on Windows</li><li>afireqsrc audio source filter</li><li>ffmpeg CLI new option: -readrate_initial_burst</li><li>zoneplate video source filter</li><li>command support in the setpts and asetpts filters</li><li>Vulkan decode hwaccel, supporting H264, HEVC and AV1</li><li>Essential Video Coding parser, muxer and demuxer</li><li>Essential Video Coding frame merge bsf</li><li>Microsoft RLE video encoder</li><li>Raw AC-4 muxer and demuxer</li><li>Raw VVC bitstream parser, muxer and demuxer</li><li>Bitstream filter for editing metadata in VVC streams</li><li>Bitstream filter for converting VVC from MP4 to Annex B</li><li>scale_vt filter for videotoolbox</li><li>transpose_vt filter for videotoolbox</li><li>support for the P_SKIP hinting to speed up libx264 encoding</li><li>Support HEVC,VP9,AV1 codec in enhanced flv format</li><li>apsnr and asisdr audio filters</li><li>Support HEVC,VP9,AV1 codec fourcclist in enhanced rtmp protocol</li><li>ffmpeg CLI '-top' option deprecated in favor of the setfield filter</li><li>ffprobe XML output schema changed to account for multiple variable-fields elements within the same parent element</li><li>ffprobe -output_format option added as an alias of -of</li></ul><p>\n    This release had been overdue for at least half a year, but due to constant activity in the repository,\n    had to be delayed, and we were finally able to branch off the release recently, before some of the large\n    changes scheduled for 7.0 were merged.\n  </p><p>\n    Internally, we have had a number of changes too. The FFT, MDCT, DCT and DST implementation used for codecs\n    and filters has been fully replaced with the faster libavutil/tx (full article about it coming soon).\n    This also led to a reduction in the the size of the compiled binary, which can be noticeable in small builds.<p>\n    There was a very large reduction in the total amount of allocations being done on each frame throughout video decoders,\n    reducing overhead.</p>\n    RISC-V optimizations for many parts of our DSP code have been merged, with mainly the large decoders being left.<p>\n    There was an effort to improve the correctness of timestamps and frame durations of each packet, increasing the\n    accurracy of variable frame rate video.\n  </p></p><p>\n    Next major release will be version 7.0, scheduled to be released in February. We will attempt to better stick\n    to the new release schedule we announced at the start of this year.\n  </p><p>\n    We strongly recommend users, distributors, and system integrators to upgrade unless they use current git master.\n  </p><h3>May 31st, 2023, Vulkan decoding</h3><p>\n    A few days ago, Vulkan-powered decoding hardware acceleration code was merged into the codebase.\n    This is the first vendor-generic and platform-generic decode acceleration API, enabling the\n    same code to be used on multiple platforms, with very minimal overhead.\n    This is also the first multi-threaded hardware decoding API, and our code makes full use of this,\n    saturating all available decode engines the hardware exposes.\n  </p><p>\n    Those wishing to test the code can read our\n    <a href=\"https://trac.ffmpeg.org/wiki/HWAccelIntro#Vulkan\">documentation page</a>.\n    For those who would like to integrate FFmpeg's Vulkan code to demux, parse, decode, and receive\n    a VkImage to present or manipulate, documentation and examples are available in our source tree.\n    Currently, using the latest available git checkout of our\n    <a href=\"https://git.videolan.org/?p=ffmpeg.git;a=summary\">repository</a> is required.\n    The functionality will be included in stable branches with the release of version 6.1, due\n    to be released soon.\n  </p><p>\n    As this is also the first practical implementation of the specifications, bugs may be present,\n    particularly in drivers, and, although passing verification, the implementation itself.\n    New codecs, and encoding support are also being worked on, by both the Khronos organization\n    for standardizing, and us as implementing it, and giving feedback on improving.\n  </p><h3>February 28th, 2023, FFmpeg 6.0 \"Von Neumann\"</h3><p>\n    A new major release, <a href=\"https://ffmpeg.org/download.html#release_6.0\">FFmpeg 6.0 \"Von Neumann\"</a>,\n    is now available for download. This release has many new encoders and decoders, filters,\n    ffmpeg CLI tool improvements, and also, changes the way releases are done. All major\n    releases will now bump the version of the ABI. We plan to have a new major release each\n    year. Another release-specific change is that deprecated APIs will be removed after 3\n    releases, upon the next major bump.\n    This means that releases will be done more often and will be more organized.\n  </p><p>\n    New decoders featured are Bonk, RKA, Radiance, SC-4, APAC, VQC, WavArc and a few ADPCM formats.\n    QSV and NVenc now support AV1 encoding. The FFmpeg CLI (we usually reffer to it as ffmpeg.c\n    to avoid confusion) has speed-up improvements due to threading, as well as statistics options,\n    and the ability to pass option values for filters from a file. There are quite a few new audio\n    and video filters, such as adrc, showcwt, backgroundkey and ssim360, with a few hardware ones too.\n    Finally, the release features many behind-the-scenes changes, including a new FFT and MDCT\n    implementation used in codecs (expect a blog post about this soon), numerous bugfixes, better\n    ICC profile handling and colorspace signalling improvement, introduction of a number of RISC-V\n    vector and scalar assembly optimized routines, and a few new improved APIs, which can be viewed\n    in the doc/APIchanges file in our tree.\n    A few submitted features, such as the Vulkan improvements and more FFT optimizations will be in the\n    next minor release, 6.1, which we plan to release soon, in line with our new release schedule.\n    Some highlights are:\n  </p><ul><li>Radiance HDR image support</li><li>ddagrab (Desktop Duplication) video capture filter</li><li>ffmpeg -shortest_buf_duration option</li><li>ffmpeg now requires threading to be built</li><li>ffmpeg now runs every muxer in a separate thread</li><li>Add new mode to cropdetect filter to detect crop-area based on motion vectors and edges</li><li>VAAPI decoding and encoding for 10/12bit 422, 10/12bit 444 HEVC and VP9</li><li>WBMP (Wireless Application Protocol Bitmap) image format</li><li>Micronas SC-4 audio decoder</li><li>nvenc AV1 encoding support</li><li>MediaCodec decoder via NDKMediaCodec</li><li>QSV decoding and encoding for 10/12bit 422, 10/12bit 444 HEVC and VP9</li><li>showcwt multimedia filter</li><li>WADY DPCM decoder and demuxer</li><li>ffmpeg CLI new options: -stats_enc_pre[_fmt], -stats_enc_post[_fmt], -stats_mux_pre[_fmt]</li><li>hstack_vaapi, vstack_vaapi and xstack_vaapi filters</li><li>XMD ADPCM decoder and demuxer</li><li>ffmpeg CLI new option: -fix_sub_duration_heartbeat</li><li>WavArc decoder and demuxer</li><li>CrystalHD decoders deprecated</li><li>filtergraph syntax in ffmpeg CLI now supports passing file contents as option values</li><li>hstack_qsv, vstack_qsv and xstack_qsv filters</li></ul><p>\n    We strongly recommend users, distributors, and system integrators to\n    upgrade unless they use current git master.\n  </p><h3>July 22nd, 2022, FFmpeg 5.1 \"Riemann\"</h3><ul><li>add ipfs/ipns protocol support</li><li>dialogue enhance audio filter</li><li>dropped obsolete XvMC hwaccel</li><li>DFPWM audio encoder/decoder and raw muxer/demuxer</li><li>Vizrt Binary Image encoder/decoder</li><li>colorchart video source filter</li><li>PGS subtitle frame merge bitstream filter</li><li>added chromakey_cuda filter</li></ul><p>\n    We strongly recommend users, distributors, and system integrators to\n    upgrade unless they use current git master.\n  </p><h3>January 17th, 2022, FFmpeg 5.0 \"Lorentz\"</h3><p><a href=\"https://ffmpeg.org/download.html#release_5.0\">FFmpeg 5.0 \"Lorentz\"</a>, a new\n    major release, is now available! For this long-overdue release, a major effort\n    underwent to remove the old encode/decode APIs and replace them with an\n    N:M-based API, the entire libavresample library was removed, libswscale\n    has a new, easier to use AVframe-based API, the Vulkan code was much improved,\n    many new filters were added, including libplacebo integration, and finally,\n    DoVi support was added, including tonemapping and remuxing. The default\n    AAC encoder settings were also changed to improve quality.\n    Some of the changelog highlights:\n  </p><ul><li>ADPCM IMA Westwood encoder</li><li>ADPCM IMA Acorn Replay decoder</li><li>Argonaut Games CVG demuxer</li><li>audio and video segment filters</li><li>Apple Graphics (SMC) encoder</li><li>hsvkey and hsvhold video filters</li><li>adecorrelate audio filter</li><li>AV1 Low overhead bitstream format muxer</li><li>huesaturation video filter</li><li>colorspectrum source video filter</li><li>RTP packetizer for uncompressed video (RFC 4175)</li><li>VideoToolbox ProRes hwaccel</li><li>aspectralstats audio filter</li><li>adynamicsmooth audio filter</li><li>vflip_vulkan, hflip_vulkan and flip_vulkan filters</li><li>adynamicequalizer audio filter</li><li>yadif_videotoolbox filter</li><li>VideoToolbox ProRes encoder</li></ul><p>\n    We strongly recommend users, distributors, and system integrators to\n    upgrade unless they use current git master.\n  </p><p>\n    We have a new IRC home at Libera Chat\n    now! Feel free to join us at #ffmpeg and #ffmpeg-devel. More info at <a href=\"https://ffmpeg.org/contact.html#IRCChannels\">contact#IRCChannels</a></p><h3>April 8th, 2021, FFmpeg 4.4 \"Rao\"</h3><p><a href=\"https://ffmpeg.org/download.html#release_4.4\">FFmpeg 4.4 \"Rao\"</a>, a new\n    major release, is now available! Some of the highlights:\n  </p><ul><li>AudioToolbox output device</li><li>VDPAU accelerated HEVC 10/12bit decoding</li><li>ADPCM IMA Ubisoft APM encoder</li><li>AV1 encoding support SVT-AV1</li><li>ADPCM Argonaut Games encoder</li><li>AV1 Low overhead bitstream format demuxer</li><li>MobiClip FastAudio decoder</li><li>AV1 decoder (Hardware acceleration used only)</li><li>Argonaut Games BRP demuxer</li><li>IPU decoder, parser and demuxer</li><li>Intel QSV-accelerated AV1 decoding</li><li>Argonaut Games Video decoder</li><li>libwavpack encoder removed</li><li>AVS3 video decoder via libuavs3d</li><li>VDPAU accelerated VP9 10/12bit decoding</li><li>afreqshift and aphaseshift filters</li><li>High Voltage Software ADPCM encoder</li><li>LEGO Racers ALP (.tun &amp; .pcm) muxer</li><li>DXVA2/D3D11VA hardware accelerated AV1 decoding</li><li>Microsoft Paint (MSP) version 2 decoder</li><li>Microsoft Paint (MSP) demuxer</li><li>AV1 monochrome encoding support via libaom &gt;= 2.0.1</li><li>asuperpass and asuperstop filter</li><li>Digital Pictures SGA demuxer and decoders</li><li>TTML subtitle encoder and muxer</li><li>RIST protocol via librist</li></ul><p>\n    We strongly recommend users, distributors, and system integrators to\n    upgrade unless they use current git master.\n  </p><h3>June 15th, 2020, FFmpeg 4.3 \"4:3\"</h3><p><a href=\"https://ffmpeg.org/download.html#release_4.3\">FFmpeg 4.3 \"4:3\"</a>, a new\n    major release, is now available! Some of the highlights:\n  </p><ul><li>Intel QSV-accelerated MJPEG decoding</li><li>Intel QSV-accelerated VP9 decoding</li><li>Support for TrueHD in mp4</li><li>Support AMD AMF encoder on Linux (via Vulkan)</li><li>support Sipro ACELP.KELVIN decoding</li><li>maskedmin and maskedmax filters</li><li>QSV-accelerated VP9 encoding</li><li>AV1 encoding support via librav1e</li><li>AV1 frame merge bitstream filter</li><li>MPEG-H 3D Audio support in mp4</li><li>Argonaut Games ADPCM decoder</li><li>Argonaut Games ASF demuxer</li><li>afirsrc audio filter source</li><li>Simon &amp; Schuster Interactive ADPCM decoder</li><li>High Voltage Software ADPCM decoder</li><li>LEGO Racers ALP (.tun &amp; .pcm) demuxer</li><li>AMQP 0-9-1 protocol (RabbitMQ)</li><li>avgblur_vulkan, overlay_vulkan, scale_vulkan and chromaber_vulkan filters</li><li>switch from AvxSynth to AviSynth+ on Linux</li><li>Expanded styling support for 3GPP Timed Text Subtitles (movtext)</li><li>Support for muxing pcm and pgs in m2ts</li><li>Cunning Developments ADPCM decoder</li><li>Pro Pinball Series Soundbank demuxer</li><li>pcm_rechunk bitstream filter</li><li>gradients source video filter</li><li>MediaFoundation encoder wrapper</li><li>Simon &amp; Schuster Interactive ADPCM encoder</li></ul><p>\n    We strongly recommend users, distributors, and system integrators to\n    upgrade unless they use current git master.\n  </p><h3>October 5th, 2019, Bright Lights</h3><p>\n  FFmpeg has added a realtime bright flash removal filter to libavfilter.\n  </p><p>\n  Note that this filter is not FDA approved, nor are we medical professionals.\n  Nor has this filter been tested with anyone who has photosensitive epilepsy.\n  FFmpeg and its photosensitivity filter are not making any medical claims.\n  </p><p>\n  That said, this is a new video filter that may help photosensitive people\n  watch tv, play video games or even be used with a VR headset to block\n  out epiletic triggers such as filtered sunlight when they are outside.\n  Or you could use it against those annoying white flashes on your tv screen.\n  The filter fails on some input, such as the\n  <a href=\"https://www.youtube.com/watch?v=8L_9hXnUzRk\">Incredibles 2 Screen Slaver</a>\n  scene. It is not perfect. If you have other clips that you want this filter to\n  work better on, please report them to us on our <a href=\"http://trac.ffmpeg.org\">trac</a>.\n  </p><p>\n  We are not professionals. Please use this in your medical studies to\n  advance epilepsy research. If you decide to use this in a medical\n  setting, or make a hardware hdmi input output realtime tv filter,\n  or find another use for this, <a href=\"mailto:compn@ffmpeg.org\">please let me know</a>.\n  This filter was a feature request of mine\n  <a href=\"https://trac.ffmpeg.org/ticket/2104\">since 2013</a>.\n  </p><h3>August 5th, 2019, FFmpeg 4.2 \"Ada\"</h3><p><a href=\"https://ffmpeg.org/download.html#release_4.2\">FFmpeg 4.2 \"Ada\"</a>, a new\n    major release, is now available! Some of the highlights:\n  </p><ul><li>AV1 decoding support through libdav1d</li><li>chromashift and rgbashift filters</li><li>truehd_core bitstream filter</li><li>libaribb24 based ARIB STD-B24 caption support (profiles A and C)</li><li>Support decoding of HEVC 4:4:4 content in nvdec and cuviddec</li><li>AV1 frame split bitstream filter</li><li>Support decoding of HEVC 4:4:4 content in vdpau</li><li>showspatial multimedia filter</li><li>mov muxer writes tracks with unspecified language instead of English by default</li><li>added support for using clang to compile CUDA kernels</li></ul><p>\n    We strongly recommend users, distributors, and system integrators to\n    upgrade unless they use current git master.\n  </p><h3>November 6th, 2018, FFmpeg 4.1 \"al-Khwarizmi\"</h3><ul><li>aderivative and aintegral audio filters</li><li>pal75bars and pal100bars video filter sources</li><li>mbedTLS based TLS support</li><li>adeclick and adeclip filters</li><li>libtensorflow backend for DNN based filters like srcnn</li><li>VC1 decoder is now bit-exact</li><li>AVS2 video decoder via libdavs2</li><li>Brooktree ProSumer video decoder</li><li>MatchWare Screen Capture Codec decoder</li><li>WinCam Motion Video decoder</li><li>RemotelyAnywhere Screen Capture decoder</li><li>Support for AV1 in MP4 and Matroska/WebM</li><li>AVS2 video encoder via libxavs2</li><li>Block-Matching 3d (bm3d) denoising filter</li><li>audio denoiser as afftdn filter</li><li>S12M timecode decoding in h264</li></ul><p>\n    We strongly recommend users, distributors, and system integrators to\n    upgrade unless they use current git master.\n  </p><h3>April 20th, 2018, FFmpeg 4.0 \"Wu\"</h3><p><a href=\"https://ffmpeg.org/download.html#release_4.0\">FFmpeg 4.0 \"Wu\"</a>, a new\n    major release, is now available! Some of the highlights:\n  </p><ul><li>Bitstream filters for editing metadata in H.264, HEVC and MPEG-2 streams</li><li>Experimental MagicYUV encoder</li><li>Intel QSV-accelerated MJPEG encoding</li><li>native aptX and aptX HD encoder and decoder</li><li>NVIDIA NVDEC-accelerated H.264, HEVC, MJPEG, MPEG-1/2/4, VC1, VP8/9 hwaccel decoding</li><li>Intel QSV-accelerated overlay filter</li><li>VAAPI MJPEG and VP8 decoding</li><li>AMD AMF H.264 and HEVC encoders</li><li>support LibreSSL (via libtls)</li><li>Dropped support for building for Windows XP. The minimum supported Windows version is Windows Vista.</li><li>hilbert audio filter source</li><li>Removed the ffserver program</li><li>Removed the ffmenc and ffmdec muxer and demuxer</li><li>VideoToolbox HEVC encoder and hwaccel</li><li>VAAPI-accelerated ProcAmp (color balance), denoise and sharpness filters</li><li>codec2 en/decoding via libcodec2</li><li>native SBC encoder and decoder</li><li>hapqa_extract bitstream filter</li><li>filter_units bitstream filter</li><li>AV1 Support through libaom</li><li>E-AC-3 dependent frames support</li><li>bitstream filter for extracting E-AC-3 core</li><li>Haivision SRT protocol via libsrt</li></ul><p>\n    We strongly recommend users, distributors, and system integrators to\n    upgrade unless they use current git master.\n  </p><h3>October 15th, 2017, FFmpeg 3.4 \"Cantor\"</h3><ul><li>oscilloscope video filter</li><li>update cuvid/nvenc headers to Video Codec SDK 8.0.14</li><li>scale_cuda CUDA based video scale filter</li><li>librsvg support for svg rasterization</li><li>spec compliant VP9 muxing support in MP4</li><li>sofalizer filter switched to libmysofa</li><li>Gremlin Digital Video demuxer and decoder</li><li>superequalizer audio filter</li><li>additional frame format support for Interplay MVE movies</li><li>support for decoding through D3D11VA in ffmpeg</li><li>Dolby E decoder and SMPTE 337M demuxer</li><li>unpremultiply video filter</li><li>raw G.726 muxer and demuxer, left- and right-justified</li><li>NewTek NDI input/output device</li><li>VP9 tile threading support</li><li>V4L2 mem2mem HW assisted codecs</li><li>Rockchip MPP hardware decoding</li></ul><p>\n    We strongly recommend users, distributors, and system integrators to\n    upgrade unless they use current git master.\n  </p><h3>April 13th, 2017, FFmpeg 3.3 \"Hilbert\"</h3><ul><li>PSD (Photoshop Document) decoder</li><li>FM Screen Capture decoder</li><li>DNxHR decoder fixes for HQX and high resolution videos</li><li>ClearVideo decoder (partial)</li><li>16.8 and 24.0 floating point PCM decoder</li><li>Intel QSV-accelerated VP8 video decoding</li><li>DNxHR 444 and HQX encoding</li><li>Quality improvements for the (M)JPEG encoder</li><li>VAAPI-accelerated MPEG-2 and VP8 encoding</li><li>abitscope multimedia filter</li><li>MPEG-7 Video Signature filter</li><li>add internal ebur128 library, remove external libebur128 dependency</li><li>Intel QSV video scaling and deinterlacing filters</li><li>Sample Dump eXchange demuxer</li><li>MIDI Sample Dump Standard demuxer</li><li>Scenarist Closed Captions demuxer and muxer</li><li>Support MOV with multiple sample description tables</li><li>Pro-MPEG CoP #3-R2 FEC protocol</li><li>Support for spherical videos</li><li>CrystalHD decoder moved to new decode API</li><li>configure now fails if autodetect-libraries are requested but not found</li></ul><p>\n    We strongly recommend users, distributors, and system integrators to\n    upgrade unless they use current git master.\n  </p><h3>October 30th, 2016, Results: Summer Of Code 2016.</h3><p>\n    This has been a long time coming but we wanted to give a proper closure to our participation in this run of the program and it takes time. Sometimes it's just to get the final report for each project trimmed down, others, is finalizing whatever was still in progress when the program finished: final patches need to be merged, TODO lists stabilized, future plans agreed; you name it.\n  </p><p>\n    Without further ado, here's the silver-lining for each one of the projects we sought to complete during this Summer of Code season:\n  </p><h4>FFv1 (Mentor: Michael Niedermayer)</h4><p>\n    Stanislav Dolganov designed and implemented experimental support for motion estimation and compensation in the lossless FFV1 codec. The design and implementation is based on the snow video codec, which uses OBMC. Stanislav's work proved that significant compression gains can be achieved with inter frame compression. FFmpeg welcomes Stanislav to continue working beyond this proof of concept and bring its advances into the official FFV1 specification within the IETF.\n  </p><h4>Self test coverage (Mentor: Michael Niedermayer)</h4><p>\n    Petru Rares Sincraian added several self-tests to FFmpeg and successfully went through the in-some-cases tedious process of fine tuning tests parameters to avoid known and hard to avoid problems, like checksum mismatches due to rounding errors on the myriad of platforms we support. His work has improved the code coverage of our self tests considerably.\n  </p><h4>MPEG-4 ALS encoder implementation (Mentor: Thilo Borgmann)</h4><p>\n    Umair Khan updated and integrated the ALS encoder to fit in the current FFmpeg codebase. He also implemented a missing feature for the ALS decoder that enables floating-point sample decoding. FFmpeg support for MPEG-4 ALS has been improved significantly by Umair's work. We welcome him to keep maintaining his improvements and hope for great contributions to come.\n  </p><h4>Tee muxer improvements (Mentor: Marton Balint)</h4><p>\n    J√°n Sebechlebsk√Ω's generic goal was to improve the tee muxer so it tolerated blocking IO and allowed transparent error recovery. During the design phase it turned out that this functionality called for a separate muxer, so J√°n spent his summer working on the so-called FIFO muxer, gradually fixing issues all over the codebase. He succeeded in his task, and the FIFO muxer is now part of the main repository, alongside several other improvements he made in the process.\n  </p><h4>TrueHD encoder (Mentor: Rostislav Pehlivanov)</h4><p>\n    Jai Luthra's objective was to update the out-of-tree and pretty much abandoned MLP (Meridian Lossless Packing) encoder for libavcodec and improve it to enable encoding to the TrueHD format. For the qualification period the encoder was updated such that it was usable and throughout the summer, successfully improved adding support for multi-channel audio and TrueHD encoding. Jai's code has been merged into the main repository now. While a few problems remain with respect to LFE channel and 32 bit sample handling, these are in the process of being fixed such that effort can be finally put in improving the encoder's speed and efficiency.\n  </p><h4>Motion interpolation filter (Mentor: Paul B Mahol)</h4><p>\n    Davinder Singh investigated existing motion estimation and interpolation approaches from the available literature and previous work by our own: Michael Niedermayer, and implemented filters based on this research. These filters allow motion interpolating frame rate conversion to be applied to a video, for example, to create a slow motion effect or change the frame rate while smoothly interpolating the video along the motion vectors. There's still work to be done to call these filters 'finished', which is rather hard all things considered, but we are looking optimistically at their future.\n  </p><p>\n    And that's it. We are happy with the results of the program and immensely thankful for the opportunity of working with such an amazing set of students. We can be a tough crowd but our mentors did an amazing job at hand holding our interns through their journey. Thanks also to Google for this wonderful program and to everyone that made room in their busy lives to help making GSoC2016 a success. See you in 2017!\n  </p><h3>September 24th, 2016, SDL1 support dropped.</h3><p>\n    Support for the SDL1 library has been dropped, due to it no longer being maintained (as of\n    January, 2012) and it being superseded by the SDL2 library. As a result, the SDL1 output device\n    has also been removed and replaced by an SDL2 implementation. Both the ffplay and opengl output\n    devices have been updated to support SDL2.\n  </p><h3>August 9th, 2016, FFmpeg 3.1.2 \"Laplace\"</h3><p><a href=\"https://ffmpeg.org/download.html#release_3.1\">FFmpeg 3.1.2</a>, a new point release from the 3.1 release branch, is now available!\n    It fixes several bugs.\n  </p><p>\n    We recommend users, distributors, and system integrators, to upgrade unless they use current git master.\n  </p><h3>July 10th, 2016, ffserver program being dropped</h3><p>\n    After thorough deliberation, we're announcing that we're about to drop the ffserver program from the project starting with the next release.\n    ffserver has been a problematic program to maintain due to its use of internal APIs, which complicated the recent cleanups to the libavformat\n    library, and block further cleanups and improvements which are desired by API users and will be easier to maintain. Furthermore the program has\n    been hard for users to deploy and run due to reliability issues, lack of knowledgable people to help and confusing configuration file syntax.\n    Current users and members of the community are invited to write a replacement program to fill the same niche that ffserver did using the new APIs\n    and to contact us so we may point users to test and contribute to its development.\n  </p><h3>July 1st, 2016, FFmpeg 3.1.1 \"Laplace\"</h3><p><a href=\"https://ffmpeg.org/download.html#release_3.1\">FFmpeg 3.1.1</a>, a new point release from the 3.1 release branch, is now available!\n    It mainly deals with a few ABI issues introduced in the previous release.\n  </p><p>\n    We strongly recommend users, distributors, and system integrators, especially those who experienced issues upgrading from 3.0, to\n    upgrade unless they use current git master.\n  </p><h3>June 27th, 2016, FFmpeg 3.1 \"Laplace\"</h3><ul><li>DXVA2-accelerated HEVC Main10 decoding</li><li>loop video filter and aloop audio filter</li><li>Bob Weaver deinterlacing filter</li><li>protocol blacklisting API</li><li>VC-2 HQ RTP payload format (draft v1) depacketizer and packetizer</li><li>VP9 RTP payload format (draft v2) packetizer</li><li>AudioToolbox audio decoders</li><li>AudioToolbox audio encoders</li><li>coreimage filter (GPU based image filtering on OSX)</li><li>bitstream filter for extracting DTS core</li><li>hash and framehash muxers</li><li>VAAPI-accelerated format conversion and scaling</li><li>libnpp/CUDA-accelerated format conversion and scaling</li><li>Duck TrueMotion 2.0 Real Time decoder</li><li>Wideband Single-bit Data (WSD) demuxer</li><li>VAAPI-accelerated H.264/HEVC/MJPEG encoding</li><li>DTS Express (LBR) decoder</li><li>Generic OpenMAX IL encoder with support for Raspberry Pi</li><li>IFF ANIM demuxer &amp; decoder</li><li>Direct Stream Transfer (DST) decoder</li><li>OpenExr improvements (tile data and B44/B44A support)</li><li>BitJazz SheerVideo decoder</li><li>CUDA CUVID H264/HEVC decoder</li><li>10-bit depth support in native utvideo decoder</li><li>libutvideo wrapper removed</li><li>YUY2 Lossless Codec decoder</li><li>VideoToolbox H.264 encoder</li></ul><p>\n    We strongly recommend users, distributors, and system integrators to\n    upgrade unless they use current git master.\n  </p><h3>March 16th, 2016, Google Summer of Code</h3><p>\n    FFmpeg has been accepted as a <a href=\"https://summerofcode.withgoogle.com/\">Google Summer of Code</a> open source organization. If you wish to\n    participate as a student see our <a href=\"https://trac.ffmpeg.org/wiki/SponsoringPrograms/GSoC/2016\">project ideas page</a>.\n    You can already get in contact with mentors and start working on qualification tasks as well as register at google and submit your project proposal draft.\n    Good luck!\n  </p><h3>February 15th, 2016, FFmpeg 3.0 \"Einstein\"</h3><p>\n    We strongly recommend users, distributors, and system integrators to\n    upgrade unless they use current git master.\n  </p><h3>January 30, 2016, Removing support for two external AAC encoders</h3><p>\n    We have just removed support for VisualOn AAC encoder (libvo-aacenc) and\n    libaacplus in FFmpeg master.\n  </p><p>\n    Even before marking our internal AAC encoder as\n    <a href=\"https://ffmpeg.org/index.html#aac_encoder_stable\">stable</a>, it was known that libvo-aacenc\n    was of an inferior quality compared to our native one for most samples.\n    However, the VisualOn encoder was used extensively by the Android Open\n    Source Project, and we would like to have a tested-and-true stable option\n    in our code base.\n  </p><p>\n    When first committed in 2011, libaacplus filled in the gap of encoding\n    High Efficiency AAC formats (HE-AAC and HE-AACv2), which was not supported\n    by any of the encoders in FFmpeg at that time.\n  </p><p>\n    The circumstances for both have changed. After the work spearheaded by\n    Rostislav Pehlivanov and Claudio Freire, the now-stable FFmpeg native AAC\n    encoder is ready to compete with much more mature encoders. The Fraunhofer\n    FDK AAC Codec Library for Android was added in 2012 as the fourth\n    supported external AAC encoder, and the one with the best quality and the\n    most features supported, including HE-AAC and HE-AACv2.\n  </p><p>\n    Therefore, we have decided that it is time to remove libvo-aacenc and\n    libaacplus. If you are currently using libvo-aacenc, prepare to transition\n    to the native encoder () when updating to the next version\n    of FFmpeg. In most cases it is as simple as merely swapping the encoder\n    name. If you are currently using libaacplus, start using FDK AAC\n    () with an appropriate  option\n    to select the exact AAC profile that fits your needs. In both cases, you\n    will enjoy an audible quality improvement and as well as fewer licensing\n    headaches.\n  </p><h3>January 16, 2016, FFmpeg 2.8.5, 2.7.5, 2.6.7, 2.5.10</h3><p>\n    We have made several new point releases ().\n    They fix various bugs, as well as CVE-2016-1897 and CVE-2016-1898.\n    Please see the changelog for each release for more details.\n  </p><p>\n    We recommend users, distributors and system integrators to upgrade unless they use\n    current git master.\n  </p><h3>December 5th, 2015, The native FFmpeg AAC encoder is now stable!</h3><p>\n    After seven years the native FFmpeg AAC encoder has had its experimental flag\n    removed and declared as ready for general use. The encoder is transparent\n    at 128kbps for most samples tested with artifacts only appearing in extreme\n    cases. Subjective quality tests put the encoder to be of equal or greater\n    quality than most of the other encoders available to the public.\n  </p><p>\n    Licensing has always been an issue with encoding AAC audio as most of the\n    encoders have had a license making FFmpeg unredistributable if compiled with\n    support for them. The fact that there now exists a fully open and truly\n    free AAC encoder integrated directly within the project means a lot to those\n    who wish to use accepted and widespread standards.\n  </p><p>\n    The majority of the work done to bring the encoder up to quality was started\n    during this year's GSoC by developer Claudio Freire and Rostislav Pehlivanov.\n    Both continued to work on the encoder with the latter joining as a developer\n    and mainainer, working on other parts of the project as well. Also, thanks\n    to <a href=\"http://d.hatena.ne.jp/kamedo2/\">Kamedo2</a> who does comparisons\n    and tests, the original authors and all past and current contributors to the\n    encoder. Users are suggested and encouraged to use the encoder and provide\n    feedback or breakage reports through our <a href=\"https://trac.ffmpeg.org/\">bug tracker</a>.\n  </p><p>\n    A big thank you note goes to our newest supporters: MediaHub and Telepoint.\n    Both companies have donated a dedicated server with free of charge internet\n    connectivity. Here is a little bit about them in their own words:\n  </p><ul><li><p><a href=\"http://www.telepoint.bg/en/\">Telepoint</a> is the biggest\n        carrier-neutral data center in Bulgaria. Located in the heart of Sofia\n        on a cross-road of many Bulgarian and International networks, the\n        facility is a fully featured Tier 3 data center that provides flexible\n        customer-oriented colocation solutions (ranging from a server to a\n        private collocation hall) and a high level of security.\n      </p></li><li><p>\n        MediaHub Ltd. is a Bulgarian IPTV platform and services provider which\n        uses FFmpeg heavily since it started operating a year ago. <i>\"Donating\n        to help keep FFmpeg online is our way of giving back to the community\"\n        </i>.\n      </p></li></ul><p>\n    Thanks Telepoint and MediaHub for their support!\n  </p><h3>September 29th, 2015, GSoC 2015 results</h3><p>\n    FFmpeg participated to the latest edition of\n    the <a href=\"http://www.google-melange.com/gsoc/homepage/google/gsoc2015\">Google\n    Summer of Code</a> Project. FFmpeg got a total of 8 assigned\n    projects, and 7 of them were successful.\n  </p><p>We want to thank <a href=\"https://www.google.com\">Google</a>, the\n    participating students, and especially the mentors who joined this\n    effort. We're looking forward to participating in the next GSoC\n    edition!\n  </p><p>\n    Below you can find a brief description of the final outcome of\n    each single project.\n  </p><h4>Basic servers for network protocols, mentee: Stephan Holljes, mentor: Nicolas George</h4><p>\n    Stephan Holljes's project for this session of Google Summer of Code was to\n    implement basic HTTP server features for libavformat, to complement the\n    already present HTTP client and RTMP and RTSP server code.\n  </p><p>\n    The first part of the project was to make the HTTP code capable of accepting\n    a single client; it was completed partly during the qualification period and\n    partly during the first week of the summer. Thanks to this work, it is now\n    possible to make a simple HTTP stream using the following commands:\n  </p><pre>    ffmpeg -i /dev/video0 -listen 1 -f matroska \\\n    -c:v libx264 -preset fast -tune zerolatency http://:8080\n    ffplay http://localhost:8080/\n  </pre><p>\n    The next part of the project was to extend the code to be able to accept\n    several clients, simultaneously or consecutively. Since libavformat did not\n    have an API for that kind of task, it was necessary to design one. This part\n    was mostly completed before the midterm and applied shortly afterwards.\n    Since the ffmpeg command-line tool is not ready to serve several clients,\n    the test ground for that new API is an example program serving hard-coded\n    content.\n  </p><p>\n    The last and most ambitious part of the project was to update ffserver to\n    make use of the new API. It would prove that the API is usable to implement\n    real HTTP servers, and expose the points where more control was needed. By\n    the end of the summer, a first working patch series was undergoing code\n    review.\n  </p><h4>Browsing content on the server, mentee: Mariusz Szczepa≈Ñczyk, mentor: Lukasz Marek</h4><p>\n    Mariusz finished an API prepared by the FFmpeg community and implemented\n    Samba directory listing as qualification task.\n  </p><p>\n    During the program he extended the API with the possibility to\n    remove and rename files on remote servers. He completed the\n    implementation of these features for file, Samba, SFTP, and FTP\n    protocols.\n  </p><p>\n    At the end of the program, Mariusz provided a sketch of an\n    implementation for HTTP directory listening.\n  </p><h4>Directshow digital video capture, mentee: Mate Sebok, mentor: Roger Pack</h4><p>\n    Mate was working on directshow input from digital video sources. He\n    got working input from ATSC input sources, with specifiable tuner.\n  </p><p>\n    The code has not been committed, but a patch of it was sent to the\n    ffmpeg-devel mailing list for future use.\n  </p><p>\n    The mentor plans on cleaning it up and committing it, at least for the\n    ATSC side of things. Mate and the mentor are still working trying to\n    finally figure out how to get DVB working.\n  </p><h4>Implementing full support for 3GPP Timed Text Subtitles, mentee: Niklesh Lalwani, mentor: Philip Langdale</h4><p>\n    Niklesh's project was to expand our support for 3GPP Timed Text\n    subtitles. This is the native subtitle format for mp4 containers, and\n    is interesting because it's usually the only subtitle format supported\n    by the stock playback applications on iOS and Android devices.\n  </p><p>\n    ffmpeg already had basic support for these subtitles which ignored all\n    formatting information - it just provided basic plain-text support.\n  </p><p>\n    Niklesh did work to add support on both the encode and decode side for\n    text formatting capabilities, such as font size/colour and effects like\n    bold/italics, highlighting, etc.\n  </p><p>\n    The main challenge here is that Timed Text handles formatting in a very\n    different way from most common subtitle formats. It uses a binary\n    encoding (based on mp4 boxes, naturally) and stores information\n    separately from the text itself. This requires additional work to track\n    which parts of the text formatting applies to, and explicitly dealing\n    with overlapping formatting (which other formats support but Timed\n    Text does not) so it requires breaking the overlapping sections into\n    separate non-overlapping ones with different formatting.\n  </p><p>\n    Finally, Niklesh had to be careful about not trusting any size\n    information in the subtitles - and that's no joke: the now infamous\n    Android stagefright bug was in code for parsing Timed Text subtitles.\n  </p><p>\n    All of Niklesh's work is committed and was released in ffmpeg 2.8.\n  </p><h4>libswscale refactoring, mentee: Pedro Arthur, mentors: Michael Niedermayer, Ramiro Polla</h4><p>\n    Pedro Arthur has modularized the vertical and horizontal scalers.\n    To do this he designed and implemented a generic filter framework\n    and moved the existing scaler code into it. These changes now allow\n    easily adding removing, splitting or merging processing steps.\n    The implementation was benchmarked and several alternatives were\n    tried to avoid speed loss.\n  </p><p>\n    He also added gamma corrected scaling support.\n    An example to use gamma corrected scaling would be:\n  </p><pre>    ffmpeg -i input -vf scale=512:384:gamma=1 output\n  </pre><p>\n    Pedro has done impressive work considering the short time available,\n    and he is a FFmpeg committer now. He continues to contribute to\n    FFmpeg, and has fixed some bugs in libswscale after GSoC has\n    ended.\n  </p><h4>AAC Encoder Improvements, mentee: Rostislav Pehlivanov, mentor: Claudio Freire</h4><p>\n    Rostislav Pehlivanov has implemented PNS, TNS, I/S coding and main\n    prediction on the native AAC encoder. Of all those extensions, only\n    TNS was left in a less-than-usable state, but the implementation has\n    been pushed (disabled) anyway since it's a good basis for further\n    improvements.\n  </p><p>\n    PNS replaces noisy bands with a single scalefactor representing the\n    energy of that band, gaining in coding efficiency considerably, and\n    the quality improvements on low bitrates are impressive for such a\n    simple feature.\n  </p><p>\n    TNS still needs some polishing, but has the potential to reduce coding\n    artifacts by applying noise shaping in the temporal domain (something\n    that is a source of annoying, notable distortion on low-entropy\n    bands).\n  </p><p>\n    Intensity Stereo coding (I/S) can double coding efficiency by\n    exploiting strong correlation between stereo channels, most effective\n    on pop-style tracks that employ panned mixing. The technique is not as\n    effective on classic X-Y recordings though.\n  </p><p>\n    Finally, main prediction improves coding efficiency by exploiting\n    correlation among successive frames. While the gains have not been\n    huge at this point, Rostislav has remained active even after the GSoC,\n    and is polishing both TNS and main prediction, as well as looking for\n    further improvements to make.\n  </p><p>\n    In the process, the MIPS port of the encoder was broken a few times,\n    something he's also working to fix.\n  </p><h4>Animated Portable Network Graphics (APNG), mentee: Donny Yang, mentor: Paul B Mahol</h4><p>\n    Donny Yang implemented basic keyframe only APNG encoder as the\n    qualification task. Later he wrote interframe compression via\n    various blend modes. The current implementation tries all blend\n    modes and picks one which takes the smallest amount of memory.\n  </p><p>\n    Special care was taken to make sure that the decoder plays\n    correctly all files found in the wild and that the encoder\n    produces files that can be played in browsers that support APNG.\n  </p><p>\n    During his work he was tasked to fix any encountered bug in the\n    decoder due to the fact that it doesn't match APNG\n    specifications. Thanks to this work, a long standing bug in the\n    PNG decoder has been fixed.\n  </p><p>\n    For latter work he plans to continue working on the encoder,\n    making it possible to select which blend modes will be used in the\n    encoding process. This could speed up encoding of APNG files.\n  </p><h3>September 9th, 2015, FFmpeg 2.8</h3><p>\n    We published release  as new major version.\n    It contains all features and bug fixes of the git master branch from September 8th. Please see\n    the \n    for a list of the most important changes.\n  </p><p>\n    We recommend users, distributors and system integrators to upgrade unless they use current git master.\n  </p><h3>August 1st, 2015, A message from the FFmpeg project</h3><p>\n    Dear multimedia community,\n  </p><p>\n    The resignation of Michael Niedermayer as leader of FFmpeg yesterday has\n    come by surprise. He has worked tirelessly on the FFmpeg project for many\n    years and we must thank him for the work that he has done. We hope that in\n    the future he will continue to contribute to the project. In the coming\n    weeks, the FFmpeg project will be managed by the active contributors.\n  </p><p>\n    The last four years have not been easy for our multimedia community - both\n    contributors and users. We should now look to the future, try to find\n    solutions to these issues, and to have reconciliation between the forks,\n    which have split the community for so long.\n  </p><p>\n    Unfortunately, much of the disagreement has taken place in inappropriate\n    venues so far, which has made finding common ground and solutions\n    difficult. We aim to discuss this in our communities online over the coming\n    weeks, and in person at the <a href=\"https://www.videolan.org/videolan/events/vdd15/\">VideoLAN Developer\n    Days</a> in Paris in September: a neutral venue for the entire open source\n    multimedia community.\n  </p><h3>July 4th, 2015, FFmpeg needs a new host</h3><p> We have received more than 7 offers for hosting and servers, thanks a lot to everyone!</p><p>\n    After graciously hosting our projects (<a href=\"http://www.ffmpeg.org\">FFmpeg</a>, <a href=\"http://www.mplayerhq.hu\">MPlayer</a>\n    and <a href=\"http://rtmpdump.mplayerhq.hu\">rtmpdump</a>) for 4 years, Arpi (our hoster) has informed us that we have to secure a new host somewhere else immediately.\n  </p><p>\n    If you want to host an open source project, please let us know, either on <a href=\"http://ffmpeg.org/mailman/listinfo/ffmpeg-devel\">ffmpeg-devel</a>\n    mailing list or irc.freenode.net #ffmpeg-devel.\n  </p><p>\n    We use about 4TB of storage and at least 4TB of bandwidth / month for various mailing lists, <a href=\"http://trac.ffmpeg.org\">trac</a>, <a href=\"http://samples.ffmpeg.org\">samples repo</a>, svn, etc.\n  </p><h3>March 16, 2015, FFmpeg 2.6.1</h3><p>\n    We have made a new major release ()\n    and now one week afterward 2.6.1. It contains all features and bugfixes of the git master branch from the 6th March.\n    Please see the  for a\n    list of note-worthy changes.\n  </p><p>\n    We recommend users, distributors and system integrators to upgrade unless they use\n    current git master.\n  </p><h3>March 4, 2015, Google Summer of Code</h3><p>\n    FFmpeg has been accepted as a <a href=\"http://www.google-melange.com/gsoc/homepage/google/gsoc2015\">Google Summer of Code</a> Project. If you wish to\n    participate as a student see our <a href=\"https://trac.ffmpeg.org/wiki/SponsoringPrograms/GSoC/2015\">project ideas page</a>.\n    You can already get in contact with mentors and start working on qualification tasks. Registration\n    at Google for students will open March 16th. Good luck!\n  </p><h3>March 1, 2015, Chemnitzer Linux-Tage</h3><p>\n    We happily announce that FFmpeg will be represented at Chemnitzer Linux-Tage\n    (CLT) in Chemnitz, Germany. The event will take place on 21st and 22nd of March.\n  </p><p>\n    More information can be found <a href=\"https://chemnitzer.linux-tage.de/2015/en/\">here</a></p><p>\n    We demonstrate usage of FFmpeg, answer your questions and listen to\n    your problems and wishes. <strong>If you have media files that cannot be\n    processed correctly with FFmpeg, be sure to have a sample with you\n    so we can have a look!</strong></p><p>\n    For the first time in our CLT history, there will be an !\n    You can read the details <a href=\"https://chemnitzer.linux-tage.de/2015/de/programm/beitrag/209\">here</a>.\n    The workshop is targeted at FFmpeg beginners. First the basics of\n    multimedia will be covered. Thereafter you will learn how to use\n    that knowledge and the FFmpeg CLI tools to analyse and process media\n    files. The workshop is in German language only and prior registration\n    is necessary. The workshop will be on Saturday starting at 10 o'clock.\n  </p><p>\n    We are looking forward to meet you (again)!\n  </p><h3>December 5, 2014, FFmpeg 2.5</h3><p>\n    We have made a new major release ()\n    It contains all features and bugfixes of the git master branch from the 4th December.\n    Please see the  for a\n    list of note-worthy changes.\n  </p><p>\n    We recommend users, distributors and system integrators to upgrade unless they use\n    current git master.\n  </p><h3>October 10, 2014, FFmpeg is in Debian unstable again</h3><p>\n    We wanted you to know there are\n    <a href=\"https://packages.debian.org/search?keywords=ffmpeg&amp;searchon=sourcenames&amp;suite=unstable&amp;section=main\">\n    FFmpeg packages in Debian unstable</a> again. <strong>A big thank-you\n    to Andreas Cadhalpun and all the people that made it possible.</strong> It has been anything but simple.\n  </p><p>\n    Unfortunately that was already the easy part of this news. The bad news is the packages probably won't\n    migrate to Debian testing to be in the upcoming release codenamed jessie.\n    <a href=\"https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=763148\">Read the argumentation over at Debian.</a></p><p><strong>However things will come out in the end, we hope for your continued remarkable support!</strong></p><h3>October 8, 2014, FFmpeg secured a place in OPW!</h3><p>\n    Thanks to a generous 6K USD donation by Samsung (Open Source Group),\n    FFmpeg will be welcoming at least 1 \"Outreach Program for Women\" intern\n    to work with our community for an initial period starting December 2014\n    (through March 2015).\n  </p><p>\n    We all know FFmpeg is used by the industry, but even while there are\n    countless products building on our code, it is not at all common for\n    companies to step up and help us out when needed. So a big thank-you\n    to Samsung and the OPW program committee!\n  </p><p>\n    If you are thinking on participating in OPW as an intern, please take\n    a look at our <a href=\"https://trac.ffmpeg.org/wiki/SponsoringPrograms/OPW/2014-12\">OPW wiki page</a>\n    for some initial guidelines. The page is still a work in progress, but\n    there should be enough information there to get you started. If you, on\n    the other hand, are thinking on sponsoring work on FFmpeg through the\n    OPW program, please get in touch with us at opw@ffmpeg.org. With your\n    help, we might be able to secure some extra intern spots for this round!\n  </p><h3>September 15, 2014, FFmpeg 2.4</h3><p>\n    We have made a new major release ()\n    It contains all features and bugfixes of the git master branch from the 14th September.\n    Please see the  for a\n    list of note-worthy changes.\n  </p><p>\n    We recommend users, distributors and system integrators to upgrade unless they use\n    current git master.\n  </p><h3>August 20, 2014, FFmpeg 2.3.3, 2.2.7, 1.2.8</h3><p>\n    We have made several new point releases ().\n    They fix various bugs, as well as CVE-2014-5271 and CVE-2014-5272.\n    Please see the changelog for more details.\n  </p><p>\n    We recommend users, distributors and system integrators to upgrade unless they use\n    current git master.\n  </p><h3>July 29, 2014, Help us out securing our spot in OPW</h3><p>\n    Following our previous post regarding our participation on this year's\n    OPW (Outreach Program for Women), we are now reaching out to our users\n    (both individuals and companies) to help us gather the needed money to\n    secure our spot in the program.\n    We need to put together 6K USD as a minimum but securing more funds would\n    help us towards getting more than one intern.<p>\n    You can donate by credit card using\n    </p><a href=\"https://co.clickandpledge.com/advanced/default.aspx?wid=56226\">\n    Click&amp;Pledge</a> and selecting the \"OPW\" option. If you would like to\n    donate by money transfer or by check, please get in touch by\n    <a href=\"mailto:opw@ffmpeg.org\">e-mail</a> and we will get back to you\n    with instructions.Thanks!\n  </p><h3>July 20, 2014, New website</h3><p>\n    The FFmpeg project is proud to announce a brand new version of the website\n    made by <a href=\"http://db0.fr\">db0</a>. While this was initially motivated\n    by the need for a larger menu, the whole website ended up being redesigned,\n    and most pages got reworked to ease navigation. We hope you'll enjoy\n    browsing it.\n  </p><h3>July 17, 2014, FFmpeg 2.3</h3><p>\n    We have made a new major release ()\n    It contains all features and bugfixes of the git master branch from the 16th July.\n    Please see the  for a\n    list of note-worthy changes.\n  </p><p>\n    We recommend users, distributors and system integrators to upgrade unless they use\n    current git master.\n  </p><h3>July 3, 2014, FFmpeg and the Outreach Program For Women</h3><p>\n    FFmpeg has started the process to become an OPW includer organization for the\n    next round of the program, with internships starting December 9. The\n    <a href=\"https://gnome.org/opw/\">OPW</a> aims to \"Help women (cis and trans)\n    and genderqueer to get involved in free and open source software\". Part of the\n    process requires securing funds to support at least one internship (6K USD), so\n    if you were holding on your donation to FFmpeg, this is a great chance for you\n    to come forward, get in touch and help both the project and a great initiative!\n  </p><p>\n    We have set up an <a href=\"mailto:opw@ffmpeg.org\">email address</a> you can use\n    to contact us about donations and general inquires regarding our participation\n    in the program. Hope to hear from you soon!\n  </p><h3>June 29, 2014, FFmpeg 2.2.4, 2.1.5, 2.0.5, 1.2.7, 1.1.12, 0.10.14</h3><p>\n    We recommend users, distributors and system integrators to upgrade unless they use\n    current git master.\n  </p><p>\n    Once again FFmpeg will be represented at LinuxTag in Berlin, Germany. The event will\n    take place from 8th to 10th of May. Please note that this year's LinuxTag is at a\n    different location closer to the city center.\n  </p><p>\n    We will have a shared booth with XBMC and VideoLAN.\n    <b>\n      If you have media files that cannot be processed correctly with\n      FFmpeg, be sure to have a sample with you so we can have a look!\n    </b></p><p>\n    More information about LinuxTag can be found <a href=\"http://www.linuxtag.org/2014/\">here</a></p><p>\n    We are looking forward to see you in Berlin!\n  </p><h3>April 18, 2014, OpenSSL Heartbeat bug</h3><p>\n    Our server hosting the Trac issue tracker was vulnerable to the attack\n    against OpenSSL known as \"heartbleed\". The OpenSSL software library\n    was updated on 7th of April, shortly after the vulnerability was publicly\n    disclosed. We have changed the private keys (and certificates) for all\n    FFmpeg servers. The details were sent to the mailing lists by\n    Alexander Strasser, who is part of the project server team. Here is a\n    link to the user mailing list\n    <a href=\"https://lists.ffmpeg.org/pipermail/ffmpeg-user/2014-April/020968.html\">archive</a>\n    .\n  </p><p>\n    We encourage you to read up on\n    <a href=\"https://www.schneier.com/blog/archives/2014/04/heartbleed.html\">\"OpenSSL heartbleed\"</a>.\n    <b>It is possible that login data for the issue tracker was exposed to\n      people exploiting this security hole. You might want to change your password\n      in the tracker and everywhere else you used that same password.</b></p><h3>April 11, 2014, FFmpeg 2.2.1</h3><p>\n    We have made a new point releases ().\n    It contains bug fixes for Tickets #2893, #3432, #3469, #3486, #3495 and #3540 as well as\n    several other fixes.\n    See the git log for details.\n  </p><h3>March 24, 2014, FFmpeg 2.2</h3><p>\n    We have made a new major release ()\n    It contains all features and bugfixes of the git master branch from 1st March.\n    A partial list of new stuff is below:\n  </p><pre>    - HNM version 4 demuxer and video decoder\n    - Live HDS muxer\n    - setsar/setdar filters now support variables in ratio expressions\n    - elbg filter\n    - string validation in ffprobe\n    - support for decoding through VDPAU in ffmpeg (the -hwaccel option)\n    - complete Voxware MetaSound decoder\n    - remove mp3_header_compress bitstream filter\n    - Windows resource files for shared libraries\n    - aeval filter\n    - stereoscopic 3d metadata handling\n    - WebP encoding via libwebp\n    - ATRAC3+ decoder\n    - VP8 in Ogg demuxing\n    - side &amp; metadata support in NUT\n    - framepack filter\n    - XYZ12 rawvideo support in NUT\n    - Exif metadata support in WebP decoder\n    - OpenGL device\n    - Use metadata_header_padding to control padding in ID3 tags (currently used in\n    MP3, AIFF, and OMA files), FLAC header, and the AVI \"junk\" block.\n    - Mirillis FIC video decoder\n    - Support DNx444\n    - libx265 encoder\n    - dejudder filter\n    - Autodetect VDA like all other hardware accelerations\n  </pre><p>\n    We recommend users, distributors and system integrators to upgrade unless they use\n    current git master.\n  </p><h3>February 3, 2014, Chemnitzer Linux-Tage</h3><p>\n    We happily announce that FFmpeg will be represented at `Chemnitzer Linux-Tage'\n    in Chemnitz, Germany. The event will take place on 15th and 16th of March.\n  </p><p>\n    More information can be found <a href=\"http://chemnitzer.linux-tage.de/2014/en/info/\">here</a></p><p>\n    We invite you to visit us at our booth located in the Linux-Live area!\n    There we will demonstrate usage of FFmpeg, answer your questions and listen to\n    your problems and wishes.\n  </p><p><b>\n      If you have media files that cannot be processed correctly with\n      FFmpeg, be sure to have a sample with you so we can have a look!\n    </b></p><p>\n    We are looking forward to meet you (again)!\n  </p><h3>February 9, 2014, trac.ffmpeg.org / trac.mplayerhq.hu Security Breach</h3><p>\n    The server on which FFmpeg and MPlayer Trac issue trackers were\n    installed was compromised. The affected server was taken offline\n    and has been replaced and all software reinstalled.\n    FFmpeg Git, releases, FATE, web and mailinglists are on other servers\n    and were not affected. We believe that the original compromise happened\n    to a server, unrelated to FFmpeg and MPlayer, several months ago.\n    That server was used as a source to clone the VM that we recently moved\n    Trac to. It is not known if anyone used the backdoor that was found.\n  </p><p>\n    We recommend all users to change their passwords.\n    <b>Especially users who use a password on Trac that they also use\n      elsewhere, should change that password at least elsewhere.</b></p><h3>November 12, 2013, FFmpeg RFP in Debian</h3><p>\n    Since the splitting of Libav the Debian/Ubuntu maintainers have followed\n    the Libav fork. Many people have requested the packaging of ffmpeg in\n    Debian, as it is more feature-complete and in many cases less buggy.\n  </p><p><a href=\"http://cynic.cc/blog/\">Rog√©rio Brito</a>, a Debian developer,\n    has proposed a Request For Package (RFP) in the Debian bug tracking\n    system.\n  </p><p>\n    Please let the Debian and Ubuntu developers know that you support packaging\n    of the real FFmpeg! See Debian <a href=\"http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=729203\">ticket #729203</a>\n    for more details.\n  </p><h3>October 28, 2013, FFmpeg 2.1</h3><p>\n    We have made a new major release ()\n    It contains all features and bugfixes of the git master branch from 28th October.\n    A partial list of new stuff is below:\n  </p><pre>    - aecho filter\n    - perspective filter ported from libmpcodecs\n    - ffprobe -show_programs option\n    - compand filter\n    - RTMP seek support\n    - when transcoding with ffmpeg (i.e. not streamcopying), -ss is now accurate\n    even when used as an input option. Previous behavior can be restored with\n    the -noaccurate_seek option.\n    - ffmpeg -t option can now be used for inputs, to limit the duration of\n    data read from an input file\n    - incomplete Voxware MetaSound decoder\n    - read EXIF metadata from JPEG\n    - DVB teletext decoder\n    - phase filter ported from libmpcodecs\n    - w3fdif filter\n    - Opus support in Matroska\n    - FFV1 version 1.3 is stable and no longer experimental\n    - FFV1: YUVA(444,422,420) 9, 10 and 16 bit support\n    - changed DTS stream id in lavf mpeg ps muxer from 0x8a to 0x88, to be\n    more consistent with other muxers.\n    - adelay filter\n    - pullup filter ported from libmpcodecs\n    - ffprobe -read_intervals option\n    - Lossless and alpha support for WebP decoder\n    - Error Resilient AAC syntax (ER AAC LC) decoding\n    - Low Delay AAC (ER AAC LD) decoding\n    - mux chapters in ASF files\n    - SFTP protocol (via libssh)\n    - libx264: add ability to encode in YUVJ422P and YUVJ444P\n    - Fraps: use BT.709 colorspace by default for yuv, as reference fraps decoder does\n    - make decoding alpha optional for prores, ffv1 and vp6 by setting\n    the skip_alpha flag.\n    - ladspa wrapper filter\n    - native VP9 decoder\n    - dpx parser\n    - max_error_rate parameter in ffmpeg\n    - PulseAudio output device\n    - ReplayGain scanner\n    - Enhanced Low Delay AAC (ER AAC ELD) decoding (no LD SBR support)\n    - Linux framebuffer output device\n    - HEVC decoder, raw HEVC demuxer, HEVC demuxing in TS, Matroska and MP4\n    - mergeplanes filter\n  </pre><p>\n    We recommend users, distributors and system integrators to upgrade unless they use\n    current git master.\n  </p>","contentLength":60817,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44985730"},{"title":"Does Rust complexity ever bother you?","url":"https://www.reddit.com/r/rust/comments/1mx8izf/does_rust_complexity_ever_bother_you/","date":1755874050,"author":"/u/GolangLinuxGuru1979","guid":615,"unread":true,"content":"<p>I'm a Go developer and I've always had a curiosity about Rust. I've tried to play around and start some personal project in it a few times. And it's mostly been ok. Like I tried to use <a href=\"http://hyper.rs\">hyper.rs</a> a few times, but the boilerplate takes a lot to understand in many of the examples. I've tried to use tokio, but the library is massive, and it gets difficult to understand which modules to important and now important. On top of that it drastically change the async functons</p><p>I'm saying all that to say Rust is very complicated. And while I do think there is a fantastic langauge under all that complexity, it prohibitively complex. I do get it that memory safety in domains like RTOS systems or in government spaces is crucial. But it feels like Rust thought leaders are trying to get the language adopted in other domains. Which I think is a bit of an issue because you're not competing with other languages where its much easier to be productive in.</p><p>Here is my main gripe with the adoption. Lots of influencers in the Rust space just seem to overlook its complexity as if its no big deal. Or you have others who embrace it because Rust \"has to be complex\". But I feel in the enterprise (where adoption matters most), no engineering manager is really going to adopt a language this complex.</p><p>Now I understand languages like C# and Java can be complex as well. But Java at one time was looked at as a far simpler version of C++, and was an \"Easy language\". It would grow in complexity as the language grew and the same with C#. And then there is also tooling to kind of easy you into the more complex parts of these languages.</p><p>I would love to see Rust adopted more, I would. But I feel advociates aren't leaning into its domain where its an open and shut case for (mission critical systems requiring strict safety standards). And is instead also trying to compete in spaces where Go, Javascript, Java already have a strong foothold.</p><p>Again this is not to critcize Rust. I like the language. But I feel too many people in the Rust community talk around its complexity.</p>","contentLength":2054,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Cargo inspired C/C++ build tool, written in rust","url":"https://github.com/EmVance1/VanGo","date":1755872267,"author":"/u/MNGay","guid":614,"unread":true,"content":"<p>Using rust for the past 3 years or so got me thinking, why can't it always be this easy? Following this, I've spent the last 10 months (on-off due to studies) developing a tool for personal use, and I'd love to see what people think about it. Introducing VanGo, if you'll excuse the pun.</p>","contentLength":287,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/rust/comments/1mx7rnc/cargo_inspired_cc_build_tool_written_in_rust/"},{"title":"Go concurrency without the channel gymnastics","url":"https://www.reddit.com/r/golang/comments/1mx7art/go_concurrency_without_the_channel_gymnastics/","date":1755871173,"author":"/u/marketbase","guid":554,"unread":true,"content":"<p>Hey y‚Äôall. I noticed every time I fan-in / fan-out in Go, I end up writing the same channel boilerplate. Got tired of it, so I built a library to one-line the patterns.</p><pre><code>// Before sem := make(chan struct{}, 3) results := make(chan int, len(tasks)) for _, task := range tasks { sem &lt;- struct{}{} go func(task func() (int, error)) { defer func() { &lt;-sem }() result, err := task() if err != nil { // handle or ignore; kept simple here } results &lt;- result }(task) } for range tasks { fmt.Println(&lt;-results) } // After results, err := gliter.InParallelThrottle(3, tasks) </code></pre><pre><code>// Before jobs := make(chan int, len(tasks)) results := make(chan int, len(tasks)) // fan-out for i := 0; i &lt; 3; i++ { go worker(jobs, results) } // send jobs for _, job := range tasks { jobs &lt;- job } close(jobs) // fan-in for range tasks { fmt.Println(&lt;-results) } // After results, errors := gliter.NewWorkerPool(3, handler). Push(1, 2, 3, 4). Close(). Collect() </code></pre><p>Didn‚Äôt think it was special at first, but I keep reaching for it out of convenience. What do you think, trash or treasure?</p>","contentLength":1055,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Quickly navigate in man pages, using emacs, neovim or w3m.","url":"https://codeberg.org/chimay/blog/src/commit/02bdd1d592f7130c2dd2cc13e35a63c551387e91/meta/man-pages.org","date":1755870977,"author":"/u/orduval","guid":575,"unread":true,"content":"<p>\nNeovim offers a nice man view with the  command.  It can handle\nreferences by using  over the word, which can easily be remapped to\nthe return key.</p><p>\nIt even has a table of content, but it's too cluttered for my taste, so I\ndecided to write my own version of it, displaying only the minimum I need.</p><p>\nFirst, let's write some functions in ~/.config/nvim/autoload/library.vim :</p><div><pre><code>## %\n\t# %\n\t##</code></pre></div><p>\nThen, go back to ~/.config/nvim/init.vim and let's map the \nwrapper to e.g.  :</p><div><pre><code>#</code></pre></div><p>\nFinally, use buffer local maps triggered when\nentering a man buffer :</p><div><pre><code>####</code></pre></div><p>\nDone! Now, try  and enter e.g.  to the prompt.  The key :</p><ul><li> opens the toc/link window</li><li> closes the toc/link window</li><li> deletes the man page buffer</li></ul><p>In the man buffer, you can press  (enter) over a reference\n(i.e. link) to follow it.</p>","contentLength":762,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/linux/comments/1mx77vh/quickly_navigate_in_man_pages_using_emacs_neovim/"},{"title":"Centrally Collecting Events from Go Microservices","url":"https://pliutau.com/centrally-collecting-events-in-go-microservices/","date":1755868657,"author":"/u/der_gopher","guid":550,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1mx6a03/centrally_collecting_events_from_go_microservices/"},{"title":"Coding a database proxy for fun","url":"https://www.youtube.com/watch?v=DU7_MQmRDUs","date":1755865509,"author":"/u/der_gopher","guid":553,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1mx52kt/coding_a_database_proxy_for_fun/"},{"title":"How Does Google Docs Work üî•","url":"https://newsletter.systemdesign.one/p/how-does-google-docs-work","date":1755863445,"author":"Neo Kim","guid":32,"unread":true,"content":"<p>Unlock access to every deep dive article by becoming a paid subscriber:</p><p>I spent hours studying how Google Docs works so you don't have to. And I wrote this newsletter to make the key concepts simple and easy for you.</p><p><em>Note: This post is based on my research and may differ from real-world implementation.</em></p><p>Once upon a time, there lived a data analyst named Maria.</p><p>She emailed draft copies many times to different people to prepare monthly reports.</p><p>So she wasted a ton of time and was frustrated.</p><p>Until one day, when she decides to use Google Docs for it.</p><p>Google Docs allows collaborative editing over the internet. It means many users can work on the same document in real-time.</p><p>Yet it‚Äôs difficult to implement Google Docs correctly for 3 reasons:</p><ul><li><p>Concurrent changes to the same document should converge to the same version.</p></li><li><p>Concurrent changes to the same document must avoid conflicts.</p></li><li><p>Any changes should be visible in real-time to each user.</p></li></ul><p>Also a user should be able to make changes while they‚Äôre offline.</p><p>A simple approach to handle concurrency is using pessimistic concurrency control.</p><p>is amechanism for handling concurrency using a lock. It offers strong consistency, but doesn‚Äôt support collaborative editing in real-time. Because it needs a central coordinator to handle data changes, only 1 user can edit at a time. Put simply, only a single document copy is available for write operations at once, while other document copies are read-only.</p><p>Besides it doesn‚Äôt support offline changes.</p><p>Also a network round-trip across the Earth takes 200 milliseconds. </p><p>This might cause a poor user experience. So they do  The idea is to keep a document copy for each user locally and then run operations locally for high responsiveness. Thus creating the illusion of lower latency than reality.</p><p>And the system propagates the changes to all users for consistency.</p><p>A simple approach for latency hiding is using the mechanism.</p><p>Yet it resolves a conflict without waiting for coordination by applying the most recent update. So there‚Äôs a risk of data loss when there are concurrent changes in high-latency networks.</p><p>It might be a good choice when concurrency is low. But it isn‚Äôt suitable for this use case.</p><p>An alternative approach to latency hiding is through <strong>differential synchronization</strong>.</p><p>It keeps a document copy for each user and tracks the changes locally. The system doesn‚Äôt send the entire document when something changes, but only the difference ().</p><p>Yet there‚Äôs a performance overhead in sending a diff for every change. Also differential synchronization only tracks diffs, and not the reason behind a change. So conflict resolution might be difficult.</p><p>While resolving conflicts manually affects the user experience.</p><p>OT is an algorithm to show document changes without wait times on high-latency networks. It allows different document copies to accept write operations at once. Also it handles conflict resolution automatically without locks or user interventions. </p><p>Besides OT tolerates divergence among document copies and converges them later.</p><p>Think of <strong>operational transformation</strong> as an event-passing mechanism; it ensures each user has the same document state even with unsynchronized changes.</p><p>With OT, the system saves each change as an event. Put simply, a change doesn‚Äôt affect the underlying character of a document; instead, it adds an event to the revision log. The system then displays the document by replaying the revision log from its start.</p><p>Operational transformation saves a document as a set of operations, but it's complex to implement properly.</p><h2>How Does Google Docs Work</h2><p>Google Docs uses a client-server architecture for simplicity.</p>","contentLength":3631,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/4b73f9d4-a8d6-4101-9dff-df53a7332de1_1280x720.png","enclosureMime":"","commentsUrl":null},{"title":"How to run database migrations in Kubernetes","url":"https://packagemain.tech/p/database-migrations-in-kubernetes","date":1755861685,"author":"/u/der_gopher","guid":568,"unread":true,"content":"<p>In the era of microservices and Kubernetes, managing database migrations has become more complex than ever. Traditional methods of running migrations during application startup are no longer sufficient. </p><p>This article explores various approaches to handling database migrations in a Kubernetes environment, with a focus on Golang-based solutions.</p><p>Kubernetes introduces new challenges for database migrations:</p><ul><li><p>Multiple replicas starting simultaneously.</p></li><li><p>Need for coordination to avoid concurrent migrations.</p></li><li><p>Separation of concerns between application and migration logic.</p></li></ul><p><a href=\"https://packagemain.tech/i/149097592/database-migrations\" rel=\"\">post</a></p><ul><li><p>Widely used and supports numerous databases.</p></li><li><p>Supports various migration sources (local files, S3, Google Storage).</p></li></ul><ul><li><p>Supports main SQL databases.</p></li><li><p>Allows migrations written in Go for complex scenarios.</p></li><li><p>Flexible versioning schemas.</p></li></ul><ul><li><p>Powerful database schema management tool</p></li><li><p>Supports declarative and versioned migrations.</p></li><li><p>Offers integrity checks and migration linting.</p></li><li><p>Provides GitHub Actions and Terraform provider.</p></li></ul><p>A naive implementation would be to run the code of the migration directly inside your main function before you start your server.</p><p><em><strong>Example using golang-migrate:</strong></em></p><pre><code>package main\n\nimport (\n    \"database/sql\"\n    \"fmt\"\n    \"log\"\n    \"net/http\"\n\n    \"github.com/golang-migrate/migrate/v4\"\n    \"github.com/golang-migrate/migrate/v4/database/postgres\"\n    _ \"github.com/golang-migrate/migrate/v4/source/file\"\n    _ \"github.com/lib/pq\"\n)\n\nfunc main() {\n    // Database connection parameters\n    url := \"postgres://user:pass@localhost:5432/dbname\"\n\n    // Connect to the database\n    db, err := sql.Open(\"postgres\", url)\n    if err != nil {\n        log.Fatalf(\"could not connect to database: %v\", err)\n    }\n    defer db.Close()\n\n    // Run migrations\n    if err := runMigrations(db); err != nil {\n        log.Fatalf(\"could not run migrations: %v\", err)\n    }\n\n    // Run the application, for example start the server\n    if err := http.ListenAndServe(\":8080\", nil); err != nil {\n        log.Fatalf(\"server failed to start: %v\", err)\n    }\n}\n\nfunc runMigrations(db *sql.DB) error {\n    driver, err := postgres.WithInstance(db, &amp;postgres.Config{})\n    if err != nil {\n        return fmt.Errorf(\"could not create database driver: %w\", err)\n    }\n\n    m, err := migrate.NewWithDatabaseInstance(\n        \"file://migrations\", // Path to your migration files\n        \"postgres\",          // Database type\n        driver,\n    )\n    if err != nil {\n        return fmt.Errorf(\"could not create migrate instance: %w\", err)\n    }\n\n    if err := m.Up(); err != nil &amp;&amp; err != migrate.ErrNoChange {\n        return fmt.Errorf(\"could not run migrations: %w\", err)\n    }\n\n    log.Println(\"migrations completed successfully\")\n    return nil\n}</code></pre><p>However, these could cause different issues like your migrations being slow and Kubernetes considering the pod didn‚Äôt start successfully and therefore killing it. You could run those migrations in a Go routine, but how do you handle failures then? </p><p>In case when multiple pods are created at the same time, you would have a potential concurrency problem. </p><p>It also means your migrations need to be inside your Docker image.</p><p><a href=\"https://kubernetes.io/docs/concepts/workloads/pods/init-containers/\" rel=\"\">initContainers</a></p><p>If the initContainer fails, the blue/green deployment from Kubernetes won‚Äôt go further and your previous pods stays where they are. It prevents having a newer version of the code without the planned migration. </p><pre><code>initContainers:\n  - name: migrations\n    image: migrate/migrate:latest\n    command: ['/migrate']\n    args: ['-source', 'file:///migrations', '-database','postgres://user:pass@db:5432/dbname', 'up']</code></pre><p><a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/job/\" rel=\"\">Kubernetes Job </a></p><pre><code>apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: db-migrate\nspec:\n  template:\n    spec:\n      containers:\n      - name: migrate\n        image: your-migration-image:latest\n        command: ['/app/migrate']</code></pre><p>You can also combine it with initContainers making sure that the pod starts only when the job is successful.</p><pre><code>initContainers:\n  - name: migrations-wait\n    image: ghcr.io/groundnuty/k8s-wait-for:v2.0\n    args:\n      - \"job\"\n      - \"my-migration-job\"</code></pre><p><a href=\"https://helm.sh/docs/topics/charts_hooks/\" rel=\"\">hooks</a></p><pre><code>apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: {{ include \"mychart.fullname\" . }}-migrations\n  annotations:\n    \"helm.sh/hook\": pre-install,pre-upgrade\n    \"helm.sh/hook-weight\": \"-5\"\n    \"helm.sh/hook-delete-policy\": hook-succeeded\nspec:\n  template:\n    spec:\n      containers:\n        - name: migrations\n          image: your-migrations-image:tag\n          command: [\"./run-migrations.sh\"]</code></pre><p>There are pre-install and post-install hooks. </p><ol><li><p>Decoupling Migrations from Application Code</p><ol><li><p>Create separate Docker image for migrations.</p></li><li><p>Use tools like Atlas to manage migrations independently.</p></li></ol></li><li><p>Version Control for Migrations</p><ol><li><p>Store migration files in your Git repository.</p></li><li><p>Use sequential or timestamp-based versioning.</p></li></ol></li><li><ol><li><p>Ensure migrations can be run multiple times without side effects.</p></li></ol></li><li><ol><li><p>Implement and test rollback procedures for each migration.</p></li></ol></li><li><ol><li><p>Use tools like Atlas Cloud for visibility into migration history.</p></li></ol></li></ol><p>Managing database migrations in a Kubernetes environment requires careful planning and execution. </p><p>By leveraging tools like golang-migrate, goose, or atlas, and following best practices, you can create robust, scalable, and maintainable migration strategies. </p><p>Remember to decouple migrations from application code, use version control, and implement proper monitoring to ensure smooth database evolution in your Kubernetes-based architecture.</p>","contentLength":5325,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/kubernetes/comments/1mx3rq2/how_to_run_database_migrations_in_kubernetes/"},{"title":"Dev Gets 4 Years For Creating Kill Switch On Ex-Employer's Systems","url":"https://yro.slashdot.org/story/25/08/22/0039200/dev-gets-4-years-for-creating-kill-switch-on-ex-employers-systems?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1755856800,"author":"BeauHD","guid":288,"unread":true,"content":"Davis Lu, a former Eaton Corporation developer, has been sentenced to four years in prison for sabotaging his ex-employer's Windows network with malware and a custom kill switch that locked out thousands of employees once his account was disabled. The attack caused significant operational disruption and financial losses, with Lu also attempting to cover his tracks by deleting data and researching privilege escalation techniques. BleepingComputer reports: After a corporate restructuring and subsequent demotion in 2018, the DOJ says that Lu retaliated by embedding malicious code throughout the company's Windows production environment. The malicious code included an infinite Java thread loop designed to overwhelm servers and crash production systems. Lu also created a kill switch named \"IsDLEnabledinAD\" (\"Is Davis Lu enabled in Active Directory\") that would automatically lock all users out of their accounts if his account was disabled in Active Directory. When his employment was terminated on September 9, 2019, and his account disabled, the kill switch activated, causing thousands of users to be locked out of their systems.\n \n\"The defendant breached his employer's trust by using his access and technical knowledge to sabotage company networks, wreaking havoc and causing hundreds of thousands of dollars in losses for a U.S. company,\" said Acting Assistant Attorney General Matthew R. Galeotti. When he was instructed to return his laptop, Lu reportedly deleted encrypted data from his device. Investigators later discovered search queries on the device researching how to elevate privileges, hide processes, and quickly delete files. Lu was found guilty earlier this year of intentionally causing damage to protected computers. After his four-year sentence, Lu will also serve three years of supervised release following his prison term.","contentLength":1854,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"LabPlot: Free, open source and cross-platform Data Visualization and Analysis","url":"https://labplot.org/","date":1755853886,"author":"turrini","guid":210,"unread":true,"content":"<p>In many cases, importing data into LabPlot for further analysis and visualization is the first step in the application: LabPlot supports many different formats (CSV, Origin, SAS, Stata, SPSS, MATLAB, SQL, JSON, binary, OpenDocument Spreadsheets (ods), Excel (xlsx), HDF5, MQTT, Binary Logging Format (BLF), FITS,‚Ä¶</p>","contentLength":315,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44982409"},{"title":"Top Secret: Automatically filter sensitive information","url":"https://thoughtbot.com/blog/top-secret","date":1755838109,"author":"thunderbong","guid":209,"unread":true,"content":"<div><p>What happens when you‚Äôre dealing with free text? Filtering the entire string may\nnot be an option if an external API needs to process the value. Think chatbots or LLMs.</p><p>You could use a regex to filter sensitive information (such as credit card\nnumbers or emails), but that won‚Äôt capture everything, since not all sensitive\ninformation can be captured with a regex.</p><p>Fortunately, <a href=\"https://en.wikipedia.org/wiki/Named-entity_recognition\">named-entity recognition</a> (NER) can be used to identify and\nclassify real-world objects, such as a person, or location. Tools like <a href=\"https://github.com/ankane/mitie-ruby\">MITIE\nRuby</a> make interfacing with NER models trivial.</p><p>By using a combination of regex patterns and NER entities, <a href=\"https://github.com/thoughtbot/top_secret\">Top Secret</a>\neffectively filters sensitive information from free text‚Äîhere are some\nreal-world examples.</p><p>If you want to see <a href=\"https://github.com/thoughtbot/top_secret\">Top Secret</a> in action, you might enjoy this <a href=\"https://www.youtube.com/live/m2UIpTaIZ8o?si=EzEkWHlNQJORVgSG&amp;t=120\">live\nstream</a>. Otherwise, see the examples below.</p><p>It‚Äôs not uncommon to send user data to chatbots. Since the data might be\nfree-form, we should be diligent about filtering it using the approach mentioned\nabove.</p><p>However, it‚Äôs likely we‚Äôll want to ‚Äúrestore‚Äù the filtered values when returning\na response from the chatbot. <a href=\"https://github.com/thoughtbot/top_secret\">Top Secret</a> returns a <a href=\"https://github.com/thoughtbot/top_secret?tab=readme-ov-file#usage\">mapping</a> that would\nallow for this.</p><div><pre><code></code></pre></div><p>The exchange might look something like this.</p><ol><li><p>Caller sends filtered text</p><div><pre><code></code></pre></div></li><li><div><pre><code>\"Hi [PERSON_1]! How is the weather in [LOCATION_1] today?\"\n</code></pre></div></li><li><p>Caller can ‚Äúrestore‚Äù from the mapping</p><div><pre><code></code></pre></div></li></ol><h3><a href=\"https://thoughtbot.com/blog/top-secret#filtering-conversation-history\">\n    Filtering conversation history\n  </a></h3><p>When working with <a href=\"https://platform.openai.com/docs/guides/conversation-state\">conversation state</a> you should filter  message\nbefore including it in the request. This ensures no sensitive data slips through\nfrom previous messages. Here‚Äôs what that might look like.</p><div><pre><code></code></pre></div><p>Top Secret can also be used as a validation tool to prevent storing sensitive\ninformation in your database.</p><div><pre><code></code></pre></div><p>If the validation is too strict, you can <a href=\"https://github.com/thoughtbot/top_secret#overriding-the-default-filters\">override</a> or <a href=\"https://github.com/thoughtbot/top_secret#disabling-a-default-filter\">disable</a> any of\nthe filters as needed.</p><div><pre><code> class Message &lt; ApplicationRecord\n   private\n   def content_cannot_contain_sensitive_information\n     return if result.mapping.empty?\n     errors.add(:content, \"contains the following sensitive information #{result.mapping.values.to_sentence}\")\n</code></pre></div><p>It‚Äôs our responsibility to protect user data. This is more important than ever\ngiven the rise in popularity of chatbots and LLMs. Tools like <a href=\"https://github.com/thoughtbot/top_secret\">Top Secret</a> aim to\nreduce this burden.</p></div><div><p>We've been helping engineering teams deliver exceptional products for over 20 years. Our designers, developers, and product managers work closely with teams to solve your toughest software challenges through collaborative design and development. <a href=\"https://thoughtbot.com/services\" target=\"_self\" rel=\"noopener\">Learn more about us</a>.</p></div>","contentLength":2469,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44981088"},{"title":"The issue of anti-cheat on Linux (2024)","url":"https://tulach.cc/the-issue-of-anti-cheat-on-linux/","date":1755824973,"author":"todsacerdoti","guid":208,"unread":true,"content":"<p>If you switch to Linux today, you‚Äôll probably be surprised by how many games run out of the box just fine (mostly due to the <a href=\"https://github.com/ValveSoftware/Proton\">Windows compatibility layer Proton</a> built right into Steam),  for basically all competitive multiplayer games that utilize any sort of anti-cheat technology.</p><p>Now I can finally get to the point of the article‚Ä¶  As someone who uses Linux daily, I would love to see these games support it, but I just don‚Äôt see that happening any time soon. Many people in the Linux community are frustrated by the fact that these anti-cheat solutions are stopping them from playing their favorite games. It also doesn‚Äôt help that some are <a href=\"https://youtu.be/_dOCtaBObg4?si=bxrl7H5Xl6FBafH5\">fear-mongering about kernel-level anti-cheat solutions</a> and <a href=\"https://www.reddit.com/r/riotgames/comments/1cjq63h/vanguard_real_is/\">spreading misinformation</a>.</p><p>In this article, I want to give you a high-level overview of how modern anti-cheat solutions work (which will hopefully be understandable even for non-technical people) and then explain why anti-cheat solutions in their current state just cannot work on Linux, as well as what the alternatives are.</p><p><em>What is a videogame cheat?</em> We could talk for hours about whether all sorts of macros and exploits should be considered cheats, but the main thing that comes to people‚Äôs minds when talking about multiplayer games is an external program that somehow manipulates the game or reads information from the game to provide you with an advantage over others. A prime example of this would be a <a href=\"https://en.wikipedia.org/wiki/Cheating_in_online_games#Wallhacking\">wallhack or aimbot</a>.</p><p>There are generally two ways you can go about this:</p><ol><li>() Have a completely separate process that copies memory between itself and the game.</li><li>() Force the game to load a <a href=\"https://learn.microsoft.com/en-us/troubleshoot/windows-client/setup-upgrade-and-drivers/dynamic-link-library\">DLL file</a> (a <a href=\"https://en.wikipedia.org/wiki/Dynamic-link_library\">shared library file</a> containing code) directly into the game, executing custom code from within the game.</li></ol><p>Unless you find some very niche way to load a DLL into the game, in both cases you will need the ability to read (and write) the game‚Äôs process memory.</p><p>If you are not a programmer (or <a href=\"https://www.youtube.com/watch?v=dQw4w9WgXcQ\">you are a JavaScript developer</a>), you most likely don‚Äôt really know how memory management works on modern systems. Let‚Äôs imagine this situation: two programs are loaded in memory. What is stopping one program from directly accessing the memory of the other program?</p><p><em>Virtual address space in Windows (<a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/gettingstarted/virtual-address-spaces\">source</a>).</em></p><p>While in the past it would have been perfectly possible to read (almost) any of the physical memory installed in the computer, nowadays OSes use <a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/gettingstarted/virtual-address-spaces\">virtual address spaces</a>. I don‚Äôt want to go into the details of how this is handled, but all you need to know is that each program is isolated in its own address space and cannot access other programs‚Äô memory unless it uses functions provided by the operating system itself, like <a href=\"https://learn.microsoft.com/en-us/windows/win32/api/memoryapi/nf-memoryapi-readprocessmemory\"></a> and <a href=\"https://learn.microsoft.com/en-us/windows/win32/api/memoryapi/nf-memoryapi-writeprocessmemory\"></a>.</p><p>In order to use those two functions, you will need to open a <a href=\"https://learn.microsoft.com/en-us/windows/win32/sysinfo/handles-and-objects\">handle</a> to the process you want to read or write memory from. This handle will be specific to your process and represent the access rights that you have relative to the object it represents (in this case, the game process). Remember this for later, as it will be important.</p><p>Modern anti-cheat solutions have three main goals:</p><ol><li>Block other processes from accessing the game‚Äôs memory whenever possible.</li><li>Detect and ban anyone who tries to get around the blocking mentioned above.</li><li>Once someone is banned, ensure that they cannot simply create a new game account and continue playing (HWID bans).</li></ol><p>This is usually achieved by multiple components working together. Let‚Äôs take a look at <a href=\"https://www.easy.ac/en-US\">Easy Anti-Cheat</a> as an example:</p><ul><li>Loader (usually  or )</li><li>Game library ( and ‚Äúinvisible‚Äù module)</li><li>Service ()</li><li>Kernel-mode driver ()</li></ul><p>Without a kernel-mode driver, there is no way to  block memory access into the game. With the kernel-mode driver, though, it‚Äôs incredibly simple. All that the driver needs to do is <a href=\"https://github.com/Microsoft/Windows-driver-samples/blob/main/general/obcallback/driver/callback.c\">register a callback for handle creation</a>, filter out requests to open such handles to the game process, check the requested permissions, and if they allow memory access, either deny the request or lower the permissions. That way, no usermode process can now read or write the games memory. Same can be applied to module loading and file system access.</p><p><em>Using open-source <a href=\"https://github.com/cheat-engine/cheat-engine\">Cheat Engine</a> to try to read protected game‚Äôs memory (all reads fail).</em></p><p>So how can anyone get around it? They also  need to get their code into the kernel, which will open many ways for them to access the game memory.</p><p>Notice how I highlighted ‚Äúsomehow‚Äù? That‚Äôs because Windows is a closed system where Microsoft has the control to decide <a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/install/kernel-mode-code-signing-requirements--windows-vista-and-later-\">who should get access to the kernel</a>. All official kernel components are signed with Microsoft code signing certificates, so it‚Äôs trivial to verify their authenticity. All 3rd party drivers need to be signed with an <a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/dashboard/code-signing-reqs\">EV code signing certificate</a> (which can only be bought by companies) and then go through the <a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/dashboard/hardware-program-register\">Hardware Developer Center</a> certification so they can even be loaded. I am not saying this is perfect; in fact, I will most likely be writing an article about how bad actors are still getting their stuff certified. However, when they do, it usually gets quickly revoked, and it‚Äôs so costly and complicated that most don‚Äôt even bother trying.</p><p>There is, of course, a way to get around it by using <a href=\"https://github.com/SamuelTulach/nullmap\">all sorts of exploits</a> or by <a href=\"https://github.com/hfiref0x/KDU\">using vulnerable drivers</a> (drivers that expose a programming interface to user-mode processes without any checks in place, which allows them to escalate their privileges and possibly even manipulate kernel components). This is where the second goal defined above comes in. The anti-cheat has to actively scan the system and try to find code that is not associated with any legitimate module (a module that was loaded properly, with all certs in place) and other modifications or patches that would otherwise not be there.</p><p>While most gamers are going to say that those anti-cheats are useless and that they see cheaters left and right, the truth is that they add a huge skill check, so not everyone is able to write a cheat and then not get banned. In fact, if done properly, the cheating problem can be basically eliminated this way (I‚Äôll get to this later).</p><p>Another reason to run in the kernel is HWID (hardware identifier) banning (the 3rd point mentioned above). If a player is banned and creates a new account, playing on the same hardware will result in an immediate ban. Since the anti-cheat has a kernel component, it can directly talk to the hardware and read its serials that way. If it was running only as a user-mode process, it would be trivial to fake the serial reads. I am not personally a big fan of this since, as you can imagine, it can result in all sorts of unintended issues (people buying used hardware), but in reality, it‚Äôs not really a problem since those HWID bans usually expire after a few months (the game devs won‚Äôt tell you this though üòâ).</p><p>If I had to pick a game which handles cheating the best, then as of now in my humble opinion it would be <a href=\"https://playvalorant.com/en-gb/\">Valorant</a> by <a href=\"https://www.riotgames.com/en\">Riot Games</a>. Keep in mind the stuff that you‚Äôve just read and let me explain:</p><ul><li>The anti-cheat is loaded on boot. While scary for some, this allows them to block/detect the previously mentioned vulnerable drivers and exploits. This raises the skill required to write a cheat for the game even higher (usually, people resort to <a href=\"https://tulach.cc/bootkits-and-kernel-patching/\">bootkits</a>).</li><li>The kernel driver then doesn‚Äôt do anything apart from logging (locally). When the game is actually started, it goes through those logs and figures out if the game launch should be allowed or not and does all the kernel protection stuff mentioned above.</li><li>More advanced methods to obtain HWID are used, such as reading <a href=\"https://learn.microsoft.com/en-us/windows-server/identity/ad-ds/manage/component-updates/tpm-key-attestation\">TPM EK</a>, which is very hard to spoof properly.</li></ul><p>But that‚Äôs not all. If that was all there was to it, other anti-cheats would be just as effective. The anti-cheat team closely works with the game development team as well. How? The anti-cheat introduces <a href=\"https://reversing.info/posts/guardedregions/\">extra protection for certain memory regions of the game</a>. Some <a href=\"https://www.unknowncheats.me/forum/valorant/401729-valorant-1-01-names-decryption.html\">game data are encrypted</a>, and the encryption keys change with every (even small) game update, making it really annoying for cheat developers. On top of all that, the team is very active in the cheating communities to get intel about what they are up to.</p><p>I have played Valorant quite extensively, all the way from Silver to Ascendant, and I have yet to meet a cheater.</p><p>There are two main concerns that people have with those kernel-mode anti-cheats:</p><ol><li>They are in the kernel doing in-depth scans; therefore, they must be vulnerable and a security issue.</li><li>They are so deep in the system (and some start on system boot) that they can spy on us without us noticing.</li></ol><p>Let me ask you a question. How many vulnerable drivers (yes, those that can be abused by bad actors to gain kernel access) do you think the average gamer has on their Windows install? I‚Äôll start with my own system. This is what I can immediately think of:</p><p>If I looked hard enough, I would most likely find more.</p><p>It would be really stupid of me to just point to random crap you could have on your computer and say ‚Äúyou have so much exploitable stuff, don‚Äôt even bother with security,‚Äù and that‚Äôs not what I am trying to say. Or maybe it is, but just a little bit‚Ä¶ What I am trying to say is that there are many ways a malicious actor could do bad stuff with your system, but anti-cheat is very unlikely to have anything to do with it. In fact, I personally trust those anti-cheat developers much more than random vendors, since they are going to be very well aware of the possible abuse.</p><p>Overall, the Windows driver ecosystem is a mess, but unfortunately, that is not going to change any time soon.</p><p>As someone who is very well versed in Windows internals, I can tell you one thing, it doesn‚Äôt make sense. If you give the program administrative permissions (at least once), it can spy on you in the same way a kernel-mode driver could. There is absolutely no difference and it‚Äôs significantly easier to just write a standalone program. There are people who don‚Äôt want to play games because of their connection to <a href=\"https://www.tencent.com/\">Tencent</a> (for example), but if it wasn‚Äôt for the kernel-mode anti-cheat, they would have no problem with it. Isn‚Äôt it a bit hypocritical? If the game company wanted to spy on you, they could have done so from the game process or the <a href=\"https://gamerant.com/stalker-2-drm/\">service they have most likely installed for DRM purposes</a>.</p><p>Oh and just by the way, the vast majority of the data networked by those previously mentioned anti-cheats to their respective servers comes from their usermode component. The only thing that‚Äôs sent ‚Äúby the kernel component‚Äù (in quotes since the usermode service requests the data from the driver and then networks it, drivers cannot directly network data) is the HWID mentioned multiple times above and then detections (something that‚Äôs out of the ordinary). There is really not some magic data grabbing happening that‚Äôs only possible in the kernel.</p><p>Another thing that is sometimes mentioned is that since it‚Äôs in the kernel, it would be harder for security researchers to debug and assess the possible spying. While technically true that it‚Äôs harder, it‚Äôs definitely not impossible or problematic for an experienced person, so trust me, security researchers and  the entire cheating community keep a close eye on it, in the same way they do on the usermode components.</p><p>Congratulations, you have successfully made it. You have read all of the stuff and now we can finally get to the Linux part of this post üéâ.</p><p>As you can probably already tell by the extensive rant above, I don‚Äôt have much good news. Linux is an open system. There is no central authority like on Windows that would tell you what you can and what you cannot do in the kernel. This obviously has countless advantages and it‚Äôs why so many people (and big corporations) love it, but is also the reason why anti-cheats cannot really function like they do on Windows.</p><p>There is no way for them to block or detect memory access into the game. Anything you could think of would just not work. Kernel module? Just recompile the kernel and change the functions it uses to hide the possible cheat and bypass all checks. Mandatory kernel patch? Same thing. What about usermode detections? Just run the game in a <a href=\"https://wiki.debian.org/FakeRoot\">fakeroot environment</a> while the cheat runs with real root privileges, being hidden from the game completely‚Ä¶ Mandatory custom kernel build? Entire Linux system dedicated to the anti-cheat? I mean‚Ä¶ that could work, but at that point, you can just install Windows.</p><p>There have been attempts to get anti-cheat to work on Linux. <a href=\"https://www.easy.ac/en-US\">Easy Anti-Cheat</a> is the most prominent one. Developers can <a href=\"https://www.gamingonlinux.com/2021/09/epic-games-announce-full-easy-anti-cheat-for-linux-including-wine-a-proton/\">choose whether they want to allow it to run on Linux or not</a>. Linux gamers look at this and use it as an argument that anti-cheat on Linux does not face any issues, but the truth is that apart from the most basic sanity checks, EAC does absolutely nothing on Linux. It‚Äôs just a simple module that facilitates the server connection and data encryption/decryption for the game.</p><p>One of the games that allowed EAC to run under Wine/Proton is <a href=\"https://www.ea.com/games/apex-legends\">Apex Legends</a>. I won‚Äôt be putting any links here, but if you search <a href=\"https://github.com/\">GitHub</a> for cheats for this game, you will find many that work on Linux and there is absolutely no anti-cheat bypass required. It just works.</p><p>As mentioned above, if you want to achieve the best results, you need to utilize both the  and  measures. Active being the kernel component on Windows blocking memory access and trying to find possible discrepancies. Passive being the code virtualization, obfuscation, game data encryption as well as proper game networking and server-sided checks.</p><p>An example of how  to utilize kernel-mode anti-cheat would be <a href=\"https://www.fallguys.com/en-US\">Fall Guys</a> (yes, that‚Äôs the game that one friend made you buy just so you could play it for 30 minutes and then never open again). This game is very specific. There would be no gain in having some sort of wallhack, there would be no gain in having any sort of aimbot (you don‚Äôt aim at stuff). All that people did was speedhacking and modifying the game in a way that allowed them to jump higher and generally change their movement. This game is a prime example of why you should write your network code properly. If the game had proper networking and server checks in place (tick-based system, actions performed on both the client and server, if there is a mismatch, the server is the authority and resets the player - that‚Äôs how <a href=\"https://en.wikipedia.org/wiki/Counter-Strike:_Global_Offensive\">CS:GO</a> did it, and that‚Äôs why people were not flying over the map in that game or speedhacking, it had other issues though), there would be no need for anti-cheat. Not even a usermode one. Instead, they fixed absolutely nothing from their side and slapped <a href=\"https://www.easy.ac/en-US\">Easy Anti-Cheat</a> on top of their game.</p><p>While it‚Äôs not really possible to do any of the previously mentioned active measures, there is nothing stopping you from utilizing the passive ones. So, if you are a game developer and want to limit cheating in your game on Linux:</p><ul><li>Write proper networking code, verify data sent by the client so your game server does not blindly accept mach 8 as a walking speed.</li><li>Use code obfuscation and virtualization as much as possible (be aware of the performance penalty, be smart about what parts of the code you protect), try to change it a bit with every update (commercial bin2bin obfuscators like <a href=\"https://vmpsoft.com/\">VMProtect</a> or <a href=\"https://www.oreans.com/Themida.php\">Themida</a> will produce different results on each run).</li><li>If you have control over the game engine itself, try to keep sensitive information on the stack as much as possible.</li></ul>","contentLength":15291,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44980064"},{"title":"Show HN: Splice ‚Äì CAD for Cable Harnesses and Electrical Assemblies","url":"https://splice-cad.com/","date":1755810634,"author":"djsdjs","guid":182,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44978140"},{"title":"ChatLoopBackOff: Episode 67 (Kserve)","url":"https://www.youtube.com/watch?v=BjXZxUR8NMo","date":1755808425,"author":"CNCF [Cloud Native Computing Foundation]","guid":384,"unread":true,"content":"<article>Join us LIVE as CNCF Ambassador Shivay Lamaba dives into KServe, the open source project designed for scalable and reliable ML models serving on Kubernetes.\n\nShivay will be  exploring the project for the very first time, right alongside you. Expect a hands-on walkthrough of the docs, community resources, and real-world use cases that make KServe a key piece in the cloud native AI/ML ecosystem.\nIf you‚Äôre curious about production-grade model inference, want to see how cloud native communities approach machine learning workloads, or just enjoy watching an experienced open source explorer break down a CNCF project live, this session is for you.\n\nBring your questions, share your experiences, and learn in real time as we explore KServe together!</article>","contentLength":751,"flags":null,"enclosureUrl":"https://www.youtube.com/v/BjXZxUR8NMo?version=3","enclosureMime":"","commentsUrl":null},{"title":"Show HN: ChartDB Cloud ‚Äì Visualize and Share Database Diagrams","url":"https://app.chartdb.io/","date":1755781271,"author":"Jonathanfishner","guid":181,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44972238"},{"title":"AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'","url":"https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/","date":1755780796,"author":"JustExAWS","guid":247,"unread":true,"content":"<p>Amazon Web Services CEO Matt Garman has suggested firing junior workers because AI can do their jobs is \"the dumbest thing I've ever heard.\"</p><p>Garman made that remark in <a target=\"_blank\" rel=\"nofollow\" href=\"https://www.youtube.com/watch?v=nfocTxMzOP4\">conversation</a> with AI investor Matthew Berman, during which he talked up AWS‚Äôs <a target=\"_blank\" href=\"https://www.theregister.com/2025/08/18/aws_updated_kiro_pricing/\">Kiro AI-assisted coding tool</a> and said he's encountered business leaders who think AI tools \"can replace all of our junior people in our company.\"</p><p>That notion led to the ‚Äúdumbest thing I've ever heard‚Äù quote, followed by a justification that junior staff are ‚Äúprobably the least expensive employees you have‚Äù and also the most engaged with AI tools.</p><p>‚ÄúHow's that going to work when ten years in the future you have no one that has learned anything,‚Äù he asked. ‚ÄúMy view is you absolutely want to keep hiring kids out of college and teaching them the right ways to go build software and decompose problems and think about it, just as much as you ever have.‚Äù</p><p>Naturally he thinks AI ‚Äì and Kiro, natch ‚Äì can help with that education.</p><p>Garman is also not keen on another idea about AI ‚Äì measuring its value by what percentage of code it contributes at an organization.</p><p>‚ÄúIt‚Äôs a silly metric,‚Äù he said, because while organizations can use AI to write ‚Äúinfinitely more lines of code‚Äù it could be bad code.</p><p>‚ÄúOften times fewer lines of code is way better than more lines of code,‚Äù he observed. ‚ÄúSo I'm never really sure why that's the exciting metric that people like to brag about.‚Äù</p><p>That said, he‚Äôs seen data that suggests over 80 percent of AWS‚Äôs developers use AI in some way.</p><p>‚ÄúSometimes it's writing unit tests, sometimes it's helping write documentation, sometimes it's writing code, sometimes it's kind of an agentic workflow‚Äù in which developers collaborate with AI agents.</p><p>Garman said usage of AI tools by AWS developers increases every week.</p><p>The CEO also offered some career advice for the AI age, suggesting that kids these days need to learn how to learn ‚Äì and not just learn specific skills.</p><p>‚ÄúI think the skills that should be emphasized are how do you think for yourself? How do you develop critical reasoning for solving problems? How do you develop creativity? How do you develop a learning mindset that you're going to go learn to do the next thing?‚Äù</p><p>Garman thinks that approach is necessary because technological development is now so rapid it‚Äôs no longer sensible to expect that studying narrow skills can sustain a career for 30 years. He wants educators to instead teach ‚Äúhow do you think and how do you decompose problems‚Äù, and thinks kids who acquire those skills will thrive. ¬Æ</p>","contentLength":2582,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44972151"},{"title":"Show HN: Using Common Lisp from Inside the Browser","url":"https://turtleware.eu/posts/Using-Common-Lisp-from-inside-the-Browser.html","date":1755778110,"author":"jackdaniel","guid":180,"unread":true,"content":"<p> Written on 2025-08-21 by Daniel Kochma≈Ñski </p><p>Web Embeddable Common Lisp is a project that brings Common Lisp and the Web\nBrowser environments together. In this post I'll outline the current progress of\nthe project and provide some technical details, including current caveats and\nfuture plans.</p><p>It is important to note that this is not a release and none of the described\nAPIs and functionalities is considered to be stable. Things are still changing\nand I'm not accepting bug reports for the time being.</p><p>The easiest way to use Common Lisp on a website is to include WECL and insert\nscript tags with a type \"text/common-lisp\". When the attribute src is present,\nthen first the runtime loads the script from that url, and then it executes the\nnode body. For example create and run this HTML document from localhost:</p><pre><code>&lt;!doctype html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;Web Embeddable Common Lisp&lt;/title&gt;\n    &lt;link rel=\"stylesheet\" href=\"https://turtleware.eu/static/misc/wecl-20250821/easy.css\" /&gt;\n    &lt;script type=\"text/javascript\" src=\"https://turtleware.eu/static/misc/wecl-20250821/boot.js\"&gt;&lt;/script&gt;\n    &lt;script type=\"text/javascript\" src=\"https://turtleware.eu/static/misc/wecl-20250821/wecl.js\"&gt;&lt;/script&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;script type=\"text/common-lisp\" src=\"https://turtleware.eu/static/misc/wecl-20250821/easy.lisp\" id='easy-script'&gt;\n(defvar *div* (make-element \"div\" :id \"my-ticker\"))\n(append-child [body] *div*)\n\n(dotimes (v 4)\n  (push-counter v))\n\n(loop for tic from 6 above 0\n      do (replace-children *div* (make-paragraph \"~a\" tic))\n         (js-sleep 1000)\n      finally (replace-children *div* (make-paragraph \"BOOM!\")))\n\n(show-script-text \"easy-script\")\n    &lt;/script&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n</code></pre><p>We may use Common Lisp that can call to JavaScript, and register callbacks to be\ncalled on specified events. The source code of the script can be found here:</p><p>Because the runtime is included as a script, the browser will usually cache the\n~10MB WebAssembly module.</p><p>The initial foreign function interface has numerous macros defining wrappers\nthat may be used from Common Lisp or passed to JavaScript.</p><p>Summary of currently available operators:</p><ul><li> an inlined expression, like </li><li> an object referenced from the object store</li><li> a function</li><li> a method of the argument, like </li><li> a slot reader of the argument</li><li> a slot writer of the first argument</li><li> combines define-js-getter and define-js-setter</li><li> template for JavaScript expressions</li><li> Common Lisp function reference callable from JavaScript</li><li> anonymous Common Lisp function reference (for closures)</li></ul><p>Summary of argument types:</p><table border=\"2\" cellspacing=\"0\" cellpadding=\"6\" rules=\"groups\" frame=\"hsides\"><thead><tr></tr></thead><tbody><tr><td>Common Lisp object reference</td></tr><tr><td>JavaScript object reference</td></tr><tr></tr><tr></tr><tr></tr></tbody></table><p>All operators, except for  have a similar lambda list:</p><blockquote><p>(DEFINE-JS NAME-AND-OPTIONS [ARGUMENTS [,@BODY]])</p></blockquote><p>The first argument is a list  that is common to all\ndefining operators:</p><ul><li> Common Lisp symbol denoting the object</li><li> a string denoting the JavaScript expression, i.e \"innerText\"</li><li> a type of the object returned by executing the expression</li></ul><pre><code>(define-js-variable ([document] :js-expr \"document\" :type :symbol))\n;; document\n(define-js-object ([body] :js-expr \"document.body\" :type :js-ref))\n;; wecl_ensure_object(document.body) /* -&gt; id   */\n;; wecl_search_object(id)            /* -&gt; node */\n</code></pre><p>The difference between a variable and an object in JS-FFI is that variable\nexpression is executed each time when the object is used (the expression is\ninlined), while the object expression is executed only once and the result is\nstored in the object store.</p><p>The second argument is a list of pairs . Names will be used in the\nlambda list of the operator callable from Common Lisp, while types will be used\nto coerce arguments to the type expected by JavaScript.</p><pre><code>(define-js-function (parse-float :js-expr \"parseFloat\" :type :js-ref)\n    ((value :string)))\n;; parseFloat(value)\n\n(define-js-method (add-event-listener :js-expr \"addEventListener\" :type :null)\n    ((self :js-ref)\n     (name :string)\n     (fun :js-ref)))\n;; self.addEventListener(name, fun)\n\n(define-js-getter (get-inner-text :js-expr \"innerText\" :type :string)\n    ((self :js-ref)))\n;; self.innerText\n\n(define-js-setter (set-inner-text :js-expr \"innerText\" :type :string)\n    ((self :js-ref)\n     (new :string)))\n;; self.innerText = new\n\n(define-js-accessor (inner-text :js-expr \"innerText\" :type :string)\n    ((self :js-ref)\n     (new :string)))\n;; self.innerText\n;; self.innerText = new\n\n(define-js-script (document :js-expr \"~a.forEach(~a)\" :type :js-ref)\n    ((nodes :js-ref)\n     (callb :object)))\n;; nodes.forEach(callb)\n</code></pre><p>The third argument is specific to callbacks, where we define Common Lisp body of\nthe callback. Argument types are used to coerce values from JavaScript to Common\nLisp.</p><pre><code>(define-js-callback (print-node :type :object)\n    ((elt :js-ref)\n     (nth :fixnum)\n     (seq :js-ref))\n  (format t \"Node ~2d: ~a~%\" nth elt))\n\n(let ((start 0))\n  (add-event-listener *my-elt* \"click\"\n                      (lambda-js-callback :null ((event :js-ref)) ;closure!\n                        (incf start)\n                        (setf (inner-text *my-elt*)\n                              (format nil \"Hello World! ~a\" start)))\n</code></pre><p>Note that callbacks are a bit different, because  does not\naccept  option and  has unique lambda list. It is\nimportant for callbacks to have an exact arity as they are called with, because\nJS-FFI does not implement variable number of arguments yet.</p><p>Callbacks can be referred by name with an operator .</p><p>While working on FFI I've decided to write an adapter for SLIME/SWANK that will\nallow interacting with WECL from Emacs. The principle is simple: we connect with\na websocket to Emacs that is listening on the specified port (i.e on localhost).\nThis adapter uses the library  written by Andrew Hyatt.</p><p>It allows for compiling individual forms with , but file compilation\ndoes not work (because files reside on a different \"host\"). REPL interaction\nworks as expected, as well as SLDB. The connection may occasionally be unstable,\nand until Common Lisp call returns, the whole page is blocked. Notably waiting\nfor new requests is not a blocking operation from the JavaScript perspective,\nbecause it is an asynchronous operation.</p><pre><code>;;; Patches for SLIME 2.31 (to be removed after the patch is merged).\n;;; It is assumed that SLIME is already loaded into Emacs.\n(defun slime-net-send (sexp proc)\n  \"Send a SEXP to Lisp over the socket PROC.\nThis is the lowest level of communication. The sexp will be READ and\nEVAL'd by Lisp.\"\n  (let* ((payload (encode-coding-string\n                   (concat (slime-prin1-to-string sexp) \"\\n\")\n                   'utf-8-unix))\n         (string (concat (slime-net-encode-length (length payload))\n                         payload))\n         (websocket (process-get proc :websocket)))\n    (slime-log-event sexp)\n    (if websocket\n        (websocket-send-text websocket string)\n      (process-send-string proc string))))\n\n(defun slime-use-sigint-for-interrupt (&amp;optional connection)\n  (let ((c (or connection (slime-connection))))\n    (cl-ecase (slime-communication-style c)\n      ((:fd-handler nil) t)\n      ((:spawn :sigio :async) nil))))\n</code></pre><pre><code>;;; lime.el --- Lisp Interaction Mode for Emacs -*-lexical-binding:t-*-\n;;; \n;;; This program extends SLIME with an ability to listen for lisp connections.\n;;; The flow is reversed - normally SLIME is a client and SWANK is a server.\n\n(require 'websocket)\n\n(defvar *lime-server* nil\n  \"The LIME server.\")\n\n(cl-defun lime-zipit (obj &amp;optional (start 0) (end 72))\n  (let* ((msg (if (stringp obj)\n                  obj\n                (slime-prin1-to-string obj)))\n         (len (length msg)))\n    (substring msg (min start len) (min end len))))\n\n(cl-defun lime-message (&amp;rest args)\n  (with-current-buffer (process-buffer *lime-server*)\n    (goto-char (point-max))\n    (dolist (arg args)\n      (insert (lime-zipit arg)))\n    (insert \"\\n\")\n    (goto-char (point-max))))\n\n(cl-defun lime-client-process (client)\n  (websocket-conn client))\n\n(cl-defun lime-process-client (process)\n  (process-get process :websocket))\n\n;;; c.f slime-net-connect\n(cl-defun lime-add-client (client)\n  (lime-message \"LIME connecting a new client\")\n  (let* ((process (websocket-conn client))\n         (buffer (generate-new-buffer \"*lime-connection*\")))\n    (set-process-buffer process buffer)\n    (push process slime-net-processes)\n    (slime-setup-connection process)\n    client))\n\n;;; When SLIME kills the process, then it invokes LIME-DISCONNECT hook.\n;;; When SWANK kills the process, then it invokes LIME-DEL-CLIENT hook.\n(cl-defun lime-del-client (client)\n  (when-let ((process (lime-client-process client)))\n    (lime-message \"LIME client disconnected\")\n    (slime-net-sentinel process \"closed by peer\")))\n\n(cl-defun lime-disconnect (process)\n  (when-let ((client (lime-process-client process)))\n    (lime-message \"LIME disconnecting client\")\n    (websocket-close client)))\n\n(cl-defun lime-on-error (client fun error)\n  (ignore client fun)\n  (lime-message \"LIME error: \" (slime-prin1-to-string error)))\n\n;;; Client sends the result over a websocket. Handling responses is implemented\n;;; by SLIME-NET-FILTER. As we can see, the flow is reversed in our case.\n(cl-defun lime-handle-message (client frame)\n  (let ((process (lime-client-process client))\n        (data (websocket-frame-text frame)))\n    (lime-message \"LIME-RECV: \" data)\n    (slime-net-filter process data)))\n\n(cl-defun lime-net-listen (host port &amp;rest parameters)\n  (when *lime-server*\n    (error \"LIME server has already started\"))\n  (setq *lime-server*\n        (apply 'websocket-server port\n               :host host\n               :on-open    (function lime-add-client)\n               :on-close   (function lime-del-client)\n               :on-error   (function lime-on-error)\n               :on-message (function lime-handle-message)\n               parameters))\n  (unless (memq 'lime-disconnect slime-net-process-close-hooks)\n    (push 'lime-disconnect slime-net-process-close-hooks))\n  (let ((buf (get-buffer-create \"*lime-server*\")))\n    (set-process-buffer *lime-server* buf)\n    (lime-message \"Welcome \" *lime-server* \"!\")\n    t))\n\n(cl-defun lime-stop ()\n  (when *lime-server*\n   (websocket-server-close *lime-server*)\n   (setq *lime-server* nil)))\n</code></pre><p>After loading this file into Emacs invoke <code>(lime-net-listen \"localhost\" 8889)</code>.\nNow our Emacs listens for new connections from SLUG (the lisp-side part adapting\nSWANK, already bundled with WECL). There are two SLUG backends in a repository:</p><ul><li> for web browser environment</li><li> for Common Lisp runtime (uses )</li></ul><p>Now you can open a page listed here and connect to SLIME:</p><pre><code>&lt;!doctype html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;Web Embeddable Common Lisp&lt;/title&gt;\n    &lt;link rel=\"stylesheet\" href=\"easy.css\" /&gt;\n    &lt;script type=\"text/javascript\" src=\"https://turtleware.eu/static/misc/wecl-20250821/boot.js\"&gt;&lt;/script&gt;\n    &lt;script type=\"text/javascript\" src=\"https://turtleware.eu/static/misc/wecl-20250821/wecl.js\"&gt;&lt;/script&gt;\n    &lt;script type=\"text/common-lisp\" src=\"https://turtleware.eu/static/misc/wecl-20250821/slug.lisp\"&gt;&lt;/script&gt;\n    &lt;script type=\"text/common-lisp\" src=\"https://turtleware.eu/static/misc/wecl-20250821/wank.lisp\"&gt;&lt;/script&gt;\n    &lt;script type=\"text/common-lisp\" src=\"https://turtleware.eu/static/misc/wecl-20250821/easy.lisp\"&gt;\n      (defvar *connect-button* (make-element \"button\" :text \"Connect\"))\n      (define-js-callback (connect-to-slug :type :null) ((event :js-ref))\n        (wank-connect \"localhost\" 8889)\n        (setf (inner-text *connect-button*) \"Crash!\"))\n      (add-event-listener *connect-button* \"click\" (js-callback connect-to-slug))\n      (append-child [body] *connect-button*)\n    &lt;/script&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n</code></pre><p>This example shows an important limitation ‚Äì  does not allow for\nmultiple asynchronous contexts in the same thread. That means that if Lisp call\ndoesn't return (i.e because it waits for input in a loop), then we can't execute\nother Common Lisp statements from elsewhere because the application will crash.</p><p>Here's another example. It is more a cool gimmick than anything else, but let's\ntry it. Open a console on this very website (on firefox C-S-i) and execute:</p><pre><code>function inject_js(url) {\n    var head = document.getElementsByTagName('head')[0];\n    var script = document.createElement('script');\n    head.appendChild(script);\n    script.type = 'text/javascript';\n    return new Promise((resolve) =&gt; {\n        script.onload = resolve;\n        script.src = url;\n    });\n}\n\nfunction inject_cl() {\n    wecl_eval('(wecl/impl::js-load-slug \"https://turtleware.eu/static/misc/wecl-20250821\")');\n}\n\ninject_js('https://turtleware.eu/static/misc/wecl-20250821/boot.js')\n    .then(() =&gt; {\n        wecl_init_hooks.push(inject_cl);\n        inject_js('https://turtleware.eu/static/misc/wecl-20250821/wecl.js');\n    });\n</code></pre><p>With this, assuming that you've kept your LIME server open, you'll have a REPL\nonto uncooperative website. Now we can fool around with queries and changes:</p><pre><code>(define-js-accessor (title :js-expr \"title\" :type :string)\n  ((self :js-ref)\n   (title :string)))\n\n(define-js-accessor (background :js-expr \"body.style.backgroundColor\" :type :string)\n  ((self :js-ref)\n   (background :string)))\n\n(setf (title [document]) \"Write in Lisp!\")\n(setf (background [document]) \"#aaffaa\")\n</code></pre><p>The first thing to address is the lack of threading primitives. Native threads\ncan be implemented with web workers, but then our GC wouldn't know how to stop\nthe world to clean up. Another option is to use cooperative threads, but that\nalso won't work, because Emscripten doesn't support independent asynchronous\ncontexts, nor ECL is ready for that yet.</p><p>I plan to address both issues simultaneously in the second stage of the project\nwhen I port the runtime to WASI. We'll be able to use browser's GC, so running\nin multiple web workers should not be a problem anymore. Unwinding and rewinding\nthe stack will require tinkering with ASYNCIFY and I have somewhat working green\nthreads implementation in place, so I will finish it and upstream in ECL.</p><p>Currently I'm focusing mostly on having things working, so JS and CL interop is\nbrittle and often relies on evaluating expressions, trampolining and coercing.\nThat impacts the performance in a significant way. Moreover all loaded scripts\nare compiled with a one-pass compiler, so the result bytecode is not optimized.</p><p>There is no support for loading cross-compiled files onto the runtime, not to\nmention that it is not possible to precompile systems with ASDF definitions.</p><p>JS-FFI requires more work to allow for defining functions with variable number\nof arguments and with optional arguments. There is no dynamic coercion of\nJavaScript exceptions to Common Lisp conditions, but it is planned.</p>","contentLength":14560,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44971744"},{"title":"I Created the most Comprehensive LLD Interview Resource","url":"https://blog.algomaster.io/p/launching-premium-lld-resource","date":1755777720,"author":"Ashish Pratap Singh","guid":713,"unread":true,"content":"<p>It‚Äôs one of the most comprehensive and high quality resource you can find online with <strong>support for 5 programming languages</strong> ‚Äî Java, Python, C++, C#, and TypeScript.</p><p>Many chapters are . To unlock full access, you would need to become a  to the newsletter.</p><ul><li><p> and </p></li><li><p> and other important </p></li><li><p> (with real-world examples)</p></li><li><p><strong>40+ LLD interview problems</strong> (with more added over time)</p></li><li><p>, with UML class diagrams and design patterns explained in context.</p></li><li><p>Support for <strong>Java, Python, C++,  C#, and TypeScript</strong></p></li><li><p>Built-in  and  where you can edit, run and see the solution output directly on the site (supports Java, Python, C++,  and C#)</p></li><li><p> to test your understanding.</p></li></ul><p>I‚Äôve poured a lot of thought and effort into making this course as useful and practical as possible. I truly hope you‚Äôll find it valuable in your interview prep journey.</p><p>I will keep making improvements and enhancements to this resource over time.</p><p>You may already know my , which is one of the most popular resources to learn LLD. This course takes it to the next level, offering a far better reading experience, focused specifically on interview prep. </p><p>I have also updated the solutions in the Github repository with more design patterns and class diagrams.</p><p>Starting , subscription pricing will increase:</p><ul></ul><p>Subscribe now to lock in the current price.</p><p>All <strong>existing paid subscribers</strong> will continue at their current rate.</p><h4>üíé New: Lifetime Access Plan</h4><p>You can now get  to all current and future AlgoMaster premium content for a .</p><p>For any questions related to content or subscription, please reply to this email or reach out at </p>","contentLength":1549,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/1bdf8340-7a0f-42e0-8609-c5174fb17828_2048x1426.jpeg","enclosureMime":"","commentsUrl":null}],"tags":["dev"]}