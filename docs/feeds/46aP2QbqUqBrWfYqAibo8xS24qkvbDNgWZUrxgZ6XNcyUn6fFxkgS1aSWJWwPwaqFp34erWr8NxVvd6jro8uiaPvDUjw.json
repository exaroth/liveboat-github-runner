{"id":"46aP2QbqUqBrWfYqAibo8xS24qkvbDNgWZUrxgZ6XNcyUn6fFxkgS1aSWJWwPwaqFp34erWr8NxVvd6jro8uiaPvDUjw","title":"top scoring links : kubernetes","displayTitle":"Reddit - Kubernetes","url":"https://www.reddit.com/r/kubernetes/top/.rss?sort=top&t=day&limit=6","feedLink":"https://www.reddit.com/r/kubernetes/top/?sort=top&t=day&limit=6","is_query":false,"items":[{"title":"Kubernetes, Kafka and Database","url":"https://www.reddit.com/r/kubernetes/comments/1hpsppv/kubernetes_kafka_and_database/","date":1735580516,"author":"/u/Lumenbyte","unread":true,"content":"<!-- SC_OFF --><div class=\"md\"><p>As a beginner, with lot of research and docker containers, i was finally able to setup everything in my Minikube cluster. The message is produced in one service, database gets updated and kafka is able to do its work. I am just happy. It was my 3 days struggle. First i used to have image in docker and pull the image from there. But using docker inside minikube cluster changes my perspective on docker and kubernetes. </p> <p>Basically at the end of the day, kubernetes just needs image to work with containers. Lot of things like resourcequota, autoscaling are still pending. But feels so great with the setup as of now. Just happy and wanted to share the feelings here ☺️☺️☺️</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Lumenbyte\"> /u/Lumenbyte </a> <br/> <span><a href=\"https://www.reddit.com/r/kubernetes/comments/1hpsppv/kubernetes_kafka_and_database/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/kubernetes/comments/1hpsppv/kubernetes_kafka_and_database/\">[comments]</a></span>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Exploring Cloud Native projects in CNCF Sandbox. Part 2: 12 arrivals of 2023 H2","url":"https://www.reddit.com/r/kubernetes/comments/1hpq4fs/exploring_cloud_native_projects_in_cncf_sandbox/","date":1735573866,"author":"/u/dshurupov","unread":true,"content":"<table> <tr><td> <a href=\"https://www.reddit.com/r/kubernetes/comments/1hpq4fs/exploring_cloud_native_projects_in_cncf_sandbox/\"> <img src=\"https://external-preview.redd.it/mt1zZckyK09P0CcRCalbGV7WnjzSIfpnTBgCne70E10.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f931935ce5c694cc779b612a97ae7f65794d9bf9\" alt=\"Exploring Cloud Native projects in CNCF Sandbox. Part 2: 12 arrivals of 2023 H2\" title=\"Exploring Cloud Native projects in CNCF Sandbox. Part 2: 12 arrivals of 2023 H2\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>A brief overview (with quick helpful links) of the projects added to the CNCF Sandbox in the second part of 2023: Logging operator, K8sGPT, kcp, KubeStellar, Copa, Kanister, KCL, Easegress, Kuasar, krkn, kube-burner, and Spiderpool.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/dshurupov\"> /u/dshurupov </a> <br/> <span><a href=\"https://blog.palark.com/cncf-sandbox-2023-h2/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/kubernetes/comments/1hpq4fs/exploring_cloud_native_projects_in_cncf_sandbox/\">[comments]</a></span> </td></tr></table>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"Deployment tools and \"GitOps\" project structure noob tooling questions","url":"https://www.reddit.com/r/kubernetes/comments/1hpoekl/deployment_tools_and_gitops_project_structure/","date":1735569035,"author":"/u/BrocoLeeOnReddit","unread":true,"content":"<!-- SC_OFF --><div class=\"md\"><p>I&#39;m quite new to Kubernetes and I understand the concept of manifests and also how a package manager like Helm works and I also took a look at kustomize. However, if I understand it correctly, in the end everything thrown at a cluster will be manifests, either directly or created by Helm from Charts or kustomize by merging kustomize manifests.</p> <p>I also stumbled upon helmfile which I thought was pretty neat because it allows you to declaratively define helm charts you want to deploy.</p> <p>However, I&#39;m having some trouble understanding how to get all of this integrated in a way so that I can easily automate it and not have to type 20 commands.</p> <p>I think it&#39;s easier if I try to explain what I want to do: I currently have 3 Control Planes and 2 Worker nodes (Talos) running on my Proxmox server in my Homelab. I also have GitLab running on my NAS. So naturally I&#39;m thinking about using GitOps and want to try ArgoCD.</p> <p>Currently, I&#39;m installing most stuff manually with helmfile + additional manifests and I&#39;m currently in the &quot;bootstrapping&quot; part of the project, e.g. Installing Cilium as CNI, SealedSecrets to handle secrets, configuring storage, etc.</p> <p>Currently the directory structure in my project is something like this:</p> <pre><code>base ├── 01-cilium │ ├── manifests │ │ ├── bgp-setup.yaml │ │ └── ip-pools.yaml │ ├── helmfile.yaml │ └── values.yaml ├── 02-sealedsecrets │ └── controller.yaml ├── 03-nfs-storage │ ├── helmfile.yaml │ └── values.yaml ├── 04-cert-manager │ ├── ... ├── 05-traefik │ ├── ... ├── 06-argocd │ ├── ... │ ... ... </code></pre> <p>You get the idea.</p> <p>As you can see, there&#39;s some things that have a helmfile, some have manifests only, some have both and I just write in my README how to deploy this, e.g. first <code>helmfile apply -f base/cilium/helmfile.yaml</code>, then <code>kubectl apply -f base/cilium/manifests</code> and so on.</p> <p>On top of that, since I am using SealedSecrets, I need to have the controller running on the Cluster to generate secrets needed for e.g. cert-manager (API-Token for Cloudflare). So that&#39;s a manual step in between so I can push the project to git without it having any unencrypted secrets in it.</p> <p>This feels really clunky and I feel like there should be a much simpler solution. I know I could just write a bash script for this but is this really how the tooling is supposed to be used or am I doing something fundamentally wrong?</p> <p>Also, how do you guys structure your projects and handle stuff like bootstrapping? Do you just use manifests when defining stuff in Code without manual intervention or do you use tools like helmfile? And do you split your git repos between infrastructure projects (deploying core resources and tooling) and application projects?</p> <p>Sorry for asking so many questions but I&#39;m nearly done with getting everything to work but I want to make sure to follow best practices when trying to structure my project and I want to do it now before it gets bigger and restructuring would get annoying...</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/BrocoLeeOnReddit\"> /u/BrocoLeeOnReddit </a> <br/> <span><a href=\"https://www.reddit.com/r/kubernetes/comments/1hpoekl/deployment_tools_and_gitops_project_structure/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/kubernetes/comments/1hpoekl/deployment_tools_and_gitops_project_structure/\">[comments]</a></span>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"A CNI 'Chicken-and-Egg' Dilemma: How Does Calico Assign IPs to Itself?","url":"https://www.reddit.com/r/kubernetes/comments/1hpljxk/a_cni_chickenandegg_dilemma_how_does_calico/","date":1735559207,"author":"/u/qingdi","unread":true,"content":"<!-- SC_OFF --><div class=\"md\"><p>an interesting issue: <strong>Calico assigns IP addresses to its own components’ Pods</strong> (e.g., calico-kube-controllers). How does Calico achieve this? From the installation of the Calico network plugin to assigning IPs to its own Pods, what happens at the underlying level?</p> <p>The post is here: <a href=\"https://midbai.com/en/post/cni-chicken-egg-problem/\">https://midbai.com/en/post/cni-chicken-egg-problem/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/qingdi\"> /u/qingdi </a> <br/> <span><a href=\"https://www.reddit.com/r/kubernetes/comments/1hpljxk/a_cni_chickenandegg_dilemma_how_does_calico/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/kubernetes/comments/1hpljxk/a_cni_chickenandegg_dilemma_how_does_calico/\">[comments]</a></span>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"What's the deal with TalosOS?","url":"https://www.reddit.com/r/kubernetes/comments/1hpjh6n/whats_the_deal_with_talosos/","date":1735550393,"author":"/u/theboredabdel","unread":true,"content":"<!-- SC_OFF --><div class=\"md\"><p>I see Talos OS all over the place these days. I have a home Lab with few Intel Nucs I&#39;m planning to turn into a k8s cluster to play around with and thinking about using Talos Linux.</p> <p>Question is why is Talos such a big deal in the k8s space? and is it worth the time!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/theboredabdel\"> /u/theboredabdel </a> <br/> <span><a href=\"https://www.reddit.com/r/kubernetes/comments/1hpjh6n/whats_the_deal_with_talosos/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/kubernetes/comments/1hpjh6n/whats_the_deal_with_talosos/\">[comments]</a></span>","flags":null,"enclosureUrl":"","enclosureMime":""},{"title":"How to use SOPS with GitOps?","url":"https://www.reddit.com/r/kubernetes/comments/1hp20m1/how_to_use_sops_with_gitops/","date":1735496218,"author":"/u/Bl4rc","unread":true,"content":"<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve explored various tools aimed at integrating SOPS with GitOps workflows, such as:</p> <ul> <li><a href=\"https://github.com/viaduct-ai/kustomize-sops\">ksops</a></li> <li><a href=\"https://github.com/jkroepke/helm-secrets\">helm-secrets</a></li> <li><a href=\"https://fluxcd.io/flux/guides/mozilla-sops/#gitops-workflow\">flux</a> (which has built-in support for SOPS)</li> <li><a href=\"https://github.com/helmfile/helmfile\">helmfile</a></li> </ul> <p>While these are all great tools, none fully meet my needs. One of the things I love about SOPS is its simplicity: as long as I have the necessary private key, I can clone a repo and immediately access all the values used for deploying an application.</p> <h1>My Challenge</h1> <p>I frequently switch between deploying applications with Helm charts and using Kustomize. This is because some applications provide well-maintained Helm charts, while others only offer plain YAML manifests.</p> <p>Here’s where things get tricky:</p> <ol> <li><strong>For Helm charts</strong>: I’d like to encrypt the <code>values.yaml</code> file.</li> <li><strong>For plain YAML manifests</strong>: I prefer to use Kustomize and encrypt specific resources, like secrets, where needed.</li> </ol> <h1>Existing Solutions</h1> <ul> <li><strong>Helm-secrets</strong> works well for encrypting <code>values.yaml</code> files in Helm charts.</li> <li><strong>Ksops</strong> can handle encryption for Kustomize, but it requires enabling a feature flag and has uncertain long-term support, as Kustomize isn’t fully committed to supporting this use case.</li> </ul> <h1>What I’m Looking For</h1> <p>I need a solution that seamlessly integrates SOPS encryption into a workflow that supports both Helm and Kustomize. It should allow me to manage encrypted resources with minimal friction, regardless of whether I&#39;m dealing with Helm charts or plain YAMLs.</p> <p>Additionally, I’m looking for a solution that integrates well with GitOps tools like <strong>Argo CD</strong> and/or <strong>Flux</strong>. Ideally, it would simplify handling SOPS-encrypted resources within these platforms without requiring too many custom workarounds.</p> <p>Does anyone have a better approach, or know of a tool or workflow that bridges this gap?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Bl4rc\"> /u/Bl4rc </a> <br/> <span><a href=\"https://www.reddit.com/r/kubernetes/comments/1hp20m1/how_to_use_sops_with_gitops/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/kubernetes/comments/1hp20m1/how_to_use_sops_with_gitops/\">[comments]</a></span>","flags":null,"enclosureUrl":"","enclosureMime":""}]}