{"id":"4W3i2hyrJTVfcLq85rWgduVQ3y3BMzrSD4pVUCMqPpFhmXWpqxQ","title":"Hacker News: Front Page","displayTitle":"HN Front","url":"https://hnrss.org/frontpage?points=75","feedLink":"https://news.ycombinator.com/","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":20,"items":[{"title":"French police free kidnapped Ledger executive","url":"https://moneycheck.com/french-police-free-kidnapped-ledger-executive-after-day-long-ordeal/","date":1737773328,"author":"ilamont","guid":179,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42819018"},{"title":"Caltrain's electric fleet more efficient than expected","url":"https://www.caltrain.com/news/caltrains-electric-fleet-more-efficient-expected","date":1737769991,"author":"ssuds","guid":178,"unread":true,"content":"<p><em></em></p><p><em></em></p>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42818692"},{"title":"File Explorer is merged to Helix editor","url":"https://github.com/helix-editor/helix/pull/11285","date":1737764900,"author":"manusachi","guid":177,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42818278"},{"title":"You could have invented Fenwick trees","url":"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D","date":1737764614,"author":"matt_d","guid":176,"unread":true,"content":"<div data-magellan-destination=\"s1\"><p> Suppose we have a sequence of  integers  and want to be able to perform arbitrary interleavings of the following two operations, as illustrated in Figure&nbsp;<a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#f1\">1</a> :</p><section><div data-magellan-destination=\"f1\"><div><p> Update and range query operations.</p></div></div></section><ul><li><p> the value at any given index<a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#fn1\"></a> by adding some value .</p></li></ul><p> Note that update is phrased in terms of  some value  to the existing value; we can also  a given index to a new value  by adding , where  is the old value.</p><p> If we simply store the integers in a mutable array, then we can update in constant time, but range queries require time linear in the size of the range, since we must iterate through the entire range  to add up the values.</p><p> In order to improve the running time of range queries, we could try to cache (at least some of) the range sums. However, this must be done with care, since the cached sums must be kept up to date when updating the value at an index. For example, a straightforward approach would be to use an array  where  stores the prefix sum ;  can be precomputed in linear time via a scan. Now range queries are fast: we can obtain  in constant time by computing  (for convenience we set  so this works even when ). Unfortunately, it is update that now takes linear time, since changing  requires updating  for every .</p><p> Is it possible to design a data structure that allows  operations to run in sublinear time? (You may wish to pause and think about it before reading the next paragraph!) This is not just academic: the problem was originally considered in the context of  (Rissanen &amp; Langdon, <a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#ref11\">1979</a>; Bird &amp; Gibbons, <a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#ref2\">2002</a>), a family of techniques for turning messages into sequences of bits for storage or transmission. In order to minimize the bits required, one generally wants to assign shorter bit sequences to more frequent characters, and vice versa; this leads to the need to maintain a dynamic table of character frequencies. We  the table every time a new character is processed and  the table for cumulative frequencies in order to subdivide a unit interval into consecutive segments proportional to the frequency of each character (Ryabko, <a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#ref12\">1989</a>; Fenwick, <a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#ref5\">1994</a>).</p><p> So, can we get both operations to run in sublinear time? The answer, of course, is yes. One simple technique is to divide the sequence into  buckets, each of size , and create an additional array of size  to cache the sum of each bucket. Updates still run in (1), since we simply have to update the value at the given index and the corresponding bucket sum. Range queries now run in  time: to find the sum , we manually add the values from  to the end of its bucket, and from  to the beginning of its bucket; for all the buckets in between we can just look up their sum.</p><p> We can make range queries even faster, at the cost of making updates slightly slower, by introducing additional levels of caching. For example, we can divide the sequence into  “big buckets” and then further subdivide each big bucket into  “small buckets”, with each small bucket holding  values. The sum of each bucket is cached; now each update requires modifying three values, and range queries run in  time.</p><p> In the limit, we end up with a binary divide-and-conquer approach to caching range sums, with both update and range query taking  time. In particular, we can make a balanced binary tree where the leaves store the sequence itself, and every internal node stores the sum of its children. (This will be a familiar idea to many functional programmers; for example, finger trees (Hinze &amp; Paterson, <a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#ref7\">2006</a>; Apfelmus, <a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#ref1\">2009</a>) use a similar sort of caching scheme.) The resulting data structure is popularly known as a ,<a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#fn2\"></a> presumably because each internal node ultimately caches the sum of a (contiguous)  of the underlying sequence. Figure&nbsp;<a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#f2\">2</a> shows a segment tree built on a sample array of length  (for simplicity, we will assume that  is a power of two, although it is easy to generalize to situations where it is not). Each leaf of the tree corresponds to an array entry; each internal node is drawn with a grey bar showing the segment of the underlying array of which it is the sum.</p><section></section><p> Let’s see how we can use a segment tree to implement the two required operations so that they run in logarithmic time.</p><ul><li><p> To update the value at index , we also need to update any cached range sums which include it. These are exactly the nodes along the path from the leaf at index  to the root of the tree; there are  such nodes. Figure&nbsp;<a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#f3\">3</a> illustrates this update process for the example segment tree from Figure&nbsp;<a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#f2\">2</a>; updating the entry at index 5 requires modifying only the shaded nodes along the path from the root to the updated entry.</p></li><li><p> To perform a range query, we descend through the tree while keeping track of the range covered by the current node.</p><ul><li><p> If the range of the current node is wholly contained within the query range, return the value of the current node.</p></li><li><p> If the range of the current node is disjoint from the query range, return 0.</p></li><li><p> Otherwise, recursively query both children and return the sum of the results.</p></li></ul></li></ul><p> Figure&nbsp;<a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#f4\">4</a> illustrates the process of computing the sum of the range . Blue nodes are the ones we recurse through; green nodes are those whose range is wholly contained in the query range and are returned without recursing further; grey nodes are disjoint from the query range and return zero. The final result in this example is the sum of values at the green nodes,  (it is easily verified that this is in fact the sum of values in the range ).</p><section><div data-magellan-destination=\"f3\"><div><p> Updating a segment tree.</p></div></div></section><section><div data-magellan-destination=\"f4\"><div><p> Performing a range query on a segment tree.</p></div></div></section><p> On this small example tree, it may seem that we visit a significant fraction of the total nodes, but in general, we visit no more than about . Figure&nbsp;<a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#f5\">5</a> makes this more clear. Only one blue node in the entire tree can have two blue children, and hence, each level of the tree can contain at most two blue nodes and two non-blue nodes. We essentially perform two binary searches, one to find each endpoint of the query range.</p><section><div data-magellan-destination=\"f5\"><div><p> Performing a range query on a larger segment tree.</p></div></div></section><p> Segment trees are a very nice solution to the problem: as we will see in Section <a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#s2\">2</a>, they fit well in a functional language; they also lend themselves to powerful generalizations such as lazily propagated range updates and persistent update history via shared immutable structure (<a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#ref9\">Ivanov, 2011</a>).</p><p>, or  (Fenwick, <a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#ref5\">1994</a>; <a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#ref8\">Ivanov, 2011</a>), are an alternative solution to the problem. What they lack in generality, they make up for with an extremely small memory footprint—they require literally nothing more than an array storing the values in the tree—and a blazing fast implementation. In other words, they are perfect for applications such as low-level coding/decoding routines where we don’t need any of the advanced features that segment trees offer, and want to squeeze out every last bit of performance.</p><p> Figure&nbsp;<a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#f6\">6</a> shows a typical implementation of Fenwick trees in Java. As you can see, the implementation is incredibly concise and consists mostly of some small loops doing just a few arithmetic and bit operations per iteration. It is not at all clear what this code is doing, or how it works! Upon closer inspection, the , , and  functions are straightforward, but the other functions are a puzzle. We can see that both the  and  functions call another function , which for some reason performs a bitwise logical AND of an integer and its negation. In fact,  computes the  of , that is, it returns the smallest  such that the th bit of  is a one. However, it is not obvious how the implementation of  works, nor how and why least significant bits are being used to compute updates and prefix sums.</p><section><div data-magellan-destination=\"f6\"><div><p> Implementing Fenwick trees with bit tricks.</p></div></div></section><p> Our goal is  to write elegant functional code for this—already solved!—problem. Rather, our goal will be to use a functional domain-specific language for bit strings, along with equational reasoning, to  and  this baffling imperative code from first principles—a demonstration of the power of functional thinking and equational reasoning to understand code written even in other, non-functional languages. After developing more intuition for segment trees (Section <a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#s2\">2</a>), we will see how Fenwick trees can be viewed as a variant on segment trees (Section <a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#s3\">3</a>). We will then take a detour into two’s complement binary encoding, develop a suitable DSL for bit manipulations, and explain the implementation of the  function (Section <a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#s4\">4</a>). Armed with the DSL, we will then derive functions for converting back and forth between Fenwick trees and standard binary trees (Section <a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#s5\">5</a>). Finally, we will be able to derive functions for moving within a Fenwick tree by converting to binary tree indices, doing the obvious operations to effect the desired motion within the binary tree, and then converting back. Fusing away the conversions via equational reasoning will finally reveal the hidden LSB function, as expected (Section <a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#s6\">6</a>).</p></div><div data-magellan-destination=\"s2\"><p> Figure&nbsp;<a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#f7\">7</a> exhibits a simple implementation of a segment tree in Haskell, using some utilities for working with index ranges shown in Figure&nbsp;<a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#f8\">8</a>. We store a segment tree as a recursive algebraic data type and implement  and  using code that directly corresponds to the recursive descriptions given in the previous section;  and  can then also be implemented in terms of them. It is not hard to generalize this code to work for segment trees storing values from either an arbitrary commutative monoid if we don’t need the  operation—or from an arbitrary Abelian group (i.e. commutative monoid with inverses) if we do need —but we keep things simple since the generalization doesn’t add anything to our story.</p><section><div data-magellan-destination=\"f7\"><div><p> Simple segment tree implementation in Haskell.</p></div></div></section><section></section><p> Although this implementation is simple and relatively straightforward to understand, compared to simply storing the sequence of values in an array, it incurs a good deal of overhead. We can be more clever in our use of space by storing all the nodes of a segment tree in an array, using the standard left-to-right breadth-first indexing scheme illustrated in Figure&nbsp;<a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#f9\">9</a> (for example, this scheme, or something like it, is commonly used to implement binary heaps). The root has label 1; every time we descend one level we append an extra bit: 0 when we descend to the left child and 1 when we descend to the right. Thus, the index of each node expressed in binary records the sequence of left-right choices along the path to that node from the root. Going from a node to its children is as simple as doing a left bit shift and optionally adding 1; going from a node to its parent is a right bit shift. This defines a bijection from the positive natural numbers to the nodes of an infinite binary tree. If we label the segment tree array with , then  stores the sum of all the ,  stores the sum of the first half of the ,  stores the sum of the second half, and so on.  themselves are stored as .</p><section><div data-magellan-destination=\"f9\"><div><p> Indexing a binary tree.</p></div></div></section><p> The important point is that since descending recursively through the tree corresponds to simple operations on indices, all the algorithms we have discussed can be straightforwardly transformed into code that works with a (mutable) array: for example, instead of storing a reference to the current subtree, we store an integer index; every time we want to descend to the left or right, we simply double the current index or double and add one, and so on. Working with tree nodes stored in an array presents an additional opportunity: rather than being forced to start at the root and recurse downwards, we can start at a particular index of interest and move  the tree instead.</p><p> So how do we get from segment trees to Fenwick trees? We start with an innocuous-seeming observation: <em>not all the values stored in a segment tree are necessary</em>. Of course, all the non-leaf nodes are “unnecessary” in the sense that they represent cached range sums which could easily be recomputed from the original sequence. That’s the whole point: caching these “redundant” sums trades off space for time, allowing us to perform arbitrary updates and range queries quickly, at the cost of doubling the required storage space.</p><p> But that’s not what I mean! In fact, there is a different set of values we can forget about, but in such a way that we still retain the logarithmic running time for updates and range queries. Which values, you ask? Simple: just forget the data stored in <em>every node which is a right child</em>. Figure&nbsp;<a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#f10\">10</a> shows the same example tree we have been using, but with the data deleted from every right child. Note that “every right child” includes both leaves and internal nodes: we forget the data associated to  node which is the right child of its parent. We will refer to the nodes with discarded data as  and the remaining nodes (that is, left children and the root) as . We also say that a tree with all its right children inactivated in this way has been .</p><section><div data-magellan-destination=\"f10\"><div><p> Inactivating all right children in a segment tree.</p></div></div></section><p> Updating a thinned segment tree is easy: just update the same nodes as before, ignoring any updates to inactive nodes. But how do we answer range queries? It’s not too hard to see that there is enough information remaining to reconstruct the information that was discarded (you might like to try convincing yourself of this: can you deduce what values must go in the greyed-out nodes in Figure&nbsp;<a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#f10\">10</a>, without peeking at any previous figures?). However, in and of itself, this observation does not give us a nice algorithm for computing range sums.</p><p> It turns out the key is to think about . As we saw in the introduction and the implementation of  in Figure&nbsp;<a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#f6\">6</a>, if we can compute the prefix sum  for any , then we can compute the range sum  as .</p><div data-magellan-destination=\"the1\"><p> Given a thinned segment tree, the sum of any prefix of the original array (and hence also any range sum) can be computed, in logarithmic time, using only the values of active nodes.</p></div><div data-magellan-destination=\"prf1\"><p> Surprisingly, in the special case of prefix queries, the original range query algorithm described in Section <a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#s1\">1</a> and implemented in Figure&nbsp;<a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#f7\">7</a> works unchanged! That is to say, the base case in which the range of the current node is wholly contained within the query range—and we thus return the value of the current node—will only ever happen at active nodes.</p></div><p> First, the root itself is active, and hence, querying the full range will work. Next, consider the case where we are at a node and recurse on both children. The left child is always active, so we only need to consider the case where we recurse to the right. It is impossible that the range of the right child will be wholly contained in the query range: since the query range is always a prefix of the form , if the right child’s range is wholly contained in  then the left child’s range must be as well—which means that the parent node’s range (which is the union of its children’s ranges) would also be wholly contained in the query range. But in that case we would simply return the parent’s value without recursing into the right child. Thus, when we do recurse into a right child, we might end up returning 0, or we might recurse further into both grandchildren, but in any case we will never try to look at the value of the right child itself.</p><p> Figure&nbsp;<a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#f11\">11</a> illustrates performing a prefix query on a segment tree. Notice that visited right children are only ever blue or grey; the only green nodes are left children.</p><section><div data-magellan-destination=\"f11\"><div><p> Performing a prefix query on a segment tree.</p></div></div></section></div><div data-magellan-destination=\"s3\"><p> How should we actually store a thinned segment tree in memory? If we stare at Figure&nbsp;<a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#f10\">10</a> again, one strategy suggests itself: simply take every active node and “slide” it down and to the right until it lands in an empty slot in the underlying array, as illustrated in Figure&nbsp;<a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#f12\">12</a>. This sets up a one-to-one correspondence between active nodes and indices in the range . Another way to understand this indexing scheme is to use a postorder traversal of the tree, skipping over inactive nodes and giving consecutive indices to active nodes encountered during the traversal. We can also visualize the result by drawing the tree in a “right-leaning” style (Figure&nbsp;<a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#f13\">13</a>), vertically aligning each active node with the array slot where it is stored.</p><section><div data-magellan-destination=\"f12\"><div><p> Sliding active values down a thinned segment tree.</p></div></div></section><section><div data-magellan-destination=\"f13\"><div><p> Right-leaning drawing of a thinned segment tree, vertically aligning nodes with their storage location.</p></div></div></section><p> This method of storing the active nodes from a thinned segment tree in an array is precisely a . I will also sometimes refer to it as a , when I want to particularly emphasize the underlying array data structure. Although it is certainly a clever use of space, the big question is how to implement the update and range query operations. Our implementations of these operations for segment trees worked by recursively descending through the tree, either directly if the tree is stored as a recursive data structure, or using simple operations on indices if the tree is stored in an array. However, when storing the active nodes of a thinned tree in a Fenwick array, it is not  obvious what operations on array indices will correspond to moving around the tree. In order to attack this problem, we first take a detour through a domain-specific language for two’s complement binary values.</p></div><div data-magellan-destination=\"s4\"><p> The bit tricks usually employed to implement Fenwick trees rely on a  representation of binary numbers, which allow positive and negative numbers to be represented in a uniform way; for example, a value consisting of all 1 bits represents . We therefore turn now to developing a domain-specific language, embedded in Haskell, for manipulating two’s complement binary representations.</p><p> First, we define a type of bits, with functions for inversion, logical conjunction, and logical disjunction:</p><p> Next, we must define bit strings, i.e. sequences of bits. Rather than fix a specific bit width, it will be much more elegant to work with  bit strings.<a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#fn3\"></a> It is tempting to use standard Haskell lists to represent potentially infinite bit strings, but this leads to a number of problems. For example, equality of infinite lists is not decidable, and there is no way in general to convert from an infinite list of bits back to an —how would we know when to stop? In fact, these practical problems stem from a more fundamental one: infinite lists of bits are actually a bad representation for two’s complement bit strings, because of “junk”, that is, infinite lists of bits which do not correspond to values in our intended semantic domain. For example,  [,] is an infinite list which alternates between  and  forever, but it does not represent a valid two’s complement encoding of an integer. Even worse are non-periodic lists, such as the one with  at every prime index and  everywhere else.</p><p> In fact, the bit strings we want are the  ones, that is, strings which eventually settle down to an infinite tail of all zeros (which represent nonnegative integers) or all ones (which represent negative integers). Every such string has a finite representation, so directly encoding eventually constant bit strings in Haskell not only gets rid of the junk but also leads to elegant, terminating algorithms for working with them.</p><p> represents an infinite sequence of bit , whereas  represents the bit string  followed by a final bit . We use , rather than , to match the way we usually write bit strings, with the least significant bit last. Note also the use of a  on the  field of ; this is to rule out infinite lists of bits using only , such as = () . In other words, the only way to make a non-bottom value of type  is to have a finite sequence of  finally terminated by .</p><p> Although we have eliminated junk values, one remaining problem is that there can be multiple distinct representations of the same value. For example,  ()  and  both represent the infinite bit string containing all zeros. However, we can solve this with a carefully constructed <em>bidirectional pattern synonym</em> (Pickering ., <a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#ref10\">2016</a>).</p><p> Matching with the pattern  uses a  (Erwig &amp; Jones, <a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#ref4\">2001</a>) to potentially expand a  one step into a , so that we can pretend  values are always constructed with . Conversely, constructing a  with  will do nothing if we happen to snoc an identical bit  onto an existing . This ensures that as long as we stick to using  and never directly use ,  values will always be  so that the terminal  is immediately followed by a different bit. Finally, we mark the pattern  as  on its own, since matching on  is indeed sufficient to handle every possible input of type . However, in order to obtain terminating algorithms we will often include one or more special cases for .</p><p> Let’s begin with some functions for converting  to and from  and for displaying  (intended only for testing).</p><p> We can now begin implementing some basic operations on . First, incrementing and decrementing can be implemented recursively as follows:</p><p> The , or LSB, of a sequence of bits can be defined as follows:</p><p> Note that we add a special case for  to ensure that  is total. Technically,  does not have a least significant bit, so defining  seems sensible.</p><p> Bitwise logical conjunction can be defined straightforwardly. Note that we only need two cases; if the finite parts of the inputs have different lengths, matching with  will automatically expand the shorter one to match the longer one.</p><p> Bitwise inversion is likewise straightforward.</p><p> The above functions follow familiar patterns. We could easily generalize to eventually constant streams over an arbitrary element type and then implement <img src=\"data:image/gif;base64,R0lGODlhAQABAIAAAMLCwgAAACH5BAAAAAAALAAAAAABAAEAAAICRAEAOw==\" data-src=\"https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20250116174732089-0720:S0956796824000169:S0956796824000169_inline9001.png?pub-status=live\" width=\"26\" height=\"16\" data-original-image=\"/binary/version/id/urn:cambridge.org:id:binary:20250116174732089-0720:S0956796824000169:S0956796824000169_inline9001.png\" data-zoomable=\"false\"> in terms of a generic  and  in terms of . However, for the present purpose we do not need the extra generality.</p><p> We implement addition with the usual carry-propagation algorithm, along with some special cases for .</p><p> It is not too hard to convince ourselves that this definition of addition is terminating and yields correct results; but we can also be fairly confident by just trying it with QuickCheck:</p><p> Finally, the following definition of negation is probably familiar to anyone who has studied two’s complement arithmetic; I leave it as an exercise for the interested reader to prove that  for all .</p><p> We now have the tools to resolve the first mystery of the Fenwick tree implementation.</p><p> For the last equality, we need a lemma that <img src=\"data:image/gif;base64,R0lGODlhAQABAIAAAMLCwgAAACH5BAAAAAAALAAAAAABAAEAAAICRAEAOw==\" data-src=\"https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20250116174732089-0720:S0956796824000169:S0956796824000169_inline9004.png?pub-status=live\" width=\"123\" height=\"16\" data-original-image=\"/binary/version/id/urn:cambridge.org:id:binary:20250116174732089-0720:S0956796824000169:S0956796824000169_inline9004.png\" data-zoomable=\"false\">, which should be intuitively clear and can easily be proved by induction as well.</p><p> Finally, in order to express the index conversion functions we will develop in the next section, we need a few more things in our DSL. First, some functions to set and clear individual bits and to test whether particular bits are set:</p><p> The only other things we will need are left and right shift, and a generic  combinator that iterates a given function, returning the first iterate for which a predicate is false.</p></div><div data-magellan-destination=\"s6\"><h2> Deriving Fenwick operations</h2><p> We can now finally derive the required operations on Fenwick array indices for moving through the tree, by starting with operations on a binary indexed tree and conjugating by conversion to and from Fenwick indices. First, in order to fuse away the resulting conversion, we will need a few lemmas.</p><div data-magellan-destination=\"lem6_1\"><p> (shr-inc-dec). For all  which are odd (that is, end with I),</p><ul></ul></div><div data-magellan-destination=\"prf2\"><p> Both are immediate by definition.</p></div><div data-magellan-destination=\"lem6_2\"><p> (while-inc-dec). <em>The following both hold for all Bits values:</em></p><ul></ul></div><p> Easy proof by induction on . For example, for the  case, the functions on both sides discard consecutive 1 bits and then flip the first 0 bit to a 1.</p><p> Finally, we will need a lemma about shifting zero bits in and out of the right side of a value.</p><div data-magellan-destination=\"prf3\"><p> Intuitively, this says that if we first shift out all the zero bits and then left shift until bit  is set, we could get the same result by forgetting about the right shifts entirely; shifting out zero bits and then shifting them back in should be the identity.</p></div><p> Formally, the proof is by induction on . If  is odd, the equality is immediate since . Otherwise, if , on the left-hand side the  is immediately discarded by , whereas on the right-hand side , and the extra  can be absorbed into the  since . What remains is simply the induction hypothesis.</p><p> With these lemmas under our belt, let’s see how to move around a Fenwick array in order to implement  and ; we’ll begin with . When implementing the  operation, we need to start at a leaf and follow the path up to the root, updating all the active nodes along the way. In fact, for any given leaf, its closest active parent is precisely the node stored in the slot that used to correspond to that leaf (see Figure&nbsp;<a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#f13\">13</a>). So to update index , we just need to start at index  in the Fenwick array, and then repeatedly find the closest active parent, updating as we go. Recall that the imperative code for  works this way, apparently finding the closest active parent at each step by adding the LSB of the current index:</p><p> Let’s see how to derive this behavior.</p><p> To find the closest active parent of a node under a binary indexing scheme, we first move up to the immediate parent (by dividing the index by two, i.e. performing a right bit shift); then continue moving up to the next immediate parent as long as the current node is a right child (i.e. has an odd index). This yields the definition:</p><p> This is why we used the slightly strange indexing scheme with the root having index 2—otherwise this definition would not work for any node whose active parent is the root!</p><p> Now, to derive the corresponding operation on Fenwick indices, we conjugate by conversion to and from Fenwick indices and compute as follows. To make the computation easier to read, the portion being rewritten is underlined at each step.</p><p> In the final step, since the input  satisfies , we have , so Lemma 6.3 applies.</p><p> Reading from right to left, the pipeline we have just computed performs the following steps:</p><p> 2. Shift out consecutive zeros until finding the least significant 1 bit</p><p> 4. Shift zeros back in to bring the most significant bit back to position , then clear it.</p><p> Intuitively, this does look a lot like adding the LSB! In general, to find the LSB, one must shift through consecutive 0 bits until finding the first 1; the question is how to keep track of how many 0 bits were shifted on the way. The  function itself keeps track via the recursion stack; after finding the first 1 bit, the recursion stack unwinds and re-snocs all the 0 bits recursed through on the way. The above pipeline represents an alternative approach: set bit  as a “sentinel” to keep track of how much we have shifted; right shift until the first 1 is literally in the ones place, at which point we increment; and then shift all the 0 bits back in by doing left shifts until the sentinel bit gets back to the  place. One example of this process is illustrated in Figure&nbsp;<a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#f19\">19</a>. Of course, this only works for values that are sufficiently small that the sentinel bit will not be disturbed throughout the operation.</p><section><div data-magellan-destination=\"f19\"><div><p> Adding LSB with a sentinel bit + shifts.</p></div></div></section><p> To make this more formal, we begin by defining a helper function , which does an operation “at the LSB”, that is, it shifts out 0 bits until finding a 1, applies the given function, then restores the 0 bits.</p><div data-magellan-destination=\"prf4\"><p> Straightforward induction on .</p></div><p> We can formally relate the “shifting with a sentinel” scheme to the use of , with the following (admittedly rather technical) lemma:</p><p> The proof is rather tedious and not all that illuminating, so we omit it</p><p> (an extended version including a full proof may be found on the author’s website, at <a href=\"http://ozark.hendrix.edu/\">http://ozark.hendrix.edu/</a> yorgey/pub/Fenwick-ext.pdf). However, we do note that both  and  fit the criteria for : incrementing or decrementing some  cannot affect the st bit as long as , and the result of incrementing or decrementing a number less than  will be a number less than . We can now put all the pieces together show that adding the LSB at each step is the correct way to implement .</p><p> We can carry out a similar process to derive an implementation for prefix query (which supposedly involves  the LSB). Again, if we want to compute the sum of [1, ], we can start at index  in the Fenwick array, which stores the sum of the unique segment ending at . If the node at index  stores the segment [,], we next need to find the unique node storing a segment that ends at . We can do this repeatedly, adding up segments as we go.</p><p> Staring at Figure&nbsp;<a href=\"https://www.cambridge.org/core/journals/journal-of-functional-programming/article/you-could-have-invented-fenwick-trees/B4628279D4E54229CED97249E96F721D#f20\">20</a> for inspiration, we can see that what we want to do is find the  of our , that is, we go up until finding the first ancestor which is a right child, then go to its left sibling. Under a binary indexing scheme, this can be implemented simply as:</p><section><div data-magellan-destination=\"f20\"><div><p> Moving up a segment tree to find successive prefix segments.</p></div></div></section><div data-magellan-destination=\"the6_7\"><p> Subtracting the LSB is the correct way to move up a Fenwick-indexed tree to the active node covering the segment previous to the current one, that is, </p><p> everywhere on the range .</p></div></div><div data-magellan-destination=\"s7\"><p> Historically, to my knowledge, Fenwick trees were not actually developed as an optimization of segment trees as presented here. This has merely been a fictional—but hopefully illuminating—alternate history of ideas, highlighting the power of functional thinking, domain-specific languages, and equational reasoning to explore relationships between different structures and algorithms. As future work, it would be interesting to explore some of the mentioned generalizations of segment trees, to see whether one can derive Fenwick-like structures that support additional operations.</p></div>","contentLength":29142,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42818248"},{"title":"Show HN: Lightpanda, an open-source headless browser in Zig","url":"https://github.com/lightpanda-io/browser","date":1737756932,"author":"fbouvier","guid":163,"unread":true,"content":"<p>We’re Francis and Pierre, and we're excited to share Lightpanda (<a href=\"https://lightpanda.io\" rel=\"nofollow\">https://lightpanda.io</a>), an open-source headless browser we’ve been building for the past 2 years from scratch in Zig (not dependent on Chromium or Firefox). It’s a faster and lighter alternative for headless operations without any graphical rendering.</p><p>Why start over? We’ve worked a lot with Chrome headless at our previous company, scraping millions of web pages per day. While it’s powerful, it’s also heavy on CPU and memory usage. For scraping at scale, building AI agents, or automating websites, the overheads are high. So we asked ourselves: what if we built a browser that only did what’s absolutely necessary for headless automation?</p><p>Our browser is made of the following main components:</p><p>- an HTML parser and DOM tree (based on Netsurf libs)</p><p>- a Javascript runtime (v8)</p><p>- partial web APIs support (currently DOM and XHR/Fetch)</p><p>- and a CDP (Chrome Debug Protocol) server to allow plug &amp; play connection with existing scripts (Puppeteer, Playwright, etc).</p><p>The main idea is to avoid any graphical rendering and just work with data manipulation, which in our experience covers a wide range of headless use cases (excluding some, like screenshot generation).</p><p>In our current test case Lightpanda is roughly 10x faster than Chrome headless while using 10x less memory.</p><p>It's a work in progress, there are hundreds of Web APIs, and for now we just support some of them. It's a beta version, so expect most websites to fail or crash. The plan is to increase coverage over time.</p><p>We chose Zig for its seamless integration with C libs and its  feature that allow us to generate bi-directional Native to JS APIs (see our zig-js-runtime lib <a href=\"https://github.com/lightpanda-io/zig-js-runtime\">https://github.com/lightpanda-io/zig-js-runtime</a>). And of course for its performance :)</p><p>As a company, our business model is based on a Managed Cloud, browser as a service. Currently, this is primarily powered by Chrome, but as we integrate more web APIs it will gradually transition to Lightpanda.</p><p>We would love to hear your thoughts and feedback. Where should we focus our efforts next to support your use cases?</p>","contentLength":2114,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42817439"},{"title":"Show HN: Onit – open-source ChatGPT Desktop with local mode, Claude, Gemini","url":"https://github.com/synth-inc/onit","date":1737756916,"author":"telenardo","guid":162,"unread":true,"content":"<p>Hey Hackernews- it’s Tim Lenardo and I’m launching v1 of Onit today!</p><p>Onit is ChatGPT Desktop, but with local mode and support for other model providers (Anthropic, GoogleAI, etc). It's also like Cursor Chat, but everywhere on your computer - not just in your IDE!</p><p>Onit is open-source! You can download a pre-built version from our website: \nwww.getonit.ai</p><p>We built this because we believe:\nUniversal Access: AI assistants should be accessible from anywhere on my computer, not just in the browser or in specific apps\nProvider Freedom: Consumers should have the choice between providers (anthropic, openAI, etc.) not be locked into a single one (ChatGPT desktop only has OpenAI models)\nLocal first: AI is more useful with access to your data. But that doesn't count for much if you have to upload personal files to an untrusted server. Onit will always provide options for local processing. No personal data leaves your computer without approval\nCustomizability: Onit is your assistant. You should be able to configure it to your liking\nExtensibility: Onit should allow the community to build and share extensions, making it more useful for everyone.</p><p>The features for V1 include:\n Local mode - chat with any model running locally on Ollama! No internet connection required\n Multi-provider support - Top models for OpenAI, Anthropic, xAI, and GoogleAI\n File upload - add images or files for context (bonus: Drag &amp; drop works too!)\n History - revisit prior chats through the history view or with a simple up/down arrow shortcut\n Customizable Shortcut - you pick your hotkey to launch the chat window. (Command+zero by default)</p><p>What data are you collecting?\nOnit V1 does not have a server. Local requests are handled locally, and remote requests are sent to model providers directly from the client. We collect crash reports through Firebase and a single \"chat sent\" event through PostHog analytics. We don't store your prompts or responses.</p><p>How to does Onit support local mode? \nFor use local mode, run Ollama. You can get Ollama here: <a href=\"https://ollama.com/\">https://ollama.com/</a> \nOnit gets a list of your local models through Ollama’s API.</p><p>Which models do you support? \nFor remote models, Onit V1 supports Anthropic, OpenAI, xAI and GoogleAI. Default models include (o1, o1-mini, GPT-4o, Claude3.5 Sonnet, Claude3.5 Haiku, Gemini 2.0, Grok 2, Grok 2 Vision).\nFor local mode, Onit supports any models you can run locally on Ollama!</p><p>What license is Onit under? \nWe’re releasing V1 available on a Creative Commons Non-Commercial license. We believe the transparency of open-source is critical. We also want to make sure individuals can customize Onit to their needs (please submit PRs!). However, we don’t want people to sell the code as their own.</p><p>Where is the monetization?\nWe’re not monetizing V1. In the future we may add paid premium features. Local chat will- of course- always remain free. If you disagree with a monetized feature, you can always build from source!</p><p>Why not Linux or Windows? \nGotta start somewhere! If the reception is positive, we’ll work hard to add further support.</p><p>Who are we? \nWe are Synth, Inc, a small team of developers in San Francisco building at the frontier of AI progress. Other projects include Checkbin (www.checkbin.dev) and Alias (deprecated - www.alias.inc).</p><p>We’d love to hear from you! Feel free to reach out at contact@getonit dot ai.</p><p>Future roadmap includes:\n Autocontext - automatically pull context from computer, rather than having to repeatedly upload. \n Local-RAG - let users index and create context from their files without uploading anything. \n Local-typeahead - i.e. Cursor Tab but for everywhere\n Additional support - add Linux/Windows, Mistral/Deepseek etc etc.\n (maybe) Bundle Ollama to avoid double-download\n And lot’s more!</p>","contentLength":3758,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42817438"},{"title":"Trying out Zed after more than a decade of Vim/Neovim","url":"https://sgoel.dev/posts/trying-out-zed-after-more-than-a-decade-of-vim-neovim/","date":1737755580,"author":"siddhant","guid":175,"unread":true,"content":"<p>I'm currently drafting this blog post in <a rel=\"noopener\" target=\"_blank\" href=\"https://zed.dev\">Zed</a>. After using Vim/Neovim for more than 15\nyears, I recently decided to try out something new. I don't know if this little\nexperiment will work, or if I'll run back to my trusty Neovim, but hey, what I do know\nis that I'd like to find out.</p><p>Why though? If you've used a specific tool for that long, why (try to) switch to\nsomething else anyway? Everyone has their own reasons. I have two.</p><h3>1. The desire to use something that just works</h3><p>Lately, I've been drifting towards things that \"just work\".</p><p>I love (Neo)Vim. Like I wrote earlier, it's been my primary editor for the past 15\nyears. What I don't love is all the configuration that goes into it before I can use it\nto start writing code.</p><p>When I first started using Vim (in 2009!), my configuration was a tiny  file\nthat was handed over to me by my internship supervisor at that time. I had no idea what\nit did, but it worked. Over time, as I felt the need to customize things, my \nstarted accumulating increasingly more code copied from StackOverflow that I didn't\nunderstand.</p><p>At some point Neovim came out, and with it, the ability to configure things using Lua.\nThis was a huge step up, because I could at least understand what I was configuring.</p><p>Either way, it's still configuration. What changed was just  that configuration was\ndone. The combination of configuring the base editor and installing a set of plugins\n(and making sure that they play nice with each other) isn't really something that I\nwould like to spend my time on, going forward.</p><p>One recent example that highlights this problem: my workflow consists of switching\nback and forth between a terminal window and an editor window. At any time, I have\nmultiple projects open in both. On macOS, it's been difficult to find a solution that\n\"just works\". The most popular Neovim GUI clients on macOS include <a rel=\"noopener\" target=\"_blank\" href=\"https://github.com/qvacua/vimr\">Vimr</a> and <a rel=\"noopener\" target=\"_blank\" href=\"https://neovide.dev/\">Neovide</a>,\nwhich are both excellent projects. Neovide though, <a rel=\"noopener\" target=\"_blank\" href=\"https://github.com/neovide/neovide/issues/1332\">does not support multiple windows</a>,\nwhich is integral to my workflow and hence requires me to implement <a href=\"https://sgoel.dev/posts/switching-between-projects-in-neovim/\">workarounds</a>, which\nactually broke last week after I ran . And while Vimr does support\nmultiple windows, it is <a rel=\"noopener\" target=\"_blank\" href=\"https://github.com/qvacua/vimr/issues/887\">not able to render icons in nvim-tree</a>, which is less than\nideal. 🤷🏻‍♂️</p><h3>2. Deeper and native LLM integration</h3><p>LLMs are happening, whether we like it or not. And no, the fact that they aren't 100%\ncorrect all the time is not a reason to discard them entirely. I understand why some\npeople don't want to use them. And I respect that. I personally find them useful and\nwould like to integrate them more into my daily workflow.</p><p>The Neovim ecosystem has a bunch of plugins for using LLMs. But as I wrote in the\nprevious section, I'd like to avoid plugins when possible. Installing plugins means\nupdating them, which inevitably breaks things.</p><p>One example where I find LLMs useful when coding is handling boilerplate stuff. In my\ncurrent Neovim setup, I have the the <a rel=\"noopener\" target=\"_blank\" href=\"https://github.com/Exafunction/codeium.nvim\">Codeium extension</a> installed, which offers code\nsuggestions that are like an autocomplete on steroids. Often, I can write a function\nname and what parameters it's expecting, and the LLM writes out the function for me.\nThis is particularly helpful when writing small functions or test cases.</p><p>I'd like to be able to do more of such things in my editor. I'm not entirely sold on the\nidea of agentic editors, as I'd like to keep at least  agency over the code that's\ngoing in, but that's a different topic.</p><p>Another example of where I find LLMs useful: I'm not a native English speaker and often\nstruggle to find the right sentence framing that is both concise and catchy. LLMs are\nexcellent at this! I can scribble my initial thoughts, throw it at an LLM and ask it to\nreframe the whole thing, which is great!</p><p>Generally, it feels like the way we're writing code is changing with the introduction of\nthis extremely powerful tool, and I'd like to move with the times.</p><p>So yeah, those are the two reasons why I've been looking to try out something else\nlately. What made me go for Zed?</p><p>Yep, that's literally the first reason. After using Vim for 15 years, my fingers have\nbuilt up enough muscle memory that not using Vim keybindings when writing code is\ndownright impossible.</p><p>Zed's <a rel=\"noopener\" target=\"_blank\" href=\"https://zed.dev/docs/vim\">Vim mode</a> is surprisingly solid! So far, I feel right at home. Almost all Vim\nkeybindings that I'm used to work just as expected. The one or two bindings that don't\nwork, are something that I can make my peace with and retrain my fingers on. Everything\nelse works excellent. It also looks like they're <a rel=\"noopener\" target=\"_blank\" href=\"https://zed.dev/blog/vim-2025\">doubling down on their Vim mode</a>\nsupport in 2025, which is a great sign!</p><p>When you fire up Zed, the editor is fully functional without having to write a single\nline of configuration. That's awesome. The editor may prompt you every now and then to\ninstall support for specific languages. But that's usually just one button click.</p><p>Lua is great, but one JSON file is even better. Zed uses JSON as the configuration\nsyntax and so far it feels a lot simpler than what I've worked with so far.</p><p>I had no idea I needed this until I had it!</p><p>While editing the Zed configuration file, I found it really helpful how the editor\nsuggests configuration keys and their potential values. This feature felt really\nthoughtful when I first saw it and I could imagine that it goes a long way in getting\nnew users up to speed quicker.</p><h3>5. Native LLM integration</h3><p>I know some people have been turned off by this, but I actually like this feature.</p><p>Zed has a feature called Assistant, which is a tool to, well, assist you, using a large\nlanguage model of your choice. A few popular LLM providers are supported. Once set up,\nyou can open up the Assistant panel to work together with the language model you've\nchosen. For instance, it's pretty easy to type in questions in the panel window and then\npaste text from your open file buffers into it to give the LLM more context. There's a\nlot more to this feature that I haven't used yet, but I'll probably get to it the more I\nuse it.</p><p>Overall, the integration feels very native and very useful.</p><p>Last but definitely not the least is speed! Zed is  fast. Everything feels very\nsnappy, and it's clear that the team has put a lot of effort into making everything\nfast.</p><p>It's only been a day since I really started using Zed instead of Neovim as my daily\ndriver. And so far the experience has been quite nice.</p><p>Like I wrote earlier, this is an experiment. We'll see how things turn out. That being\nsaid though, the first impression looks  good.</p>","contentLength":6413,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42817277"},{"title":"A very Chicago gamble","url":"https://www.bitsaboutmoney.com/archive/chicago-casino-investment-offering/","date":1737748591,"author":"gregorymichael","guid":174,"unread":true,"content":"<p>This column doesn’t offer investment advice, as I am not a registered investment advisor. This is not merely a mandatory disclaimer; this is a warning. We will discuss some specific securities below that I am not  of recommending.</p><p>Finance performs a strange alchemy, teleporting value through time and space. Ordinarily, Bits about Money focuses more on the plumbing of it than the deals. But a deal enthusiast who goes by <a href=\"https://www.patreon.com/theconservativeincomeinvestor\">The Conservative Income Investor</a> recently flagged a capital raise to me. It has everything: echoes of the culture that is the American PMC 2020-2024, complex financial structuring, a novel web application to move money, a crypto company in the background, and municipal politics. So it seems squarely within this column’s beat.</p><p>The municipality happens to be Chicago, my hometown and (after a 20 year stint in Japan) current residence. And so I feel some sense of civic duty, as a Chicagoan, taxpayer, and reasonably financially sophisticated person, to say the following publicly: </p><p>But before we get to present-day shenanigans, we need to go back several decades, because municipal politics is inextricable from the shenanigans.</p><h2>Chicago has wanted a casino for a long time</h2><p>Chicago and the state of Illinois more broadly have a deeply unserious polity. It has mortgaged its future through consistently overpaying public sector employees (principally, in Chicago, police/fire/teachers) and undertaxing. Neither decreasing total compensation of public sector employees nor reneging on previously-negotiated deferred compensation (pensions and healthcare for retirees) nor raising taxes to appropriate levels is considered politically palatable. One reason is that the <a href=\"https://www.ilga.gov/commission/lrb/conent.htm\">Illinois state constitution</a> (Article 13 Section 5) makes public employee pensions sacrosanct. The constitution is, of course, not a fact of nature; it is a political compromise by, again, a deeply unserious polity.</p><p>And so Illinois and Chicago specifically are constantly on the make for new revenue streams. One which was mooted <a href=\"https://repryanspain.com/2024/02/07/looking-back-riverboat-gambling-enacted-in-illinois-february-7-1990/\">since my childhood in the 1980s</a> was an expansion of gambling. So-called sin taxes (on gambling, liquor, tobacco, and similar) are politically attractive because they do not cause as much opposition as raising consumption or property taxes.</p><p>And so Chicago has had a decades-long campaign to build a casino within city limits. Why couldn’t Chicago actually get this done in several decades? One reason is the usual incompetence. The other reason is that the political economy of casinos is controversial. Many policies create winners and losers, but casinos inescapably create losers than most policies up for vote. Local political elites often band together against them, worried about siphoning money from local consumers. They also worry that they tend to create spillover effects, such as crime and moral collapse among a portion of patrons.</p><p>And so, as I once mentioned in a <a href=\"https://www.thinkingpoker.net/2020/12/episode-341-patrick-mckenzie/\">podcast with Thinking Poker</a>, pro-casino political coalitions try to pick off anti-casino political elites by assuaging their concerns and/or bribing them. (In Japan, the de facto concession was “We’ll limit the amount Japanese people can lose here and maximize for soaking Chinese tourists. Now, let’s write that down in a way which doesn’t say exactly that, because it sounds bad if you put it that way.”)</p><p>In Chicago, much of the opposition came from African American political elites. They had the usual set of concerns for casinos, plus one other which is slightly more idiosyncratic. A belief with wide currency in that community is that the community would be much more wealthy than it currently is, but for vice entrepreneurs siphoning that community’s resources out of the community. This belief has lead to e.g. <a href=\"https://www.latimes.com/california/story/2020-02-11/south-los-angeles-korean-liquor-protest-leimert-park-riots\">pogroms</a> against Korean liquor store owners. I direct interested readers to histories of the Rodney King riots or the Asian American experience in 20th century America. (This was covered extensively in an elective I took more than 20 years ago, and so I have since forgotten the academic citations for this true but parenthetical point.)</p><p>Bally’s <a href=\"https://seminoletribune.org/ballys-wins-bid-for-chicago-casino/\">won the bid</a> for the newly licensed Chicago casino in 2022, in part due to offering the right mix of concessions and inducements in its <a href=\"https://www.chicago.gov/city/en/sites/chicago-casino/home/hca.html\">Host Community Agreement</a>. One of those was promising Chicago that the new casino would be at least 25% owned by women and Minorities. The M is capital in the Chicago municipal code, and I will preserve this stylistic choice, because the word does not mean what most educated Americans assume it means. We shall return to that meaning later.</p><p>In fulfillment of its obligations under the HCA, Bally’s Chicago, Inc., an entity in the corporate web which will build and operate the casino, has <a href=\"http://ballyschicagoinvest.com\">conducted a stock offering</a> since December. It runs through January 2025.</p><p>The stock offering has a <a href=\"https://www.sec.gov/Archives/edgar/data/1935799/000110465924132193/tm2310971-13_s1a.htm\">prospectus</a> associated with it. BCI does not appear to be relying on an exemption from registration, in the fashion that e.g. most startups would, restricting them to raising money from accredited investors.</p><p>While reading the prospectus, I read a <a href=\"https://wirepoints.org/no-white-men-allowed-in-ballys-chicago-share-offering-promoted-by-city-officials-wirepoints/\">much-remarked-upon</a> statement, and assumed it was a misprint.</p><p><em>This offering is only being made to individuals and entities that satisfy the Class A Qualification Criteria (as defined herein). Our Host Community Agreement with the City of Chicago requires that 25% of Bally’s Chicago OpCo’s equity must be owned by persons that have satisfied the Class A Qualification Criteria. The Class A Qualification Criteria include, among other criteria, that the person:</em></p><ul><li><em>if an individual, must be a woman;</em></li><li><em>if an individual, must be a Minority, as defined by MCC 2-92-670(n) (see below); or</em></li><li><em>if an entity, must be controlled by women or Minorities.</em></li></ul><p>Why did I assume this was a mistake? Well, for one thing, on the face of it Bally’s has told the SEC that this offering is only available to Minorities who are  women, which does not match the intent expressed elsewhere or during their roadshow. I have immense sympathy for drafting errors. Bally’s, feel free to let the lawyers know they forgot a significant “or” on the first bullet point. [: An actual lawyer, not an Internet lawyer, informs me that the first bullet point has an implied \"or\" in this construction. Mea maxima culpa, associate who drafted this.] </p><p>The other reason I thought this was likely a mistake is that the American social, legal, and constitutional order is profoundly opposed to discrimination by race, and considers that action . Even when individual actors  to do it, they usually feel embarrassed enough about it to dissemble.&nbsp;</p><p>For example, the last few years tech companies <a href=\"https://x.com/patio11/status/1678235882481127427\">absolutely</a>, <a href=\"https://www.wsj.com/articles/youtube-hiring-for-some-positions-excluded-white-and-asian-males-lawsuit-says-1519948013\">notoriously</a> engaged in legally prohibited discrimination in hiring, sometimes as an intentionally directed and explicitly written down policy. This is often assumed to be a conspiracy theory by disaffected white males. Perhaps that is an understandable belief, since people who read the project plans either a) supported them or b) value their future careers and are therefore mostly not leaking them, and thus we only have public evidence of those project plans which end up screenshotted in litigation. Similarly, when I say that the state of California <a href=\"https://worksinprogress.co/issue/the-story-of-vaccinateca/\">proudly engaged in redlining in the provision of lifesaving medical care</a> in 2021, many people of good-will assume that I simply  be mistaken.&nbsp;<em>I get it, but I was there.</em></p><p>Returning from the ancient history of 2021 to this very week: Chicago has directed a private entity to segregate, and that entity is segregating, principally via web application. If you attempt to engage Bally’s for an investment here, you will see the following blocking question during qualification stages for the investment opportunity. (The web application will also ask for your name, address, social security number, and accredited investor status.)</p><p>There is a right answer to this question. If you give the wrong answer, Bally’s will decline you the opportunity to invest. You get entirely stopped by the web application.</p><p>I express no opinion on whether this is legal, by Bally’s or Chicago. After all, I am not a lawyer, and this has certainly been seen by many lawyers at this point, in e.g. preparing the submission to the SEC. Presumably all of them went through 1L courses which introduced concepts like the <a href=\"https://constitution.congress.gov/constitution/amendment-14/\">Fourteenth Amendment</a>, case law which says government actions discriminating by race are <a href=\"https://crsreports.congress.gov/product/pdf/IF/IF12391\">subject to strict scrutiny</a>, and case law which says that the government cannot proxy through a private entity to do things it is prohibited to do itself. And clearly no one admitted to the bar in Illinois thinks that Chicago can waive the U.S. Constitution if it considers that politically advantageous to get a gridlocked casino through municipal politics.</p><p>So I will charitably assume the existence of a memo where competent professionals have laid out a case for the legality of this course of action. They must have concluded that no future Department of Justice Civil Rights Division, not even in an administration elected after the Host Community Agreement had been inked, would descend upon this official act like the hammer of an avenging god.</p><h2>Chicago’s peculiar definition of Minority</h2><p>Long-time observers of Chicago politics might opine that the city very rarely does anything without creating a carveout for politically connected individuals. The local phrase for this sort of social connection is having “clout” or, sometimes, “<a href=\"https://www.google.com/search?q=site%3Achicagotribune.com+%22is+clouted%22\">is clouted</a>.” You can find examples of the sort of carveouts Chicago reserves for the clouted in the professional histories of the board members of Bally’s Chicago, Inc, for example, which are included in the prospectus.</p><p>So what’s the carveout here? The definition of a racial or ethnic minority is a legendarily contentious one in U.S. politics, largely because inclusion or exclusion from it makes one eligible (or ineligible) for concrete benefits. Sites of contention often include e.g. are Asian Americans a minority, or are e.g. Cuban Americans Hispanic, etc.</p><p>Chicago leaves itself an out for its definition of Minority, which <em>lets it designate any individual or group as a Minority</em>, on an ad hoc, unreported, unaccountable basis. That sounds like I must be strawmanning Chicago. See the below screenshot and explanation in the prospectus</p><p><em>Qualification under [the final] clause is determined on a case-by-case basis and there is no exhaustive or definitive list of groups or individuals that the City of Chicago has determined to qualify as Minority under this clause. However, in the event the City of Chicago identifies any additional groups or individuals as falling under this clause in the future, members of such groups would satisfy the Class A Qualification Criteria.</em></p><p>Now, fairminded people reading “groups… found by the City of Chicago to be socially disadvantaged by having suffered racial or ethnic prejudice or cultural bias within American society” would note “Well, OK, on the face of it, that definitely includes e.g. Jewish Americans or Irish Americans. We have some lamentable history as a nation and city, sure. But no intellectually serious person in the United States considers Irish Americans ‘a racial or ethnic minority’ <em>in the common usage of the term</em>.” And thus, the capitalization of Minority.</p><p>You’ll have to ask the city for their list of ad hoc exceptions made under this bullet point. Long-time watchers of Chicago municipal politics, however, might say that asking is of limited utility.</p><p>I will note that, as a matter of engineering fact, the web application will blithely accept self-certification under this bullet point . You are welcome to your guess as to whether Bally’s or any city employee will review the 1,000 investors individually and, if they review them, what the process is for determining whether e.g. a particular Patrick counts as a Minority or not.&nbsp;</p><p>I’d wager there is no process at all here. It seems like a better bet than most offered in the casino.</p><p>Bally’s Chicago is a product of Bally’s, a publicly traded company. You can read <a href=\"https://www.ballys.com/investor-relations/financials/default.aspx\">their 10-Ks</a>. According to their <a href=\"https://d18rn0p25nwr6d.cloudfront.net/CIK-0001747079/e72243a7-c47d-4ca7-a9fc-e91f8f95fb18.pdf\">most recent quarterly report</a>, they operate 15 casinos across the U.S., and have substantial online gambling operations. Like many casinos, they are  diversified, insofar as a casino resort also functions as a hotel and restaurant/bar/etc venue.</p><p>Bally’s Chicago has a complex capital stack, which one would probably need to understand to evaluate the opportunity to invest in it. I am not saying “complex” as a criticism: this is fairly ho hum by the standards of large commercial real estate developments, a subject I am not an expert on but <a href=\"https://www.complexsystemspodcast.com/episodes/the-hundred-year-old-telegram-worth-5-million-with-jim-mckenzie-2/\">grew up hearing about at the dinner table</a>. I  heavily implying that I would not expect a Chicagoan picked at random, or for that matter an alderman, to be able to look at the following diagram and correctly describe what it means. Prospectus, ibid, pg 145.</p><p>The entity which Chicago is stumping for is Bally’s Chicago, Inc. (BCI), the central square on that diagram.  investors are receiving ownership in , not in , which will be operated by Bally’s Chicago Operating Company, LLC (BCOC). That entity gets 25% economic interest in the future profits (insert  asterisk here) of the casino; the other 75% flows to Bally’s Chicago Holding Company, LLC (BCHC). BCHC is a wholly-owned subsidiary of Bally’s, Inc, the publicly traded company.</p><p>When one offers someone the opportunity to invest in something, one has to decide upon a valuation for the something. The price of a slice of the pie is set in notional reference to the price of the whole pie.</p><p>Bally’s says that its good faith guesstimate on the whole pie is the economic interest in future profits of the Chicago casino is… <em>a billion dollars exactly</em>. The prospectus, as is wont for these situations, disclaims floridly that that price might not be accurate. One example of many: “We made a number of assumptions to determine the price of our Class A Interests. If any of our assumptions are incorrect, including our assumptions regarding the total enterprise value of the Company, then the Class A Interests will be worth less than the price stated in this prospectus. In such case, the return on investment or rate of return on an investment in our Class A Interests could be significantly below an investor’s expectation.”</p><p>Bally’s will, as is standard and customary for this sort of thing, pretend that investors have read and understood the ~200 page prospectus, and civil society will pretend to believe them.</p><p>It isn’t  to pick a billion dollars out of one’s hindquarters as an investment valuation. That particular number exerts a sort of memetic quality in e.g. Silicon Valley, and there are legendary amounts of negotiation between sophisticated parties to accept just a bit more structure to get a e.g. $920 million valuation to a $1 billion valuation, because so-called unicorn status is good for PR, for attracting prospective employees, and (a real factor) for founder ego.</p><p>But if you invest at a valuation not justified by the fundamentals of the investment, you will tend to underperform. This is an inescapable fact of investing. (And that is why the sophisticated investors, accepting a “worse” valuation, want “better” structure to compensate for it.)</p><p>And this partially explains why Chicago is holding a roadshow in African American churches attempting to convince participants to invest in a mezzanine-y equity slice of a casino at a $1 billion valuation, perhaps at 100X leverage. (I tip my cap to <a href=\"https://thetriibe.com/2025/01/chicagos-black-residents-can-invest-in-ballys-casino/\">publicly available reporting</a> of the roadshow.) And not, for example, attempting to convince Goldman Sachs to put together some sophisticated investors and take down the $250 million allocation.</p><h2>Is this valuation a gift to investors?</h2><p>Chicago’s pitch to investors, delivered (per above reporting by Triibe) by “City Treasurer Melissa Conyears-Ervin and members of the Chicago Aldermanic Black Caucus”, emphasizes the potential of creating “generational wealth” (direct quote) with this casino investment. This point of view aligns with the above described political economy of attempting to buy off influential communities and/or community elites with an equity carveout, which successfully got this particular casino through decades of political gridlock.</p><p>And so the investment case  that Bally’s is intentionally giving takers something for nothing. That is, they must be sandbagging the valuation they assigned to this bundle of rights: it’s not really worth $1 billion, it is worth e.g. $5 billion. Only you favored Chicagoans well-loved by your alderman are able to buy at the non-market price, leading to essentially free money. Not merely small amounts of it, either. Generational. Wealth.</p><p>The pitch very likely explicitly said the requisite words about this being a risky investment, wink wink, and very definitely described an opportunity for extreme levels of leverage and a lengthy expected road to ROI, which we’ll return to in a moment.</p><p>Do I think sophisticated investors would agree with Bally’s that this bundle of rights is worth $1 billion? </p><p>One reason is the perception of an absence: why is this pitch being given to individual savers in a church at a minimum investment of $250, and not in a swank office to an entity capable of committing $25 million? But perhaps I’m just suspicious.</p><p>No, let’s go to more direct evidence: if 25% of this bundle of rights is worth $250 million, then 75% must be worth $750 million, right? And if an entity owning 75% of the bundle, Bally’s, also owns 14 other casinos, online gambling properties, and similar, then that entity must be worth a lot more than $750 million, right?</p><p><strong>The market does not agree with this assessment</strong>. The entire market capitalization of Bally’s (NYSE: BALY) is, as of this writing, ~$1.5 billion. What’s the difference between the $50 million average imputed value of the other casinos and the $750 million imputed value of the Chicago casino?<strong> The $750 million is , that’s what.</strong></p><p>And, again, the  of this pitch is that the bundle of rights is getting sold on the cheap, and that it is actually worth much more than $1 billion. It very clearly is not, or sophisticated investors would be swooping in and buying BALY’s common stock. Crack it open like an oyster and dig into that sweet sweet Chicago gambling revenue if you need to!</p><p>This is somewhat elementary and handwavy napkin analysis of a complicated business which, like most casinos and hotels, is heavily levered with a complex capital stack. But the investment case gets smothered by a napkin.</p><h2>Capital stack arbitrage, or, giving retail 100:1 leverage on single stock issuances</h2><p>The Host Community Agreement, as above, obligates Bally’s to find a way to sell preferred Chicagoans $250 million of stock. This was likely complicated by rich Chicagoans not being suckers and less-well-off Chicagoans not having $250 million lying around.</p><p>And so Bally’s has introduced a novel structure.</p><p>In brief, that structure sells stock to investors on credit, with the credit being extended by Bally’s, and paid down by future dividend distributions of the stock. If you’re very interested in the mechanics, you can find them at length in the prospectus, but the complex legal code is an excuse for this screenshot:</p><p>What is the “Attributable Subordinated Loan?” I’m glad you asked. Bally’s staked (ba dum bum) BCI with a few hundred million dollars to fund development. Where did it find the money to do that? A mix of equity and debt financing, as is common for virtually all complex commercial real estate transactions. Bally’s, per their <a href=\"https://d18rn0p25nwr6d.cloudfront.net/CIK-0001747079/0a22a582-5179-4a27-8a24-cbfc84043b0f.pdf\">most recent 10-K</a>, has long-term debt from sophisticated investors which costs them 5.x% per year. (It would be more expensive if they wanted to lock that down today.)</p><p>In return for Bally’s advancing BCI money through BCHC, BCI owed BCHC money, on an intercompany IOU. This capital offering cancels that intercompany IOU and replaces it with the Subordinated Loans. The prospectus does not quote the rate that the left pocket of Bally’s charged the right pocket of Bally’s. It does quote the rate for the Subordinated Loans: 11% annually compounding quarterly.</p><p>The road show makes much of the fact that this leverage is non-recourse. Quoting the Triibe reporting again:</p><p><em>The loan is non-recourse, explained Sidney Dillard of Loop Capital Markets, who is the underwriter of the offering, during the information session. “That loan is not recourse, meaning that you are not responsible for it,” she said.</em></p><p>I am not someone who has ever offered SEC registered securities for sale, but I am aware that when one does that, one has to adopt a  with respect to how one simultaneously a) sells a product that one has to offer and b) describes the operations of that product without wandering into lying.</p><p>And so  would not describe “non-recourse” as a loan one is not responsible for. I have a non-recourse mortgage. I am very, very much responsible for paying the mortgage. If I do not pay the mortgage, I expect to swiftly not own the property securing the mortgage. The “non-recourse” bit means that the lender cannot come after your  assets or income, for example by suing you for a judgement, then forcing you to disgorge your savings account or e.g. interests in a wholly owned LLC.</p><p>The Subordinated Loans are, per the prospectus (probably a bit more reliable than the understanding of e.g. Chicago employees on the finer details), not between the owners of the Class-A{1,2,3} equity and any Bally’s entities. They are strictly loans between Bally’s entities themselves. Those loans are senior to Class-A{1,2,3} equity in the payments waterfall of future profits (we need that asterisk again!) from the casino to equity holders. The expectation is that Bally’s will individually book repayments against records which are kept on a per-shareholder basis without actually obligating the shareholder, <em>while keeping the actual cash thrown off by the casino</em>, prior to eventually releasing a shareholder from the indebtedness that Bally’s will say that, technically speaking, they have not actually incurred.</p><p>At that point, the shareholder will own the slice of equity that an unsophisticated listener of that roadshow might think they own free-and-clear.</p><p>Now, Bally’s forecasts that many shareholders will be very underwater on these investments. (Wow, that’s a  sentence.) Prospectus, ibid, pg 23:</p><p><em>Given the capital intensity of developing, constructing, opening and operating a casino resort project of this scale, we currently expect that Bally’s Chicago OpCo will not have any OpCo cash available for distribution until approximately three to five years after our permanent resort and casino begins operations.</em></p><p>Assuming the most charitable estimate from that range, a Class A-3 shareholder will have $250 of equity securing a notional $25,000 investment and future obligations of approximately $34,000 (three years of compound interest on $24,750). This suggests that the holder’s equity value is  and that no sophisticated investor would purchase that investment for the $25,000 which the unsophisticated shareholder might believe it to be worth in 3 years. They might be willing to pay something more similar to, hmm, negative nine thousand dollars.</p><p>Seen in that light <em>this offer of investment sounds predatory</em>. But don’t worry, Chicagoans, Bally’s has your back. You do not have to worry about not being able to sell your stock due to its lack of intrinsic value, because you are not able to sell your stock. Prospectus, ibid, pg 179 under heading Shares Eligible For Future Sale, and elsewhere in the document.</p><p>Class A-4 holders, the ones with no notional debt, who purchased their shares for $25,000 cash-on-the-barrel, are not eligible to sell their stock at any time except as allowed by Bally’s to people approved by Bally’s. (I’ll flag that this is not an unusual term in private equities. Bally’s pre-commitment to discriminating racially against future prospective buyers?  unusual.)</p><p>Buyers of Class A-{1,2,3} stock are unable to sell until the associated Subordinated Loan is paid off in full.</p><p>One wonders whether senior Chicago officials will be doing a roadshow in 2030 explaining what happened.</p><h2>The casino will not distribute profits, per se</h2><p>While the natural expectation is that one is participating in the profits of the casino, the prospectus helpfully clarifies that one is not. The \"cash available for distribution\" does not necessarily correspond 1:1 with profits. It... well. See the discussion on page 22 and 23 of the prospectus, including the excerpt below.</p><p><em>While we and Bally’s Chicago OpCo intend to make distributions equal to 100% of the cash available for distribution and OpCo cash available for distribution, respectively, on a quarterly basis, the actual amount of any distributions may fluctuate depending on our and Bally’s Chicago OpCo’s ability to generate cash from operations and our and Bally’s Chicago OpCo’s cash flow needs, which, among other things, may be impacted by debt service payments on our or Bally’s Chicago OpCo’s senior indebtedness, capital expenditures, potential expansion opportunities and the availability of financing alternatives, the need to service any future indebtedness or other liquidity needs and general industry and business conditions, including the pace of the construction and development of our permanent resort and casino in Chicago. Our Board will have full discretion on how to deploy cash available for distribution, including the payment of dividends. Any debt we or Bally’s Chicago OpCo may incur in the future is likely to restrict our and Bally’s Chicago OpCo ability to pay dividends or distributions, and such restriction may prohibit us and Bally’s Chicago OpCo from making distributions, or reduce the amount of cash available for distribution and OpCo cash available for distribution.</em></p><p>Now, as someone who grew up with a father constantly complaining about sharp operating in Chicago commercial real estate, I can quickly outline about two dozen different ways for one to cause the operating company here to a) transfer money to other corporate entities and b) therefore have less cash available for distribution.</p><p>As a representative but not limiting example, you can probably choose your own marks for technology services from a parent to a great-grandchild subsidiary. Sure, there is some notional expectation that the marks be at arms-length price, but what is the arms-length price for e.g. casino loyalty accounting software and a particular chain's database of existing users? What low-resourced investor could possibly mount a court challenge against <em>the entity with all the data necessary to value that asset</em>. In Las Vegas, a casino has to calculate and diligently communicate the house edge before raking punters. Here... not so much.</p><p>That would require sharp operating... of a sort which is  in Chicago commercial real estate. This is a constant risk of being the junior partner in a structure, particularly without an aligned senior partner who would be as adversely impacted by sharp operating as you would be. Of course, here the senior partner owns e.g. the database they are renting to the entity that they also control, and so funds available for distribution from that entity might not match the expectations of junior partners.</p><p>Pick your sponsors carefully, folks.</p><h2>Tax consequences of this offering</h2><p>Suppose, and this is very unlikely because it is illegal (<a href=\"https://www.finra.org/rules-guidance/key-topics/margin-accounts\">Reg T</a>) but run with it, that one has a typical brokerage account in the United States and, with $250, purchases $25,000 of marketable securities. Those securities periodically throw off dividend payments. One periodically pays one’s brokerage interest, because one has borrowed money from the brokerage to buy those securities on margin.</p><p>In the typical case, one would be taxed upon those interest payments, which are income. One does not simply  one’s margin interest against that income before paying taxes. One instead must itemize, and then one <a href=\"https://www.irs.gov/forms-pubs/about-schedule-a-form-1040\">will be able to</a> (on Schedule A) deduct investment expenses, as described in <a href=\"https://www.irs.gov/publications/p550\">Publication 550</a>. Feel free to run this by your accountant; the details get complicated and wonky.</p><p>If one does not itemize, as many lower-income taxpayers do not, one must of course simply pay the tax on the entirety of one’s interest income. If one protests that one does not actually  any interest income, because it has been taken by one’s brokerage to pay margin interest, the IRS will not be maximally sympathetic.</p><p>Bally’s has very creative professionals involved in the structuring of this offering, and realizing the above issue would compromise fitness for purpose, they have… adopted a theory. I will quote that theory, from the prospectus, verbatim. I have taken the liberty of bolding an important bit in the middle of this.</p><p><em>Section 305 of the Internal Revenue Code provides that if a corporation distributes property to some shareholders and other shareholders have an increase in their proportionate interests in the assets or earnings and profits of the corporation, such other shareholders may be deemed to receive a distribution that could be a taxable dividend. In this case, because we and Bally’s expect to treat the Subordinated Loans as “stock” for U.S. federal income tax purposes, “property” distributions will likely be considered to be made to “some shareholders” of Bally’s Chicago, Inc. as payments are made on the Subordinated Loans, and equivalent cash (“property”) distributions will be made with respect to the Class A-4 Interests. In addition, as payments are made on the Subordinated Loans, particularly those that repay the original principal amount of such Subordinated Loans, the proportionate interests of holders of our Class A-1 Interests, Class A-2 Interests and Class A-3 Interests in the assets or earnings and profits of Bally’s Chicago, Inc. may be viewed as increasing. Accordingly, it is possible that such increase could be treated as a deemed distribution under Section 305 of the Code or otherwise as taxable income to such holders under other theories. However, under the Treasury Regulations relating to Section 305 of the Code and other IRS administrative guidance, certain financing arrangements in the form of preferred stock investments that fund a corporation and then are systematically eliminated through property distributions until they are fully retired, and are designed to facilitate the ownership of a business with an effect of increasing another stockholder’s proportionate interests in the assets or earnings and profits of a corporation over such period, do not result in a deemed distribution to such other stockholder. The applicability of these authorities to the holders of our Class A-1 Interests, Class A-2 Interests and Class A-3 Interests in this situation is uncertain. <strong>Although the matter is not free from doubt, we intend to take the position, and this discussion assumes, that U.S. Holders of applicable series of Class A Interests would not be treated as receiving a deemed distribution from us or otherwise realizing income as a result of repayment of the Subordinated Loans corresponding to such shares. However, there can be no assurance that the IRS will not take a contrary position</strong>, for example, treating the proportionate interest in our earnings and profits owned by U.S. Holders of the applicable series of Class A Interests as having increased upon repayment of the Subordinated Loans corresponding to such shares, and treating such U.S. Holders as having received a distribution. In that case, such deemed distribution will be taxable as a dividend, return of capital or capital gain as described above under “— Distributions,” and U.S. Holders may be subject to U.S. federal income tax without the receipt of any cash. U.S. Holders should consult their own tax advisors about the application of Code Section 305 and any other potential deemed receipt of income risk with respect to our Class A Interests .</em></p><p>Now, I’m neither a lawyer, tax accountant, nor am I someone who listened carefully to the roadshow when it doubtlessly stepped through this for the benefit of the audience. But here’s what it means:</p><p>Bally’s is taking the position, though they acknowledge that the IRS might disagree, that owners of the Class A-{2,3,4} interests aren’t  getting any income until the Subordinated Loans have been paid in full. This means that they don’t have to pay income taxes in years where they are not actually receiving cash distributions.</p><p>No, they wait until the Subordinated Loan is paid in full, and then immediately owe income taxes in one whack, at the difference between their basis in the stock (say, $250) and the then-FMV of the stock (say, $25,000). Resulting in Bally’s diligently filing a document with the IRS saying that e.g. a lower-income Chicagoan has just received a bit less than $25,000 in income from them, and should probably pay taxes on it. You can, of course, receive income without receiving ; it happens all the time in tech, and is the cause of much structuring to avoid the consequences of it, which can be painful for e.g. early career employees.&nbsp;</p><p>Those taxes will be paid substantially out-of-pocket, because there is almost no conceivable universe where a stock of an actual healthy operating enterprise worth e.g. $25,000 pays an ordinary dividend of e.g. $5,000. The market would adjust the value of the stock upwards to account for the extraordinarily rich stream of dividends, which would adjust the tax bill upwards.</p><p>Financially sophisticated investors might prepare for a tax bomb like this by e.g. borrowing against the value of the stock. That’s basically impossible for this issuance, due to the stock not being publicly listed, the restrictions on transfer, small dollar amounts, etc. The other option is, of course, selling the stock, to whomever Bally’s deigns to approve.</p><p>Tax-motivated transactions are, of course, , and the lucky buyer will probably be able to extract a bit of a deal, doubly so because they are likely much more sophisticated than the initial buyer of the stock, and they have less risk to account for (because of e.g. several years of operating history of the casino before the tax bomb explodes).</p><p>I am not an investment advisor, and not your investment advisor. I am, however, a recreational poker player who lives in Chicago. I intend to periodically donate money to the Chicago economy by making poor decisions on the river at Bally’s Chicago. </p><p>I do not, however, presently intend to participate in Bally’s stock offering, nor do I presently intend to buy their common stock.</p><p>I will note, out of an overabundance of scrupulousness, that I own a tiny amount of MGM stock, which is a direct competitor to Bally’s. I caught the poker bug at a conference in Las Vegas (hosted at the Tropicana, since acquired by Bally’s and then <a href=\"https://www.ballys.com/news/news-details/2024/Tropicana-Las-Vegas-Implosion-to-Make-Way-for-the-As-Ballpark-and-Ballys-Entertainment-Resort-Destination-2024-9NZuey6eTG/default.aspx\">brought down in a controlled implosion</a>).</p><p>MGM, across the street, actually had poker tables. I have had many enjoyable post-conference excursions staying at their hotel to (in several but not all years) lose money at those tables. I bought the stock for the same reason I buy stock in every hotel, airline, bank, and similar I use: in the unlikely event a not-particularly-high-stakes poker player has a routine customer service complaint, Investor Relations is available as an escalation strategy, over e.g. hotel staff who might be long-since inured to listening to complaints from people who lost money in a casino.</p><p>Oh yeah, I mentioned that there is a crypto angle to this. The registrar and transfer agent for offering 100:1 leverage to retail investors on a casino stock is, see prospectus pg 41, <a href=\"https://www.bitgo.com/\">BitGo Trust</a>. If I had made up that detail, as a crypto skeptic, you might have accused me of being a bit on the nose.</p><div><div><a href=\"https://www.bitsaboutmoney.com/archive/bam-2024-retrospective/\">Bits about Money yearly recap and plans →</a></div></div>","contentLength":35871,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42816418"},{"title":"The hidden complexity of scaling WebSockets","url":"https://composehq.com/blog/scaling-websockets-1-23-25","date":1737748131,"author":"atul-jalan","guid":173,"unread":true,"content":"<p>With the rising demand for sync engines and real-time feature, WebSockets have become a critical component for modern applications. At Compose, WebSockets form the backbone of our service, powering our backend SDKs that enable developers to deliver low-latency interactive applications with just backend code.</p><p>But, scaling WebSockets has proven to be far more complex than we expected. Below are some of the most important lessons we've learned along the way.</p><h3>Handle deployments gracefully</h3><div>Users should never notice when deployments happen, so WebSocket connections need to persist across deployments. This is a delicate process, and requires robust reconnection logic to deal with unexpected issues. At Compose, we achieve near-zero downtime by following these steps:<ol><li><p>Once the new servers are healthy, old servers begin returning responses to health checks.</p></li><li><p>After 4 consecutive  responses, the load balancer declares the server unhealthy and removes the old servers from the pool. The load balancer health checks every 5 seconds, so this process takes up to 25 seconds.</p></li><li><div>Old servers send a custom WebSocket close message instructing clients to delay reconnection by a random interval to avoid a reconnection surge.<ul><li><p>The custom close message lets clients show users a more accurate message during the ~10 second period where the client is disconnected.</p></li><li><p>The random delay helps prevent thundering herd issues where all clients reconnect at once. Clients also double the exponential backoff for deployment-related reconnections to account for unforseen issues.</p></li><li><p>The close message is delayed by 20 seconds to account for the time it takes for the load balancer to shift traffic.</p></li></ul></div></li><li><p>Once all clients disconnect, the old servers shut down completely.</p></li></ol></div><p>If you're using a managed service like Render or Railway, you should be especially cognizant that client connections are transferred gracefully during deployments.</p><p>Many managed services that tout zero-downtime deployments will wait until all outstanding requests are processed before shutting down a server. Since WebSocket connections are persistent, this can lead to situations in which old servers are active for minutes or even hours after a deploy until the managed service forcibly terminates the process.</p><h3>Establish a consistent message schema</h3><div>While HTTP comes with built-in routing conventions (,,), WebSockets require developers to define their own schema for organizing messages.</div><div>At Compose, every WebSocket message starts with a fixed 2-byte prefix for categorizing messages.<ul><li><p>It's space-efficient (only 2 bytes), while still scaling to 65,536 different types.</p></li><li><p>It enables clients to reliably slice the prefix from the message without affecting the rest of the data, since the prefix is always 2 bytes.</p></li><li><p>It gives us a simple method for upgrading our APIs by versioning message types.</p></li></ul></div><div><div><pre><code> = {\n  : ,\n  : ,\n  : ,\n  : ,\n  \n}</code></pre></div></div><p>Additionally, we use delimiters to separate different fields inside the message, which is both faster to encode/decode and more memory-efficient than JSON.</p><div><div><pre><code> = ;\n\n() {\n   [[], ...args].();\n}\n\n() {\n   [, ...args] = message.();\n   { , args };\n}</code></pre></div></div><p>We're lucky that our backend and frontend are written in TypeScript, allowing us to share message schemas between the two and ensure that neither falls out of sync.</p><h3>Detect silent disconnects with heartbeats</h3><div>Connections can drop unexpectedly without triggering a<a href=\"https://developer.mozilla.org/en-US/docs/Web/API/WebSocket/close_event\">close event</a>, leading to a situation in which the client thinks they're connected, but actually aren't. To prevent stale connections, implementing a robust heartbeat mechanism is essential.</div><div>We send periodic<a href=\"https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API/Writing_WebSocket_servers#pings_and_pongs_the_heartbeat_of_websockets\">ping/pong messages</a>between client and server and reconnect in cases where the heartbeat isn't received within some interval.</div><div>Our server sends a  message every 30 seconds, and expects a  response. In cases where the client doesn't receive a every 45 seconds, it immediately drops the connection and tries to reconnect. Similarly, the server closes connections that miss responses within 45 seconds.</div><p>By monitoring heartbeats on both ends, we detect and handle rare cases where the client side network appears functional but the server never receives responses.</p><div>WebSocket connections can be unexpectedly blocked, especially on restrictive public networks. To mitigate such issues, Compose uses<a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events\">server-sent events (SSE)</a>as a fallback for receiving updates, while HTTP requests handle client-to-server communication.</div><img src=\"https://composehq.com/blog-scaling-websockets-fallback.png\" alt=\"SSE fallback\"><p>Since SSE is HTTP-based, it's much less likely to be blocked, providing a reliable alternative in restricted environments. Plus it still achieves decently low latency, especially compared to short-polling solutions.</p><div>There's a whole lot more to scaling WebSockets that we didn't cover here. For example:<ul><li><p>: While most frameworks include built-in tools for rate limiting, data validation, and error handling, you'll generally have to implement these features on your own for WebSockets.</p></li><li><p>: Edge networks make it easy to cache HTTP responses close to users, but there's no standard way to accomplish this with WebSockets.</p></li><li><p>: Guarding against abuse by ensuring that each message is valid for that user before processing it.</p></li></ul></div><p>But regardless of the complexity, users expect modern applications to be fast, realtime, and collaborative. And, as of now, there's no better way to achieve that than WebSockets.</p><div>At Compose, WebSockets power the entire platform - from the database all the way to the main UI thread. Via our SDKs, developers can generate full web apps from their backend logic. Making sure those apps are fast and performant at scale requires WebSockets. If you're interested in learning more,<a href=\"https://docs.composehq.com\" target=\"_blank\" rel=\"noopener noreferrer\">check out our docs</a>. It takes less than 5 minutes to install the SDK and build your first app.</div>","contentLength":5632,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42816359"},{"title":"Anatomy of a Formal Proof","url":"https://www.ams.org/journals/notices/202502/noti3114/noti3114.html","date":1737742775,"author":"bikenaga","guid":172,"unread":true,"content":"<section data-ams-doc=\"frontmatter\"></section><section role=\"doc-introduction\" data-ams-doc=\"section\" data-ams-doc-level=\"1\"><p>It has been a long day and you are making your way through a paper related to your work. You suddenly come across the following remark: “…since  and  are eigenvectors of  with distinct eigenvalues, they are linearly independent.” Wait—how does the proof go? You should really know this. Here  and  are nonzero elements of a vector space  and  is a linear map. You force yourself to pick up a pen and write down the following argument:</p><blockquote data-ams-style=\"null\"><p>Let  and  with  Suppose  Applying  and using linearity, we have  Multiplying the original equation by  we have  Subtracting the two yields  and since  and  are nonzero, we have  The corresponding argument with  and  swapped yields  so the only linear combination of  and  that yields  is the trivial one.</p></blockquote><p>Your colleagues have all gone home and there is nobody around to discuss this with. So, instead, you turn to your computer and start up Lean, the proof assistant you happen to use. Can you prove the claim formally? As you type, the information window in your editor complains about every misstep—the syntax is fiddly, and you have to get the notation and the instructions just right—but that’s okay, because working through the proof is relaxing and kind of fun. Lean often makes you spell out arguments that are painfully obvious, but you have found that if you set things up just right, it will cheerfully fill in some of the details. After a short while, you have success! Lean signs off on the proof, confirming you have managed to construct a formal derivation in the system’s axiomatic foundation.</p><pre data-ams-specific-use=\"numbers=right\">import Mathlib.LinearAlgebra.LinearIndependent\n\nvariable [Field K] [AddCommGroup V] [Module K V]\n\nexample (f : V →ₗ[K] V)\n    (μ ν : K) (hμν : μ ≠ ν)\n    (x y : V) (hx₀ : x ≠ 0) (hy₀ : y ≠ 0)\n    (hx : f x = μ • x) (hy : f y = ν • y) :\n    ∀ a b : K,\n      a • x + b • y = 0 → a = 0 ∧ b = 0 := by\n  intro a b hab\n  have :=\n  calc (μ - ν) • a • x\n      = (a • μ • x + b • ν • y) -\n        ν • (a • x + b • y) := by module\n    _ = f (a • x + b • y) -\n        ν • (a • x + b • y) := by simp [hx, hy]\n    _ = 0 := by simp [hab]\n  simp_all [sub_eq_zero]</pre><p>What a lovely proof! It took some effort to work it out, but it was a pleasure seeing the steps play out formally, and you are proud of the result.</p></section><section data-ams-doc=\"section\" data-ams-doc-level=\"1\"><p>Let’s take a look at what you have done. You are using Lean’s mathematical library, Mathlib, a communally developed and maintained repository of formally verified mathematics. At the time of writing, Mathlib contains more than 80,000 definitions and more than 160,000 theorems, starting from axiomatic primitives and developing mathematics from the bottom up. It also contains dozens of user-contributed automated reasoning procedures that help with the formalization process, as well as notation declarations and configuration information, all of which codify different aspects of our mathematical understanding.</p><p>To avoid having to load the entire library into memory at once, Lean asks you to tell the system what parts of the library you want to use. So the first line of the proof, the one that starts with the keyword , tells Lean you want to use the file with the name shown. That pulls in all the files in the library that those notions depend on, which is quite a lot, including basic algebra, properties of scalars and vectors, and so on.</p><p>The next line, the one that begins with the word , declares some of the objects you want to work with: a field,  and a vector space,  You could have, alternatively, put these declarations after the  keyword on line 5; using the  command to declare them separately is especially convenient when multiple definitions and theorems share the same data and hypotheses. It’s a quirk of the library’s design that you declare that  is an additive, commutative, group, coupled with a scalar action that turns  into a  (Remember, a vector space is nothing more than a module over a ring in which the ring in question is actually a field.) Mathlib includes thousands of axiomatically declared structures, and the contributors to the library take great care to maximize reusability by breaking structural hypotheses into reusable pieces that can easily be configured and composed.</p><p>Next comes the keyword  (line&nbsp;5), which indicates that the result you are proving is not intended for future use. Using  is good for experimentation. To prove a lemma or theorem that you intend to use later, you would instead use  or  and provide a name. In that case, once Lean has processed the proof, it is stored in the , which means that any file that imports this one can see it. If you think you have proved a theorem that ought to go into Mathlib, you can issue a  to add it to the library. Mathlib is overseen by teams of  and  who moderate and update the contents, ensuring the quality and stability of the library.</p><p>You begin stating the claim by introducing the key players:</p><dl data-ams-content-type=\"itemize\"><div><dd><p>a linear map  from  to itself. Lean’s notation for such linear maps is ,</p></dd></div><div><dd><p>two elements of  denoted  and  which will end up being your eigenvalues, and a hypothesis called  that says  and  are distinct,</p></dd></div><div><dd><p>two vectors called  and  as well as hypotheses  and  that say that they are nonzero,</p></dd></div><div><dd><p>and, finally, your two key assumptions,  and , which say that  and </p></dd></div></dl><p>In the notation , the  is a fixed symbol signifying linear maps, whereas the parameter in brackets indicates that we mean linearity over .</p><p>At this point, you have set up your , that is, the data and hypotheses you need to state your claim. You have your  space  a linear map  two scalars  and  and eigenvectors  and  for  and  respectively. At that point you are ready to state the conclusion (lines&nbsp;9 and&nbsp;10), namely, that  and  are linearly independent: . You have decided to use the definition of linear independence for a pair of vectors: Whenever  and  are scalars, if  then  and </p><p>Notice that you have used the symbol  in expressions like  (line&nbsp;7) to express that  and  are elements of , rather than writing  and . In Lean’s axiomatic foundation, a version of , every object has a fundamental data type. In this example, we would say that that  and  are  of the  Interestingly, we use the same notation in an expression like  (also line&nbsp;7) to express that  is a label for the assumption . In dependent type theory, assertions like  (also known as ) are analogous to data types, and they are handled by the same fundamental mechanisms. Lean checks that an expression like  is a well-formed expression of type , given information about the variables and symbols involved, and, in the same way, it checks that a formal expression is a well-formed proof of the proposition , given the data and assumptions it depends on. That is why the latter appears after the colon in the example’s conclusion: the statement of the example announces your intent to construct a formal proof of the conclusion, given the data and assumptions that come before.</p><p>What comes after the symbol  (line&nbsp;10) is the proof itself, or, more precisely, instructions that tell Lean how to construct the proof. If you are successful, the corresponding expression is stored in memory and checked for correctness by Lean’s trusted . The keyword  after the  instructs Lean to enter , which means that the text that follows should be interpreted as a list of instructions that tell Lean how to build the required proof. A  is a procedure that automatically fills in a chain of formal inferences that is needed to justify a reasoning step. Such a chain can be as short as a single logical axiom or rule, but it can also be quite long and involved. Tactics thus play an important role in bridging the gap between the kind of reasoning that is intuitively clear and natural to mathematicians and the stringent axiomatic rules embodied by a formal system.</p><p>The first tactic you use is  (line&nbsp;11). This introduces the two variables ,  which your statement quantifies over, as well as the antecedent of the implication, that is, the assumption . As you type or move your cursor around a proof, Lean displays the , i.e., information that is relevant at that point in the proof, in its  window. After the  tactic, the tactic state looks something like this:</p><pre>K : Type\nV : Type\nf : V →ₗ[K] V\nμ ν : K\nhμν : μ ≠ ν\nx y : V\nhx₀ : x ≠ 0\nhy₀ : y ≠ 0\nhx : f x = μ • x\nhy : f y = ν • y\na b : K\nhab : a • x + b • y = 0\n⊢ a = 0 ∧ b = 0</pre><p>This is nice a summary of where you are in the proof, including the objects and assumptions you started with as well as the objects ,  and the assumption  that you introduced in the first step. The line that starts with  indicates that your current  is to prove the conjunction .</p><p>While writing the proof, you notice that Lean complains with warnings and error messages. This is expected, since the proof is incomplete. You can appease Lean by apologizing for the incomplete proof: If you use the  tactic on the final line of the proof, Lean will not raise an error over the fact that the proof is incomplete, but it will still raise a gentle warning about the use of .</p><p>The next step in the proof starts with  (line&nbsp;12). This introduces a calculation, similar to a  block in LaTeX. The calculation itself is very similar to the one in the proof sketch above, but notice that the individual steps in the calculation are justified by short subproofs like  (line&nbsp;15) or  (line&nbsp;17). The  tactic proves equalities of universal linear expressions, in other words, linear equalities that are true in all modules, and do not use specific facts about the module at hand. The  tactic is a powerful tool that uses a database of equalities and equivalences from Mathlib, together with user-specified equations (like ) to rewrite its goal into a simpler form. Happily, in this case, the goal becomes a trivial equality, and the goal is therefore closed. In a moment, we will consider the steps that  has taken in greater detail.</p><p>After this calculation, you completed your proof with the  tactic (line&nbsp;19), which is a variant of  that recursively uses all the hypotheses to simplify all hypotheses and the goal. Now if you leave a  after the , Lean will complain that there is nothing to be sorry about and insist that remove the apology. Lean checks the correctness of the proof and confirms it with its silence: the absence of errors is the proclamation that you have succeeded.</p></section><section data-ams-doc=\"section\" data-ams-doc-level=\"1\"><p>So what exactly does the  tactic do? The following provides a manual, more detailed proof of one step of the calculation in your proof, with the direction of the equality reversed.</p><pre>variable (f : V →ₗ[K] V)\n  (μ ν : K) (x y : V) (a b : K)\n\nexample (hx : f x = μ • x) (hy : f y = ν • y) :\n  f (a • x + b • y) = (a • μ • x + b • ν • y) := by\ncalc f (a • x + b • y)\n    = f (a • x) + f (b • y) := by\n        rw [map_add]\n  _ = a • f x + b • f y := by\n        rw [map_smul, map_smul]\n  _ = (a • μ • x + b • ν • y) := by\n        rw [hx, hy]</pre><p>This example demonstrates the  tactic, denoted . In the calculation, we first rewrite with the lemma , which states that for any linear map , the equation  holds. The next step in the calculation is justified by rewriting twice with the lemma , which states that for any linear map , scalar , and vector , the equation  holds. (Here  stands for “scalar multiplication.”) The underscores before each subsequent step are part of the  syntax, indicating to the parser that the calculation continues. The proof concludes by rewriting with the hypotheses  and , which assert that  and  are eigenvectors of  with eigenvalues  and  respectively.</p><p>The lemmas  and  are part of the Mathlib library, and they are labeled with the . This attribute tells Lean that the lemma should be added to the database of lemmas that  uses to simplify expressions. And that is the reason why the  tactic could prove the goal in one go: it chained together the  steps that we spelled out step by step in the calculation above.</p><p>One of the challenges of formalization is that we often need to spell out, in painful detail, inferences that seem obvious or straightforward to us. The more we can get the computer to fill in, the better. The simplifier is an important example of  that can help in this respect. The  tactic is another.</p><p>Broadly speaking, there are two classes of automation. Firstly, there is  automation. One example that we have seen is the  tactic, the simplifier. Another example is , a tactic that provides “Automated Extensible Search for Obvious Proofs.” In the proof assistant Isabelle, there is a tool called , which can search for proofs using a large database of lemmas. And recently AI copilots have demonstrated the ability to suggest tactics and fill in parts of proofs in Lean. The wide applicability of these general-purpose tools is balanced by the fact that, at least for now, they can only assist with proofs that are relatively straightforward.</p><p>The other class of automation is  automation. Here we have also seen an example: the  tactic. Other examples include the  tactic, which solves equations in commutative rings, the  tactic, which solves linear arithmetic problems, and the  tactic, which proves that functions satisfy a given property such as “continuity” or “measurability.” These tactics are less general; they typically have a well-defined and narrow scope, but they can be very powerful in their domain of applicability. A prime example of this approach comes from the use of software tools known as SAT solvers and SMT solvers: if a claim can be encoded as a boolean formula or a formula in some decidable theory, then these can be used to justify it automatically. This has been fruitfully applied in non-trivial ways, see for example&nbsp;.</p></section><section data-ams-doc=\"section\" data-ams-doc-level=\"1\"><h2></h2><p>Often, one of the first things we do when we have proved a lemma or a theorem is check whether the hypotheses can be weakened, in order to increase its applicability. Proof assistants are especially helpful in this respect, because they enable us to tinker with hypotheses interactively and see what breaks. Returning to our example, upon verifying the initial result, you might wonder: what are the minimal assumptions that we need to make this proof go through? Let’s experiment. The proof never mentions inverses of scalars, so it should work for a larger class of rings. In a first attempt, we might try to replace the vector space  by an arbitrary module  as follows:</p><pre>variable {R M : Type}\n  [Ring R] [AddCommGroup M] [Module R M]</pre><p>But Lean complains at the first step in the calculation, which requires . We can address this by assuming that the ring of scalars is commutative. However, after making that change, the final step of the proof is still broken. A bit of reflection shows that this step uses the result of the calculation steps together with the assumptions  and  to prove that . In other words, we need the additional property that  implies that  or  for every  in  and  in . Mathlib expresses this as the property , and we can add that assumption as follows:</p><pre>variable {R M : Type}\n  [CommRing R] [AddCommGroup M] [Module R M]\n  [NoZeroSMulDivisors R M]\n\nexample (f : M →ₗ[R] M)\n  (μ ν : R) (hμν : μ ≠ ν)\n  (x y : M) (hx₀ : x ≠ 0) (hy₀ : y ≠ 0)\n  (hx : f x = μ • x) (hy : f y = ν • y) :\n  ∀ a b : R, a • x + b • y = 0 → a = 0 ∧ b = 0</pre><p>Lean accepts this statement with the same proof as before! We have therefore obtained a more general theorem without changing a single character of the proof.</p></section><section data-ams-doc=\"section\" data-ams-doc-level=\"1\"><h2></h2><p>Let’s see if we can strengthen your result even further. You started with a basic version involving vector spaces over fields and only two eigenvectors, and we just generalized it to suitable modules over commutative rings. Where can we go from here?</p><p>Let’s try to generalize the theorem to arbitrary families of eigenvectors. To do this, we will need to think carefully about how to express, in Lean, the fact that an arbitrary family of vectors is linearly independent. We could write down a definition from scratch, but it makes sense to see if we can take advantage of things that are already in the library. If we navigate to the Mathlib documentation webpage ⁠<a role=\"doc-noteref\" data-ams-ref=\"fn\" href=\"https://www.ams.org/journals/notices/202502/noti3114/noti3114.html#ltxid12\"></a> and start typing  in the search box, one of the first few results that comes up is the following:</p><pre>def LinearIndependent {ι : Type}\n  (R : Type) {M : Type}\n  (v : ι → M) [Semiring R]\n  [AddCommMonoid M] [Module R M] :\n  Prop</pre><p>Here  and  are the relevant ring and module, as before,  is an indexing type, and  is a family of elements of  indexed by . It is standard, and convenient, to represent a family  of elements of  as a function , in which case the  element,  is simply written . All the arguments in curly and square brackets are generally left implicit, which is to say, we expect to write  and have Lean figure out the rest. The annotation  means that the expression  is a proposition, namely, the proposition that the family  is linearly independent over . At the moment, we don’t need to know the body of the definition; we can use it as a black box.</p><p>To do so, we will add an indexing type  to the statement of our theorem, and since we also want to say that the vectors are all , we will also use  to index a family  of scalars which will act as the eigenvalues. We can now formulate the statement we are after as follows:</p><pre>example {R M : Type} [CommRing R]\n    [AddCommGroup M] [Module R M]\n    [NoZeroSMulDivisors R M]\n    (f : M →ₗ[R] M)\n    (μ : ι → R) (hμ : Function.Injective μ)\n    (v : ι → M) (hv : ∀ i, v i ≠ 0)\n    (h : ∀ i, f (v i) = μ i • v i) :\n    LinearIndependent R v</pre><p>Note that we have formulated the fact that we are considering  eigenvalues by assuming  is injective.</p><p>We should check to see whether something like this theorem is already in the library. If we go back to the documentation webpage and search for , only two results come up:</p><pre>theorem\n  Module.End.eigenvectors_linearIndependent\n  {R : Type} {M : Type} [CommRing R]\n  [AddCommGroup M] [Module R M]\n  [NoZeroSMulDivisors R M]\n  (f : Module.End R M)\n  (μs : Set R) (xs : ↑μs → M)\n  (h_eigenvec : ∀ (μ : ↑μs),\n    f.HasEigenvector (↑μ) (xs μ)) :\n  LinearIndependent (ι := ↑μs) R xs</pre><pre>theorem\n  Module.End.eigenvectors_linearIndependent'\n  {R : Type} {M : Type} [CommRing R]\n  [AddCommGroup M] [Module R M] {ι : Type}\n  [NoZeroSMulDivisors R M]\n  (f : Module.End R M)\n  (μ : ι → R) (hμ : Function.Injective μ)\n  (v : ι → M)\n  (h_eigenvec : ∀ (i : ι),\n    f.HasEigenvector (μ i) (v i)) :\n  LinearIndependent R v</pre><p>The difference between the two is that the first is about a set of scalars and a function assigning an eigenvector to each scalar, whereas the second one is about indexed families of scalars and eigenvectors. The second one is more promising for our application, since we also chose to use indexed families of vectors and scalars. To use this theorem to prove our version, we invoke the  tactic.</p><pre>example {R M : Type} [CommRing R]\n    [AddCommGroup M] [Module R M]\n    [NoZeroSMulDivisors R M]\n    (f : M →ₗ[R] M)\n    (μ : ι → R) (hμ : Function.Injective μ)\n    (v : ι → M) (hv : ∀ i, v i ≠ 0)\n    (h : ∀ i, f (v i) = μ i • v i) :\n    LinearIndependent R v := by\n  apply Module.End.eigenvectors_linearIndependent'</pre><p>This leaves us with a number of goals:</p><dl data-ams-content-type=\"enumerate\"><div><dd><p>, asking us to prove that something is injective.</p></dd></div><div><dd><p>, which looks like it should have something to do with our assumptions  and .</p></dd></div><div><dd><p>, asking us to provide an endomorphism of  this should just be our linear map .</p></dd></div><div><dd><p>And finally, , which will be our </p></dd></div></dl><p>The  in the first two goals and the  in the second goal mean that Lean does not yet know how to instantiate the variables  and  in the theorem we have invoked. It left those tasks as the third and fourth goals; Lean expects that it will be more convenient for us to provide that information implicitly when we solve the other goals.</p><p>We have made progress, but we still need to provide the information requested. We should clearly use  to solve the first goal, which we do by adding the next line to our proof:</p><pre>apply Module.End.eigenvectors_linearIndependent'\n  exact hμ</pre><p>As you might guess, the  tactic tells Lean to use the assumption  to close the goal. As a side effect, that also closes goal 4: Lean is now able to infer that the family in question is  We then have two goals left:</p><dl data-ams-content-type=\"enumerate\"><div><dd><p>, and</p></dd></div></dl><p>We know that the endomorphism of  should be  so we swap the order of the goals and give Lean this information:</p><pre>apply Module.End.eigenvectors_linearIndependent'\n  exact hμ\n  swap ; exact f</pre><p>This leaves us with one last goal, namely, . We need to use our assumptions  and , but it’s unclear how to package them together to satisfy the definition of . Instead of going back to the documentation page and looking up the definition, we can ask Lean what we have to do.</p><pre>apply Module.End.eigenvectors_linearIndependent'\n  exact hμ\n  swap ; exact f\n  intro i ; constructor</pre><p>As before, the  tactic introduces an arbitrary , and then the  tactic tells Lean that we are ready to provide the information needed to show that  is an eigenvector of  with eigenvalue . This makes progress, but we still have the following goals to fulfill:</p><dl data-ams-content-type=\"enumerate\"><div><dd><p>, which is obviously an application of .</p></dd></div></dl><p>For 1, the hypothesis  should do the trick, but applying it directly doesn’t work. After digging into the details, we see that this is because the eigenspace of  with respect to a scalar  is defined as the kernel of  so we will need to convert  to this form. We could do this manually, but we can first check whether we can use a preexisting lemma from the library. The fastest way to do this, in the middle of a Lean proof, is to try the  tactic. This will do a search for ways of applying existing lemmas to close the goal . This tactic doesn’t always work, but it can’t hurt to try. Aha! In this case it tells us right away that we can close the first goal by writing . The second goal is also easy to close by applying , so now we have a complete proof:</p><pre>apply Module.End.eigenvectors_linearIndependent'\n  exact hμ\n  swap ; exact f\n  intro i\n  constructor\n  exact Module.End.mem_eigenspace_iff.mpr (h i)\n  apply hv</pre><p>The beginning of our proof was a bit messy, but we can clean things up to obtain a nice final result:</p><pre>example {R M : Type} [CommRing R]\n    [AddCommGroup M] [Module R M]\n    [NoZeroSMulDivisors R M]\n    (f : M →ₗ[R] M)\n    (μ : ι → R) (hμ : Function.Injective μ)\n    (v : ι → M) (hv : ∀ i, v i ≠ 0)\n    (h : ∀ i, f (v i) = μ i • v i) :\n    LinearIndependent R v := by\n  apply\n    Module.End.eigenvectors_linearIndependent' f μ hμ\n  intro i\n  constructor\n  · exact Module.End.mem_eigenspace_iff.mpr (h i)\n  · apply hv</pre><p>The  tactic now supplies , , and  right away, leaving only one remaining goal.</p><p>We have thus achieved the level of generality we were after. Should this theorem be added to Mathlib? Upon consideration, we should conclude that our theorem is not substantially different from . In our proof, we only added some plumbing and changed the way we talk about eigenvectors to match the theorem in the library. Now that we know about , it seems that this is the standard way to talk about eigenvectors in Mathlib. If we were to modify our statement to use this instead of our bespoke  and , our theorem would be a direct application of . In other words, we have come to realize that the theorem in the library is what we really wanted all along. But the good news is that we have learned a lot in the process, and we are now much more comfortable reasoning about linear independence and eigenvectors with Mathlib.</p></section><section data-ams-doc=\"section\" data-ams-doc-level=\"1\"><p>Programmers and computer scientists have long made use of  platforms like GitHub to work on large, collaborative software projects. Formalization has brought the same tools and methodologies to mathematics. At the time of writing, Mathlib comprises approximately 5,000 files and 1.5 million lines, written by over 300 contributors. These contributions go through an open review process on GitHub, before they are merged into the main repository. In total there have been a bit more than 30,000 contributions since Mathlib’s inception in 2017.</p><p>A nice thing about version control tools is that they maintain the entire history of the project, allowing us to see what has changed and when. For example, we can trace the history of the concept of “linear independence” in Mathlib. It all started on December 7, 2017, when Johannes Hölzl committed⁠<a role=\"doc-noteref\" data-ams-ref=\"fn\" href=\"https://www.ams.org/journals/notices/202502/noti3114/noti3114.html#ltxid22\"></a> the file  to the repository. The file was 708 lines long, and on line 186 it contained a definition of linear independence.</p><pre>def linear_independent (s : set β) : Prop :=\n  ∀ l : lc α β, (∀x∉s, l x = 0) →\n    l.sum (λv c, c • v) = 0 → l = 0</pre><p>The terms  quantify over , the type of all linear combinations of elements of  with coefficients in .</p><p>On March 10, 2018, an administrative operation⁠<a role=\"doc-noteref\" data-ams-ref=\"fn\" href=\"https://www.ams.org/journals/notices/202502/noti3114/noti3114.html#ltxid23\"></a> moved  out of  so that it became a top-level folder. Another such move occurred on January 15, 2019, when Simon Hudon moved⁠<a role=\"doc-noteref\" data-ams-ref=\"fn\" href=\"https://www.ams.org/journals/notices/202502/noti3114/noti3114.html#ltxid24\"></a> all the mathematical content into  to separate it from the tests and other auxiliary files.</p><p>On July 3, 2019, Alexander Bentkamp morphed⁠<a role=\"doc-noteref\" data-ams-ref=\"fn\" href=\"https://www.ams.org/journals/notices/202502/noti3114/noti3114.html#ltxid25\"></a> the definition into</p><pre>def linear_independent : Prop :=\n  (finsupp.total ι M R v).ker = ⊥</pre><p>In other words, a collection of vectors  in  is linearly independent if the natural map from the free module generated by the vectors  to  has trivial kernel.</p><p>Then, on October 5, 2020, Anne Baanen split⁠<a role=\"doc-noteref\" data-ams-ref=\"fn\" href=\"https://www.ams.org/journals/notices/202502/noti3114/noti3114.html#ltxid26\"></a> linear independence and the accumulated supporting theory into a separate file: . The file was 918 lines long. The story continued on February 23, 2023, when Pol’tta / Miyahara Kō ported⁠<a role=\"doc-noteref\" data-ams-ref=\"fn\" href=\"https://www.ams.org/journals/notices/202502/noti3114/noti3114.html#ltxid27\"></a> the file to Lean 4 as part of a massive collaborative effort to move all of Mathlib to the new version of Lean. The filename is now , and it lives in the new  repository on GitHub. The definition has not changed substantially since the change by Bentkamp. At the time of writing, it reads as follows:</p><pre>def LinearIndependent : Prop :=\n  LinearMap.ker (Finsupp.total ι M R v) = ⊥</pre></section><section data-ams-doc=\"section\" data-ams-doc-level=\"1\"><p>The earliest programs for checking mathematical proofs include Nicolaas de Bruijn’s Automath system, launched in 1967, and Andrzej Trybulec’s Mizar system, launched in 1973. Since then, dozens of proof assistants have been developed; Coq, Isabelle, and HOL Light are among the more prominent ones still in use today. The Lean project, launched by Leonardo de Moura in 2013, is a relative newcomer. A special issue of the , with articles by John Harrison&nbsp;, Thomas Hales&nbsp;, and Freek Wiedijk&nbsp;, surveyed the state of the field in 2008. We have come a long way since then.</p><p>Proof assistants are now commonly used in industry to verify hardware, software, network protocols, cryptographic protocols, cyberphysical systems, and more. Mathematicians have only recently begun to embrace the technology, and it is becoming clear that there are several benefits to representing mathematics in digital form. Just as the word processor opened up new opportunities for written expression and communication, the digitization of mathematics opens up new opportunities for mathematical research and teaching.⁠<a role=\"doc-noteref\" data-ams-ref=\"fn\" href=\"https://www.ams.org/journals/notices/202502/noti3114/noti3114.html#ltxid29\"></a> The practical benefits are not the only motivation; to many of us, formalizing mathematics feels like the right thing to do. Mathematical definitions and theorems  to be rendered digitally.</p><p>It is also becoming clear that the technology is here to stay. Mathlib currently has roughly 1.5 million lines of code and continues to grow. Important results, including foundations for Clausen and Scholze’s condensed mathematics,⁠<a role=\"doc-noteref\" data-ams-ref=\"fn\" href=\"https://www.ams.org/journals/notices/202502/noti3114/noti3114.html#ltxid30\"></a> the polynomial Freiman–Ruzsa conjecture,⁠<a role=\"doc-noteref\" data-ams-ref=\"fn\" href=\"https://www.ams.org/journals/notices/202502/noti3114/noti3114.html#ltxid31\"></a> and an exponentially improved upper bound to Ramsey’s theorem,⁠<a role=\"doc-noteref\" data-ams-ref=\"fn\" href=\"https://www.ams.org/journals/notices/202502/noti3114/noti3114.html#ltxid32\"></a> have been formally verified before journal referees signed off on them. A number of collaborative verification projects have been launched, including a proof of the sphere eversion theorem⁠<a role=\"doc-noteref\" data-ams-ref=\"fn\" href=\"https://www.ams.org/journals/notices/202502/noti3114/noti3114.html#ltxid33\"></a> and a proof of a strengthened version of Carlson’s theorem on pointwise almost everywhere convergence of Fourier series.⁠<a role=\"doc-noteref\" data-ams-ref=\"fn\" href=\"https://www.ams.org/journals/notices/202502/noti3114/noti3114.html#ltxid34\"></a></p><p>We expect that, in the years to come, AI copilots that combine neural and symbolic methods will significantly ease the burden of formalization. More dramatically, we expect that the technology we have discussed here will play a significant role in the discovery of new mathematics. Note that DeepMind’s AlphaProof, which was deemed to have performed at the level of a silver medalist at the most recent International Mathematical Olympiad,⁠<a role=\"doc-noteref\" data-ams-ref=\"fn\" href=\"https://www.ams.org/journals/notices/202502/noti3114/noti3114.html#ltxid35\"></a> was trained to find formal proofs in Lean. It is exciting to think about what a synergetic combination of machine learning, symbolic methods, and user interaction will bring to mathematics in the years ahead.</p><p>You can find online documentation and tutorials for all the proof assistants we have just mentioned. Lean’s lively social media channel on the Zulip platform is welcoming to newcomers, and the Lean community web pages contain links⁠<a role=\"doc-noteref\" data-ams-ref=\"fn\" href=\"https://www.ams.org/journals/notices/202502/noti3114/noti3114.html#ltxid36\"></a> to learning resources, like the Natural Number Game, to help you get started. Proof assistants are not easy to use, and learning to formalize mathematics requires significant time and effort. Interaction with proof assistants like Lean comes naturally, however, to those who have grown up immersed in computational technology. We have therefore found that one of the best ways to take advantage of proof assistants is to have our students help us out. Formal mathematics is a language, and only they can claim to be among the first generation of native speakers, while the rest of us struggle to master the grammar and intonation.</p><p>With all the changes looming, we ought to be concerned about the ways that proof assistants and AI will change the mathematics that we know and love. It is therefore all the more important for those of us who are more settled in our careers to play an active role in the adoption of the new technologies, using our mathematical values and expertise to guide our students as they negotiate the changing landscape. The new developments offer us a wonderful opportunity to lead from behind, and it falls on all of us to support the next generation of mathematicians as they forge a path into the digital future.</p></section><section role=\"doc-acknowledgments\" data-ams-doc=\"section\" data-ams-doc-level=\"1\"><p>We are grateful to the Hausdorff Research Institute for Mathematics for hosting three of us for the trimester program, “Prospects of Formal Mathematics,” in the summer of 2024, during which most of this article was written. We are also grateful to Paul Buckingham and three anonymous referees for helpful comments, corrections, and suggestions.</p></section><section role=\"doc-bibliography\" data-ams-content-type=\"biblist\" data-ams-doc-level=\"1\"><dl><dd><div data-ams-doc=\"biblioentry\"> Jeremy Avigad, <i>Mathematics and the formal turn</i>, Bull. Amer. Math. Soc. (N.S.)  (2024), no.&nbsp;2, 225–240, DOI <a href=\"https://doi.org/10.1090/bull/1832\">10.1090/bull/1832</a>. MR<a href=\"https://mathscinet.ams.org/mathscinet-getitem?mr=4726989\">4726989</a>, </div></dd><dd><div data-ams-doc=\"biblioentry\"> Joshua Brakensiek, Marijn Heule, John Mackey, and David Narváez, <i>The resolution of Keller’s conjecture</i>, J. Automat. Reason.  (2022), no.&nbsp;3, 277–300, DOI <a href=\"https://doi.org/10.1007/s10817-022-09623-5\">10.1007/s10817-022-09623-5</a>. MR<a href=\"https://mathscinet.ams.org/mathscinet-getitem?mr=4449705\">4449705</a>, </div></dd><dd><div data-ams-doc=\"biblioentry\"> Kevin Buzzard, <i>What is the point of computers? A question for pure mathematicians</i>, ICM—International Congress of Mathematicians. Vol. 2. Plenary lectures, EMS Press, Berlin, 2023, pp.&nbsp;578–608. MR<a href=\"https://mathscinet.ams.org/mathscinet-getitem?mr=4680264\">4680264</a>, </div></dd><dd><div data-ams-doc=\"biblioentry\"> Thomas C. Hales, , Notices Amer. Math. Soc.  (2008), no.&nbsp;11, 1370–1380. MR<a href=\"https://mathscinet.ams.org/mathscinet-getitem?mr=2463990\">2463990</a>, </div></dd><dd><div data-ams-doc=\"biblioentry\"> John Harrison, <i>Formal proof—theory and practice</i>, Notices Amer. Math. Soc.  (2008), no.&nbsp;11, 1395–1406. MR<a href=\"https://mathscinet.ams.org/mathscinet-getitem?mr=2463992\">2463992</a>, </div></dd><dd><div data-ams-doc=\"biblioentry\"> Patrick Massot, <i>Why formalize mathematics</i> (2021)., </div></dd><dd><div data-ams-doc=\"biblioentry\"> Freek Wiedijk, <i>Formal proof—getting started</i>, Notices Amer. Math. Soc.  (2008), no.&nbsp;11, 1408–1417. MR<a href=\"https://mathscinet.ams.org/mathscinet-getitem?mr=2463993\">2463993</a>, </div></dd></dl></section><section data-ams-doc=\"refhead\" data-ams-doc-level=\"1\"><p>Photo of Jeremy Avigad is courtesy of Carnegie Mellon University.</p><p>Photo of Johan Commelin is courtesy of Johan Commelin.</p><p>Photo of Heather Macbeth is courtesy of Peter Insley.</p><p>Photo of Adam Topaz is courtesy of Adam Topaz.</p></section>","contentLength":31464,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42815755"},{"title":"Subpixel Snake [video]","url":"https://www.youtube.com/watch?v=iDwganLjpW0","date":1737739304,"author":"codetrotter","guid":171,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42815288"},{"title":"A WebAssembly compiler that fits in a tweet","url":"https://wasmgroundup.com/blog/wasm-compiler-in-a-tweet/","date":1737737476,"author":"todsacerdoti","guid":170,"unread":true,"content":"<p>One of the initial explorations that started this book was how small and simple a compile-to-WebAssembly language implemented in JavaScript could be. Our first “WebAssembly compiler in a tweet” was 269 bytes; since then, we’ve managed to whittle it down to a measly 192 bytes.</p><p>The final result is a compiler that takes an arithmetic expression — written in reverse polish notation — and compiles it down to a valid WebAssembly module. That module exports a single function which returns the result of the original arithmetic expression. Here it is:</p><p>And here’s an example of how you can use it:</p><p>But this is not just a clever trick — if you take the time to understand what this code does, you’ll learn a surprising amount about WebAssembly! In the rest of the post, we’ll explain how it all works by de-obfuscating the code one step at a time.</p><p>The first thing we can do to make it more readable is to format it:</p><div data-ch-theme=\"nord\"><div data-ch-measured=\"false\"><code></code></div></div><p>While it’s still pretty unreadable, now we can at least identify different parts of the code.</p><p>At a high level, what we’re doing is ‘parsing’ the expression in a very simple way, turning it into the appropriate Wasm bytecode,\nand then hand-crafting the bytes for a single-function module.</p><p>In a more complex compiler you would probably use a library to generate the WebAssembly module and compile the expressions but our main metric\nhere is code size so we write the bytes directly in an array.</p><p>In JavaScript the assignment operator is an expression. This means that it generates a result after evaluating, as you can see in the following examples:</p><p>The code above will output:</p><p>This is because  assigns  to  and the whole assignment expression evaluates to the value being assigned.</p><p>In , we assign the result of evaluating  to . This equivalent expression may be easier to understand: .</p><p>In our code, we use this trick to reuse variables and update their value in places where\nwe can also use the value being assigned. It also allows us to have our compiler in a single expression, avoiding the need for curly braces, semicolons and return statements.</p><p>To undo it, we turn the body of our function into a block and do each assignment on its own line:</p><section><div data-ch-theme=\"nord\"><div data-ch-measured=\"false\"><code></code></div></div></section><p>Now the assignments are easier to identify but the meaning of variables and function\narguments are still hard to understand. Let’s fix that by undoing a couple of variable tricks.</p><p>The first step is to stop using single letter variables, and to use more descriptive names instead. The next step is to stop reusing variables: for example,  initially holds the code to compile, but once we don’t need that any more we reuse it to hold the bytecode instructions.</p><p>To undo this we are going to introduce a new  variable and rename  to . We’ll also rename  to . This variable contains a value that is close to the number of bytecodes.</p><p>By declaring  in the body we can remove it from the function argument’s list. We did this\nas a trick to avoid the need to declare it with  or , saving some bytes and the need for a function body.</p><p>The trick works by adding unused arguments at the end of the function argument list and using them as local variables. Our compiler function expects a single argument with the code;  is there for us to use since we don’t expect the caller to provide any value for it.</p><p>Here’s the code without this trick:</p><section><div data-ch-theme=\"nord\"><div data-ch-measured=\"false\"><code></code></div></div></section><p>If you look at the array in our code, you may notice that there are many commas followed by another comma instead of a value. This syntax defines “sparse arrays”. Here’s an example:</p><p>We use this syntactic trick to save one byte each time we need a  to appear in the array. This works because <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Typed_arrays\" target=\"_blank\" rel=\"noopener noreferrer\">Typed Arrays</a> coerce all array items to numbers, and an “empty item” will be converted to 0:</p><p>Let’s undo this trick by adding all the zeroes back:</p><section><div data-ch-theme=\"nord\"><div data-ch-measured=\"false\"><code></code></div></div></section><p>In our code, we have a variable  that contains a number that is close to the number\nof bytecodes in the compiled expression, but not exactly the same:</p><p>In the WebAssembly module we need to use the number of bytes in the function body (the expression to evaluate) in two places:</p><ul><li>To define the code section’s length</li><li>To define the function body’s length</li></ul><p>Since there’s only one function in the code section both values are similar:</p><ul><li>The section takes two extra bytes (section identifier and number of code entries)</li><li>The function body takes another two bytes (number of locals and  instruction)</li></ul><p>To avoid writing  twice we assign to  the value of  in the place where we need the code section byte count\nand then calculate  () where we need the function body byte count.</p><p>This is all a trick to avoid having to write  twice.</p><p>let’s assign the length to  and calculate the right value in each place:</p><section><div data-ch-theme=\"nord\"><div data-ch-measured=\"false\"><code></code></div></div></section><p>Let’s see how it works by creating a simple tagged template that turns the string to uppercase:</p><p>As you can see, the first argument to the tagged template function is an array. Luckily for us, the first argument of <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/split#separator\" target=\"_blank\" rel=\"noopener noreferrer\">String.prototype.split</a> is handled in the following way:</p><blockquote><p>All values that are not undefined or objects with a  method are coerced to strings.</p></blockquote><p>And coercing an array with one string in it is the same as the string itself:</p><p>Since the function we want to call takes a single string argument, we can use it as a tagged template and save the parentheses in the function call.</p><p>Let’s write it as a function call instead:</p><section><div data-ch-theme=\"nord\"><div data-ch-measured=\"false\"><code></code></div></div></section><p>The ternary operator has expressions on each branch saving us the  statements. Here’s what the code looks like when we use an  statement instead:</p><section><div data-ch-theme=\"nord\"><div data-ch-measured=\"false\"><code></code></div></div></section><p>The next trick to undo is the one present twice in the following code:</p><p>First we use coercion in  to check if the token  is a string representing a\npositive number. Then we use coercion again in  to let JavaScript turn  into a  in the :</p><p>The code above evaluates to:</p><p>Let’s write the parsing and checking explicitly:</p><section><div data-ch-theme=\"nord\"><div data-ch-measured=\"false\"><code></code></div></div></section><p>The semantics of our compiler change a little bit here. The original version will only accept\npositive integers as input; if you want a negative number you have to subtract from zero:  to get . The new version allows negative numbers since it checks with  instead of .</p><p>The next trick is in the  branch:</p><p>Our calculator compiler only accepts four arithmetic operations: , , , and . But\nin the code above you can only see three:  and a magical number: . Here’s how it works — these are the bytecode numbers for arithmetic operations in WebAssembly:</p><p>We only enter this branch if the token  is not a number, which means it can only be\none of the arithmetic operators above. So, given a single character which is one of those four operators, we want to produce the appropriate opcode.</p><p>We  have written . That is, we find the symbol’s index in the string:</p><p>…and add  to it to get the bytecode number. But when  is not in the string,  returns . We can use that to our advantage, and treat  to mean “plus or any other token”:</p><ul><li>:  (any other token will be  too)</li></ul><p>And that’s why we add  instead of . Let’s undo the  trick:</p><section><div data-ch-theme=\"nord\"><div data-ch-measured=\"false\"><code></code></div></div></section><p>Here again the semantics change a little bit. Before, if the token  wasn’t found, the expression would evaluate to  which would map to an addition. Now it will evaluate to  which will map to bytecode  which is the <a href=\"https://developer.mozilla.org/en-US/docs/WebAssembly/Reference/Numeric/Population_count\" target=\"_blank\" rel=\"noopener noreferrer\"></a> instruction.</p><p>But don’t worry, we’ll fix it in the next step.</p><p>After explaining how the  trick works and removing the  part, let’s\ngo ahead and remove the trick completely. To do it we are going to create an object that maps from an arithmetic operation token to its bytecode:</p><section><div data-ch-theme=\"nord\"><div data-ch-measured=\"false\"><code></code></div></div></section><p>To keep the initial semantics, if the token is not a valid operation we return the bytecode for : in .</p><p>From the usage example at the beginning of the post, you may have noticed that the exported\nfunction’s name is the empty string:</p><p>We did this to save us the bytes needed to specify the export name,\nbut also to save an extra byte/character in the code because with the length of the export name being \nwe can use the sparse array syntax to leave an empty spot in the WebAssembly module array.</p><p>To revert this trick we are going to name the exported function as , which in UTF-8 is the byte :</p><section><div data-ch-theme=\"nord\"><div data-ch-measured=\"false\"><code></code></div></div></section><p>We can now call it with a nicer name:</p><p>Our initial implementation only supported positive numbers, but that’s not the only number restriction in our compiler.</p><p>To keep WebAssembly modules as small as possible, numbers are encoded using a variable-length encoding algorithm called <a href=\"https://en.wikipedia.org/wiki/LEB128\" target=\"_blank\" rel=\"noopener noreferrer\">LEB128</a>. You can tell we are not implementing the whole algorithm by looking at the part of the code that encodes numbers: . We’re assuming the number being encoded fits in 7 bits, the shortest possible LEB128 representation.</p><p>Let’s try the limits of our implementation:</p><p>This means the only numbers that will be parsed correctly are from  to .</p><blockquote><p>Uncaught CompileError: WebAssembly.instantiate(): Compiling function #0 failed: function body must end with “end” opcode @+33</p></blockquote><p>In the last one we went over the 7 bits and the module was rejected during validation.</p><p>Explaining and implementing LEB128 takes a lot of text and code. If you want to read more\nabout it we have a whole deep dive on LEB128 in <a href=\"https://wasmgroundup.com/\" target=\"_blank\" rel=\"noopener noreferrer\">our book</a>.</p><p>During the code golfing phase I had a literal shower thought but sadly it didn’t work.</p><p>The idea was to simplify  by using the UTF-8 character code plus an offset like this:  and saving 3 bytes in the process. The reason it didn’t work is that the characters  don’t appear in the same order in UTF-8 and WebAssembly bytecode.</p><p>The last part to expand/explain is the array of numbers used to build the WebAssembly module.</p><p>It takes a big part of a <a href=\"https://www.w3.org/TR/2019/REC-wasm-core-1-20191205/\" target=\"_blank\" rel=\"noopener noreferrer\">specification</a> to explain every byte in the array, but here’s a commented version that should give you a high level idea of what each part does:</p><div data-ch-theme=\"nord\"><div data-ch-measured=\"false\"><code></code></div></div><p>There you go! We’ve turned a rather opaque 192-byte snippet into something that’s almost readable. And in the process, you hopefully learned a little bit about WebAssembly.</p><p>If we dropped the size restrictions, there are lots of things we might want to improve in this compiler: handle numbers greater than 127, add nicer syntax, add support for conditionals, loops, etc. If you’re interested in what that might look like, I encourage you to check out our book <a href=\"https://wasmgroundup.com/\" target=\"_blank\" rel=\"noopener noreferrer\">WebAssembly from the Ground Up</a>. You’ll learn the ins and outs of WebAssembly by writing a real compiler for a simple programming language. It’s a lot of fun!</p><p>Special thanks to <a href=\"https://bsky.app/profile/orthoplex.bsky.social\" target=\"_blank\" rel=\"noopener noreferrer\">lexi</a> for contributing some of the tricks used above.</p>","contentLength":10187,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42814948"},{"title":"Snowdrop OS – a homebrew operating system from scratch, in assembly language","url":"http://sebastianmihai.com/snowdrop/","date":1737736811,"author":"ksec","guid":169,"unread":true,"content":"\n\nWelcome to the pages of Snowdrop OS, my homebrew operating system project.\nSnowdrop OS was born of my childhood curiosity around what happens when a PC is turned on, the mysteries of bootable disks, and the hidden aspects of operating systems. It is a 16-bit real mode operating system for the IBM PC architecture. I designed and developed this homebrew OS from scratch, using only x86 assembly language. \n<p>I have created and included a number of utilities, including a file manager, text editor, graphical applications, BASIC interpreter, x86 assembler and debugger. I also ported one of my DOS games to it. After all, what kind of an operating system doesn't have games?\n</p><p>The Snowdrop OS and the apps are distributed as both a floppy disk (1.44Mb) image, as well as a CD-ROM image. The images contain the following, all programmed from scratch:\n</p><ul><li>a boot loader which loads the kernel into memory</li><li>a kernel which sets up interrupt vectors to be used by user apps, and then loads the startup app</li><li>user apps, including a shell (command line interface), utilities, test apps, and aSMtris, my Tetris clone</li></ul>\nSnowdrop OS can also be installed to a hard disk - prompting the user to do so during boot - if it detects one. \n<p>I hope that Snowdrop can serve other programmers who are looking to get a basic understanding of operating system functions. Like my other projects, the source code is fully available, without any restrictions on its usage and modification.\n</p>\nSome interesting areas in the <a href=\"http://sebastianmihai.com/snowdrop/src\">source code</a> are: <div>v1 - initial version, single tasking, shell, aSMtris\nv2 - PS/2 mouse driver and mouse test apps\n<p>v3 - basic multi-tasking support and virtual display support\n</p>v4 - FAT12 driver write/delete, file manager, text editor\n<p>v5 - serial port driver, formatting utilities, file copy support\n</p>v6 - multiplayer snake game (over serial port)\n<p>v7 - slide show presentation app\n</p>v8 - \"keep memory\" task lifetime mode, for custom services\n<p>v9 - parallel port driver, BMP image support, sprites\n</p>v10 - system timer frequency change\n<p>v11 - animated sprites, sound driver (internal speaker)\n</p>v12 - keyboard driver\n<p>v13 - more sprites functionality, Storks game\n</p>v14 - kernel config, program arguments, file utilities\n<p>v15 - 16x2 LCD controller app, text editor fixes\n</p>v16 - GUI framework\n<p>v17 - Snowmine (Minesweeper-like game)\n</p>v18 - BASIC interpreter and linker\n<p>v19 - install to hard disk\n</p>v20 - BASIC and text editor improvements\n<p>v21 - integration of BASIC and GUI framework\n</p>v22 - x86 assembler, multi-disk support, file view utilities\nv24 - service loading\n<p>v25 - dynamic memory and data structures\n</p>v26 - installer improvements, pseudo-mouse driver\n<p>v27 - kernel and inter-task messaging\n</p>v28 - GUI higher resolution, draw application, desktop application\n<p>v29 - data compression, Hangman game\n</p>v30 - pseudo-mouse driver improvements\n<p>v31 - runtime libraries (RTL), BASIC interpreter RTL\n</p></div>","contentLength":2851,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42814820"},{"title":"Wild – A fast linker for Linux","url":"https://github.com/davidlattimore/wild","date":1737735953,"author":"hkalbasi","guid":168,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42814683"},{"title":"New book-sorting algorithm almost reaches perfection","url":"https://www.quantamagazine.org/new-book-sorting-algorithm-almost-reaches-perfection-20250124/","date":1737733823,"author":"isaacfrond","guid":167,"unread":true,"content":"<p>Computer scientists often deal with abstract problems that are hard to comprehend, but an exciting new algorithm matters to anyone who owns books and at least one shelf. The algorithm addresses something called the library sorting problem (more formally, the “list labeling” problem). The challenge is to devise a strategy for organizing books in some kind of sorted order — alphabetically, for instance — that minimizes how long it takes to place a new book on the shelf.</p><p>Imagine, for example, that you keep your books clumped together, leaving empty space on the far right of the shelf. Then, if you add a book by Isabel Allende to your collection, you might have to move every book on the shelf to make room for it. That would be a time-consuming operation. And if you then get a book by Douglas Adams, you’ll have to do it all over again. A better arrangement would leave unoccupied spaces distributed throughout the shelf — but how, exactly, should they be distributed?</p><p>This problem was introduced in a <a href=\"https://link.springer.com/chapter/10.1007/3-540-10843-2_34\">1981 paper</a>, and it goes beyond simply providing librarians with organizational guidance. That’s because the problem also applies to the arrangement of files on hard drives and in databases, where the items to be arranged could number in the billions. An inefficient system means significant wait times and major computational expense. Researchers have invented some efficient methods for storing items, but they’ve long wanted to determine the best possible way.</p><p>Last year, in <a href=\"https://arxiv.org/abs/2405.00807\">a study</a> that was presented at the Foundations of Computer Science conference in Chicago, a team of seven researchers described a way to organize items that comes tantalizingly close to the theoretical ideal. The new approach combines a little knowledge of the bookshelf’s past contents with the surprising power of randomness.</p><p>“It’s a very important problem,” said <a href=\"https://web.eecs.umich.edu/~pettie/\">Seth Pettie</a>, a computer scientist at the University of Michigan, because many of the data structures we rely upon today store information sequentially. He called the new work “extremely inspired [and] easily one of my top three favorite papers of the year.”</p><p>So how does one measure a well-sorted bookshelf? A common way is to see how long it takes to insert an individual item. Naturally, that depends on how many items there are in the first place, a value typically denoted by . In the Isabel Allende example, when all the books have to move to accommodate a new one, the time it takes is proportional to . The bigger the , the longer it takes. That makes this an “upper bound” to the problem: It will never take longer than a time proportional to  to add one book to the shelf.</p><p>The authors of the 1981 paper that ushered in this problem wanted to know if it was possible to design an algorithm with an average insertion time much less than. And indeed, they proved that one could do better. They created an algorithm that was guaranteed to achieve an average insertion time proportional to (log ). This algorithm had two properties: It was “deterministic,” meaning that its decisions did not depend on any randomness, and it was also “smooth,” meaning that the books must be spread evenly within subsections of the shelf where insertions (or deletions) are made. The authors left open the question of whether the upper bound could be improved even further. For over four decades, no one managed to do so.</p><p>However, the intervening years did see improvements to the lower bound. While the upper bound specifies the maximum possible time needed to insert a book, the lower bound gives the fastest possible insertion time. To find a definitive solution to a problem, researchers strive to narrow the gap between the upper and lower bounds, ideally until they coincide. When that happens, the algorithm is deemed optimal — inexorably bounded from above and below, leaving no room for further refinement.</p><p>In 2004, a team of researchers found that the <a href=\"https://epubs.siam.org/doi/abs/10.1137/S0895480100315808?journalCode=sjdmec\">best any algorithm could do</a> for the library sorting problem — in other words, the ultimate lower bound — was log . This result pertained to the most general version of the problem, applying to any algorithm of any type. Two of the same authors had already secured a result for a more specific version of the problem in 1990, showing that for any smooth algorithm, <a href=\"https://link.springer.com/chapter/10.1007/3-540-52846-6_87\">the lower bound is significantly higher</a>: (log ). And in 2012, another team <a href=\"https://dl.acm.org/doi/abs/10.1145/2213977.2214083\">proved the same lower bound</a>, (log ), for any deterministic algorithm that does not use randomness at all.</p><p>These results showed that for any smooth or deterministic algorithm, you could not achieve an average insertion time better than (log ), which was the same as the upper bound established in the 1981 paper. In other words, to improve that upper bound, researchers would need to devise a different kind of algorithm. “If you’re going to do better, you have to be randomized and non-smooth,” said <a href=\"https://www.cs.stonybrook.edu/people/faculty/michaelbender\">Michael Bender</a>, a computer scientist at Stony Brook University.</p><figure></figure><p>But getting rid of smoothness, which requires items to be spread apart more or less evenly, seemed like a mistake. (Remember the problems that arose from our initial example — the non-smooth configuration where all the books were clumped together on the left-hand side of the shelf.) And it also was not obvious how leaving things to random chance — essentially a coin toss — would help matters. “Intuitively, it wasn’t clear that was a direction that made sense,” Bender said.</p><p>Nevertheless, in 2022, Bender and five colleagues decided to try out a randomized, non-smooth algorithm anyway, just to see whether it might offer any advantages.</p><p>Ironically, progress came from another restriction. There are sound privacy or security reasons why you may want to use an algorithm that’s blind to the history of the bookshelf. “If I had on my bookshelf and took it off,” said <a href=\"https://csd.cmu.edu/people/faculty/william-kuszmaul\">William Kuszmaul</a> of Carnegie Mellon University, nobody would be able to tell.</p><p>In a 2022 paper, Bender, Kuszmaul and four co-authors created just such an algorithm — one that was “history independent,” non-smooth and randomized — which finally <a href=\"https://arxiv.org/abs/2203.02763\">reduced the 1981 upper bound</a>, bringing the average insertion time down to (log ).</p><p>Kuszmaul remembers being surprised that a tool normally used to ensure privacy could confer other benefits. “It’s as if you used cryptography to make your algorithm faster,” he said. “Which just seems kind of strange.”</p><p><a href=\"https://www.cc.gatech.edu/people/helen-xu\">Helen Xu</a> of the Georgia Institute of Technology, who was not part of this research team, was also impressed.&nbsp; She said that the idea of using history independence for reasons other than security may have implications for many other types of problems.</p><p>Bender, Kuszmaul and others made an even bigger improvement with last year’s paper. They again broke the record, lowering the upper bound to (log ) times (log log ) — equivalent to (log ). In other words, they came exceedingly close to the theoretical limit, the ultimate lower bound of log .</p><p>Once again, their approach was non-smooth and randomized, but this time their algorithm relied on a limited degree of history dependence. It looked at past trends to plan for future events, but only up to a point. Suppose, for instance, you’ve been getting a lot of books by authors whose last name starts with N — Nabokov, Neruda, Ng. The algorithm extrapolates from that and assumes more are probably coming, so it’ll leave a little extra space in the N section. But reserving too much space could lead to trouble if a bunch of A-name authors start pouring in. “The way we made it a good thing was by being strategically random about how much history to look at when we make our decisions,” Bender said.</p><p>The result built on and transformed their previous work. It “uses randomness in a completely different way than the 2022 paper,” Pettie said.</p><p>These papers collectively represent “a significant improvement” on the theory side, said <a href=\"https://computerscience.uchicago.edu/people/brian-wheatman/\">Brian Wheatman</a>, a computer scientist at the University of Chicago. “And on the applied side, I think they have the potential for a big improvement as well.”</p><p>Xu agrees. “In the past few years, there’s been interest in using data structures based on list labeling for storing and processing dynamic graphs,” she said. These advances would almost certainly make things faster.</p><p>Meanwhile, there’s more for theorists to contemplate. “We know that we can almost do log ,” Bender said, “[but] there’s still this tiny gap” — the diminutive log log term that stands in the way of a complete solution. “We don’t know if the right thing to do is to lower the upper bound or raise the lower bound.”</p><p>Pettie, for one, doesn’t expect the lower bound to change. “Usually in these situations, when you see a gap this close, and one of the bounds looks quite natural and the other looks unnatural, then the natural one is the right answer,” he said. It’s much more likely that any future improvements will affect the upper bound, bringing it all the way down to log  “But the world’s full of weird surprises.”</p>","contentLength":9019,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42814275"},{"title":"Show HN: Cs16.css – CSS library based on Counter Strike 1.6 UI","url":"https://cs16.samke.me/","date":1737733027,"author":"samke-","guid":161,"unread":true,"content":"<div>\n                Lorem ipsum dolor sit amet consectetur adipisicing elit.\n                Distinctio ad suscipit aut asperiores laudantium error amet\n                sapiente et tempora numquam voluptates, velit sint quos\n                exercitationem unde obcaecati deleniti maiores officia natus\n                ipsa rem fuga commodi esse. Sunt repellendus ipsa illo a\n                accusantium consequuntur nihil dicta necessitatibus porro,\n                saepe, sed repudiandae!\n              </div>","contentLength":501,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42814110"},{"title":"How I Use Home Assistant in 2025","url":"https://vpetersson.com/2025/01/22/how-i-use-home-assistant-in-2025.html","date":1737730293,"author":"ingve","guid":166,"unread":true,"content":"<p>I’ve been using Home Assistant for about seven years now, starting back when I was living in a small apartment. At the time, my setup was modest: I used the  (when it first launched) to tie together all my apartment’s lights. As I got more comfortable with automations, I also began building <a href=\"https://vpetersson.com/2019/11/16/home-assistant-and-esphome.html\">custom hardware like temperature and humidity sensors</a>.</p><p>However, once I started adding more complexity (more devices, more automations), I realized that running Home Assistant on a Raspberry Pi just wasn’t viable anymore. This was before Home Assistant offered their own hardware (which I haven’t tried, so I can’t say much about it). But for me, the main issue was the database. By default, Home Assistant uses SQLite, and when you have a ton of sensor data flowing in, SQLite can start choking.</p><p>My solution was to move everything to a VM on my home server. I also migrated Home Assistant’s main database to MySQL, and for longer-term metrics and historical data, I set up an InfluxDB server. (I’ve documented the details of my <a href=\"https://vpetersson.com/2024/05/04/home-server-journey.html\">home server build in another blog post</a>.)</p><h2>Scaling Up in a New House</h2><p>When I moved into a house, my Home Assistant installation grew significantly: more rooms, more lights, and more devices overall. Right now, I have over 100 devices connected to Home Assistant, including a large number of smart lights (all IKEA), plus an assortment of other smart devices. Practically every bulb in my home is now integrated into Home Assistant.</p><h3>Adaptive Lighting: Moving Beyond Flux</h3><p>One of the crucial features for me is . Initially, I used <a href=\"https://vpetersson.com/2020/05/25/homeassistant-ikea-tradfri-flux-sensors.html\">Flux</a> (an older solution for synchronizing lights with the time of day), but I’ve recently migrated to the new Adaptive Lighting integration available through HACS (Home Assistant Community Store). This newer system is much more sophisticated and has better capabilities for adjusting color temperature and brightness throughout the day.</p><p>Managing this setup comes with two main challenges. First, neither Flux nor Adaptive Lighting can target light groups. Instead, you need to explicitly list every single light entity in your configuration. This becomes particularly tedious when you have dozens of lights that you want to manage together. It would have been much more convenient to just point the integration to a group and have it handle all the lights within that group automatically.</p><p>The second challenge is that even though all my bulbs are from IKEA, they don’t have all the same features. This means I need separate configurations for each category to get Adaptive Lighting working correctly. But the effort is worth it: circadian rhythms are important to me, and I really want that smooth, automatic shift in color temperature from warm yellows in the morning and evenings to cooler whites and blues during midday.</p><h2>Using Cursor to Speed Up Configuration</h2><p>One big leap for me this year has been leveraging <a href=\"https://www.cursor.com\">Cursor</a>, an AI coding assistant, to handle the more tedious parts of Home Assistant’s YAML configurations. I’ll admit, I’ve never had the time to master every detail of Home Assistant’s DSL or its configuration files.</p><p>The first major task I tackled with Cursor was writing a custom script to parse all my lights, figure out exactly what kind of bulb each one is, and spit out debugging information. This is the foundation of building the correct adaptive lighting setup. Once the script categorizes the bulbs, I can then create or update the YAML configuration for each bulb type.</p><p>Here’s the script I use to analyze my Home Assistant lights. It connects to the Home Assistant API, categorizes all lights by their capabilities, and provides detailed debugging information about their current state and supported features:</p><div><div><pre><code></code></pre></div></div><ol><li><strong>Run the custom parsing script</strong> on my Home Assistant setup to produce a detailed list of bulbs and their capabilities.</li><li> into Cursor (in “agent mode” or similar), along with my old configuration.</li><li> the updated YAML for the new Adaptive Lighting system.</li></ol><p>It’s been a huge time-saver. Sure, I still do some manual debugging, but I also use Cursor to assist with the troubleshooting. For instance, if something breaks in Home Assistant, I feed the logs into Cursor and ask it to help me fix the error. It’s surprisingly effective.</p><p>After extensive testing, I’ve optimized my adaptive lighting configurations for different IKEA bulb types. Here are my recommended settings that provide smooth transitions while maintaining good visibility throughout the day.</p><p>For IKEA’s <em>LED bulb GU10 345 lumen, smart/wireless dimmable white spectrum</em> bulbs.</p><div><div><pre><code></code></pre></div></div><h3>Dimmable color and white spectrum</h3><p>For the <em>LED bulb E27 806 lumen, wireless dimmable color and white spectrum/globe opal white</em> bulbs.</p><div><div><pre><code></code></pre></div></div><p>For the basic <em>LED bulb GU10 345 lumen, smart/wireless dimmable warm white</em> bulbs.</p><div><div><pre><code></code></pre></div></div><p>Now that the lighting is running smoothly, my next big smart home project is upgrading all my radiators with Zigbee-based smart TRVs (thermostatic radiator valves). The goal is to have each room in my home maintain an optimal temperature by reading from the central Nest thermostat. In older British homes like mine, temperature control isn’t very granular, so having each radiator adjust itself is a major comfort and efficiency boost.</p><p>I’ve already purchased <a href=\"https://s.click.aliexpress.com/e/_EzwaYAM\">these TRVs</a> but haven’t had time to configure them yet. My plan is:</p><ol><li> to my Zigbee network.</li><li> from my Nest thermostat (the main sensor).</li><li> in Home Assistant so that each room’s radiator valve opens or closes based on its own target temperature.</li></ol><p>I’m hoping this will help solve the typical British house problem: some rooms end up too warm, while others are never warm enough. With per-room heating control, it should be far more balanced and efficient.</p><p>That’s where my Home Assistant journey sits at the moment. I’m thrilled with how the adaptive lighting is working, especially now that I’ve harnessed an AI coding assistant to manage the complexity of my YAML files. The next challenge, smart radiator valves, will hopefully bring my home’s temperature control on par with my lighting automation.</p><i>Found an error or typo? File PR against <a href=\"https://github.com/vpetersson/vpetersson.com/tree/master/_posts/2025-01-22-how-i-use-home-assistant-in-2025.md\" rel=\"nofollow\">this file</a>.</i>","contentLength":6057,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42813513"},{"title":"Ask HN: Why buy domains and 301 redirect them to me?","url":"https://news.ycombinator.com/item?id=42812779","date":1737724856,"author":"HughParry","guid":165,"unread":true,"content":"Say I'm running a SaaS product, example.com.<p>Somebody has bought several domains like getexample.com, buyexample.io, joinexample.net, and is 301 redirecting them to example.com.</p><p>What's their play here? Is this setup for a phishing attack in the future? Are they just going to try and sell the domains to me in the future? Not encountered behaviour like this before (or at least, I don't know if this is the beginning phase of a common scam)</p>","contentLength":438,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42812779"},{"title":"A phishing attack involving g.co, Google's URL shortener","url":"https://gist.github.com/zachlatta/f86317493654b550c689dc6509973aa4","date":1737689926,"author":"zachlatta","guid":164,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42810252"},{"title":"Show HN: Trolling SMS spammers with Ollama","url":"https://evan.widloski.com/software/sms_llm/","date":1737573828,"author":"Evidlo","guid":156,"unread":true,"content":"<p>I occasionally get unsolicited texts from real estate brokers looking to buy specific properties in my hometown where I own no property and don't even live.  I assume they scrape cell phone numbers from WhitePages and just spray-and-pray hoping to get a response.</p><p>My parents own some undeveloped land in the middle of town which lies mostly in a flood zone and the usable acreage is much less than it appears on paper.  Of course the brokers don't know this, so the prospect of buying up a big plot which has been vacant for decades for cheap probably gets their mouths watering.</p><p>Over Christmas break I worked on a system for controlling my phone's SMS application over MQTT from a remote workstation running Ollama.  Below is an overview of the system:</p><div><pre><code>                      ANDROID PHONE                  LLM SERVER    \n\n                    +---------------+      |                         \n                    | SMS Messaging |      |                        \n  SMS Victims ------|     App       |                              \n                    +---------------+      |                        \n                            |              |                        \n                    +---------------+              +---------------+\n                    |  Gateway App  |--------------|  MQTT Broker  |\n                    +---------------+              +---------------+\n                                           |               |        \n                                           |       +---------------+\n                                                   |    llm.py     |\n                                           |       +---------------+\n                                           |               |        \n                                                   +---------------+\n                                           |       | Ollama Server |\n                                           |       +---------------+\n</code></pre></div><p>The first step is to forward text messages somehow to the LLM workstation.  There are several SMS forwarding tools on both F-Droid and the Play store, but most of them only supported one-way forwarding received SMS via POST request to some REST endpoint.  I saw one application which supports POSTing messages back to the phone, but since the phone is behind a CGLAN, I really wanted some kind of long-running socket connection to the workstation.</p><p>I ended up finding the verbosely named <a href=\"https://github.com/ibnux/Android-SMS-Gateway-MQTT\">Android-SMS-Gateway-MQTT</a>, which runs in the background and waits to send/receive messages and works without changing the default messaging app.</p><p>For some reason the app can be commanded to send messages via MQTT, but received messages are forwarded via POST request only.  I made some modifications to use MQTT for communication both ways.</p><p>I really don't enjoy touching Android development, so I gave a shot at using Cursor.ai to make the changes and it worked perfectly first try!  The prompt I used is below:</p><div><pre><code>[SMSListener.java (41-46)]\nHow do I turn this POST request into an MQTT message?  I'd like to use the MQTT connection already present in the file `BackgroundService.java` if possible.\n</code></pre></div><p>Disabling battery optimization is necessary for the application to run reliably in the background.  Fortunately the power consumption for the app is insignificant.  The .apk is available in the project files.</p><p>The job of the Python script is simply to listen on MQTT for new SMS messages and send generated LLM responses back to the Android application.\nI want the language model to be able to give responses that make sense in context, so I store each ongoing conversation in a separate JSON file and feed the last N messages to the language model when generating responses.</p><figure><div><pre><code>[\n    {\n        \"role\": \"user\",\n        \"content\": \"I forgore to register for ece500 :(\"\n    },\n    {\n        \"role\": \"assistant\",\n        \"content\": \"that sucks bro, did u talk to the prof about gettin in tho?\"\n    },\n    {\n        \"role\": \"user\",\n        \"content\": \"Tf\"\n    },\n    {\n        \"role\": \"assistant\",\n        \"content\": \"lol what's that supposed to mean, are u gonna try to crash the class or somethin?\"\n    },\n    {\n        \"role\": \"user\",\n        \"content\": \"Hello\"\n    },\n    {\n        \"role\": \"assistant\",\n        \"content\": \"hey whats good, just got back from leg day and i'm hella sore btw\"\n    },\n    {\n        \"role\": \"user\",\n        \"content\": \"Ok bro\"\n    }\n]\n</code></pre></div></figure><p>A big part of the fun is being able to create different ridiculous personalities and backstories.  The Python script reads from a config where I can assign different personalities to conversations.</p><p>The Ollama TUI also makes it really convenient to experiment with different prompts and update these personas.  I don't even have to restart the script!</p><figure><div><pre><code>[evan@copernicus ~] ollama run llama3.3\n\n&gt;&gt;&gt; /set system \"you are a college bro responding via SMS.  you want to sell your property.  you only respond with single sentences and use millenial speak. your responses are very short and you don't capitalize letters.  you always want to sell.  everything you write is lowercase and your property is for sale. you should be open to negotiation and accept even low offers\"\n\nSet system message.\n\n&gt;&gt;&gt; Hey this is Bob with [redacted].  We're looking to buy vacant land near the one you own in [redacted].  Are you interested in a fair offer?\n\nmy property in [redacted] goes hard and i'm down to sell for a lowkey decent price, hit me with an offer fam\n\n&gt;&gt;&gt; /save llama3.3bro\n</code></pre></div><figcaption>Experimentation in the Ollama shell</figcaption></figure><p>And now for what you've been waiting for!  The first message in these screenshots is written by me to get the other person to respond after I've whitelisted the conversation.  These chats are all I have at the moment, but I may come back and add more as more spam rolls in.</p><ul><li><p>I started off the project using Phi4, but I had difficulty keeping the LLM responses short.  After switching to llama3.3, this seems to have improved a lot.</p></li><li><p>I'm not sure what the legal implications are of agreeing to sell land that I don't even own, so lately I've instructed the models to never actually close on anything.</p></li><li><p>People have mentioned that responding to SMS spam helps the spammers to \"warm up\" a number and build carrier reputation so they can send more spam texts.  I figure that reporting and blocking the numbers after I've had my fun is a reasonable compromise.</p></li><li><p>I do get some spam calls in addition to texts, but I haven't noticed an increase in either quite yet.</p></li></ul>","contentLength":6406,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42796496"}]}