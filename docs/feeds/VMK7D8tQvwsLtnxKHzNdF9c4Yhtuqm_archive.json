{"id":"VMK7D8tQvwsLtnxKHzNdF9c4Yhtuqm","title":"Hacker News: Best","displayTitle":"HN","url":"https://hnrss.org/best","feedLink":"https://news.ycombinator.com/best","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":30,"items":[{"title":"Everyone knows your location: tracking myself down through in-app ads","url":"https://timsh.org/tracking-myself-down-through-in-app-ads/","date":1738516051,"author":"apokryptein","guid":176,"unread":true,"content":"<p>Recently I read about a <a href=\"https://www.404media.co/hackers-claim-massive-breach-of-location-data-giant-threaten-to-leak-data/?ref=timsh.org\" rel=\"noreferrer\">massive geolocation data leak from Gravy Analytics</a>, which exposed more than 2000 apps, both in AppStore and Google Play, that secretly collect geolocation data without user consent. Oftentimes, even without developers` knowledge. </p><p>I looked into the list (<a href=\"https://docs.google.com/spreadsheets/d/1Ukgd0gIWd9gpV6bOx2pcSHsVO6yIUqbjnlM4ewjO6Cs/edit?gid=1257088277&amp;ref=timsh.org#gid=1257088277\" rel=\"noreferrer\">link here</a>) and found at least 3 apps I have installed on my iPhone. Take a look for yourself! This made me come up with an idea to track myself down externally, e.g. to buy my geolocation data leaked by some application. </p><p>After more than couple dozen hours of trying, here are the main takeaways: </p><ol><li>I found a couple requests sent by my phone with + 5 requests that leak , which can be turned into geolocation using reverse DNS. </li><li>Learned a lot about the RTB (real-time bidding) auctions and OpenRTB protocol and was shocked by the amount and types of data sent with the bids to ad exchanges. </li><li>Gave up on the idea to buy my location data from a data broker or a tracking service, because I don't have a big enough company to take a trial or $10-50k to buy a huge database with the data of millions of people + me. Well maybe I do, but such expense seems a bit irrational. <p>Turns out that EU-based peoples` data is almost the most expensive. </p></li></ol><p>But still, I know my location data was collected and I know where to buy it! </p><p>My setup for this research included:</p><ul><li>My old iPhone 11 restored to factory defaults + new apple id. Felt too uncomfortable to do all this on my current phone. </li><li>Charles Proxy to record all traffic coming in and out. I set up the SSL certificate on the iPhone to decrypt all https traffic.</li><li>A simple game called Stack by KetchApp - I remember playing it at school 10-12 years ago. Choosing it as a lab rat felt nostalgic. To my surprise, there were a lot of KetchApp games on the list. </li></ul><p>Ok, here we go: only 1 app installed without the default Apple ones, Charles on, launching Stack in 3, 2, 1.... </p><p>These are the requests that the app sends in the first minute after launch. Take a look at the timing of the requests - almost every split second. </p><p>Let's take a look at the contents of the requests. I actually checked every single one of them - but I'll leave out only the interesting ones here. </p><p>Let's start with the juiciest request sent to <code>https://o.isx.unity3d.com</code> - the first one that included my geo, while I <strong>disabled Location Services</strong> on iPhone for all apps! If you are as naive as I was before this, you might be surprised - what does Unity, the 3D engine, have to do with the in-app advertisement or location tracking? <p>Perhaps that's just some monitoring data to help improve the engine? </p></p><p>Turns out that Unity's main revenue stream (they made $2 bln+ in 2023) is Unity Ads - \"Mobile Game Ad Network\". Sounds quite interesting.</p><p>Below is the request body in json format sent to Unity Ads. I will only leave the  fields worth mentioning - the actual size is 200+ keys. </p><pre><code>{\n  \"ts\": \"2025-01-18T23:27:39Z\", // Timestamp\n  \"c\": \"ES\", // Country code,\n  \"d\": \"sports.bwin.es\", // Domain; the app or website where the ad will be displayed.\n  \"bn\": \"molocoads-eu-banner\", // WTF is moloco ads? We'll see!\n  \"cip\": \"181.41.[redacted]\", // my IP !!\n  \"dm\": \"iPhone12,1\", \n  \"ct\": \"2\", // Connection type; e.g., Wi-Fi\n  \"car\": \"Yoigo\", // mobile network operator\n  \"ifv\": \"6B00D8E5-E37B-4EA0-BB58-[redacted]\", // ID for Vendor. We'll get back to it!\n  \"lon\": \"2.[redacted]\", // Longitude ... \n  \"lat\": \"41.[redacted]\", // Latitude ... \n  \"sip\": \"34.227.224.225\", // Server IP (Amazon AWS in US) \n  \"uc\": \"1\", // User consent for tracking = True; OK what ?!\n}</code></pre><p>Ok, so my IP + location + timestamp + some  id are shared with Unity → Moloco Ads → Bwin, and then I see the actual Bwin ad in the game. Wonderful! </p><div><div>As a quick note - location shared was not very precise (but still in the same postal index), I guess due to the fact that iPhone was connected to WiFi and had no SIM installed. If it was LTE, I bet the lat/lon would be much more precise. </div></div><h3>Hello Facebook... What are you doing here?</h3><p>Next interesting request that leaks my IP + timestamp (= geo-datapoint) is Facebook.What?!</p><ul><li>I don't have any Meta [Facebook] app installed on this iPhone</li><li>I didn't link the app nor my Apple ID to any Facebook account</li><li>I didn't consent to Facebook getting my IP address!</li></ul><pre><code>{ \n\t\"bundles\": {\n\t\t\"bidder_token_info\": {\n\t\t\t\"data\": {\n\t\t\t\t\"bt_extras\": {\n                  \"ip\":\"181.41.[redacted], // nice Extras, bro\n                  \"ts\":1737244649\n\t\t\t},\n\t\t\t\"fingerprint\": null\n\t\t},\n        {\n          \"a lot of data: yes a loooooooot\"\n         }</code></pre><p>We'll talk more about this one in the next section. </p><h3>Why do you need my screen brightness level? </h3><pre><code>{\n  \"osVersion\":\"16.7.1\",\n  \"connectionType\":\"wifi\",\n  \"eventTimeStamp\":1737244651,\n  \"vendorIdentifier\":\"6B00D8E5-E37B-[redacted]\", // ifv once again \n  \"wiredHeadset\":false, // excuse me? \n  \"volume\":0.5,\n  \"cpuCount\":6,\n  \"systemBootTime\":1737215978,\n  \"batteryStatus\":3,\n  \"screenBrightness\":0.34999999403953552,\n  \"freeMemory\":507888,\n  \"totalMemory\":3550640, // is this RAM?\n  \"timeZone\":\"+0100\",\n  \"deviceFreeSpace\":112945148\n  \"networkOperator\":\"6553565535\"\n  \"advertisingTrackingId\":\"00000000-0000....\", // interesting ...\n  }</code></pre><p>There's no \"personal information\" here, but honestly this amount of data shared with an arbitrary list of 3rd parties is scary. Why do they need to know my screen brightness, memory amount, current volume and if I'm wearing headphones? </p><p>I know the \"right\" answer - to help companies target their audience better! For example, if you're promoting a mobile app that is 1 GB of size, and the user only has 500 MB of space left - don't show him the ad, right?</p><p>But I also heard lots of controversies on this topic. Like Uber dynamically adjusting taxi price based on your battery level - because you're not waiting for a cheaper option with 4% left while standing in the street. </p><p>I can't know if that or another one is true. But the fact that this data is available and accessible by advertisers suggests that they should at least think of using it. </p><p>Ok, enough with the requests. We can already see the examples of different ip and geolocation leaks.  + timestamp was adjust.com - but the request body was too boring to include. </p><p>You might've already noticed  and  ==  in the requests above - what are those? </p><p>IFV, or IDFV, is \"ID for Vendor\". This is my id unique for each vendor, a.k.a developer - in this case, KetchApp. <p>This checks out: I installed another KetchApp game to quickly record the requests, and the </p> value was the same for it. </p><p>Advertising Tracking ID, on the other hand, is the cross-vendor value, the one that is shared with an app if you choose \"Allow app to track your activity across ...\". As you can see above, it was actually set to  because I \"Asked app not to track\". </p><p>I checked this by manually disabling and enabling tracking option for the Stack app and comparing requests in both cases. </p><h3><strong>And that's the only difference between allowing and disallowing tracking</strong></h3><p>I understand there might be nothing shocking to you in it - this is not really kept secret, you can go and check the docs for Apple developers, for example. </p><p>But I believe this is  communicated correctly to the end users, you and me, in any adequate way, shape or form: the free apps you install and use <strong>collect your precise location</strong> with timestamp and send it to some 3rd-party companies. </p><p>The only thing that stops anyone with access to bid data (yet another ad buying agent, or ad exchange, or a dataset bought or rented from data broker, as you'll see later) from tracking you down with all trips you make daily is this  that is not shared when you disallow apps to \"track you across apps\" to \"enhance and personalise your ads experience\". </p><p>By the way: if you're using 10 apps from the same vendor (Playrix, KetchApp or another 1000-app company) and allow  to track you – it would mean that the data collected in all 10 apps will be enriched with your IDFA which can later be exchanged to your personal data. </p><p>At the same time, there is so much data in the requests that I'd expect ad exchanges to find some loophole ID that would allow cross-app tracking without the need for IDFA. I found at least 20 ids like  and ,  and  (these 2 are shared with Facebook), and so on. </p><p>By the way, the fact that Facebook collected my IP + timestamp without any adequate consent / app connection from my end is crazy. I think Facebook is more than capable of connecting the dots and my Meta Account to this hit as soon as I login to Instagram or Facebook app on the same IP address. </p><p>Let's get back to the request that leaked my location for a second and look at its trace. We'll focus on the parties in the middle:</p><p>stack<strong> →  o.isx.unity3d.com → molocoads →</strong> bwin (advertiser)</p><p>Unity [ads] is an SSP (supply-side platform) that acts as a collector of data from the app via SDK. As an app developer, you don't need to worry about gathering the right data, registering as a publisher on an ad exchange or whatever - just install the SDK and receive the money. </p><p>Moloco ads is a DSP network that resells data from multiple SSPs (like Unity, Applovin, Chartboost). Basically, from almost every one of the requested hosts I've seen pop up in Charles Proxy.It then applies some \"smart optimisation\" and connects a vacant banner space on your phone screen with the advertiser.</p><p>Sounds like moloco aggregates a lot of data and basically anyone (<em>- any company that becomes an ad partner</em>) can access the data by bidding lower than others. Or imagine a real ad exchange that bids normally and collects all of the data along the way \"as a side gig\". <p>Basically, this is how intelligence companies and data brokers get their data. </p></p><p>At this point I was looking for any mentions of Moloco on Telegram and Reddit, and I ran into this post that answered a lot of my questions:</p><blockquote>They access it if they integrate with the provider of bidstream, which would be the SSP. It's on the SSP to verify the vendor to whom they give access to bids. Usually, the requirement would be that you actually... bid. SSPs want you to spend money, that's how their business makes revenue. They might open up only part of the traffic to specific vendors (i.e.. if you don't bid worldwide, you won't get the bidstream worldwide, only in the regions in which you operate).</blockquote><p>Let's move further. When I found out how the data gets out, I started looking for any place where it's being sold. It was a quick search.</p><p>I found a data marketplace called <a href=\"https://datarade.ai/data-categories/device-graph-data?ref=timsh.org\" rel=\"noreferrer\">Datarade</a> which is a panel with all sorts of data. When I searched for MAID-specific data, hundreds of options showed up, like these two: </p><p>The price of the Redmob dataset surprised me, - $120k a year... for what?Let's now take a look at their promo:</p><p>Check out the list of features on the right - do any of them look familiar? : \"low latency\" means they know your location from the last time any of the apps shared it. It can be as little as 5 seconds ago. What's even better is that Redmob provides a  of the data. </p><p>I tried to request it from their website, but the sample never landed in my mailbox (surprise-surprise, timsh.org doesn't seem like a customer with high potential). Thankfully, this sample is public on <a href=\"https://marketplace.databricks.com/details/caa4c07a-b27e-4876-9c9c-3f3c2bbbc11f/Redmob_SAMPLE-Redmob-MAID-Data-for-Identity-Graph-I-Global-I-15B-Users-RealTime?ref=timsh.org\" rel=\"noreferrer\">Databricks Marketplace</a> with this annotation:</p><blockquote>Enhance your products and services using our global location data covering over 1.5 billion devices. Using our extensive location dataset, you can unearth concealed patterns, conduct rapid analyses, and obtain profound knowledge.<p>We can also provide region-specific data (MENA, Africa, APAC, etc.) based on your specific requirements. Our pricing model includes an annual licensing option, and we provide free sample data so that you can evaluate the quality of our dataset for yourself. </p></blockquote><p>To me, the most absurd part is the  column - the source of the data can't be more obvious. I'm also quite interested in the  column - if it's the birthyear, where did they get it from? Never mind, who cares about your birthyear.</p><p>All right, imagine I bought the access to a huge stream of Redmob data. But my goal is to track and stalk people like myself or anyone else, so I need some way to exchange MAIDs () for the actual personal info: name, address, phone number... </p><p>No problem! This kind of dataset is surprisingly also present on Datarade. Take a look at a sample table with  type that is provided by \"<a href=\"https://www.agrmarketingsolutions.com/data-nuggets/?ref=timsh.org\" rel=\"noreferrer\">AGR Marketing Solutions</a>\":</p><p>Inside - all personal info (full name, email, phone number, physical address, property ownership... and IDFAs. </p><p>Congrats, you have just reached the bottom of this rabbit hole. Let's wrap it up and make a couple of bold statements.</p><h2>How to track yourself down?</h2><p>Easy! Just follow this simple step-by-step guide:</p><ol><li>Use some free apps for a bit. Move around and commute - this makes the geo data more valuable. </li><li>\"Allow\" or \"ask not to track\" - a combo of IP + location + User-agent + geolocation will still be leaked to hundreds of \"3rd parties\" regardless of your choice.</li><li>Wait for a few seconds until fake DSPs and data brokers receive your data.</li><li>Exchange your full name or phone number for an IDFA (if present), IP address and user-agent through the  data purchased somewhere.</li><li>Now, access the \"Mobility data\" consisting of geolocation history, and filter it using the values from the previous step. </li></ol><p>Congratulations! You found yourself. </p><p>I <a href=\"https://excalidraw.com/?ref=timsh.org#json=Ip5AaR-FPppPmtL3AcrBg,-woEvDuI7vER5B7skpT3zA\" rel=\"noreferrer\">created a flowchart</a> that includes almost all actors and data mentioned above - now you can see how it's all connected. </p><p>This is the worst thing about these data trades that happen constantly around the world - each small part of it is (or seems) legit. It's the bigger picture that makes them look ugly. </p><p>Thanks for reading this story until the end!My research was heavily influenced by these posts and investigations: </p>","contentLength":13600,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42909921"},{"title":"CDC: Unpublished manuscripts mentioning certain topics must be pulled or revised","url":"https://insidemedicine.substack.com/p/breaking-news-cdc-orders-mass-retraction","date":1738471948,"author":"KittenInABox","guid":212,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42905937"},{"title":"CDC data are disappearing","url":"https://www.theatlantic.com/health/archive/2025/01/cdc-dei-scientific-data/681531/","date":1738410738,"author":"doener","guid":211,"unread":true,"content":"<p data-flatplan-paragraph=\"true\"><em><small>Updated at 5:53 p.m. on January 31, 2025</small></em></p><p data-flatplan-paragraph=\"true\"> Last night, scientists began to hear cryptic and foreboding warnings from colleagues:<em> Go to the CDC website, and download your data now. </em>They were all telling one another the same thing: Data on the website were about to disappear, or be altered, to comply with the Trump administration’s ongoing attempt to scrub federal agencies of any mention of gender, DEI, and accessibility. “I was up until 2 a.m.,” Angela Rasmussen, a virologist at the Vaccine and Infectious Disease Organization at the University of Saskatchewan who relies on the CDC’s data to track viral outbreaks, told me. She archived whatever she could.</p><p data-flatplan-paragraph=\"true\">The full scope of the purge isn’t yet clear. One document obtained by  indicated that the government was, as of yesterday evening, intending to target and replace, at a minimum, several “suggested keywords”—including “pregnant people, transgender, binary, non-binary, gender, assigned at birth, binary [], non-binary [], cisgender, queer, gender identity, gender minority, anything with pronouns”—in CDC content. While these terms are often politicized, some represent demographic variables that researchers collect when tracking the ebb and flow of diseases and health conditions across populations. Should they be reworded, or even removed entirely, from data sets to comply with the executive order, researchers and health-care providers might have a much harder time figuring out how diseases affect specific communities—making it more challenging to serve Americans on the whole.</p><p data-flatplan-paragraph=\"true\">CDC data’s “explicit purpose” is to guide researchers toward the places and people who most need attention, Patrick Sullivan, an epidemiologist at Emory University and a former CDC Epidemic Intelligence Service officer, told me. As the changes unfold before him, he said, “it’s hard to understand how this benefits health.”</p><p data-flatplan-paragraph=\"true\">When I contacted the CDC, a spokesperson redirected my requests for comment to the Department of Health and Human Services. After this story was published, an HHS spokesperson said that “all changes to the HHS website and HHS division websites are in accordance with President Trump’s January 20 Executive Orders” on gender and DEI.</p><p data-flatplan-paragraph=\"true\">The government appears to understand that these changes could have scientific implications: The document directing a review of CDC content suggests that some work could be altered without “changing the meaning or scientific integrity of the content,” and that any such changes should be considered “routine.” Changing other content, according to the document, would require review by an expert precisely because any alterations would risk scientific integrity. But the document does not specify how data would be sorted into those categories, or at whose discretion.</p><p data-flatplan-paragraph=\"true\">“My fear is that in the short term, entire data sets would be taken down,” then reappear with demographic variables removed or altered to conform with DEI restrictions, Katie Biello, an epidemiologist at Brown, told me. Excising mention of gender and sexual orientation, for instance, from public-health data sets could require stripping entire columns of data out. If the government chooses to define sex as binary, transgender people and nonbinary people, among others, could be effectively erased. In response to the ongoing changes, some groups of researchers are now rushing to archive the CDC website in full.</p><p data-flatplan-paragraph=\"true\">Acknowledging and addressing health differences among demographic groups is a basic epidemiological tenet, Biello told me, “so we know where to target our health interventions.” She pointed to examples in her own field: Gay men have <a data-event-element=\"inline link\" href=\"https://www.cdc.gov/sti/about/about-stis-and-gay-men.html\">higher rates of STIs</a>, but <a data-event-element=\"inline link\" href=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC9067055/\">lower rates of obesity</a>; transgender women have <a data-event-element=\"inline link\" href=\"https://www.statnews.com/2024/01/25/transgender-women-hiv-socioeconomic-risks-cdc/\">higher rates of HIV</a>, but lower rates of prostate cancer. More broadly, demographic changes to data sets could limit the country’s ability to identify which Americans are most at risk from an expansive list of conditions including adolescent depression, STIs, even sex-specific cancers. Changing data sets in this way would be tantamount to “erasing our ability to use data and evidence” to care for people, Rachel Hardeman, a health-equity expert at the University of Minnesota, told me.</p><p data-flatplan-paragraph=\"true\">Jennifer Nuzzo, an epidemiologist at Brown, pointed to mpox as a recent example of how replacing “gender” with “sex,” or ignoring sexual orientation, could limit effective public-health responses. At the beginning of the United States’ 2022 outbreak, neither researchers nor the public had much clarity on who was most affected, leading to widespread panic. “Officials were talking about the situation as if it was a risk we equally faced,” Nuzzo said. By collecting detailed demographic information, researchers were able to show that the disease was primarily affecting men who have sex with men, allowing officials to more efficiently allocate resources, including vaccines, and bring the epidemic under control before it affected Americans more widely.</p><p data-flatplan-paragraph=\"true\">A scrub such as this could also change how the government allocates funds for long-standing threats to public health, which could widen health-equity gaps, or reverse progress in combatting them. Rates of STIs more generally have recently begun to <a data-event-element=\"inline link\" href=\"https://www.nytimes.com/2024/11/12/health/syphilis-gonorrhea-chlamydia-cdc.html\">plateau</a> in the U.S., after decades of steady increase—but altering data that focus interventions on, say, transgender populations, or men who have sex with men, could undo those gains. If no data exist to prove that a health issue concentrates within a particular community, that “provides a justification to cut funding,” one researcher told me. (Several scientists who spoke with me for this article requested anonymity, for fear of retaliation for speaking out about the loss of federal data.) Sullivan, whose work focuses on HIV surveillance, compared the government’s actions to, effectively, destroying the road map to determining who in America most needs screening, pre-exposure prophylaxis, and treatment.</p><p data-flatplan-paragraph=\"true\">Much of the data on the CDC website have been aggregated from states, so it would be possible for researchers to reassemble those data sets, Nuzzo pointed out. But that’s an onerous task, and several scientists told me they never thought they’d be in a position where they’d have to scramble to squirrel away publicly available federal data. Nuzzo also worried that states might be reluctant in the future to share data with the federal government, or might decide not to bother collecting certain data at all. On the most basic scientific level, changing federal-government data means those data become unreliable. Public-health data are collected with the intention of sussing out which populations most need health interventions; altering those data leaves behind a skewed portrait of reality.</p>","contentLength":6778,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42897696"},{"title":"Add \"fucking\" to your Google searches to neutralize AI summaries","url":"https://gizmodo.com/add-fcking-to-your-google-searches-to-neutralize-ai-summaries-2000557710","date":1738358440,"author":"jsheard","guid":210,"unread":true,"content":"<p>If you are tired of Google’s AI-powered search results leading you astray with poor information from bad sources, there is some good news. It turns out that if you include any expletives in your search query, Google will not return an AI Overview, as they are called, at the top of the results page.</p><p>For instance, if you search “How large is the student body of Yale University?” the search results page will return a large AI-generated blurb above the blue links. If you instead search, “How large is the fucking student body at Yale University?” you will instead get a standard list of blue link results, sans-AI summary.</p><p>This is not the first time internet sleuths have discovered a way to disable Google’s AI-powered results. Other methods are more complicated, however, like adding a specific string of characters to the search results page URL. This method of swearing and pleading at Google to “just give me the fucking links” is much more cathartic.</p><p>We are going to go out on a limb here and say that if people are regularly finding techniques to disable AI summaries in Google searches, perhaps that means they do not want them in the first place? Google search results have never been perfect, of course—there is still a lot of poor information across the web. But AI summaries present users with a prominent blurb at the top of their search that looks authoritative when it just risks compounding the misinformation problem with more erroneous slop.</p><p>It is the same way Siri has been made worse by its integration with ChatGPT. At least in the past, when the voice assistant did not know how to answer a question it would just throw users to the web. Now Siri offers up ChatGPT-generated responses instead, sometimes <a href=\"https://www.macrumors.com/2025/01/24/siri-eagles-33-false-super-bowl-wins-basic-test/\">spitting out incorrect nonsense</a> instead of admitting it is not sure. But this is all being forced on users whether they like it or not. From Google Docs to X and Instagram, there are AI buttons and search boxes and dropdowns everywhere now, because every tech company needs to have an AI strategy. Is a basic keyword search too much to ask?</p><p>When Google first introduced AI Overviews into search, it went viral for <a href=\"https://gizmodo.com/worst-google-ai-answers-glue-pizza-dogs-playing-sports-1851495298\">returning nonsensical responses</a>, such as suggesting that one can prevent cheese from sliding off their pizzas by using glue or improve gut health by eating pebbles. It is believed Google’s model sourced the information from Reddit comments. AI does not know how to identify sarcasm or satire.</p><p> earlier <a href=\"https://arstechnica.com/google/2025/01/just-give-me-the-fing-links-cursing-disables-googles-ai-overviews/?comments-page=1\">reported</a> on the new loophole, which, if we are speculating, is caused by Google’s overly cautious steering of its AI model. Whereas a bot like xAI’s Grok is more than happy to swear and discuss sensitive topics, Google’s Gemini keeps it PG. Google has likely trained Gemini to avoid repeating expletives, so it simply is disabled in search when a curse word is present in order to avoid that.</p><p>Google has argued that AI Overviews, as they are called, do not reduce traffic sent to websites because users will view summaries and be interested in delving deeper into the source material after finding something of interest. That logic has not comforted media companies, which have been litigating the likes of OpenAI and Perplexity for ingesting their content into large language models.</p><p>We imagine Google will close the expletive loophole eventually, but in the meantime, if you are sick of AI, you now know an easy way to avoid it. Just tell Google to give you the fucking links.</p>","contentLength":3439,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42892191"},{"title":"Bypass DeepSeek censorship by speaking in hex","url":"https://substack.com/home/post/p-156004330","date":1738352509,"author":"MedadNewman","guid":209,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42891042"},{"title":"OpenAI O3-Mini","url":"https://openai.com/index/openai-o3-mini/","date":1738350495,"author":"johnneville","guid":208,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42890627"},{"title":"Archivists work to save disappearing data.gov datasets","url":"https://www.404media.co/archivists-work-to-identify-and-save-the-thousands-of-datasets-disappearing-from-data-gov/","date":1738266033,"author":"johnneville","guid":207,"unread":true,"content":"<div>More than 2,000 datasets have disappeared from data.gov since Trump was inaugurated. But analyzing exactly what happened and where it went is going to take some time.</div>","contentLength":166,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42881367"},{"title":"JavaScript Temporal is coming","url":"https://developer.mozilla.org/en-US/blog/javascript-temporal-is-coming/","date":1738236511,"author":"SigmundurM","guid":206,"unread":true,"content":"<p>To understand Temporal, we can look at JavaScript's  object.\nWhen JavaScript was created in 1995, the <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Date\"></a> object was copied from Java's early, flawed  implementation.\nJava replaced this implementation in 1997, but JavaScript is stuck with the same API for almost 30 years, despite known problems.</p><p>The major issues with JavaScript's  object are that it only supports the user's local time and UTC, and there's no time zone support.\nAdditionally, its parsing behavior is very unreliable, and  itself is mutable, which can introduce hard-to-trace bugs.\nThere are other problems like calculations across Daylight Saving Time (DST) and historical calendar changes, which are notoriously difficult to work with.</p><p>All of these issues make working with dates and times in JavaScript complex and prone to bugs, which can have serious consequences for some systems.\nMost developers rely on dedicated libraries like <a href=\"https://momentjs.com/\" target=\"_blank\">Moment.js</a> and <a href=\"https://date-fns.org/\" target=\"_blank\">date-fns</a> for better handling of dates and times in their applications.</p><p>Temporal is designed as a full replacement for the <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Date\"></a> object, making date and time management reliable and predictable.\nTemporal adds support for time zone and calendar representations, many built-in methods for conversions, comparisons and computations, formatting, and more.\nThe API surface has over 200 utility methods, and you can find information about all of them in the <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Temporal\">Temporal docs on MDN</a>.</p>","contentLength":1379,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42876840"},{"title":"An analysis of DeepSeek's R1-Zero and R1","url":"https://arcprize.org/blog/r1-zero-r1-results-analysis","date":1738172685,"author":"meetpateltech","guid":205,"unread":true,"content":"<h2>R1-Zero is more important than R1</h2><blockquote><p>Special thanks to <a href=\"https://x.com/tuhinone\">Tuhin</a> and <a href=\"https://www.linkedin.com/in/abuqader/\">Abu</a> from <a href=\"https://www.baseten.co/\">Baseten</a> and <a href=\"https://x.com/yuchenj_uw\">Yuchen</a> from <a href=\"https://hyperbolic.xyz/\">Hyperbolic Labs</a> for hosting r1-zero for us. Hardly any providers are hosting this model variant, and its availability is important for research purposes.</p></blockquote><p>ARC Prize Foundation’s goal is to define, measure, and inspire new ideas towards AGI. To this end, we strive to create the strongest global innovation environment possible.</p><p>We do not have AGI yet and are still innovation constrained – scaling up pure LLM pretraining is not the path, despite this being the dominant AI industry narrative and mainstream public view as of last summer.</p><p>The reason narratives are important is they end up driving economic activity, like investment, research focus, funding, geopolitics, trade, etc. For example, in 2023-24 there was ~$20B invested into new LLM startups compared to only ~$200M into new AGI startups.</p><p>We <a href=\"https://arcprize.org/blog/launch\">launched ARC Prize 2024 last June</a> to grow awareness of limits of scaling LLMs and promote a useful benchmark, ARC-AGI-1, towards a new direction that requires AI systems to adapt to novel, unseen problems instead of being able to rely strictly on memorization.</p><p>Last week, DeepSeek <a href=\"https://arxiv.org/abs/2501.12948\">published</a> their new R1-Zero and R1 “reasoner” systems that is <a href=\"https://x.com/arcprize/status/1881761987090325517\">competitive with OpenAI’s o1 system</a> on ARC-AGI-1. R1-Zero, R1, and o1 (low compute) all score around 15-20% – in contrast to ’s 5%, the pinnacle of years of pure LLM scaling. Based on this week’s <a href=\"https://www.reuters.com/technology/chinas-deepseek-sets-off-ai-market-rout-2025-01-27/\">US market reaction</a>, the public is starting to understand the limits of scaling pure LLMs too. However, there is still broad public ignorance about impending inference demand.</p><p>In December 2024, OpenAI announced a <a href=\"https://arcprize.org/blog/oai-o3-pub-breakthrough\">new breakthrough o3 system that we verified</a>. It scored 76% in a low compute mode and 88% in a high compute mode. The o3 system demonstrates the first practical, general implementation of a computer adapting to novel unseen problems.</p><p>This is an incredibly important moment for the field of AI and for computer science and these systems demand study. But due to the closed nature of o1/o3, we’re forced to rely on speculation. Thanks to ARC-AGI-1 and now (nearly) open source R1-Zero and R1, we can add to our understanding. In particular, R1-Zero is significantly more important than R1.</p><blockquote><p>“Nearly” because DeepSeek did not publish a reproducible way to generate their model weights from scratch</p></blockquote><h2>R1-Zero removes the human bottleneck</h2><p>In our <a href=\"https://arcprize.org/blog/openai-o1-results-arc-prize\">o1</a> and <a href=\"https://arcprize.org/blog/oai-o3-pub-breakthrough\">o3 analysis</a>, we speculated how these reasoning systems work. The key ideas:</p><ol><li>Generate chains-of-thought (CoT) for a problem domain.</li><li>Label the intermediary CoT steps using a combination of human experts (“supervised fine tuning” or SFT) and automated machines (“reinforcement learning” or RL).</li><li>Train base model using (2).</li><li>At test time, iteratively inference from the process model.</li></ol><p>Techniques used to iterative sample, along with ARC-AGI-1 scores, are reviewed below:</p><div><table><thead><tr></tr></thead><tbody><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr></tbody></table></div><p><em>Note: ARC-AGI-1 semi-private score shown.</em></p><p>With DeepSeek’s new published research, we can better inform our speculation. The key insight is that higher degrees of novelty adaptation (and reliability) for LLM reasoning systems are achieved along three dimensions:</p><ol><li>Adding human labels aka SFT to CoT process model training</li><li>CoT search instead of linear inference (parallel per-step CoT inference)</li><li>Whole CoT sampling (parallel trajectory inference)</li></ol><p>Item (1) is bottlenecked by human data generation and constrains which domains these reasoning systems benefit most. For example, the <a href=\"https://openai.com/index/learning-to-reason-with-llms/\">MMLU professional law category</a> is surprisingly much lower than the math and logic on o1.</p><p>Items (2) and (3) are bottlenecked by efficiency. o1 and o3 both <a href=\"https://arcprize.org/blog/oai-o3-pub-breakthrough\">show logarithmic improvement</a> in benchmark accuracy on ARC-AGI-1 as they spend more inference compute at test time, while the different ways to spend that compute adjust the x-axis of the curve.</p><p>In my opinion, the most interesting thing DeepSeek has done is to publish R1-Zero separately. R1-Zero is a model which does not use SFT, the (1) item. Instead it relies purely on reinforcement learning.</p><p>R1-Zero and R1 show strong score agreement on  ARC-AGI-1, scoring 14% and 15% respectively. DeepSeeks’s own reported benchmark scores also show strong agreement between R1-Zero and R1, eg. on MATH AIME 2024 scores are 71% and 76% respectively (up from ~40% on the base DeepSeek V3).</p><p>In the paper, R1-Zero authors say “DeepSeek-R1-Zero encounters challenges such as poor readability, and language mixing” and <a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1i765q0/r1zero_pure_rl_creates_a_mind_we_cant_decodeis/\">has been corroborated online</a>. However in our testing, we found little to no evidence of incoherence when testing R1-Zero on ARC-AGI-1 which is similar to the math and coding domains the system was RL’d on.</p><p>Taken together, these findings suggest:</p><ol><li>SFT (eg. human expert labeling) is not necessary for accurate and legible CoT reasoning in domains with strong verification.</li><li>The R1-Zero training process is capable of creating its own internal domain specific language (“DSL”) in token space via RL optimization.</li><li>SFT is necessary for increasing CoT reasoning domain generality.</li></ol><p>This makes intuitive sense, as language itself is effectively a reasoning DSL. The exact same “words” can be learned in one domain and applied in another, like a program. The pure RL approach can not yet discover a broad shared vocabulary and I expect this will be a strong focus for future research.</p><p>Ultimately, R1-Zero demonstrates the prototype of a potential scaling regime with zero human bottlenecks – even in the training data acquisition itself.</p><p>Almost certainly DeepSeek has set its sights on OpenAI’s o3 system. It is important to watch whether SFT ends up being a requirement to add CoT search and sampling, or whether a hypothetical “R2-Zero” could exist along the same logarithmic accuracy vs inference scaling curve. Based on R1-Zero results, I believe SFT will not be required to beat ARC-AGI-1 in this hypothetical scaled up version.</p><p>There are two major shifts happening in AI, economically speaking:</p><ol><li>You can now spend more $ to get higher accuracy and reliability</li><li>Training $ is moving to inference $</li></ol><p>Both are going to drive a massive amount of demand for inference and neither will curtail the demand for more compute. In fact, they will increase the demand for compute.</p><p>AI reasoning systems promise much greater returns than simply higher accuracy on benchmarks. The number one issue preventing more AI automation use (e.g. inference demand) is reliability. I’ve spoken with hundreds of Zapier’s customers trying to deploy AI agents in their businesses and the feedback is strongly consistent: “I don’t trust them yet because they don’t work reliably”.</p><p><a href=\"https://www.cognitiverevolution.ai/the-arc-prize-efficiency-intuition-and-agi-with-mike-knoop-co-founder-of-zapier/\">Previously</a> I’ve argued that progress towards ARC-AGI would result in higher reliability. The challenge with LLM agents is they need strong local domain steering to work reliably. Stronger generalization capability requires the ability to adapt to unseen situations. We’re now starting to <a href=\"https://x.com/woj_zaremba/status/1882290021778313272\">see evidence</a> this view is correct. And so it’s no surprise several companies are now introducing agents (Anthropic, OpenAI, Apple, …)</p><p>Agents will drive significant near-term demand inference due the reliability needs. More broadly, developers can choose to spend more compute to increase user trust in the system. More reliability does not mean 100% accuracy though – but you’d expect to be more <a href=\"https://commons.wikimedia.org/wiki/File:Statistical_bias_and_statistical_noise_illustration.png\">consistently inaccurate</a>. This is okay because users and developers can now more confidently steer behavior via prompting when accuracy is low.</p><p>Problems that were impossible for computers previously now have dollar amounts attached to them. And as efficiency climbs, those dollar amounts will go down.</p><p>The other major shift occurring is in the provenance of data going into LLM systems for pretraining. Previously, most data was either purchased, scraped, or synthetically generated from an existing LLM (eg. distilling or augmenting).</p><p>These reasoning systems offer a new option which is to generate “real” data as opposed to “synthetic”. The AI industry uses the term synthetic to identify low quality data that is typically recycled through an LLM to boost the overall amount of training data – with diminishing returns.</p><p>But now with reasoning systems and verifiers, we can create brand new legitimate data to train on. This can either be done offline where the developer pays to create the data or at inference time where the end user pays!</p><p>This is a fascinating shift in economics and suggests there could be a runaway power concentrating moment for AI system developers who have the largest number of paying customers. Those customers are footing the bill to create new high quality data … which improves the model … which becomes better and more preferred by users … you get the idea.</p><p>If we can break through the human expert CoT barrier and create an extremely efficient system to create new data via search/synthesis and verification, then we should expect a massive influx of compute to go into these inference systems as they quite literally get better just by inputting dollars and raw data. Eventually this type of AI training will eclipse pretraining on human generated data altogether.</p><p>We will continue to see market corrections as increased inference demand becomes clear. AI system efficiency is only going to drive more usage, not just due to <a href=\"https://en.wikipedia.org/wiki/Jevons_paradox\">Jevons Paradox</a> but because new regimes of training are unlocked as efficiency increases.</p><p>With R1 being open and reproducible, more people and teams will be pushing CoT and search to the limits. This will more quickly tell us where the frontier actually lies and will fuel a wave of innovation that increases the chance of reaching AGI quickly.</p><p>Several people have already told me they plan to use R1-style systems for <a href=\"https://arcprize.org/blog/arc-prize-2025\">ARC Prize 2025</a> and I’m excited to see the results.</p><p>The fact that R1 is open is a great thing for the world. DeepSeek has pushed the frontier of science forward.</p>","contentLength":9811,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42868390"},{"title":"OpenAI Furious DeepSeek Might Have Stolen All the Data OpenAI Stole from Us","url":"https://www.404media.co/openai-furious-deepseek-might-have-stolen-all-the-data-openai-stole-from-us/","date":1738162354,"author":"latexr","guid":204,"unread":true,"content":"<div>OpenAI shocked that an AI company would train on someone else's data without permission or compensation.</div>","contentLength":104,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42865527"},{"title":"I still like Sublime Text","url":"https://ohdoylerules.com/workflows/why-i-still-like-sublime-text-in-2025/","date":1738133023,"author":"james2doyle","guid":203,"unread":true,"content":"<p>I still get people asking me why I use Sublime Text in 2025 given there are  many other great editors out there.</p><p>My response: there is? Because I still think Sublime Text holds up as a great editor.</p><p>I started with Sublime Text 2 back in 2010/2011 while I was in college. I mainly started using it because it was free, cross-platform, and came as a \"portable app\" that I could put on a USB and just use.</p><p>Back then, I had a really basic Toshiba laptop that dual booted Windows XP and Ubuntu (or maybe it was Mint?) so it was nice that it worked on both. I really liked how snappy it was compared to the tools our teacher suggested using. At that time it was Dreamweaver and maybe Notepad++.</p><p>Sublime, at that time, was pretty novel. It clearly took a lot of inspirations from <a rel=\"noopener nofollow noreferrer\" href=\"https://github.com/textmate/textmate\" target=\"_blank\">TextMate</a>, another classic editor, considering that one is 4 years older than Sublime. It had multiple cursors, plugins, a build system. But the <a rel=\"noopener nofollow noreferrer\" href=\"https://www.vendr.com/blog/consumer-dev-tools-command-palette\" target=\"_blank\">biggest claim to fame for Sublime, was the \"command palette\"</a>. I'm sure there is some other older app that had a precursor or similar feature to it, but generally speaking, it seems like that user experience pattern really kicked off with Sublime.</p><p>I built my web-dev chops on Sublime. The shortcuts are ingrained in my bones at this point. I'm not some key-combo-king, but I know a lot of the shortcuts that can help me get the UI and commands I need without thinking much at all.</p><blockquote><p>I have been, and continue to be, a Sublime user of about 15 years.</p></blockquote><p>So take all this with that in mind. I have been, and continue to be, a Sublime user of about 15 years.</p><p>So why do I keep using Sublime?</p><p>If you thought Sublime was dead, well you couldn't be more wrong! The latest build of Sublime as of this post is \"4192\" and was released 20th January 2025. So basically a week ago from this post. Not too bad.</p><p>It has regularly been updated with minor tweaks and fixes about a dozen times a year. I think the last major upgrade would be when Package Control (the plugin installer/manager) bumped to the next version which allowed plugins to install external dependencies.</p><p>You can nitpick here and say that Package Control is not part of Sublime. But most people won't use Sublime without it. So I am going to take some liberties and say it is part of it.</p><p>I think the thing to consider is how Sublime is basically \"done\" software. It has been around a  time. It was first released around 2008. It just passed it's 17-year anniversary actually. Congrats to them!</p><p>Before I dive into the details of  I still use it, consider this: if you are using a modern GUI-driven editor, it probably has taken inspiration from Sublime. So why not check out one of the OGs? You might find something you like.</p><p>Without further adieu, my reasons for still using Sublime in 2025:</p><p>Sublime is fast. It starts instantly. Uses very few resources. Handles large files gracefully. Rarely crashes.</p><p>Nothing else to add here. A+ performance.</p><p><a rel=\"noopener nofollow noreferrer\" href=\"https://github.com/sublimelsp\" target=\"_blank\">Sublime LSP</a> is really doing a lot for Sublime to keep it feeling modern and keeping up with other tools in the same class.</p><p>If you aren't aware of what an LSP is, this isn't the post to learn about it. But the gist is, it handles all that fancy code-aware completion and hover info you like from VS Code. If you want to learn more <a href=\"https://www.youtube.com/watch?v=LaS32vctfOY\" rel=\"noopener nofollow noreferrer\" target=\"_blank\">give TJ 5 minutes to learn you</a>.</p><p>Some of the cool things about the Sublime LSP:</p><p><strong>Multiple servers per file</strong></p><p>You can enable as many LSP servers per file that you want. Restart them individually and configure them on a per-project basis (more on that later) which really helps bolster the capabilities of this already great editor.</p><p><strong>Detection on a scope level</strong></p><p>When configuring an LSP, outside of one installed with a plugin, you tell the LSP plugin which \"scope\" (think of this as an id for a syntax) to enable an LSP on.</p><p>Want your LSP to only turn on if you only open a file with a specific syntax? No problem. Want it to turn on only if a type of syntax is detected? Like a specific flavour of CSS? Sure. It is very configurable.</p><p>I know VS Code is the LSP king, which the tech originating with that editor, but I haven't seen the ability to just add an LSP installed as a binary in on your .</p><p>There are a few \"cutting-edge\" LSPs that are installed via Cargo that are usually only targeting Neovim, but can easily be configured in Sublime with a simple JSON object.</p><p>Here is an example of configuring <a rel=\"noopener nofollow noreferrer\" href=\"https://github.com/matkrin/md-lsp\" target=\"_blank\">md-lsp</a> (Markdown language server with support for GitHub flavored Markdown) in a few lines:</p><pre data-lang=\"json\"><code data-lang=\"json\"></code></pre><p>It should be noted that md-lsp <strong>does not have a Sublime LSP plugin</strong> nor any mention of Sublime in their README. They only mention support for  and . Well, guess what? You support Sublime too!</p><p>I write a lot of snippets. Right now, my snippets folder in Sublime has 123 snippets. The latest one was added . It was a \"TODO\" snippet for Blade.</p><p>Sublime lets you create snippets from the <code>Tools &gt; Developer &gt; New Snippet</code> dropdown. They get sent to your \"User\" folder in the Sublime directory and are sourced on startup.</p><p>Snippets are also scope-based. VS Code has scopes too, so there is nothing new here. I wonder where they got that from? 😮</p><p>A quick note on scopes: they can be very vague (like , targeting a whole  file) or super specific (like <code>text.html.basic.liquid text.html.basic meta.object.liquid</code> which targets a nested object in a liquid template) based on what you need.</p><p>I have found the Sublime scope integration to be straightforward to understand. A syntax defines scopes, and you can target those scopes in snippets, keybindings, and macros. More on those other two later.</p><p>I'm sure I didn't get the details perfect. But it doesn't really matter given the point I'm going to make: not all snippet systems work this way.</p><p>Specifically, I have found Helix, Neovim, and Zed snippets to be more based around \"filetype\" and not the scope of the where you are in the \"syntax\".</p><p>I'm sure this will change. Or perhaps I've missed something. From what I can see on the surface, snippets based on syntax-specific scopes seem to be the default in VS Code and Sublime.</p><p><strong>Tab stops with nesting, placeholders, and references</strong></p><p>Here is the snippet I made today:</p><pre data-lang=\"xml\"><code data-lang=\"xml\"></code></pre><p>Pretty simple. People who have written snippets before will recognize the syntax. The  is where your caret is sent first, you can then type, then hit tab, and you get sent to .</p><p>Here is a TODO snippet I have for \"javascript\" files:</p><pre data-lang=\"xml\"><code data-lang=\"xml\"></code></pre><p>Here you can see that the first tab stop has default content of \"this is my todo\". Here you can see a more complex scope setup that only expands this snippet under those conditions. Nothing really spectacular here.</p><p>But snippets in Sublime also support some transformations...</p><p><strong>Transformations (Vue component)</strong></p><p>Here is a much more complicated snippet:</p><pre data-lang=\"xml\"><code data-lang=\"xml\"></code></pre><p>This snippet has some transformations in it. This means we can actually format what the content in the different tab stops will be.</p><p>I won't harp on what is going on too much. Just know that I can format the content in the \"Usage\" comment as  and I can format the content in  to be . VS Code can do this. The syntax for it is a bit nicer. But I prefer authoring snippets in XML rather than JSON.</p><p>Sublime supports the concept of workspaces under the banner of a \"project\". All without a plugin, by the way. You can open a folder and save that folder as a project.</p><p>This creates an empty <code>your-project-name.sublime-project</code> which you can really save wherever you like in your project as it has some features to target where the root of the project is.</p><p>This file is just a JSON file and contains editor settings that you are overriding for that specific project. You can target global settings, set rules for specific folders, create a build system, tweak/toggle LSP settings, etc. etc.</p><p>This is a lot like the  file from what I understand. I also believe you can do this in Vim with a  folder in the root of your project with a feature called \"exrc\". I haven't used it personally, so I can't speak to it much.</p><p>In my brief flirtations with Neovim and Helix, you need a plugin for this. In Zed, they also have a settings file that can be saved into a project root to get the same thing.</p><p><strong>Including/excluding files and folders</strong></p><p>I think all the editors I referenced above can do this. Not much to share. It is just nice to have an array of file configurations for a project that may or not be in that directory, can be matched with a glob, or just listed explicitly.</p><p>Here is an example of how I would use the project file in a Next.js site:</p><pre data-lang=\"json\"><code data-lang=\"json\"></code></pre><p>I'm doing a lot here. Setting files to ignore, folders to exclude from indexing, setting build commands that use  as well as , setting from editor setting for tab spacing, and finally a few LSP tweaks that make sense for a Next project.</p><p>VS Code can do all of what I've listed here. But they split it up into different files. Kinda annoying.</p><p><strong>Configure plugin settings per project</strong></p><p>You can also configure plugin settings per project. Here is how I would add project settings for the \"syntax override\" plugin. This plugin forces the editor to use a specific syntax for certain files that match a given pattern:</p><pre data-lang=\"json\"><code data-lang=\"json\"></code></pre><p>I don't always want all  files to be highlighted with the Tailwind syntax. But in this project I do. So I can set it locally here, and when I open a  file in this project, it will switch the syntax for me. Nice!</p><p><strong>Add build systems per project</strong></p><p>You can see in the example above that I have set build systems on this specific project. You can do this in VS Code with \"tasks\". Zed has this feature as well and calls it \"tasks\" too. I just find it annoying that they are in their own files. I guess that makes them more portable.</p><p>I just like my project configuration . I must be nuts.</p><p>I've touched on build systems a bit already. But in summation, they are just tasks you can run in your project.</p><p>Sometimes they call a global command (like ), sometimes a local dependency is installed with a package manager (think some binary in ), or maybe just runs a command already setup in your other tools (like  or <code>php artisan migrate:fresh</code>) that run in the root of the project but need some context.</p><p><strong>Can also be provided by a plugin</strong></p><p>A plugin can provide build systems. The neat thing is they are just Sublime files. JSON that ends in . Like snippets. So they are really portable too. Just like the other editors with their  file.</p><p>Here is one I saved in my \"User\" directory called <code>dot-env-linter.sublime-build</code>:</p><pre data-lang=\"json\"><code data-lang=\"json\"></code></pre><p>You can see there are some special variables (like ) that will expand based on context. In this case, that one is the full path to the currently active file.</p><p>Here is my  with a bit more flavour:</p><pre data-lang=\"json\"><code data-lang=\"json\"></code></pre><p>You can see some more vars here for the project path as well as a reference to my system PATH. Of course, we got a nice lil scope as well.</p><p>You don't even need to make any semblance of a plugin. You can toss a  file in your \"User\" directory and implement a class that takes a <code>sublime_plugin.WindowCommand</code>.</p><p>Yep. Multiple cursors. I use them all the time. I know that the \"vim\" way is to start recording a macro, apply the changes on a single line, and then replay that macro on all the lines you want to change. Or do some  fu for a fancy find and replace. I get it. I just don't like it.</p><p>Most of the editors these days have multiple cursors. Including some terminal editors like Helix. I have tried Helix and I think it is a lot closer to what I would want from a modern editor than my previous terminal editor of Neovim + LazyVim.</p><p>The key and mouse bindings are what you would expect from a modern editor. It is basically the same as VS Code. Nothing exhilarating here. But I do like the way conceptual key bindings are handled.</p><p>Like any good editor, Sublime supports contextual key bindings.</p><p>When you have an active selection, and that selection is not empty, and you are inside a string-like scope, then ` will wrap that selection with `. Basically, it will wrap your selection as a template string. Handy!</p><p>Like the build systems and snippets, key bindings are just saved in a file that ends with . They can be in your \"User\" directory or in a plugin. Unfortunately, unlike build systems, they cannot be saved on a per-project basis - from what I can tell.</p><p>You can also have key bindings for different platforms. They are named as follows:</p><pre><code></code></pre><p>These are just some notable mentions of things I like:</p><p>Given how Python is probably the most popular language, at least <a rel=\"noopener nofollow noreferrer\" href=\"https://www.theregister.com/2024/11/05/python_dethrones_javascript_github/\" target=\"_blank\">the last time GitHub checked</a>, I'm surprised this isn't the go-to editor. I don't think you need to know python to use Sublime but it helps if you want to craft a nice plugin.</p><p>One more thing to add around authoring plugins, they are super simple. It is just a  file in a folder. No build system, external dependencies, or ever-changing APIs to navigate.</p><p>This plugin has been trucking along for 11 years. I can't imagine any VS Code plugin lasting that long!</p><p>Yep you can record macros in Sublime. You can also save them to... a file! Then put that file () in a plugin, or, of course, your \"User\" folder. The macro is just an array of key presses. They also support scopes and can be bound to a key combo. Pretty sweet.</p><p>This is one feature that VS Code has not stolen - I mean implemented - and that requires an additional plugin to have. Of course the Vimmers have had this for decades.</p><p><strong>Diff hunks (revert or show)</strong></p><p>Sublime supports viewing inline diff hunks. Handy for when you don't want to dive into the diff of a file. You can just ask to see the diff hunk for that line or group of lines. You can also revert just as easily.</p><p><strong>Case conversion and line permute functions</strong></p><p>There are some handy case conversion functions that are built in. Nice with multiple cursors. VS Code has a couple of conversion choices. Sublime has 8 different case conversions built in.</p><p><strong>Package control and repo URLs for packages</strong></p><p>Package control packages can be installed from the central repository. But you can also install them from a git repo URL. You can also clone a repo to your \"Packages\" folder, and it will work too. No marketplace or anything like that is required.</p><p>This is really handy if you have forked a package and just want to install your fork.</p><p><strong>All the config and settings are plain files</strong></p><p>Since the whole of a Sublime setup is mostly plain files, that makes it really easy to sync your setup across multiple computers. I actually symlink my Sublime folder to Dropbox. So any changes I make will be shared across all my computers that use it.</p><p>This isn't unique to Sublime. I think it is just a benefit of having tools that use plain text-driven configuration.</p><p>Sublime has a \"distraction free mode\" which will full-screen your editor and focus the content to the middle of the screen. I am using it to write this post right now!</p><p>Of course there could be a few things that could be better.</p><p>I do find the docs for developing plugins to be sparse. There are doc sites. There are two big ones. One for the \"official\" docs that document the APIs. There is also another site that is tagged as the \"unofficial\" docs.</p><p>Usually when I want to know how to do something in a plugin, I just read the source of another plugin that does something I want to emulate. It isn't a bad way to learn, it is just a bit tedious.</p><p>Speaking of building plugins, there does not seem to be any \"stubs\" for the Sublime python API. I am by no means a python guru. I only use it in Sublime, and I usually forget everything once I finish what I am trying to do. But I think there could be some \"plugin starter template\" that could include a Pyright setup and some basic guide for how to get going.</p><p>I also find that getting plugins on the Package Control site to be quite a chore. You need to open a PR to a repo and put your repo into a list based on where it goes into an alphabet. It doesn't allow forks and plugins that are too similar. There is also no way to mark a package as \"abandoned\".</p><p>I like the way Composer/Packagist does packages. You create a repo, submit that URL to the Packagist site, and it will automatically keep track of it for you. You release a new version by just using git tags and releases.</p><p>NPM is also a bit nicer. But forcing an NPM account and having to juggle the mixing of git tags and the  \"version\" key to be a bit unclear at times.</p><p><strong>Key/Mouse bindings per project</strong></p><p>Simple one here. It would be nice to have key and mouse bindings on a project level. I don't know how often I would really use it, but it would be nice to have just for those projects that have tedious tasks or macros that I want to run under specific scopes.</p><p>I like Sublime. I think it is still incredibly capable in 2025. If you are in search of something a little snappier, classier, and not riddled with AI slop, then give it a try.</p><p>I doubt I can pry your Vim from your  riddled right hand, but if you have been let down or uninspired by the latest offerings when it comes to editors, you might find Sublime still has a lot to offer.</p><p><em>Note: if any of my information is wrong or outdated, I will update it accordingly</em></p>","contentLength":16706,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42862246"},{"title":"Science YouTuber physicsgirl (Dianna Cowern) stands for the first time in 2 yrs","url":"https://www.youtube.com/shorts/2ntx91cOYEc","date":1738131374,"author":"m348e912","guid":202,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42862118"},{"title":"OpenAI says it has evidence DeepSeek used its model to train competitor","url":"https://www.ft.com/content/a0dfedd1-5255-4fa9-8ccc-1fe01de87ea6","date":1738124480,"author":"timsuchanek","guid":201,"unread":true,"content":"<div aria-hidden=\"true\" data-offer-type=\"trial\"><ul></ul></div>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42861475"},{"title":"New speculative attacks on Apple CPUs","url":"https://predictors.fail/","date":1738089094,"author":"cylo","guid":200,"unread":true,"content":"<p>\n\t\t\t\t\t\t\t\t\t\tVirtually all modern CPUs use a performance optimization where they predict the\n\t\t\t\t\t\t\t\t\t\tcontrol flow the CPU should take (such as branches and returns), should the\n\t\t\t\t\t\t\t\t\t\toutcome not be readily available. Once a prediction is made, the CPU will execute instructions along\n\t\t\t\t\t\t\t\t\t\tthe prediction, a process called speculative execution. If the CPU realizes it had\n\t\t\t\t\t\t\t\t\t\tmispredicted, it must revert all changes in the state it performed after the\n\t\t\t\t\t\t\t\t\t\tprediction. Nearly all desktop and mobile CPUs exhibit this behavior, regardless of\n\t\t\t\t\t\t\t\t\t\tmanufacturer (such as Apple, AMD, or Intel).\n\t\t\t\t\t\t\t\t\t</p><p><a href=\"https://spectreattack.com/\">Spectre</a> is a hardware vulnerability in\n\t\t\t\t\t\t\t\t\t\tvirtually all modern CPUs that occurs when speculative execution backfires.\n\t\t\t\t\t\t\t\t\t\tWhile the CPU should ideally revert all changes in state, speculative execution leaves\n\t\t\t\t\t\t\t\t\t\ttraces in the CPU's microarchitectural state and especially the cache. A Spectre\n\t\t\t\t\t\t\t\t\t\tattack coerces the CPU into speculatively executing the wrong flow of\n\t\t\t\t\t\t\t\t\t\tinstructions. If this wrong flow has instructions depending on sensitive data, their value can\n\t\t\t\t\t\t\t\t\t\tbe inferred through a side channel even after the CPU realizes the mistake and\n\t\t\t\t\t\t\t\t\t\treverts its changes. An adversary can abuse this behavior to read data that they cannot\n\t\t\t\t\t\t\t\t\t\tnormally access through program semantics. Because speculative execution is an\n\t\t\t\t\t\t\t\t\t\timportant part of CPU performance that is infeasible to simply remove as a\n\t\t\t\t\t\t\t\t\t\tcountermeasure, Spectre continues to be dangerous to software even years after\n\t\t\t\t\t\t\t\t\t\tits discovery.\n\t\t\t\t\t\t\t\t\t</p><p>\n\t\t\t\t\t\t\t\t\t\tIn SLAP and FLOP, we demonstrate that recent Apple CPUs go beyond this, not only\n\t\t\t\t\t\t\t\t\t\tpredicting the control flow the CPU should take, but also the data flow the CPU\n\t\t\t\t\t\t\t\t\t\tshould operate on if data are not readily available from the memory subsystem.\n\t\t\t\t\t\t\t\t\t\tUnlike Spectre, mispredictions on data flow do not directly result in the CPU\n\t\t\t\t\t\t\t\t\t\tspeculatively executing the wrong instructions. Instead, they result in the CPU\n\t\t\t\t\t\t\t\t\t\texecuting arbitrary instructions on the wrong data. However, we show this can be combined with\n\t\t\t\t\t\t\t\t\t\tindirection techniques to execute wrong instructions.\n\t\t\t\t\t\t\t\t\t</p>","contentLength":2235,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42856023"},{"title":"Boom XB-1 First Supersonic Flight [video]","url":"https://www.youtube.com/watch?v=-qisIViAHwI","date":1738079213,"author":"rayhaanj","guid":199,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42853633"},{"title":"Promising results from DeepSeek R1 for code","url":"https://simonwillison.net/2025/Jan/27/llamacpp-pr/","date":1738075446,"author":"k__","guid":198,"unread":true,"content":"<blockquote><p>This PR provides a big jump in speed for WASM by leveraging SIMD instructions for  and  dot product functions.</p><p>Surprisingly, 99% of the code in this PR is . The only thing I do is to develop tests and write prompts (with some trails and errors)</p></blockquote><p>I tried the <a href=\"https://gist.github.com/simonw/c9024b7feffda865ef10138dacfddcdc\">same thing against o1</a>, but I think DeepSeek R1 did it better. In particular, from the R1 chain of thought:</p><blockquote><p>Wait, but in the model_map, \"groq-gemma\" maps to \"gemma-7b-it\". So, perhaps the model_map is needed to map the local model IDs to the actual Groq model names.</p><p>But since the model_map is hardcoded, and the API returns available models, perhaps the model_map should be built dynamically from the API response.</p><p>Alternatively, perhaps the model_map can be eliminated, and the models are registered based on the fetched models.</p><p>Wait, perhaps the model_map is no longer necessary. Instead, when the models are fetched from the API, each model's \"id\" is the actual model name used in the Groq API. So, when registering the models, the local model ID is \"groq-{id}\", and the groq_model_id is \"id\".</p></blockquote><p>(It thought about  a  before finally deciding to eliminate it, which was also my preferred resolution.)</p><div>Posted <a href=\"https://simonwillison.net/2025/Jan/27/\">27th January 2025</a> at 6:32 pm</div>","contentLength":1185,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42852866"},{"title":"Run DeepSeek R1 Dynamic 1.58-bit","url":"https://unsloth.ai/blog/deepseekr1-dynamic","date":1738054367,"author":"noch","guid":197,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42850222"},{"title":"We're bringing Pebble back","url":"https://repebble.com/","date":1738008679,"author":"erohead","guid":196,"unread":true,"content":"<div><h2>We're making new Pebble watches</h2><p>I've tried pretty much every other smartwatch on Earth, yet I still wear my Pebble every day—nothing else matches its features and long battery life. I really, ,  hoped someone else would create a proper replacement, but no one has stepped up, and my stash of old Pebbles is dwindling!</p><p>It's time to take matters into my own hands. A small team and I are working on a new Pebble-like smartwatch that runs open source PebbleOS, has the same beloved features (plus some fun new stuff), and stays true to the core Pebble vision. If enough people are interested, we'll build it. <a href=\"https://repebble.com/signup.html\">Sign up</a> to get one!</p><a href=\"https://ericmigi.com/blog/why-were-bringing-pebble-back\" target=\"_blank\"><p>Why We're Bringing Pebble Back</p></a></div><div><h2>PebbleOS is now open source</h2><p>Google (which purchased Fitbit, which had bought Pebble) still owns PebbleOS. Over the last year, a team inside Google (including some amazing ex-Pebblers turned Googlers) has been working on open sourcing the OS! The source code for PebbleOS is now available at <a href=\"https://github.com/google/pebble\" target=\"_blank\">github.com/google/pebble</a>. Read more on their <a href=\"https://opensource.googleblog.com/2025/01/see-code-that-powered-pebble-smartwatches.html\" target=\"_blank\">blog</a>.</p><p>Thank you so much, Google! I can't stress how thankful I am to the individuals who did the heavy lifting. This was also made possible by the <a href=\"https://rebble.io\" target=\"_blank\">Rebble</a> team and community, who have supported Pebble since it shut down. Check out the vibrant <a href=\"https://reddit.com/r/pebble\" target=\"_blank\">r/Pebble</a> and <a href=\"https://discordapp.com/invite/aRUAYFN\" target=\"_blank\">Discord</a>.</p></div><div><p>The source code that powers each Pebble smartwatch is now freely available to download, modify and improve on <a href=\"https://github.com/google/pebble\" target=\"_blank\">Github</a>. Want a reminder of how awesome Pebble OS is? Dive back into the <a href=\"https://ericmigi.com/blog/pebbleos-is-awesome\" target=\"_blank\">beautiful, retro, pixelated world</a> of Pebble.</p><p>Anyone can use PebbleOS in any way they want. You can get it working on existing Pebble watches, emulate it, run it on other embedded devices, or create new hardware specifically for it.\n                    </p><p>We're setting out to bring Pebble back, we'd love for you to join the fun!</p></div>","contentLength":1759,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42845091"},{"title":"Google open-sources the Pebble OS","url":"https://opensource.googleblog.com/2025/01/see-code-that-powered-pebble-smartwatches.html","date":1738008549,"author":"hexxeh","guid":195,"unread":true,"content":"<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjHCX-mb_DqHgkNn1By45jRl-t4yGY82D79aFivyvhLIjiW9oglYr2fu7qOXFTEPj4sg-18anq6Aydli437ogx_AfTNI4V8Kq9Wjm1pPpOpqsSG1aiTwNLURTHgzFTeND8VuCxmndTLxT48Hr5RQgWvilKyeI9ORfoRNE40ZyqV49xuxTNarCAIoErsYbw/s1600/Pebble-Smartwatch%20%281%29.png\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjHCX-mb_DqHgkNn1By45jRl-t4yGY82D79aFivyvhLIjiW9oglYr2fu7qOXFTEPj4sg-18anq6Aydli437ogx_AfTNI4V8Kq9Wjm1pPpOpqsSG1aiTwNLURTHgzFTeND8VuCxmndTLxT48Hr5RQgWvilKyeI9ORfoRNE40ZyqV49xuxTNarCAIoErsYbw/s1600/Pebble-Smartwatch%20%281%29.png\" imageanchor=\"1\"><img border=\"0\" data-original-height=\"800\" data-original-width=\"100%\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjHCX-mb_DqHgkNn1By45jRl-t4yGY82D79aFivyvhLIjiW9oglYr2fu7qOXFTEPj4sg-18anq6Aydli437ogx_AfTNI4V8Kq9Wjm1pPpOpqsSG1aiTwNLURTHgzFTeND8VuCxmndTLxT48Hr5RQgWvilKyeI9ORfoRNE40ZyqV49xuxTNarCAIoErsYbw/s1600/Pebble-Smartwatch%20%281%29.png\"></a><p>We are excited to announce that the source code that powered Pebble smartwatches is now <a href=\"https://github.com/google/pebble\" target=\"_blank\">available for download</a>.</p><p>This is part of an effort from Google to help and support the <a href=\"https://rebble.io/\" target=\"_blank\">volunteers</a> who have come together to maintain functionality for Pebble watches after the original company ceased operations in 2016.</p><p>Pebble was initially launched through a very successful <a href=\"https://www.kickstarter.com/projects/getpebble/pebble-e-paper-watch-for-iphone-and-android\" target=\"_blank\">Kickstarter project</a>. Pebble’s first Kickstarter was the single most funded at the time, and its successor Kickstarter for the <a href=\"https://www.kickstarter.com/projects/getpebble/pebble-time-awesome-smartwatch-no-compromises\" target=\"_blank\">Pebble Time</a> repeated that feat – and remains the second most funded today! Over the course of four years, Pebble sold over two million smartwatches, cultivating a thriving community of thousands of developers who created over ten thousand Pebble apps and watchfaces.</p><p>In 2016, Fitbit acquired Pebble, including Pebble’s intellectual property. Later on, Fitbit itself was acquired by Google, taking the Pebble OS with it.</p><p>Despite the Pebble hardware and software support being discontinued eight years ago, Pebble still has thousands of dedicated fans.</p><p>We are releasing most of the source code for the Pebble operating system. This repository contains the entire OS, which provides all the standard smartwatch functionality – notifications, media controls, fitness tracking, and support for custom apps and watchfaces – on tiny ARM Cortex-M microcontrollers. Built with <a href=\"https://www.freertos.org/\" target=\"_blank\">FreeRTOS</a>, it contains multiple modules for memory management, graphics, and timekeeping, as well as an extensive framework to load and run custom applications written in C, as well as in Javascript via the <a href=\"https://jerryscript.net/\" target=\"_blank\">Jerryscript</a> Javascript engine. The Pebble architecture allowed for a lightweight system delivering a rich user experience as well as a very long battery life.</p><p>It's important to note that some proprietary code was removed from this codebase, particularly for chipset support and the Bluetooth stack. This means the code being released contains all the build system files (using the <a href=\"https://waf.io/\" target=\"_blank\">waf</a> build system), but it will not compile or link as released.</p><p>From here, we are hoping this release will assist the dedicated community and volunteers from the <a href=\"https://rebble.io/\" target=\"_blank\">Rebble project</a> to carry forward the support for Pebble watches that users still love. For someone to build a new firmware update, there is a non-trivial amount of work to do in finding replacements for the pieces that were stripped out of this code, as well as updating this source code that has not been maintained for a few years.</p><p><i>By Matthieu Jeanson, Katharine Berry, and Liam McLoughlin</i></p>","contentLength":2498,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42845070"},{"title":"DeepSeek releases Janus Pro, a text-to-image generator [pdf]","url":"https://github.com/deepseek-ai/Janus/blob/main/janus_pro_tech_report.pdf","date":1737997065,"author":"reissbaker","guid":194,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42843131"},{"title":"Facebook ban on discussing Linux?","url":"https://distrowatch.com/weekly-mobile.php?issue=20250127#sitenews","date":1737973956,"author":"rogerthis","guid":193,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42839502"},{"title":"A layoff fundamentally changed how I perceive work","url":"https://mertbulan.com/2025/01/26/once-you-are-laid-off-you-will-never-be-the-same-again/","date":1737966161,"author":"mertbio","guid":192,"unread":true,"content":"<p>It happened on the afternoon of May 4th. A message from a colleague—who has since become a good friend—popped up on my screen, urging me to check my emails. When I opened my inbox, there it was: an email from the COO. The email announced an impending company-wide layoff and mentioned that, within a few minutes, I’d receive another email letting me know whether I was impacted. A short while later, the second email arrived. I was among those affected—along with most of my team.</p><p>The situation felt surreal. One by one, my colleagues posted in our team chat, confirming they’d been impacted too. Before our accounts were locked, we quickly jumped on a call. We had just 30 minutes to have one final conversation as a team, to say our goodbyes. It was a bittersweet moment, sharing those last words with people I’d worked so closely with.</p><p>It was difficult to process what was happening. Just ten months earlier, the company had gone through another round of layoffs. And at the beginning of the year, during the company’s kick-off event, the president assured us there wouldn’t be any more layoffs. They even said the company was performing well financially. So, why was this happening?</p><p>Looking back, my colleagues and I were not entirely surprised by the layoff. There were several warning signs that hinted something was coming. I want to share these signs so you can be better prepared if you ever face a similar situation.</p><h3>1. Cancellation of Team Events</h3><p>One of the earliest indicators was the sudden cancellation of team events. When I heard from other teams that their off-site events were canceled without any clear explanation, it immediately raised red flags. These cancellations often signal that the company is going to announce something about the team structure and doesn’t want you to be with your team in the same place. This is because one of your teammates—or you—might be impacted, and you’d need to cancel flights, hotels, etc. To avoid dealing with these logistical issues, the company preemptively cancels the event.</p><h3>2. Unexpected Notifications About Packages</h3><p>Some employees at the company received notifications about packages scheduled to arrive at their homes. This happens because services like DHL notify you through their app when a package is on the way. If your company requires you to return your work equipment, like a laptop, after being laid off, they often arrange for these shipping boxes to be delivered in advance. If you unexpectedly see a notification about a package from your company’s IT provider, it’s a strong sign that a layoff is imminent—and you may be impacted.</p><h3>3. Lack of Vision from Leadership</h3><p>The absence of a clear vision from leadership is one of the most common signs of an impending layoff. During off-site or kick-off events, you might notice that leaders seem unsure of the company’s direction. When this lack of clarity is followed by team restructuring, and then another restructuring just a few months later, it becomes evident that the leadership is struggling to find focus. Ultimately, this cycle often ends with a layoff, accompanied by yet another round of restructuring for those who remain.</p><h3>4. Sudden, Vague Meetings</h3><p>Another sign is the appearance of unexpected, vague meetings on your calendar. These meetings are marked as “important” with no clear agenda, and attendance is mandatory. If this happens, it’s often a precursor to a layoff announcement. Public companies, in particular, may choose to send layoff notices via email to align the timing with when they notify investors.</p><h3>5. Timing Around Quarterly Results</h3><p>If your company is publicly traded, layoffs are frequently announced in conjunction with quarterly earnings reports. This can be especially stressful because, leading up to every financial results announcement, employees may anxiously wait to see if layoffs will accompany the news. If no layoffs are announced, you know you’re safe—for at least one more quarter.</p><p>When I looked back on my time at the company and all the things I had accomplished, I was surprised to be impacted by the layoffs. It wasn’t because I thought I was better than others—it was because I believed I was doing more than what was expected of me. However, during a layoff, it seems that who you are and what you do doesn’t matter. In most cases, the decision is made by people who don’t even know you. This realization made me question the concept of work, which is part of the reason I’m writing this blog post.</p><p>I was hired as a Backend Developer. When I joined my team, I noticed a project that needed a developer to implement the client-side feature in React Native. Although I had no prior experience with React Native, I had worked with React before, so I volunteered for the task. I shipped the feature without any issues, received positive feedback from my team and lead, and eventually, my title was changed to Developer, making me a full-stack developer.</p><p>In some instances, I worked on projects independently, always aligning with my team and ensuring my work was reviewed. I would implement the backend first and then move on to the client-side. This was my expected role, and in performance reviews, I was consistently rated as a high performer. Yet, I was always doing more than what was expected of me.</p><p>Sometimes, I worked on small features I thought would enhance the app. These features might not have been used by many, but they provided significant value to heavy users. Occasionally, I shipped these under the radar. I created dashboards to measure the impact of my team’s work, helping us focus on features that would bring the most value to users. I also built proof-of-concept features based on user requests to show leadership how easily they could be implemented, advocating for their prioritization. Additionally, I participated in hackdays, creating projects to showcase innovative ideas.</p><p>On several occasions, I was selected for special projects outside my team. These projects often came directly from the CEO, and I was chosen because I constantly wanted to do more for the company and our users. For some of these projects, I worked more than eight hours a day, including weekends. A few of these initiatives were mentioned in financial reports, praised by the CEO during all-hands meetings, or retweeted multiple times by the CEO on Twitter.</p><p>Over time, I gained the attention of senior management in my business unit, which consisted of about 400 people. I began directly interacting with the VP of Product and the VP of Engineering, both of whom were four or five levels above me. Occasionally, the VP of Product would message me directly to ask if a feature was feasible to implement. Later, the VP of Engineering started scheduling regular one-on-one meetings with me, which was highly uncommon. During these calls, he told me multiple times that if I continued working at this level, I could quickly climb the ladder to become a Staff Developer. He wasn’t the only one saying this to me.</p><p>Beyond my immediate role, I also sought ways to contribute to the broader company. Whenever a new tool was introduced, I would explore it, write detailed articles about my findings, and share them to help other teams use the tool more effectively.</p><p>I referred many friends and former colleagues to the company because I believed in its mission. If I recall correctly, I referred over ten people, four of whom received offers, and three were ultimately hired. I also encouraged many others to consider joining the company.</p><p>I even initiated discussions about translating our website into Turkish to support the many customers we had in Turkey. A few weeks before the layoff announcement, I was helping a team working on this project find a Turkish-speaking content designer because they noticed my willingness to assist.</p><p>Additionally, I tried to convince friends who were CTOs at major e-commerce companies to migrate their websites to our platform. Whenever I received job offers from e-commerce companies on LinkedIn, I used those opportunities to promote our platform instead. I passed along leads to the sales team and later noticed that one of those companies had indeed moved to our platform.</p><p>I’m not sharing all of this to brag but to highlight that, in the end, none of it mattered. On the day I announced I had been laid off, I received numerous messages from colleagues, even those I hadn’t worked with directly, telling me that I had inspired and motivated them. While those messages were heartwarming, they didn’t change the reality: to the company, I was just a row in an Excel sheet.</p><p>Layoffs were uncommon when I started working, and being a developer felt like an incredibly safe job. In most professions, the unspoken rule was simple: if you performed well and the company was financially stable, your job was secure.</p><p>But today, companies are announcing layoffs alongside record-breaking financial results. You work hard, focus on impactful projects, and receive praise from your lead—only to find yourself let go by someone who likely doesn’t even know you exist. It feels as though the trust between companies and employees is now broken. Companies, it seems, are either unaware of this shift or unwilling to address it. And frankly, I’m not sure how they could fix it.</p><p>What’s particularly strange is that the layoffs predominantly affect individual contributors—the people who have little say in deciding the company’s direction. These are the team members closest to the users, the ones who spend hours planning how to improve the product. But after those plans are made, leadership often swoops in and redirects efforts toward entirely different goals. You trust their judgment, work on their priorities, and deliver on time. Then, when the arbitrary goals they set aren’t met, the company decides to cut staff. Those who made the poor decisions remain, and some are even promoted, while the people carrying out the work are let go. It feels surreal—like <a rel=\"nofollow noopener\" target=\"_blank\" href=\"https://www.youtube.com/watch?v=u48vYSLvKNQ\">an episode from Silicon Valley</a>—but this is how big companies operate.</p><p>I’m not alone in feeling this way. Many friends and ex-colleagues who’ve been laid off in recent years share similar experiences. They’ve lost trust in their employers. They believe their efforts won’t matter in the long run and anticipate being part of the next layoff cycle. As a result, they only do what’s strictly required to avoid a performance improvement plan. No one goes above and beyond anymore; no one takes initiative to improve things. Why? Because it doesn’t matter. They’ve seen firsthand that it changes nothing.</p><p>For those like me who’ve experienced layoffs, work has become just that—work. You do what’s assigned, and if your company squanders your potential or forces you to waste time on unnecessary projects, you simply stop caring. You collect your paycheck at the end of the month, and that’s it. This is the new modern work: no more striving to be 40% better every year.</p><p>Since I was working for a German entity of a company, I want to address a common myth about job security in Germany. Many people believe that it’s nearly impossible to be fired in Germany. While this is partially true for individuals who have completed their probation period, it doesn’t hold up in the context of layoffs. If a company decides to lay off, for instance, 40 employees, German law doesn’t prevent this. Instead, the law enforces a social scoring system to determine who is affected, prioritizing the protection of the most vulnerable employees, such as those with children. In this sense, when it comes to layoffs, the difference between Germany and the US is minimal.</p><p>When I talk to friends who were laid off in recent years, we often reflect on what we could have done differently. Here are some of the lessons we’ve learned:</p><ul><li><strong>Stick to your contract hours.</strong> If your contract says 40 hours, work 40 hours—no more, no less. Protect your personal time and well-being.</li><li><strong>Avoid going above and beyond with initiatives.</strong> Many companies encourage impactful work to earn promotions, but instead of chasing internal advancements, focus on switching companies to achieve your next career step.</li><li><strong>Always keep interviewing.</strong> One of the biggest mistakes I’ve seen is stopping interviews after starting a new job, trusting in the company. Instead, continuously explore opportunities so that if a layoff happens, you already have other options lined up.</li><li><strong>Leverage external offers for salary growth.</strong> Companies often resist giving substantial raises to existing employees but pay top dollar for new hires. Regularly interview elsewhere, and if you get an offer with a 20% or higher salary increase, consider taking it. Many people have seen their compensation triple or quadruple this way in just a few years.</li><li><strong>Don’t overthink your résumé.</strong> Worrying about short experiences on your CV isn’t worth it. You can always tailor your résumé—leave out brief roles, or consolidate short-term jobs as freelance experience. Ultimately, your résumé is just a starting point; your skills will be assessed during the interview process.</li></ul><p>You’ve probably noticed that I didn’t mention the name of the company I was laid off from. That’s because I believe it’s irrelevant. Everything I’ve shared reflects the current state of the tech industry. It might differ at very small companies, but once you work at a company with more than 100 employees, you’ll likely encounter many of the same patterns I’ve described.</p><p>I’ve wanted to write about this topic for a long time, but it’s been difficult to find the energy. The subject itself is a deep disappointment for me, and every time I reflect on layoffs, it makes me profoundly sad. It’s a stark reminder of how companies treat workers as disposable. Before you join, they go to great lengths to make you feel valued and excited to accept their offer. You meet multiple people, and some even offer signing bonuses. But when layoffs come, you’re reduced to a name on a list. During the exit interview, a random person from the company reads a prepared script and can’t answer your questions. The HR team that once worked to make you feel valued doesn’t even conduct an actual conversation with you. That random person becomes the last connection you have to a company you spent years at.</p><p>The layoff fundamentally changed how I perceive work now. I don’t think that I’ll be the same person again.</p>","contentLength":14447,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42838700"},{"title":"It's not a crime if we do it with an app","url":"https://pluralistic.net/2025/01/25/potatotrac/#carbo-loading","date":1737905093,"author":"keepit","guid":191,"unread":true,"content":"<p>The core regulatory proposition of the tech industry is \"it's not a crime if we do it with an app.\" It's not an unlicensed taxi if we do it with an app. It's not an illegal hotel room if we do it with an app. It's not an unregistered security if we do it with an app. It's not wage theft if we do it with an app.</p><p>Inflation is one of the most politically salient factors of this decade, and so much of inflation can be attributed to a crime, done with an app, with impunity for the criminals. The entire food supply has been sewn up by cartels of 2-5 giant companies, and they colluded to raise prices, and bragged about it, and got away with it, because neoclassical economists insist that it's impossible for this kind of price fixing to occur in an \"efficient market.\"</p><p>Some of these cartels are well-known, like the Coke/Pepsi duopoly. Pepsi's bosses boasted to their shareholders about \"Pepsi pricing power,\" and how they were able to raise prices over the inflationary increases caused by covid and the Russian invasion of Ukraine:</p><p>You might know that pretty much every packaged good in your grocery store is made by one of two companies, Unilever and Procter and Gamble. Both CEOs boasted to their investors about their above-inflation price increases:</p><p>But other cartels are harder to spot. It may seem like your grocer's eggs department is filled with many different companies' products. In reality, a single company, Cal-Maine Foods, owns practically every brand of eggs in the case: Farmhouse Eggs, Sunups, Sunny Meadow, Egg-Land’s Best and Land O’ Lakes. They made record profits after the pandemic and through bird flu, a fact that CFO Max Bowman attributed to \"significantly higher selling prices\" and \"our ability to adapt to inflationary market pressures\":</p><p>But Cal-Maine is comparatively transparent. The other food cartels – especially those that serve the restaurant sector – are harder to spot. In , Katya Schwenk describes how four companies – Lamb Weston, JR Simplot, McCain Foods and Cavendish Farms – have captured the frozen potato market and all that comes with it (fries, tater tots, etc):</p><p>These companies have been hiking prices for years, but  started to turn the screws during the post-covid inflationary period. One of Schwenk's sources is Josh Saltzman, owner of the DC sports bar Ivy and Coney. Ten years ago, Saltzman charged $3 for fries; now it's $6 – and Saltzman's margins have declined. Saltzman has a limited number of suppliers, and they all get their potatoes from Big Potato, and they bundle those potato orders with their other supplies, making it effectively impossible for Saltzman to buy his potatoes from anyone else.</p><p>Big Potato controls  of the frozen potato market, and any sector that large and concentrated is going to be pretty cozy. The execs from these companies meet up at industry associations, lobbying bodies, and by job-hopping between companies in the cartel. But they don't have to rely on personal connections to rig the price of potatoes: they do it through a third-party data-broker called Potatotrac. Each cartel member sends all their commercially sensitive data – supply costs, pricing, sales figures – to Potatotrac, and then Potatotrac uses that data to give \"advice\" to the cartel members about \"optimal pricing.\"</p><p>This is just price-fixing, with an app. The fact that they don't sit around a table and openly discuss pricing doesn't keep this from being price-fixing. What's more, they . A director at McCain said that \"higher ups\" forbade anyone in the company from competing on price. A Lamb Weston exec described the arrangement as everyone \"behaving themselves,\" chortling that they'd \"never seen margins this high in the history of the potato industry.\" Lamb Weston's CEO attributed a 111% increase in net income to \"pricing actions.\"</p><p>Lamb Weston's execs understand that they're driving small restaurants out of business, and that the real beneficiaries are big chains that can pass the price increases onto their customers, like \"Chili’s and the Texas Roadhouses and Cheesecake Factory\":</p><p>This is by no means unique to the potato industry. A data-broker called Agri Stats works with America's largest meat-packers to rig the price of meat – packers send Agri Stats the same kind of data that Big Potato sends to Potatotrac, and Agri Stats sends back the same \"recommendations\" that allow them to raise meat prices across the board, in lockstep:</p><p>Lots of food categories are as inbred as meat and potatoes: \"four firms controlled nearly 80 percent of the almond milk market, for instance. Three companies controlled 83 percent of the canned tuna market, and four companies controlled more than 86 percent of the microwave popcorn market.\"</p><p>The \"price fixing is legal if we do it with an app\" gambit is not just about food, either. Apps like Realpage let big corporate landlords – who've bought up a sizable fraction of all the available homes in America – collude to raise rents:</p><p>And private equity companies have rolled up all the  companies, hiking the price of trucks, creating backlogs and bottlenecks for parts and service, and starving the nation's municipalities (including Los Angeles) of fire-fighting equipment:</p><p>This kind of price-fixing was central to the enforcement actions of the Biden administration's trustbusters at the FTC, and their investigations and actions inspired state AGs and private parties to bring their own antitrust suits. The question is, will Trump's enforcers continue this agenda? And will Trump's judges – steeped in Heritage Foundation economics that insists that monopolies are \"efficient\" – find in their favor if they do?</p><p>Inflation has lots of causes, it's true. But when an industry is consolidated enough to take advantage of a data brokerage or just engage in tacit collusion,  source of inflation – war, disease, weather – allows whole sectors to raise prices together, and keep them high, long after the shock has passed.</p><ul><li>Picks and Shovels: a sequel to \"Red Team Blues,\" about the heroic era of the PC, Tor Books, February 2025</li><li><p>Unauthorized Bread: a middle-grades graphic novel adapted from my novella about refugees, toasters and DRM, FirstSecond, 2025</p></li></ul><ul><li>Enshittification: a nonfiction book about platform decay for Farrar, Straus, Giroux. Status: second pass edit underway (readaloud)</li><li><p>A Little Brother short story about DIY insulin PLANNING</p></li><li><p>Picks and Shovels, a Martin Hench noir thriller about the heroic era of the PC. FORTHCOMING TOR BOOKS FEB 2025</p></li></ul><p>This work – excluding any serialized fiction – is licensed under a Creative Commons Attribution 4.0 license. That means you can use it any way you like, including commercially, provided that you attribute it to me, Cory Doctorow, and include a link to pluralistic.net.</p><p>Quotations and images are not included in this license; they are included either under a limitation or exception to copyright, or on the basis of a separate license. Please exercise caution.</p><p>Blog (no ads, tracking, or data-collection):</p><p>Newsletter (no ads, tracking, or data-collection):</p><p>Mastodon (no ads, tracking, or data-collection):</p><p>Medium (no ads, paywalled):</p><p>Twitter (mass-scale, unrestricted, third-party surveillance and advertising):</p><p>Tumblr (mass-scale, unrestricted, third-party surveillance and advertising):</p><p>\"<em>When life gives you SARS, you make sarsaparilla</em>\" -Joey \"Accordion Guy\" DeVilla</p>","contentLength":7342,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42830646"},{"title":"Steam Brick: No screen, no controller, just a power button and a USB port","url":"https://crastinator-pro.github.io/steam-brick/","date":1737843313,"author":"sbarre","guid":190,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42825441"},{"title":"DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via RL","url":"https://arxiv.org/abs/2501.12948","date":1737830389,"author":"gradus_ad","guid":189,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42823568"},{"title":"Show HN: Cs16.css – CSS library based on Counter Strike 1.6 UI","url":"https://cs16.samke.me/","date":1737733027,"author":"samke-","guid":188,"unread":true,"content":"<div>\n                Lorem ipsum dolor sit amet consectetur adipisicing elit.\n                Distinctio ad suscipit aut asperiores laudantium error amet\n                sapiente et tempora numquam voluptates, velit sint quos\n                exercitationem unde obcaecati deleniti maiores officia natus\n                ipsa rem fuga commodi esse. Sunt repellendus ipsa illo a\n                accusantium consequuntur nihil dicta necessitatibus porro,\n                saepe, sed repudiandae!\n              </div>","contentLength":501,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42814110"},{"title":"Thank HN: My bootstrapped startup got acquired today","url":"https://news.ycombinator.com/item?id=42806247","date":1737655085,"author":"paraschopra","guid":187,"unread":true,"content":"Hello HN,<p>Today, I sold the company to a private equity firm for $200mn.</p><p>I was a 22 year old fresh graduate when I launched VWO on HN and got initial users. Feedback from people like @patio11 helped me get to PMF. And now, 15 years later, \"site:ycombinator.com\" is what I appended when I wanted to search for advice on what to keep in mind while selling my company.</p><p>Thank you HN for sharing inspiration and wisdom all along. I honestly don't think I would have been an entrepreneur had it not been for hacker news.</p><p>Every single day, HN is the first website I open! I'm feeling very grateful towards the community. Thanks @dang, and thank you Paul Graham for your essays and for creating this beautiful corner of the internet!</p>","contentLength":721,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42806247"},{"title":"Show HN: I made an open-source laptop from scratch","url":"https://www.byran.ee/posts/creation/","date":1737578512,"author":"Hello9999901","guid":186,"unread":true,"content":"<blockquote><p>I do not think there is any thrill that can go through the human heart like that felt by the inventor as he sees some creation of the brain unfolding to success\n– <a href=\"https://en.wikipedia.org/wiki/Nikola_Tesla\" target=\"_blank\">Nikola Tesla</a></p></blockquote><p><strong>It’s got a 4K AMOLED display, a Cherry MX mechanical keyboard, plays Minecraft at 4K, runs +7B LLMs, surfs the web, and has ~7h battery life. All open-source.</strong></p><p><em>How I Made A Laptop From Scratch (YouTube.com). Demo at 22:14.</em></p><p><strong>The writeup below pretty much abridges the video above.</strong></p><p>Imagine a skill-chart of qualities of technology: screen, audio, performance, build, tactility, touch-interaction, efficiency, size, and so many more. At the balancing point of all these qualities is the laptop. To that end, let’s build a laptop that hits as many qualities of a modern commercial thin &amp; light laptop—while trying to do as much from scratch as possible.</p><img src=\"https://www.byran.ee/img/photo.jpg\"><p><em>Booting and inserting magnetically attached keyboard</em></p><img src=\"https://www.byran.ee/img/minecraft.jpg\"><p><em>Epic Hypixel Bedwars gaming</em></p><h2>Finding an electron in a cloud</h2><p>I first made a mental map and transferred it into Obsidian:</p><p>Boiling it down, it landed me with a lofty list of goals:</p><ul><li><a href=\"https://www.rock-chips.com/uploads/pdf/2022.8.26/192/RK3588%20Brief%20Datasheet.pdf\" target=\"_blank\">RK3588</a> SoC Motherboard\n<ul></ul></li><li>Powertrain\n<ul><li>~60Wh Li-ion battery pack</li></ul></li><li>Peripherals\n<ul><li>Wireless mechanical keyboard</li><li>Glass-topped multi-touch trackpad</li></ul></li><li>Anodized aluminum CNC chassis</li></ul><p>I looked towards single-board computer SoCs, as board manufacturers commonly release schematics for reference. In many aspects, the Rockchip RK3588 is the fastest consumer-procurable chip on the market. Despite the spotty software support, the hardware documentation has lots of developer resources and <a href=\"https://wiki.friendlyelec.com/wiki/images/1/15/CM3588_NAS_SDK_2309_SCH.PDF\" target=\"_blank\">reference schematics</a> from SBC manufacturers.</p><ul><li>Quad core A76 and quad core A55</li><li>I/O: 8K display, dual USB3.1, PCIe 3.0 x 4, HDMI2.1/eDP 1.4, etc.</li></ul><p>With only a few months to work on this project, an SoM (system on module) like the Raspberry Pi CM5 presented the best option for its hardware compatibility and a high likelihood of a snug integration. Choosing an SoM also alleviates memory and other high-speed signaling concerns. Looking around for a RK3588 SoM, I came across the CM3588 by FriendlyElec. Cheap, well-documented, and easily procurable. Sounds good!</p><img src=\"https://www.byran.ee/img/cm3588.jpg\"><p>I hopped on <a href=\"https://www.panelook.com\" target=\"_blank\">panelook.com</a> and filtered by size and resolution. I’ve always been a sucker for high pixel density, so I went with a 4K AMOLED 13.3” display. Cross referencing stock availability on Taobao (Chinese domestic Aliexpress), the <a href=\"https://www.panelook.com/ATNA33TP11_Samsung_13.3_OLED_parameter_59424.html\" target=\"_blank\">ATNA33TP11</a> seemed to be the one with most  stock since OLED risked burn-in.</p><p>A highlight: during display evaluation, switching out a connector and shortening the board by 2mm improved signal integrity  for the 1.5GHz x 4 signals go pass through. Getting the display running on Linux meant finding system logs from Asus laptops that have this display, reverse-engineering the values, and tuning the power-on timings amongst other things . TLDR; getting a 4K AMOLED eDP display running on non-mainline Linux was a heck of a journey, so read <a href=\"https://www.byran.ee/posts/creation/\">this if you’re interested</a> (coming soon).</p><img src=\"https://www.byran.ee/img/screen.jpg\"><p><em>ATNA33TP11 working with display evaluation board V2 short</em></p><p>The cells had to be 6mm thin and four packs lined up should take roughly half of the entire chassis volume. Chinese manufacturers don’t stock batteries readily, and shipping them to the US would be a pain. Thus, I looked on the American side. I stumbled upon with <a href=\"https://www.batteryspace.com/polymerli-ionmodule37v4250mah157wh85arate-prewiredwithpcbpl5467100.aspx\" target=\"_blank\">these batteries</a> from AA Portable Power Corp. or batteryspace.com. or Powerizer. Doing the power calculations, we get: 4.250Ah  4S = 62.9 Wh with max 8A (so max 134.4W discharge)! Solid.</p><p>The total voltage is 4.2V (peak) * 4S = 16.8V. The system’s designed for up to 20V USB-C (AKA 100W) and passed into the <a href=\"https://www.ti.com/product/BQ25713\" target=\"_blank\">BQ25713</a> charging IC. The batteries are balanced with the <a href=\"https://www.ti.com/product/BQ77915\" target=\"_blank\">BQ77915</a> to ensure safe charging, and the power is tracked with an <a href=\"https://www.analog.com/en/products/ltc2943.html\" target=\"_blank\">LTC2943</a> to calculate a state-of-charge percentage. I popped in an ESP32-S3 module as the controller for everything, and set it to production.</p><p>After writing drivers and sitting on the undecipherable datasheets for days, I had the batteries charging. I successfully <a href=\"https://a.co/d/3b8R9mN\" target=\"_blank\">load tested</a> it to around 5A and powered the full system. There’s still a lot of quiescent current (about ~50mA), but I haven’t had the time to optimize the firmware.</p><p>The USB of the ESP32 connects to the internal USB on the motherboard to feed the power telemetry over UART. A Python script and kernel module in the OS forwards it to the battery service in the kernel to display it natively.</p><img src=\"https://www.byran.ee/img/powertrain.jpg\"><p><em>Powertrain V0.2 inside laptop</em></p><p>In settings, tick “Align controls with KiCad” for mouse pan/zoom/scroll</p><p>With those decisions made up, I aimed for &gt;90mm motherboard width based on a prelim CAD from the batteries and display dimensions.</p><p>On the physical I/O side, I settled on dual USB3.1 Type-C ports, a USB2.0 Type-A port, a headphone jack, and a microSD card slot. Internally, the M.2 E-key connects to an <a href=\"https://a.co/d/4lJDnwX\" target=\"_blank\">RTL8852BE</a> WiFi 6 (802.11ax) + BT5.2 wireless card and the M.2 M-key accommodates up to an 2242-sized NVMe SSD. A full size NVMe SSD can fit with some modifications of the chassis too.</p><p>Tangent over, this leaves me with around ~90mm of board height. Implementing all the features on the final mainboard would stretch this writeup too long, so read <a href=\"https://www.byran.ee/posts/creation/\">this if you’re interested</a> (coming soon).</p><p>In settings, tick “Align controls with KiCad” for mouse pan/zoom/scroll</p><img src=\"https://www.byran.ee/img/mainboard.jpg\"><p><em>Detailed hardware overview</em></p><p><a href=\"https://github.com/Joshua-Riek/ubuntu-rockchip\" target=\"_blank\">Joshua Riek’s ubuntu-rockchip</a> kernel/distro combined an out-of-the-box experience with lots of optimizations. Using Armbian’s kernel (I believe it’s still off Rockchip’s kernel) meant that it offered nearly all the features of the RK3588 on a developer-ready kernel configuration.</p><p>Since nearly all the work I needed to do was abstracted in the DeviceTree (DTS) hardware configuration language implemented with U-boot, the bootloader, I took advantage of their system-agnostic nature to speed up my trial-and-error process having never done any Linux work.</p><p>Instead of developing and compiling code on the RK3588 itself, I used my daily driver MacBook and Visual Studio Code. Once I made a change in the DTS, I’d use Orbstack (virtualization software) running Ubuntu 24.04 (shared filesystem and kernel with macOS) and compile the DeviceTree there.</p><pre tabindex=\"0\" data-language=\"txt\"><code></code></pre><p>Pointing U-Boot to a custom compiled DTB (devicetree binary), I ’ed the compiled  to the OS. A  regenerates the bootloader configurations, and a reboot updates the changes.</p><p>That’s how I did the hardware bringup—display configurations, PCIe, USB, and other low-level system tweaks. The rest is just a standard install of Ubuntu 24.04 LTS with Linux Kernel 6.1.</p><img src=\"https://www.byran.ee/img/working.jpg\"><p><em>Testing batteries and writing DTS</em></p><p><em>In-depth software overview</em></p><p>Imagine being able to just pull out your laptop’s keyboard and use it as just another wireless keyboard for literally anything! Just me? Maybe.</p><p>Being a mechanical keyboard addict with quite a few <a href=\"https://zmk.dev\" target=\"_blank\">ZMK keyboards</a> designed, I chose the <a href=\"https://github.com/pashutk/Cherry_MX_ULP\" target=\"_blank\">Cherry MX ULP mechanical switches</a> for the best feel. Of course, a battery and fully mechanical switches add  of height. I used a 1mm thin <a href=\"https://www.powerstream.com/thin-lithium-ion.htm\" target=\"_blank\">200mAh battery</a> and a custom battery protection board that sticks up between two rows of keys to cut down on ~1.6mm (PCB height). The nRF52840 SoC running ZMK Firmware is right underneath the spacebar. A sandwich of PLA and 6061 aluminum from Fabworks crammed everything under ~7mm.</p><p>Since the keycaps aren’t easily procurable, I got a <a href=\"https://www.printedsolid.com/products/e3d-revo-nozzles?srsltid=AfmBOopKMJDs7gFpzrJg3kHQ-aJLDFTjeFO0ZJAYf1hADzy5iurNlkLB\" target=\"_blank\">0.15mm nozzle</a> for my Bambu Lab X1C and printed them with PLA. It got me down a rabbit hole of tungsten nozzles, and I got quoted ~$400 for 20x 0.15mm nozzles. I’ve been thinking of trying that out too. But alas, printing out all the keycaps and assembling for the last time, the keyboard was done.</p><p>Moving on to the trackpad, it was quite quick. I knew from the start that I wanted a good trackpad, so making my own with zero capacitive tracking experience is a no-go. Searching online, I came across the Azoteq <a href=\"https://www.mouser.com/ProductDetail/Azoteq/PXM0057-401-S?qs=t7xnP681wgVkp9ZZYy6TPA%3D%3D\" target=\"_blank\">PXM0057-401</a> evaluation module on Mouser. It had it all—glass surface, multi-touch, and worked over USB. And, it was only 35 bucks or so. However, the trackpad has ceased production without many alternatives.</p><p>With the keyboard and trackpad working, it was time to put on the finishing touches.</p><p>In settings, tick “Align controls with KiCad” for mouse pan/zoom/scroll</p><img src=\"https://www.byran.ee/img/peripherals.jpg\"><p>*Counterclockwise from top left: keyboard side profile, typing on keyboard, trackpad, 1mm battery on back, nRF52840 SoC area</p><p><em>OnShape wireframe exploded view</em></p><p>Roughly the same time I began the system design, I sent a few CNC aluminum blocks off to JLC for evaluation with different anodization finishes. The dark gray anodization felt “best”, but I preferred the look of the matte black, so I settled on that.\nUsing PTC OnShape, I (attempted) CAD’ed a robust and minimalistic look and a blend of my two favorite laptop lineup designs, the Razer Blade and the MacBook Pro. Because of the removable keyboard, the bottom has no screws. Instead, the palm rest screws into the bottom chassis. <a href=\"https://cad.onshape.com/documents/a18bb6df7dbba66df24a7ec8/w/967d921e60c207e3b6f5cf7b/e/1f78a9387b17c2d178742295?renderMode=0&amp;uiState=678da20d5bee0d1ad2dd55f1\" target=\"_blank\">CAD Link here.</a></p><p>The hardest part about the chassis was the hinge. I used <a href=\"https://frame.work/products/display-hinge-kit?v=FRANFB0001\" target=\"_blank\">Framework’s 13.3” hinge</a> because it has a 3D model. I constrained it in OnShape so I can see the exact closing angles.</p><p>The chassis layout is fairly simple: batteries on the bottom, the power board on the right, motherboard on the left, and the hinge mechanism on top. Oh, and a transparent PETG FDM printed power button that lights up on a custom PCB. To balance out the asymmetric hinge (caused by the mainboard being too wide), a little <a href=\"https://www.mcmaster.com/2153T11/\" target=\"_blank\">carbon fiber rod</a> lines up on the left side too.</p><img src=\"https://www.byran.ee/img/chassis_empty.jpg\"><p>It was a battle to get the screen assembly to not hit anything while also covering\nAlthough I started considering thermals way in advance, hence the gap here for the heatpipe to go through, I still had difficulty fitting everything in. The distance between the bottom of the keyboard and the top of the heatsink is less than a half a millimeter. The cooling system is really constrained because I don’t have the resources to make a custom heatpipe and fin solution. So, I made a full copper CNC heatsink (from JLCCNC) and a heatpipe connected to a fan. It’s all connected with <a href=\"https://www.lttstore.com/products/ptm7950-phase-change-thermal-pad\" target=\"_blank\">PTM7950</a>.</p><p>I also added <a href=\"https://puiaudio.com/product/speakers-and-receivers/as04004mo-sp40\" target=\"_blank\">these</a> PUI audio speakers on either side. The audio from the CM3588’s DAC didn’t work and I ran out of debugging time, so I made a USB to audio converter board separately and shot it through an Class-D amplifier. I would’ve also made the amp, but I ran out of time.</p><p>As I reached final assembly, I used a mix of JLC’s selective laser sintering (SLS) of nylon powder and FDM printed PA6-CF for smaller structural parts. Putting it all together with the matte black CNC aluminum chassis, I finally had my laptop.</p><img src=\"https://www.byran.ee/img/inside.jpg\"><p><em>Inside full laptop assembly</em></p><p>The hardest class I’ve taken so far was quantum mechanics in my junior spring term. A few months before spending hours solving time-independent and dependent Schrödinger equations, I was on the squash bus (the sport, not the vegetable). My friend suggested I make a laptop for my senior project—and that was all.\nI came up with the name anyon_e in June, after I finished the quantum course.</p><p>Making this laptop was hard. Mentally pressured with a deadline, and a constant inter-disciplinary challenge across electrical, software, and mechanical systems. Summing up everything I’ve ever done. It took up most of my mind from May until now.</p><p>Inspired by open-source projects like <a href=\"https://zmk.dev\" target=\"_blank\">ZMK</a>, <a href=\"https://www.kicad.org\" target=\"_blank\">KiCAD</a>, <a href=\"https://www.blender.org\" target=\"_blank\">Blender</a>, and countless <a href=\"https://certification.oshwa.org/basics.html\" target=\"_blank\">OSHW</a> projects, I want to do my own little part. To put power in people’s hands in creation, innovation, imagination, or whatever else. To attempt the impossible.</p><img src=\"https://www.byran.ee/img/conclusion.jpg\">","contentLength":11328,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42797260"},{"title":"TabBoo – add random jumpscares to websites you're trying to avoid","url":"https://tabboo.xyz/","date":1737566834,"author":"thatsnotoptimal","guid":185,"unread":true,"content":"<h2>\n          Add  to sites you're\n          trying to avoid\n        </h2><p>\n          You're stuck in an addictive, endless loop, loading the same sites\n          over and over again. Install the extension and let\n           do the rest.\n        </p><a href=\"https://chromewebstore.google.com/detail/tabboo/jjdalbijcodgjpeepgllndclalllbopg\" target=\"_blank\">+ Add to Chrome</a>","contentLength":252,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42795237"},{"title":"Mastercard DNS error went unnoticed for years","url":"https://krebsonsecurity.com/2025/01/mastercard-dns-error-went-unnoticed-for-years/","date":1737559557,"author":"todsacerdoti","guid":184,"unread":true,"content":"<p>The payment card giant  just fixed a glaring error in its domain name server settings that could have allowed anyone to intercept or divert Internet traffic for the company by registering an unused domain name. The misconfiguration persisted for nearly five years until a security researcher spent $300 to register the domain and prevent it from being grabbed by cybercriminals.</p><div><img aria-describedby=\"caption-attachment-70128\" decoding=\"async\" src=\"https://krebsonsecurity.com/wp-content/uploads/2025/01/akamne.png\" alt=\"\" width=\"667\" height=\"478\"><p>A DNS lookup on the domain az.mastercard.com on Jan. 14, 2025 shows the mistyped domain name a22-65.akam.ne.</p></div><p>From June 30, 2020 until January 14, 2025, one of the core Internet servers that MasterCard uses to direct traffic for portions of the mastercard.com network was misnamed. MasterCard.com relies on five shared Domain Name System (DNS) servers at the Internet infrastructure provider [DNS acts as a kind of Internet phone book, by translating website names to numeric Internet addresses that are easier for computers to manage].</p><p>All of the Akamai DNS server names that MasterCard uses are supposed to end in “akam.net” but one of them was misconfigured to rely on the domain “.”</p><p>This tiny but potentially critical typo was discovered recently by ,&nbsp;founder of the security consultancy <a href=\"https://www.seralys.com/\" target=\"_blank\" rel=\"noopener\">Seralys</a>. Caturegli said he guessed that nobody had yet registered the domain akam.ne, which is under the purview of the top-level domain authority for the West Africa nation of <a href=\"https://en.wikipedia.org/wiki/Niger\" target=\"_blank\" rel=\"noopener\">Niger</a>.</p><p>Caturegli said it took $300 and nearly three months of waiting to secure the domain with the registry in Niger. After enabling a DNS server on akam.ne, he noticed hundreds of thousands of DNS requests hitting his server each day from locations around the globe. Apparently, MasterCard wasn’t the only organization that had fat-fingered a DNS entry to include “akam.ne,” but they were by far the largest.</p><p>But the researcher said he didn’t attempt to do any of that. Instead, he alerted MasterCard that the domain was theirs if they wanted it, copying this author on his notifications. A few hours later, MasterCard acknowledged the mistake, but said there was never any real threat to the security of its operations.</p><p>“We have looked into the matter and there was not a risk to our systems,” a MasterCard spokesperson wrote. “This typo has now been corrected.”</p><p>Meanwhile, Caturegli received a request submitted through , a program that offers financial rewards and recognition to security researchers who find flaws and work privately with the affected vendor to fix them. The message suggested his public disclosure of the MasterCard DNS error via <a href=\"https://www.linkedin.com/feed/update/urn:li:activity:7285038365236682753/\" target=\"_blank\" rel=\"noopener\">a post on LinkedIn</a> (after he’d secured the akam.ne domain) was not aligned with ethical security practices, and passed on a request from MasterCard to have the post removed.</p><div><img aria-describedby=\"caption-attachment-70126\" decoding=\"async\" loading=\"lazy\" src=\"https://krebsonsecurity.com/wp-content/uploads/2025/01/mastercard-response.png\" alt=\"\" width=\"708\" height=\"855\"><p>MasterCard’s request to Caturegli, a.k.a. “Titon” on infosec.exchange.</p></div><p>Caturegli said while he does have an account on Bugcrowd, he has never submitted anything through the Bugcrowd program, and that he reported this issue directly to MasterCard.</p><p>“I did not disclose this issue through Bugcrowd,” Caturegli wrote in reply. “Before making any public disclosure, I ensured that the affected domain was registered to prevent exploitation, mitigating any risk to MasterCard or its customers. This action, which we took at our own expense, demonstrates our commitment to ethical security practices and responsible disclosure.” </p><p>Most organizations have at least two authoritative domain name servers, but some handle so many DNS requests that they need to spread the load over additional DNS server domains. In MasterCard’s case, that number is five, so it stands to reason that if an attacker managed to seize control over just one of those domains they would only be able to see about one-fifth of the overall DNS requests coming in.</p><p>But Caturegli said the reality is that many Internet users are relying at least to some degree on public traffic forwarders or DNS resolvers like  and .</p><p>“So all we need is for one of these resolvers to query our name server and cache the result,” Caturegli said. By setting their DNS server records with a long TTL or “Time To Live” — a setting that can adjust the lifespan of data packets on a network — an attacker’s poisoned instructions for the target domain can be propagated by large cloud providers.</p><p>“With a long TTL, we may reroute a LOT more than just 1/5 of the traffic,” he said.</p><p>The researcher said he’d hoped that the credit card giant might thank him, or at least offer to cover the cost of buying the domain.</p><p>“We obviously disagree with this assessment,” Caturegli wrote in <a href=\"https://www.linkedin.com/feed/update/urn:li:activity:7285038365236682753?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7285038365236682753%2C7285289297706909697%29&amp;dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287285289297706909697%2Curn%3Ali%3Aactivity%3A7285038365236682753%29\" target=\"_blank\" rel=\"noopener\">a follow-up post</a> on LinkedIn regarding MasterCard’s public statement. “But we’ll let you judge— here are some of the DNS lookups we recorded before reporting the issue.”</p><div><img aria-describedby=\"caption-attachment-70125\" decoding=\"async\" loading=\"lazy\" src=\"https://krebsonsecurity.com/wp-content/uploads/2025/01/mastercard-domains.png\" alt=\"\" width=\"790\" height=\"561\" srcset=\"https://krebsonsecurity.com/wp-content/uploads/2025/01/mastercard-domains.png 790w, https://krebsonsecurity.com/wp-content/uploads/2025/01/mastercard-domains-768x545.png 768w, https://krebsonsecurity.com/wp-content/uploads/2025/01/mastercard-domains-782x555.png 782w, https://krebsonsecurity.com/wp-content/uploads/2025/01/mastercard-domains-100x70.png 100w\" sizes=\"(max-width: 790px) 100vw, 790px\"><p>Caturegli posted this screenshot of MasterCard domains that were potentially at risk from the misconfigured domain.</p></div><p>As the screenshot above shows, the misconfigured DNS server Caturegli found involved the MasterCard subdomain . It is not clear exactly how this subdomain is used by MasterCard, however their naming conventions suggest the domains correspond to production servers at Microsoft’s  cloud service. Caturegli said the domains all resolve to Internet addresses at Microsoft.</p><p>“Don’t be like Mastercard,” Caturegli concluded in his LinkedIn post. “Don’t dismiss risk, and don’t let your marketing team handle security disclosures.”</p><p>One final note: The domain akam.ne has been registered previously — in December 2016 by someone using the email address um-i-delo@yandex.ru. The Russian search giant Yandex reports this user account belongs to an “Ivan I.” from Moscow. Passive DNS records from <a href=\"https://www.domaintools.com\" target=\"_blank\" rel=\"noopener\">DomainTools.com</a> show that between 2016 and 2018 the domain was connected to an Internet server in Germany, and that the domain was left to expire in 2018.</p><p>This is interesting given <a href=\"https://www.linkedin.com/feed/update/urn:li:activity:7285038365236682753?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7285038365236682753%2C7285221445796835329%29&amp;replyUrn=urn%3Ali%3Acomment%3A%28activity%3A7285038365236682753%2C7285223757982363648%29&amp;dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287285221445796835329%2Curn%3Ali%3Aactivity%3A7285038365236682753%29&amp;dashReplyUrn=urn%3Ali%3Afsd_comment%3A%287285223757982363648%2Curn%3Ali%3Aactivity%3A7285038365236682753%29\" target=\"_blank\" rel=\"noopener\">a comment on Caturegli’s LinkedIn post from an ex-Cloudflare employee</a> who linked to a report he co-authored on a similar typo domain apparently registered in 2017 for organizations that may have mistyped their AWS DNS server as “” instead of “.” DomainTools reports that this typo domain also was registered to a Yandex user (playlotto@yandex.ru), and was hosted at the same German ISP — Team Internet (AS61969).</p>","contentLength":6248,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42793783"}],"tags":["dev","hn"]}