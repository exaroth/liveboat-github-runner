{"id":"VMK7D8tQvwsLtnxKHzNdF9c4Yhtuqm","title":"Hacker News: Best","displayTitle":"HN","url":"https://hnrss.org/best","feedLink":"https://news.ycombinator.com/best","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":30,"items":[{"title":"Motorola announces a partnership with GrapheneOS Foundation","url":"https://motorolanews.com/motorola-three-new-b2b-solutions-at-mwc-2026/","date":1772434087,"author":"km","guid":137,"unread":true,"content":"<p><b>GrapheneOS Foundation Partnership</b><a href=\"https://grapheneos.org/\"></a></p><p>Today, Motorola also introduced Moto Analytics, an enterprise‚Äëgrade analytics platform designed to give IT administrators real‚Äëtime visibility into device performance across their fleet. Unlike traditional EMM tools that focus primarily on access control, Moto Analytics provides deep operational insights, from app stability to battery health and connectivity performance.</p><p>Motorola is also expanding its Moto Secure platform with a new feature, Private Image Data. This tool gives users greater control over the hidden data stored in their photos. When enabled, it automatically removes sensitive metadata from all new camera images on the device, helping protect details like location and device information. This protection runs quietly in the background, preserving the image itself while clearing some of the private data attached to it.</p><p><a href=\"https://motorolanews.com/motorola-launches-new-moto-secure-app-to-give-consumers-more-peace-of-mind/\"></a></p><p>Certain features, functionality, and product specifications may be network-dependent and subject to additional terms, conditions, and charges. All are subject to change without notice. MOTOROLA, the Stylized M Logo, MOTO, and the MOTO family of marks are trademarks of Motorola Trademark Holdings, LLC. LENOVO and THINKSHIELD are trademarks of Lenovo. Android is a trademark of Google, LLC. All other trademarks are the property of their respective owners. ¬©2026 Motorola Mobility LLC. All rights reserved.</p>","contentLength":1385,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47214645"},{"title":"WebMCP is available for early preview","url":"https://developer.chrome.com/blog/webmcp-epp","date":1772403238,"author":"andsoitis","guid":131,"unread":true,"content":"<p>\n  Published: February 10, 2026\n</p><p>As the agentic web evolves, we want to help websites play an active role in how AI agents interact with them. WebMCP aims to provide a standard way for exposing structured tools, ensuring AI agents can perform actions on your site with increased speed, reliability, and precision.</p><p>By defining these tools, you tell agents how and where to interact with your site, whether it's booking a flight, filing a support ticket, or navigating complex data. This direct communication channel eliminates ambiguity and allows for faster, more robust agent workflows.</p><h2 data-text=\"Structured interactions for the agentic web\" tabindex=\"-1\">Structured interactions for the agentic web</h2><p>WebMCP proposes two new APIs that allow browser agents to take action on behalf of the user:</p><ul><li>: Perform standard actions that can be defined directly in HTML forms.</li><li>: Perform complex, more dynamic interactions that require JavaScript execution.</li></ul><p>These APIs serve as a bridge, making your website \"agent-ready\" and enabling more reliable and performant agent workflows compared to raw DOM actuation.</p><p>Imagine an agent that can handle complex tasks for your users with confidence and speed.</p><ul><li>: Help users create detailed customer support tickets, by enabling agents to fill in all of the necessary technical details automatically.</li><li>: Users can better shop your products when agents can easily find what they're looking for, configure particular shopping options, and navigate checkout flows with precision.</li><li>: Users could more easily get the exact flights they want, by allowing the agent to search, filter results, and handle bookings using structured data to ensure accurate results every time.</li></ul><h2 data-text=\"Join the early preview program\" tabindex=\"-1\">Join the early preview program</h2><p>WebMCP is available for prototyping to early preview program participants.</p><p>Sign up for the <a href=\"https://developer.chrome.com/docs/ai/join-epp\">early preview program</a> to gain access to the documentation and demos, stay up-to-date with the latest changes, and discover new APIs.</p>","contentLength":1861,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47211249"},{"title":"When does MCP make sense vs CLI?","url":"https://ejholmes.github.io/2026/02/28/mcp-is-dead-long-live-the-cli.html","date":1772384089,"author":"ejholmes","guid":129,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47208398"},{"title":"New iron nanomaterial wipes out cancer cells without harming healthy tissue","url":"https://www.sciencedaily.com/releases/2026/02/260228093456.htm","date":1772377795,"author":"gradus_ad","guid":165,"unread":true,"content":"<p>The work, led by Oleh Taratula, Olena Taratula, and Chao Wang from the OSU College of Pharmacy, was published in <em>Advanced Functional Materials</em>.</p><p><strong>Advancing Chemodynamic Therapy</strong></p><p>The discovery strengthens the growing field of chemodynamic therapy or CDT. This emerging cancer treatment strategy takes advantage of the unique chemical conditions found inside tumors. Compared with normal tissue, cancer cells tend to be more acidic and contain higher levels of hydrogen peroxide.</p><p>Traditional CDT uses these tumor conditions to spark the formation of hydroxyl radicals, highly reactive molecules made of oxygen and hydrogen that contain an unpaired electron. These reactive oxygen species damage cells through oxidation, stripping electrons from essential components such as lipids, proteins, and DNA.</p><p>More recent CDT approaches have also succeeded in generating singlet oxygen inside tumors. Singlet oxygen is another reactive oxygen species, named for its single electron spin state rather than the three spin states seen in the more stable oxygen molecules present in the air.</p><p><strong>Overcoming Limits of Existing CDT Agents</strong></p><p>\"However, existing CDT agents are limited,\" Oleh Taratula said. \"They efficiently generate either radical hydroxyls or singlet oxygen but not both, and they often lack sufficient catalytic activity to sustain robust reactive oxygen species production. Consequently, preclinical studies often only show partial tumor regression and not a durable therapeutic benefit.\"</p><p>To address these shortcomings, the team developed a new CDT nanoagent built from an iron-based metal-organic framework or MOF. This structure is capable of producing both hydroxyl radicals and singlet oxygen, increasing its cancer-fighting potential. The MOF demonstrated strong toxicity across multiple cancer cell lines while causing minimal harm to noncancerous cells.</p><p><strong>Complete Tumor Regression in Mice</strong></p><p>\"When we systemically administered our nanoagent in mice bearing human breast cancer cells, it efficiently accumulated in tumors, robustly generated reactive oxygen species and completely eradicated the cancer without adverse effects,\" Olena Taratula said. \"We saw total tumor regression and long-term prevention of recurrence, all without seeing any systemic toxicity.\"</p><p>In these preclinical experiments, tumors disappeared entirely and did not return, and the animals showed no signs of harmful side effects.</p><p><strong>Next Steps Toward Broader Cancer Treatment</strong></p><p>Before moving into human trials, the researchers plan to test the treatment in additional cancer types, including aggressive pancreatic cancer, to determine whether the approach can be effective across a wide range of tumors.</p><p>Other contributors to the study included Oregon State researchers Kongbrailatpam Shitaljit Sharma, Yoon Tae Goo, Vladislav Grigoriev, Constanze Raitmayr, Ana Paula Mesquita Souza, and Manali Parag Phawde. Funding was provided by the National Cancer Institute of the National Institutes of Health and the Eunice Kennedy Shriver National Institute of Child Health and Human Development.</p>","contentLength":3038,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47207404"},{"title":"AI Made Writing Code Easier. It Made Being an Engineer Harder","url":"https://www.ivanturkovic.com/2026/02/25/ai-made-writing-code-easier-engineering-harder/","date":1772374164,"author":"saikatsg","guid":164,"unread":true,"content":"<p>Yes, writing code is easier than ever.</p><p>AI assistants autocomplete your functions. Agents scaffold entire features. You can describe what you want in plain English and watch working code appear in seconds. The barrier to producing code has never been lower.</p><p>And yet, the day-to-day life of software engineers has gotten more complex, more demanding, and more exhausting than it was two years ago.</p><p>This is not a contradiction. It is the reality of what happens when an industry adopts a powerful new tool without pausing to consider the second-order effects on the people using it.</p><p>If you are a software engineer reading this and feeling like your job quietly became harder while everyone around you celebrates how easy everything is now, you are not imagining things. The job changed. The expectations changed. And nobody sent a memo.</p><h2>The Baseline Moved and Nobody Told You</h2><p>There is a phenomenon happening right now that most engineers feel but struggle to articulate. The expected output of a software engineer in 2026 is dramatically higher than it was in 2023. Not because anyone held a meeting and announced new targets. Not because your manager sat you down and explained the new rules. The baseline just moved.</p><p>It moved because AI tools made certain tasks faster. And when tasks become faster, the assumption follows immediately: you should be doing more. Not in the future. Now.</p><p>A February 2026 study published in Harvard Business Review tracked 200 employees at a U.S. tech company over eight months. The researchers found something that will sound familiar to anyone living through this shift. Workers did not use AI to finish earlier and go home. They used it to do more. They took on broader tasks, worked at a faster pace, and extended their hours, often without anyone asking them to. The researchers described a self-reinforcing cycle: AI accelerated certain tasks, which raised expectations for speed. Higher speed made workers more reliant on AI. Increased reliance widened the scope of what workers attempted. And a wider scope further expanded the quantity and density of work.</p><p>The numbers tell the rest of the story. Eighty-three percent of workers in the study said AI increased their workload. Burnout was reported by 62 percent of associates and 61 percent of entry-level workers. Among C-suite leaders? Just 38 percent. The people doing the actual work are carrying the intensity. The people setting the expectations are not feeling it the same way.</p><p>This gap matters enormously. If leadership believes AI is making everything easier while engineers are drowning in a new kind of complexity, the result is a slow erosion of trust, morale, and eventually talent.</p><p>A separate survey of over 600 engineering professionals found that nearly two-thirds of engineers experience burnout despite their organizations using AI in development. Forty-three percent said leadership was out of touch with team challenges. Over a third reported that productivity had actually decreased over the past year, even as their companies invested more in AI tooling.</p><p>The baseline moved. The expectations rose. And for many engineers, no one acknowledged that the job they signed up for had fundamentally changed.</p><h2>The Identity Crisis Nobody Talks About</h2><p>Here is something that gets lost in all the excitement about AI productivity: most software engineers became engineers because they love writing code.</p><p>Not managing code. Not reviewing code. Not supervising systems that produce code. Writing it. The act of thinking through a problem, designing a solution, and expressing it precisely in a language that makes a machine do exactly what you intended. That is what drew most of us to this profession. It is a creative act, a form of craftsmanship, and for many engineers, the most satisfying part of their day.</p><p>Now they are being told to stop.</p><p>Not explicitly, of course. Nobody walks into a standup and says ‚Äústop writing code.‚Äù But the message is there, subtle and persistent. Use AI to write it faster. Let the agent handle the implementation. Focus on higher-level tasks. Your value is not in the code you write anymore, it is in how well you direct the systems that write it for you.</p><p>For early adopters, this feels exciting. It feels like evolution. For a significant portion of working engineers, it feels like being told that the thing they spent years mastering, the skill that defines their professional identity, is suddenly less important.</p><p>One engineer captured this shift perfectly in a widely shared essay, describing how AI transformed the engineering role from builder to reviewer. Every day felt like being a judge on an assembly line that never stops. You just keep stamping those pull requests. The production volume went up. The sense of craftsmanship went down.</p><p>This is not a minor adjustment. It is a fundamental shift in professional identity. Engineers who built their careers around deep technical skill are being asked to redefine what they do and who they are, essentially overnight, without any transition period, training, or acknowledgment that something significant was lost in the process.</p><p>Having led engineering teams for over two decades, I have seen technology shifts before. New frameworks, new languages, new methodologies. Engineers adapt. They always have. But this is different because it is not asking engineers to learn a new way of doing what they do. It is asking them to stop doing the thing that made them engineers in the first place and become something else entirely.</p><p>That is not an upgrade. That is a career identity crisis. And pretending it is not happening does not make it go away.</p><h2>The Expanding Role: When Everything Becomes Your Problem</h2><p>While engineers are being asked to write less code, they are simultaneously being asked to do more of everything else.</p><p>More product thinking. More architectural decision-making. More code review. More context switching. More planning. More testing oversight. More deployment awareness. More risk assessment.</p><p>The scope of what it means to be a ‚Äúsoftware engineer‚Äù expanded dramatically in the last two years, and it happened without a pause to catch up.</p><p>This is partly a direct consequence of AI acceleration. When code gets produced faster, the bottleneck shifts. It moves from implementation to everything surrounding implementation: requirements clarity, architecture decisions, integration testing, deployment strategy, monitoring, and maintenance. These were always part of the engineering lifecycle, but they were distributed across roles. Product managers handled requirements. QA handled testing. DevOps handled deployment. Senior architects handled system design.</p><p>Now, with AI collapsing the implementation phase, organizations are quietly redistributing those responsibilities to the engineers themselves. The Harvard Business Review study documented this exact pattern. Product managers began writing code. Engineers took on product work. Researchers started doing engineering tasks. Roles that once had clear boundaries blurred as workers used AI to handle jobs that previously sat outside their remit.</p><p>The industry is openly talking about this as a positive development. Engineers should be ‚ÄúT-shaped‚Äù or ‚Äúfull-stack‚Äù in a broader sense. Nearly 45 percent of engineering roles now expect proficiency across multiple domains. AI tools augment generalists more effectively, making it easier for one person to handle multiple components of a system.</p><p>On paper, this sounds empowering. In practice, it means that a mid-level backend engineer is now expected to understand product strategy, review AI-generated frontend code they did not write, think about deployment infrastructure, consider security implications of code they cannot fully trace, and maintain a big-picture architectural awareness that used to be someone else‚Äôs job.</p><p>That is not empowerment. That is scope creep without a corresponding increase in compensation, authority, or time.</p><p>From my experience building and scaling teams in fintech and high-traffic platforms, I can tell you that role expansion without clear boundaries always leads to the same outcome: people try to do everything, nothing gets done with the depth it requires, and burnout follows. The engineers who survive are the ones who learn to say no, to prioritize ruthlessly, and to push back when the scope of their role quietly doubles without anyone acknowledging it.</p><p>There is an irony at the center of the AI-assisted engineering workflow that nobody wants to talk about: reviewing AI-generated code is often harder than writing the code yourself.</p><p>When you write code, you carry the context of every decision in your head. You know why you chose this data structure, why you handled this edge case, why you structured the module this way. The code is an expression of your thinking, and reviewing it later is straightforward because the reasoning is already stored in your memory.</p><p>When AI writes code, you inherit the output without the reasoning. You see the code, but you do not see the decisions. You do not know what tradeoffs were made, what assumptions were baked in, what edge cases were considered or ignored. You are reviewing someone else‚Äôs work, except that someone is not a colleague you can ask questions. It is a statistical model that produces plausible-looking code without any understanding of your system‚Äôs specific constraints.</p><p>A survey by Harness found that 67 percent of developers reported spending more time debugging AI-generated code, and 68 percent spent more time reviewing it than they did with human-written code. This is not a failure of the tools. It is a structural property of the workflow. Code review without shared context is inherently more demanding than reviewing code you participated in creating.</p><p>Yet the expectation from management is that AI should be making everything faster. So engineers find themselves in a bind: they are producing more code than ever, but the quality assurance burden has increased, the context-per-line-of-code has decreased, and the cognitive load of maintaining a system they only partially built is growing with every sprint.</p><p>This is the supervision paradox. The faster AI generates code, the more human attention is required to ensure that code actually works in the context of a real system with real users and real business constraints. The production bottleneck did not disappear. It moved from writing to understanding, and understanding is harder to speed up.</p><p>What makes all of this especially difficult is the self-reinforcing nature of the cycle.</p><p>AI makes certain tasks faster. Faster tasks create the perception of more available capacity. More perceived capacity leads to more work being assigned. More work leads to more AI reliance. More AI reliance leads to more code that needs review, more context that needs to be maintained, more systems that need to be understood, and more cognitive load on engineers who are already stretched thin.</p><p>The Harvard Business Review researchers described this as ‚Äúworkload creep.‚Äù Workers did not consciously decide to work harder. The expansion happened naturally, almost invisibly. Each individual step felt reasonable. In aggregate, it produced an unsustainable pace.</p><p>Before AI, there was a natural ceiling on how much you could produce in a day. That ceiling was set by thinking speed, typing speed, and the time it takes to look things up. It was frustrating sometimes, but it was also a governor. A natural speed limit that prevented you from outrunning your own ability to maintain quality.</p><p>AI removed the governor. Now the only limit is your cognitive endurance. And most people do not know their cognitive limits until they have already blown past them.</p><p>This is where many engineers find themselves right now. Shipping more code than any quarter in their career. Feeling more drained than any quarter in their career. The two facts are not unrelated.</p><p>The trap is that it looks like productivity from the outside. Metrics go up. Velocity charts look great. More features shipped. More pull requests merged. But underneath the numbers, quality is quietly eroding, technical debt is accumulating faster than it can be addressed, and the people doing the work are running on fumes.</p><h2>What Junior Engineers Are Facing</h2><p>If the picture is difficult for experienced engineers, it is even harder for those starting their careers.</p><p>Junior engineers have traditionally learned by doing the simpler, more task-oriented work. Fixing small bugs. Writing straightforward features. Implementing well-defined tickets. This hands-on work built the foundational understanding that eventually allowed them to take on more complex challenges.</p><p>AI is rapidly consuming that training ground. If an agent can handle the routine API hookup, the boilerplate module, the straightforward CRUD endpoint, what is left for a junior engineer to learn from? The expectation is shifting toward needing to contribute at a higher level almost from day one, without the gradual ramp-up that previous generations of engineers relied on.</p><p>Entry-level hiring at the 15 largest tech firms fell 25 percent from 2023 to 2024. The HackerRank 2025 Developer Skills Report confirmed that expectations are rising faster than productivity gains, and that early-career hiring remains sluggish compared to senior-level roles. Companies are prioritizing experienced talent, but the pipeline that produces experienced talent is being quietly dismantled.</p><p>This is a problem that extends beyond individual career concerns. If junior engineers do not get the opportunity to build foundational skills through hands-on work, the industry will eventually face a shortage of senior engineers who truly understand the systems they oversee. You cannot supervise what you never learned to build.</p><p>As I have written before, code is for humans to read. If the next generation of engineers never develops the fluency to read, understand, and reason about code at a deep level, no amount of AI tooling will compensate for that gap.</p><h2>What Good Leadership Looks Like Right Now</h2><p>If you lead engineering teams, the most important thing you can do right now is acknowledge that this transition is genuinely difficult. Not theoretically. Not abstractly. For the actual people on your team.</p><p>The career they signed up for changed fast. The skills they were hired for are being repositioned. The expectations they are working under shifted without a clear announcement. Acknowledging this reality is not a sign of weakness. It is a prerequisite for maintaining a team that trusts you.</p><p>Start with empathy, but do not stop there.</p><p>Give your team real training. Not a lunch-and-learn about prompt engineering. Real investment in the skills that the new engineering landscape actually requires: system design, architectural thinking, product reasoning, security awareness, and the ability to critically evaluate code they did not write. These are not trivial skills. They take time to develop, and your team needs structured support to build them.</p><p>Give them space to experiment without the pressure of immediate productivity gains. The engineers who will thrive in this environment are the ones who have room to figure out how AI fits into their workflow without being penalized for the learning curve. Every experienced technologist I know who has successfully integrated AI tools went through an adjustment period where they were less productive before they became more productive. That adjustment period is normal, and it needs to be protected.</p><p>Set explicit boundaries around role scope. If you are asking engineers to take on product thinking, planning, and risk assessment in addition to their technical work, name it. Define it. Compensate for it. Do not let it happen silently and then wonder why your team is burned out.</p><p>Rethink your metrics. If your engineering success metrics are still centered on velocity, tickets closed, and lines of code, you are measuring the wrong things in an AI-assisted world. System stability, code quality, decision quality, customer outcomes, and team health are better indicators of whether your engineering organization is actually producing value or just producing volume.</p><p>Protect the junior pipeline. If you have stopped hiring junior engineers because AI can handle entry-level tasks, you are solving a short-term efficiency problem by creating a long-term talent crisis. The senior engineers you rely on today were junior engineers who learned by doing the work that AI is now consuming. That path still matters.</p><p>And finally, keep challenging your team. I have never met a good engineer who did not love a good challenge. The engineers on your team are not fragile. They are capable, intelligent people who signed up for hard problems. They can handle this transition. Just make sure they are set up to meet it.</p><h2>What Engineers Can Do for Themselves</h2><p>If you are an engineer navigating this shift, here is what I would tell you based on two decades of watching technology cycles reshape this profession.</p><p>First, do not abandon your fundamentals. The pressure to become an ‚ÄúAI-first‚Äù engineer is real, but the engineers who will be most valuable in five years are the ones who deeply understand the systems they work on. AI is a tool. Understanding architecture, debugging complex systems, reasoning about performance and security: these skills are not becoming less important. They are becoming more important because someone needs to be the adult in the room when AI-generated code breaks in production at 2 AM.</p><p>Second, learn to set boundaries with the acceleration trap. Just because you can produce more does not mean you should. Sustainable pace matters. The engineers who burn out trying to match the theoretical maximum output AI makes possible are not the ones who build lasting careers. The ones who learn to work with AI deliberately, choosing when to use it and when to think independently, are the ones who will still be thriving in this profession a decade from now.</p><p>Third, embrace the parts of the expanded role that genuinely interest you. If the engineering role now includes more product thinking, more architectural decision-making, more cross-functional communication, treat that as an opportunity rather than an imposition. These are skills that senior engineers and technical leaders need. You are being given access to a broader set of capabilities earlier in your career than any previous generation of engineers. That is not a burden. It is a head start.</p><p>Fourth, talk about what you are experiencing. The isolation of feeling like you are the only one struggling with this transition is one of the most damaging aspects of the current moment. You are not the only one. The data confirms it. Two-thirds of engineers report burnout. The expectation gap between leadership and engineering teams is well documented. Talking openly about these challenges, with your team, with your manager, with your broader network, is not complaining. It is professional honesty.</p><p>And fifth, remember that this profession has survived every prediction of its demise. COBOL was supposed to eliminate programmers. Expert systems were supposed to replace them. Fourth-generation languages, CASE tools, visual programming, no-code platforms, outsourcing. Every decade brings a new technology that promises to make software engineers obsolete, and every decade the demand for skilled engineers grows. AI will not be different. The tools change. The fundamentals endure.</p><h2>The Paradox We Need to Name</h2><p>AI made writing code easier and made being an engineer harder. Both of these things are true at the same time, and pretending that only the first one matters is how organizations lose their best people.</p><p>The engineers who are struggling right now are not struggling because they are bad at their jobs. They are struggling because their jobs changed underneath them while the industry celebrated the part that got easier and ignored the parts that got harder.</p><p>Expectations rose without announcement. Roles expanded without boundaries. Output demands increased without corresponding increases in support, training, or acknowledgment. And the engineers who raised concerns were told, implicitly or explicitly, that they just needed to adapt faster.</p><p>That is not how you build a sustainable engineering culture. That is how you build a burnout machine.</p><p>The industry needs to name this paradox honestly. AI is an incredible tool. It is also placing enormous new demands on the people using it. Both things can be true. Both things need to be addressed.</p><p>The organizations that get this right, that invest in their people alongside their tools, that acknowledge the human cost of rapid technological change while still pushing forward, those are the organizations that will attract and retain the best engineering talent in the years ahead.</p><p>The ones that do not will discover something that every technology cycle eventually teaches: tools do not build products. People do. And people have limits that no amount of AI can automate away.</p><p><em>If this resonated with you, I would love to hear your perspective. What has changed most about your engineering role in the last year? Drop me a message or connect with me on <a href=\"https://www.linkedin.com/in/ivanturkovic/\">LinkedIn</a>. I write regularly about the intersection of AI, software engineering, and leadership at <a href=\"https://ivanturkovic.com\">ivanturkovic.com</a>. Follow along if you want honest, experience-driven perspectives on how technology is actually changing this profession.</em></p>","contentLength":21396,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47206824"},{"title":"Ghostty ‚Äì Terminal Emulator","url":"https://ghostty.org/docs","date":1772367183,"author":"oli5679","guid":126,"unread":true,"content":"<p>Ghostty is a fast, feature-rich, and cross-platform terminal emulator\nthat uses platform-native UI and GPU acceleration.</p>","contentLength":120,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47206009"},{"title":"I built a demo of what AI chat will look like when it's ‚Äúfree‚Äù and ad-supported","url":"https://99helpers.com/tools/ad-supported-chat","date":1772365741,"author":"nickk81","guid":163,"unread":true,"content":"<div>üì∫ Advertisement ‚Äî Before Your Free Chat</div><p>The #1 AI Productivity App of 2025!</p><p>Join  who think faster, focus better, and accomplish more. AI-powered goal tracking, habit building, and memory enhancement.</p>","contentLength":203,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47205890"},{"title":"Microgpt explained interactively","url":"https://growingswe.com/blog/microgpt","date":1772358223,"author":"growingswe","guid":124,"unread":true,"content":"<p><em>Trying my best to visualize it. I'm a n00b at machine learning though</em></p><p><a href=\"https://gist.github.com/karpathy/8627fe009c40f57531cb18360106ce95\" target=\"_blank\" rel=\"noopener noreferrer\">Andrej Karpathy wrote a 200-line Python script that trains and runs a GPT from scratch</a>, with no libraries or dependencies, just pure Python. The script contains the algorithm that powers LLMs like ChatGPT.</p><p>Let's walk through it piece by piece and watch each part work. <a href=\"https://karpathy.github.io/2026/02/12/microgpt/\" target=\"_blank\" rel=\"noopener noreferrer\">Andrej did a walkthrough on his blog</a>, but here I take a more visual approach, tailored for beginners.</p><p>The model trains on 32,000 human names, one per line: emma, olivia, ava, isabella, sophia... Each name is a document. The model's job is to learn the statistical patterns in these names and generate plausible new ones that sound like they could be real.</p><p>By the end of training, the model produces names like \"kamon\", \"karai\", \"anna\", and \"anton\".The model has learned which characters tend to follow which, which sounds are common at the start vs. the end, and how long a typical name runs. From ChatGPT's perspective, your conversation is just a document. When you type a prompt, the model's response is a statistical document completion.</p><p>Neural networks work with numbers, not characters. So we need a way to convert text into a sequence of integers and back. The simplest possible tokenizer assigns one integer to each unique character in the dataset. The 26 lowercase letters get ids 0 through 25, and we add one special token called BOS (Beginning of Sequence) with id 26 that marks where a name starts and ends.</p><p>Type a name below and watch it get tokenized. Each character maps to its integer id, and BOS tokens wrap both ends:</p><div><div><svg width=\"100%\" height=\"124\" viewBox=\"0 0 420 124\" preserveAspectRatio=\"xMidYMid meet\" font-family=\"ui-monospace, SFMono-Regular, &quot;SF Mono&quot;, Menlo, Consolas, monospace\"></svg></div></div><div data-presentation-hide=\"\"><p>The integer values themselves have no meaning. Token 4 isn't \"more\" than token 2. Each token is just a distinct symbol, like assigning a different color to each letter. Production tokenizers like tiktoken (used by GPT-4) work on chunks of characters for efficiency, giving a vocabulary of ~100,000 tokens, but the principle is the same.</p></div><p>Here's the core task: given the tokens we've seen so far, predict what comes next. We slide through the sequence one position at a time. At position 0, the model sees only BOS and must predict the first letter. At position 1, it sees BOS and the first letter and must predict the second letter. And so on.</p><p>Step through the sequence below and watch the context grow while the target shifts forward:</p><div><div><svg width=\"100%\" height=\"104\" viewBox=\"0 0 420 104\" preserveAspectRatio=\"xMidYMid meet\" font-family=\"ui-monospace, SFMono-Regular, &quot;SF Mono&quot;, Menlo, Consolas, monospace\"></svg></div></div><p>Each step produces one training example: the context on the left is the input, the green token on the right is what the model should predict. For the name \"emma\", that's five input-target pairs. This sliding window is how all language models train, including ChatGPT.</p><h2></h2><p>At each position, the model outputs 27 raw numbers, one per possible next token. These numbers (called ) can be anything: positive, negative, large, small. We need to convert them into probabilities that are positive and sum to 1.  does this by exponentiating each score and dividing by the total.</p><p>Adjust the logits below and watch the probability distribution change. Notice how one large logit dominates, and the exponential amplifies differences.</p><div><div><svg width=\"100%\" height=\"192\" viewBox=\"0 0 420 192\" preserveAspectRatio=\"xMidYMid meet\" font-family=\"ui-monospace, SFMono-Regular, &quot;SF Mono&quot;, Menlo, Consolas, monospace\"></svg></div></div><p>Here's the actual softmax code from microgpt. Step through it to see the intermediate values at each line:</p><div><div><div><div><svg width=\"100%\" height=\"144\" viewBox=\"0 0 240 144\" preserveAspectRatio=\"xMidYMid meet\" font-family=\"ui-monospace, SFMono-Regular, &quot;SF Mono&quot;, Menlo, Consolas, monospace\"></svg></div></div></div></div><div data-presentation-hide=\"\"><p>The subtraction of the max value before exponentiating doesn't change the result mathematically (dividing numerator and denominator by the same constant cancels out) but prevents overflow. Without it,  would produce infinity.</p></div><p>How wrong was the prediction? We need a single number that captures \"the model thought the correct answer was unlikely.\" If the model assigns probability 0.9 to the correct next token, the loss is low (0.1). If it assigns probability 0.01, the loss is high (4.6). The formula is  where  is the probability the model assigned to the correct token. This is called .</p><p>Drag the slider to adjust the probability of the correct token and watch the loss change:</p><div><div><svg width=\"100%\" height=\"200\" viewBox=\"0 0 420 200\" preserveAspectRatio=\"xMidYMid meet\" font-family=\"ui-monospace, SFMono-Regular, &quot;SF Mono&quot;, Menlo, Consolas, monospace\"></svg></div></div><p>The curve has two properties that make it useful. First, it's zero when the model is perfectly confident in the right answer (). Second, it goes to infinity as the model assigns near-zero probability to the truth (), which punishes confident wrong answers severely. Training minimizes this number.</p><h2></h2><p>To improve, the model needs to answer: \"for each of my 4,192 , if I nudge it up by a tiny amount, does the loss go up or down, and by how much?\"  computes this by walking the computation backward, applying the  at each step.</p><p>Every mathematical operation (add, multiply, exp, log) is a node in a graph. Each node remembers its inputs and knows its local derivative. The backward pass starts at the loss (where the  is trivially 1.0) and multiplies local derivatives along every path back to the inputs.</p><p>Step through the forward pass, then the backward pass for a small example where  with :</p><p>Now step through the actual  class code. Watch how each operation records its children and local gradients, then how  walks the graph in reverse, accumulating gradients:</p><div data-presentation-hide=\"\"><p>Notice that  has a gradient of 4.0, not 3.0. That's because  is used in two places: once in the multiplication () and once in the addition (). The gradients from both paths sum up: . This is the multivariable chain rule in action. If a value contributes to the loss through multiple paths, the total derivative is the sum of contributions from each path.</p><p>This is the same algorithm that PyTorch's  runs, operating on scalars instead of tensors.</p></div><p>We know how to measure error and how to trace that error back to every parameter. Now let's build the model itself, starting with how it represents tokens.</p><p>A raw token id like 4 is just an index. The model can't do math with a bare integer. So each token looks up a learned vector (a list of 16 numbers) from an  table. Think of it as each token having a 16-dimensional \"personality\" that the model can adjust during training.</p><p>Position matters too. The letter \"a\" at position 0 plays a different role than \"a\" at position 4. So there's a second embedding table indexed by position. The token embedding and position embedding are added together to form the input to the rest of the network.</p><p>Click a token below to see its embedding vectors and how they combine:</p><div><div><svg width=\"100%\" height=\"200\" viewBox=\"0 0 420 200\" preserveAspectRatio=\"xMidYMid meet\" font-family=\"ui-monospace, SFMono-Regular, &quot;SF Mono&quot;, Menlo, Consolas, monospace\"></svg></div></div><div data-presentation-hide=\"\"><p>The embedding values start as small random numbers and get tuned during training. After training, tokens that behave similarly (like vowels) tend to end up with similar embedding vectors. The model learns these representations from scratch, with no prior knowledge of what a vowel is.</p></div><h2></h2><p>This is how  work. At each position, the model needs to gather information from previous positions. It does this through : each token produces three vectors from its embedding.</p><p>A  (\"what am I looking for?\"), a  (\"what do I contain?\"), and a  (\"what information do I offer if selected?\"). The query at the current position is compared against all keys from previous positions via . High dot product means high relevance. Softmax converts these scores into attention weights, and the weighted sum of values is the output.</p><p>Explore the attention weights below. Each cell shows how much one position attends to another. Switch between the four attention heads to see different patterns:</p><div><div><svg width=\"100%\" height=\"334\" viewBox=\"0 0 420 334\" preserveAspectRatio=\"xMidYMid meet\" font-family=\"ui-monospace, SFMono-Regular, &quot;SF Mono&quot;, Menlo, Consolas, monospace\"></svg></div></div><div data-presentation-hide=\"\"><p>The gray region in the upper-right is the causal mask. Position 2 can't attend to position 4 because position 4 hasn't happened yet. This is what makes the model : each position only sees the past.</p><p>Different heads learn different patterns. One head might attend strongly to the most recent token. Another might focus on the BOS token (to remember \"we're generating a name\"). A third might look for vowels. The four heads run in parallel, each operating on a 4-dimensional slice of the 16-dimensional embedding, and their outputs are concatenated and projected back to 16 dimensions.</p></div><p>The model pipes each token through: embed, normalize, attend, add , normalize, MLP, add residual, project to output logits. The  (multilayer perceptron) is a two-layer feed-forward network: project up to 64 dimensions, apply  (zero out negatives), project back to 16. If attention is how tokens communicate, the MLP is where each position thinks independently.</p><p>Step through the pipeline for one token and watch data flow through each stage:</p><div><div><svg width=\"100%\" height=\"120\" viewBox=\"0 0 420 120\" preserveAspectRatio=\"xMidYMid meet\" font-family=\"ui-monospace, SFMono-Regular, &quot;SF Mono&quot;, Menlo, Consolas, monospace\"></svg></div></div><p>Here's the actual  function from microgpt. Step through to see the code executing line by line, with the intermediate vector at each stage:</p><div data-presentation-hide=\"\"><p>The residual connections (the \"Add\" steps) are load-bearing. Without them, gradients would shrink to near-zero by the time they reach the early layers, and training would stall. The residual connection gives gradients a shortcut, which is why deep networks can train at all.</p><p>RMSNorm (root-mean-square normalization) rescales each vector to have unit root-mean-square. This prevents activations from growing or shrinking as they pass through the network, which stabilizes training. GPT-2 used LayerNorm; RMSNorm is simpler and works just as well.</p></div><p>The training loop repeats 1,000 times: pick a name, tokenize it, run the model forward over every position, compute the cross-entropy loss at each position, average the losses, backpropagate to get gradients for every parameter, and update the parameters to make the loss a bit lower.</p><p>The optimizer is Adam, which is smarter than naive gradient descent. It maintains a running average of each parameter's recent gradients (momentum) and a running average of the squared gradients (adaptive ). Parameters that have been getting consistent gradients take larger steps. Parameters that have been oscillating take smaller ones.</p><p>Watch the loss decrease over 1,000 training steps. The model starts at ~3.3 (random guessing among 27 tokens: ) and settles around 2.37. The generated names evolve from gibberish to plausible:</p><div><div><div><div><svg width=\"100%\" height=\"180\" viewBox=\"0 0 420 180\" preserveAspectRatio=\"xMidYMid meet\" font-family=\"ui-monospace, SFMono-Regular, &quot;SF Mono&quot;, Menlo, Consolas, monospace\"></svg></div></div></div></div><p>Step through the code for one complete training iteration. Watch it pick a name, run the forward pass at each position, compute the loss, run backward, and update the parameters:</p><p>Once training is done,  is straightforward. Start with BOS, run the forward pass, get 27 probabilities, randomly sample one token, feed it back in, and repeat until the model outputs BOS again (meaning \"I'm done\") or we hit the maximum length.</p><p>Temperature controls how we sample. Before softmax, we divide the logits by the temperature. A temperature of 1.0 samples directly from the learned distribution. Lower temperatures sharpen the distribution (the model picks its top choices more often). Higher temperatures flatten it (more diverse but potentially less coherent output).</p><p>Adjust the temperature and watch the probability distribution change:</p><div><div><svg width=\"100%\" height=\"164\" viewBox=\"0 0 420 164\" preserveAspectRatio=\"xMidYMid meet\" font-family=\"ui-monospace, SFMono-Regular, &quot;SF Mono&quot;, Menlo, Consolas, monospace\"></svg></div></div><p>Step through the inference loop to see a name being generated character by character. At each step, the model runs forward, produces probabilities, and samples the next token:</p><div data-presentation-hide=\"\"><p>A temperature approaching 0 would always pick the highest-probability token (greedy decoding). This produces the most \"average\" output. A temperature of 1.0 matches what the model actually learned. Values above 1.0 inject extra randomness, which can produce creative outputs but also nonsense. The sweet spot for names is around 0.5.</p></div><h2></h2><p>This 200-line script contains the complete algorithm. Between this and ChatGPT, litte changes conceptually. The differences are things like: trillions of tokens instead of 32,000 names. Subword tokenization (100K vocabulary) instead of characters. Tensors on GPUs instead of scalar  objects in Python. Hundreds of billions of parameters instead of 4,192. Hundreds of layers instead of one. Training across thousands of GPUs for months.</p><p>But the loop is the same. Tokenize, embed, attend, compute, predict the next token, measure surprise, walk the gradients backward, nudge the parameters. Repeat.</p>","contentLength":11459,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47205208"},{"title":"Decision trees ‚Äì the unreasonable power of nested decision rules","url":"https://mlu-explain.github.io/decision-tree/","date":1772355352,"author":"mschnell","guid":123,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47204964"},{"title":"Switch to Claude without starting over","url":"https://claude.com/import-memory","date":1772350612,"author":"doener","guid":162,"unread":true,"content":"<p>You‚Äôve spent months teaching another AI how you work. That context shouldn‚Äôt disappear because you want to try something new. Claude can import what matters, so your first conversation feels like your hundredth.</p>","contentLength":215,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47204571"},{"title":"10-202: Introduction to Modern AI (CMU)","url":"https://modernaicourse.org/","date":1772350503,"author":"vismit2000","guid":161,"unread":true,"content":"<ul><li> MW[F] 9:30‚Äì10:50 Tepper 1403 (note: Friday lectures will only be used for review sessions or makeup lectures when needed)</li></ul>\n    A minimal free version of this course will be offered online, simultaneous to the CMU offering, starting on 1/26 (with a two-week delay from the CMU course).  This means that  (lecture videos, assignments available on mugrade, etc) will be available to the online course  after the dates indicated in the schedule below.  By this, we mean that anyone will be able to watch lecture videos for the course, and submit (autograded) assignments (though not quizzes or midterms/final).  <a href=\"https://modernaicourse.org/enroll.html\">Enroll here</a> to receive emails on lectures and homeworks once they are available.  Note that information here about TAs, office hours, grading, prerequisites, etc, are for the CMU version, not the online offering.\n\n  <p>\n    This course provides an introduction to how modern AI systems work. By ‚Äúmodern AI‚Äù, we specifically mean the machine learning methods and large language models (LLMs) behind systems like ChatGPT, Gemini, and Claude.\n    <a href=\"https://modernaicourse.org/#\" onclick=\"toggleFootnote('fn1-box', this); return false;\">[Note]</a>\n    Despite their seemingly amazing generality, the basic techniques that underlie these AI models are surprisingly simple: a minimal LLM implementation leverages a fairly small set of machine learning methods and architectures, and can be written in a few hundred lines of code.\n  </p><p>\n    This course will guide you through the basic methods that will let you implement a basic AI chatbot. You will learn the basics of supervised machine learning, large language models, and post-training. By the end of the course you will be able to write the code that runs an open source LLM from scratch, as well as train these models based upon a corpus of data. The material we cover will include:\n  </p><ul><li>Supervised machine learning\n      <ul><li>Loss functions and optimization</li></ul></li><li>Large language models\n      <ul><li>Self attention and transformers</li></ul></li><li>Post-training\n      <ul><li>Alignment and instruction tuning</li><li>Reasoning models and reinforcement learning</li><li>Safety and security of AI systems</li></ul></li></ul><p>\n    The topics above are a general framing of what the course will cover. However, as this course is being offered for the first time in Spring 2026, some elements are likely to change over the first offering.\n  </p><ul><li>20% - Homework and Programming Assignments</li><li>40% - Midterms and Final (10% each midterm, 20% final)</li></ul><ul><li> 15-112 or 15-122. You must be proficient in basic Python programming, including object oriented methods.</li><li> 21-111 or 21-120. The course will use basic methods from differential calculus, including computing derivatives. Some familiarity with linear algebra and probability is also beneficial, but these topics will be covered to the extent needed for the course.</li></ul><h2>Homework and Programming Assignments</h2><p>\n    A major component of the course will be the development of a minimal AI chatbot through a series of programming assignments.  Homeworks are submitted using <a href=\"https://mugrade.org\">mugrade</a> system (<a href=\"https://youtu.be/jrtb9y6xg6U\">tutorial video</a>). Some assignments build on previous ones, though for the in-class CMu version we'll distribute solutions to help you work through any errors that may have cropped up in previous assignments (for the online version, we'd suggest talking to others who were able to complete the assignment). In addition to the (main) programming aspect, some homeworks may contain  shorter written portion that works out some of the mathematical details behind the approach.\n  </p><p>\n    All homeworks are released as Colab notebooks, at the links below.  We are also releasing <a href=\"https://marimo.io/\">Marimo</a> notebook versions.  The mugrade version of the online assignment will be available two weeks after the release dates for the CMU course.\n  </p><p>\n    Each homework will be accompanied by an in-class (15 minute) quiz that assesses basic questions based upon the assignment. This will include replicating (at a high level) some of the code you wrote for the assignment, or answering conceptual questions about the assignment. All quizzes are closed book and closed notes.\n  </p><p>\n    In addition to the homework quizzes, there will be 3 in-person exams, two midterms and a final (during finals period). The midterms will focus on material only covered during that section of the courses, while the final will be cumulative (but with an emphasis on the last third of the course). All midterms and final and closed book and closed notes.\n  </p><p>\n    Lecture schedule is tentative and will be updated over the course of semester.  All materials will be available to the online course two weeks after the dates here.\n  </p><table border=\"0\" cellspacing=\"0\" cellpadding=\"4\"><tbody><tr></tr><tr><td>Intro to supervised learning (<a href=\"https://youtu.be/xIQkf7ZGQhM\">video</a>) </td></tr><tr><td>Linear algebra and PyTorch (<a href=\"https://youtu.be/tlbLH77GFLQ\">video</a>) </td></tr><tr></tr><tr><td>Loss functions and probability (<a href=\"https://youtu.be/v3-kn7ErcE4\">video</a>) </td></tr><tr><td>Optimization and gradient descent (<a href=\"https://youtu.be/zKSghsymDdc\">video</a>) </td></tr><tr><td>Putting it together: Training a linear model (<a href=\"https://youtu.be/DaZFJ1tKbAQ\">video</a>)/td&gt;</td></tr><tr><td>Neural networks models (<a href=\"https://youtu.be/9ukf-DPcqcQ\">video</a>) </td></tr><tr><td>Neural network implementation</td></tr><tr><td><strong>Midterm 1 - Supervised machine learning</strong></td></tr><tr><td>Sequence models: handling sets of inputs</td></tr><tr><td>Self attention and positional embeddings</td></tr><tr></tr><tr></tr><tr></tr><tr><td>Efficient inference and key-value caching</td></tr><tr><td>Putting it together: your first LLM</td></tr><tr><td><strong>Midterm 2 - Large Language Models</strong></td></tr><tr></tr><tr><td>Alignment and instruction/chat tuning</td></tr><tr></tr><tr><td>Reinforcement learning basics</td></tr><tr></tr><tr></tr><tr><td>The future: AGI and beyond</td></tr></tbody></table><h2>AI Policy for the AI course</h2><p>\n    Students are permitted to use AI assistants for all homework and programming assignments (especially as a reference for understanding any topics that seem confusing), but we strongly encourage you to complete your final submitted version of your assignment without AI. You cannot use any such assistants, or any external materials, during in-class evaluations (both the homework quizzes and the midterms and final).\n  </p><p>\n    The rationale behind this policy is a simple one: AI can be extremely helpful as a learning tool (and to be clear, as an actual implementation tool), but over-reliance on these systems can currently be a detriment to learning in many cases. You  need to learn how to code and do other tasks using AI tools, but turning in AI-generated solutions for the relatively short assignments we give you can (at least in our current experience) ultimately lead to substantially less understanding of the material. The choice is yours on assignments, but we believe that you will ultimately perform much better on the in-class quizzes and exams if you do work through your final submitted homework solutions yourself.\n  </p>","contentLength":6211,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47204559"},{"title":"Microgpt","url":"http://karpathy.github.io/2026/02/12/microgpt/","date":1772329166,"author":"tambourine_man","guid":160,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47202708"},{"title":"Claude becomes number one app on the U.S. App Store","url":"https://apps.apple.com/us/iphone/charts","date":1772323728,"author":"byincugnito","guid":159,"unread":true,"content":"<p>Simple. Reliable. Private.</p>","contentLength":26,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47202032"},{"title":"The Windows 95 user interface: A case study in usability engineering (1996)","url":"https://dl.acm.org/doi/fullHtml/10.1145/238386.238611","date":1772317176,"author":"ksec","guid":158,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47200904"},{"title":"Iran's Ayatollah Ali Khamenei is killed in Israeli strike, ending 36-year rule","url":"https://www.npr.org/2026/02/28/1123499337/iran-israel-ayatollah-ali-khamenei-killed","date":1772316968,"author":"andsoitis","guid":157,"unread":true,"content":"<div><div><div><div aria-label=\"Image caption\"><p>\n                In this 2017 photo, Ayatollah Ali Khamenei, Iran's supreme leader, sits in a session to deliver his message for the Iranian New Year. A portrait of the late revolutionary founder, Ayatollah Ruhollah Khomeini, is next to him.\n                <b aria-label=\"Image credit\">\n                    \n                    Office of the Iranian Supreme Leader/AP\n                    \n                </b></p></div></div></div><div><div><p>In this 2017 photo, Ayatollah Ali Khamenei, Iran's supreme leader, sits in a session to deliver his message for the Iranian New Year. A portrait of the late revolutionary founder, Ayatollah Ruhollah Khomeini, is next to him.</p></div></div></div><p>Iran's supreme leader, Ayatollah Ali Khamenei, was <a href=\"https://www.npr.org/2026/02/28/nx-s1-5730158/israel-iran-strikes-trump-us\" target=\"_blank\">killed in Israeli attacks</a>, with U.S. support, on Saturday. He was 86 years old.</p><p>His death was confirmed by <a href=\"https://truthsocial.com/@realDonaldTrump/posts/116150413051904167\" target=\"_blank\">President Trump</a>, who joined Israeli leaders in calling for the overthrow of Khamenei's authoritarian regime as the U.S. and Israel launched airstrikes across Iran. The Israeli military said its forces killed Khamenei. The Iranian government confirmed the supreme leader's death and announced 40 days of mourning.</p><p>During his 36-year rule, Khamenei was unwavering in his steadfast antipathy to the U.S. and Israel and to any efforts to reform and bring Iran into the 21st century.</p><p>Khamenei was born in July 1939 into a religious family in the Shia Muslim holy city of Mashhad in northeastern Iran and attended theological school. An outspoken opponent of the U.S.-backed Shah Mohammad Reza Pahlavi, Khamenei was arrested several times.</p><p>He was surrounded by other Iranian activists, including Ayatollah Ruhollah Khomeini, who became Iran's first supreme leader following the country's Islamic Revolution in the late 1970s.</p><p>Khamenei survived an assassination attempt in 1981 that cost him the use of his right arm. He served as Iran's president before succeeding Khomeini as supreme leader in 1989.</p><p>Alex Vatanka, a senior fellow at the Middle East Institute in Washington, D.C., says Khamenei was an unlikely candidate. Then a midlevel cleric, Khamenei lacked religious credentials, which left him feeling vulnerable, Vatanka says.</p><p>\"He knew himself. He didn't have the prestige, the gravitas to be ‚Ä¶ the successor to the founder of the Islamic Republic, Ayatollah Khomeini,\"he says. </p><div><div><div><div aria-label=\"Image caption\"><p>\n                In 2005, Ali Khamenei (center), newly elected President Mahmoud Ahmadinejad (right), outgoing President Mohammad Khatami and former President Ali Akbar Hashemi Rafsanjani attend Ahmadinejad's inaugural ceremony in Tehran.\n                <b aria-label=\"Image credit\">\n                    \n                    Atta Kenare/AFP via Getty Images\n                    \n                </b></p></div></div></div><div><div><p>In 2005, Ali Khamenei (center), newly elected President Mahmoud Ahmadinejad (right), outgoing President Mohammad Khatami and former President Ali Akbar Hashemi Rafsanjani attend Ahmadinejad's inaugural ceremony in Tehran.</p></div></div></div><p>\"He spent the first few years in power being very nervous,\" says Vatanka. \"He really literally felt that somebody is going to, you know, take him down from the position of power.\"</p><p>But Khamenei was cunning and able to outwit other senior political figures in the Islamic Republic, according to Ali Vaez, director of the Iran Project at the International Crisis Group. He says that with the help of the formidable Islamic Revolutionary Guard Corps, Khamenei built up his power base to become the longest-serving leader in the Middle East.</p><p>\"Ayatollah Khamenei was a man with strategic patience and was able to calculate a few steps ahead,\" he says.&nbsp;\"That's why I think he managed ‚Äî on the back of the Revolutionary Guards ‚Äî to increasingly appropriate all the levers of power in his hands and sideline everyone else.\"</p><p>Khamenei's close ties to the Revolutionary Guards allowed Iran's military to develop a vast commercial empire in control of many parts of the economy, while ordinary Iranians struggled to get by.</p><div><div><div><div aria-label=\"Image caption\"><p>\n                Ali Khamenei (right) speaks to members of the armed forces of the Islamic Republic during the Iran-Iraq War on Oct. 4, 1981.\n                </p></div></div></div><div><div><p>Ali Khamenei (right) speaks to members of the armed forces of the Islamic Republic during the Iran-Iraq War on Oct. 4, 1981.</p></div></div></div><p>Vaez says Khamenei also began to build up Iran's defensive policies, such as developing proxies like Hezbollah in Lebanon and Hamas in the Gaza Strip to deter a direct attack on Iranian soil.</p><p>\"And then also becoming self-reliant in developing a viable conventional deterrence, which took the form of Iran's ballistic missile program,\" Vaez says.</p><p>As supreme leader, Khamenei also had the final word on anything to do with Iran's nuclear program.</p><p>Over time, Khamenei increasingly injected himself into politics. Such was the case in 2009, when he intervened in the presidential election to ensure that his favored candidate, the controversial conservative Mahmoud Ahmadinejad, won office. </p><p>Iranians took to the streets to protest what was widely seen as a fraudulent election. Khamenei brutally crushed those demonstrations, triggering both a backlash and more protest movements over the years.</p><p>Iran killed thousands of its citizens under Khamenei's rule, including more than 7,000 people killed during weeks of mass protests that started in late December 2025, according to the <a href=\"https://www.en-hrana.org/day-50-of-the-protests-intensification-of-security-prosecutions-and-uncertainty-regarding-the-status-of-detainees/\" target=\"_blank\">Human Rights Activists News Agency</a>, a U.S.-based organization that closely tracks rights abuses in Iran.</p><div><div><div><div aria-label=\"Image caption\"><p>\n                Iran's supreme leader, Ayatollah Ali Khamenei (center), prays with the Iranian president and other government officials in Tehran in 2014.\n                <b aria-label=\"Image credit\">\n                    \n                    Anadolu Agency/Getty Images\n                    \n                </b></p></div></div></div><div><div><p>Iran's supreme leader, Ayatollah Ali Khamenei (center), prays with the Iranian president and other government officials in Tehran in 2014.</p></div></div></div><p>\"Khamenei had always supported and endorsed repressive government crackdown, recognizing that these protests were damaging to the stability and legitimacy of the state,\" says Sanam Vakil, an Iran expert at Chatham House, a London-based think tank.</p><p>But Khamenei was unconcerned about getting to the root of the protests, says the Middle East Institute's Vatanka, and remained stuck in an Islamic revolutionary mindset against the West.</p><p>\"He onso many occasions refused point-blank to accept the basic reality that where he was in terms of his worldview was not where the rest of his people were,\" Vatanka says.</p><p>He adds that 75% of Iran's 90 million people were born after the revolution and have watched other countries in the region modernize and integrate with the international community.</p><p>\"The 75% he should have catered to, listened to and address[ed] policies to satisfy their aspirations,\" he says. \"He failed in that miserably.\"</p><div><div><div><div aria-label=\"Image caption\"><p>\n                Ali Khamenei wears a mask due to the COVID-19 pandemic as he arrives to cast his ballot during Iran's presidential election on June 18, 2021.\n                <b aria-label=\"Image credit\">\n                    \n                    Atta Kenare/AFP via Getty Images\n                    \n                </b></p></div></div></div><div><div><p>Ali Khamenei wears a mask due to the COVID-19 pandemic as he arrives to cast his ballot during Iran's presidential election on June 18, 2021.</p></div></div></div><p>The International Crisis Group's Vaez says after the Arab Spring uprisings in 2011, Khamenei did start worrying about the survival of his regime. Iran's economy was crumbling, due in large part to stringent Western sanctions, fueling more unrest.</p><p>In 2013, Khamenei agreed to secret negotiations with the U.S. about Iran's nuclear program, which eventually led to the 2015 Joint Comprehensive Plan of Action nuclear agreement. Vaez says Khamenei deeply distrusted the U.S. and was skeptical about the deal.</p><p>\"His argument has always been that the U.S. is always looking for pretexts, for putting pressure on Iran,\" he says. \"And if Iran concedes on the nuclear issue, then the U.S. would put pressure on Iran because of its missiles program or because of human rights violations or because of its regional policies.\"</p><p>President Trump's withdrawal from the nuclear deal during his first term in office gave some credence to Khamenei's cynicism. Analysts say Iran increased its nuclear enrichment after that to a point where it was close to being able to build a bomb.</p><p>In early 2025, when Trump reached out to Iran about a new deal, Khamenei dragged out negotiations until they began in mid-April.</p><p>But time ran out. In June,Israel made good on its threat to neutralize Iran's nuclear program, launching strikes on key facilities and killing scientists and generals. Iran retaliated, and the two sides exchanged several days of missile strikes.</p><p>On June 21, 2025, the U.S. <a href=\"https://www.npr.org/2025/06/21/nx-s1-5441127/iran-us-strike-nuclear-trump\" target=\"_blank\">launched major airstrikes</a> on three of Iran's nuclear enrichment sites. Trump said the facilities had been \"completely and totally obliterated,\" although there was debate among the White House and nuclear experts as to how serious Iran's nuclear program had been set back.</p><p>Vakil, of Chatham House, says Khamenei underestimated what Israel and the U.S. would do.</p><p>\"I think that Khamenei always assumed that he could play for time, and what he really didn't understand is that the world around Iran had very much changed,\" she says. \"The world had tired of Khamenei and Iranian foot-dragging and antics ‚Ä¶&nbsp;and so that was a miscalculation.\"</p><p>But it was Iran's use of proxy militias across the region that eventually led to Khamenei's downfall. </p><p>When Hamas ‚Äî the Palestinian Islamist group backed by Iran ‚Äî attacked Israel on Oct. 7, 2023, killing nearly 1,200 people and kidnapping 251 others, it triggered a cascade of events that ultimately led to Israel's attack on Iran.&nbsp;</p><p>The day after the 2023 Hamas-led attack, Iran-backed Hezbollah in Lebanon started firing rockets into Israel, triggering a conflict that led to the Shia militia's top brass being decimated ‚Äî including top leader <a href=\"https://www.npr.org/2024/09/28/g-s1-25302/who-was-hassan-nasrallah-the-hezbollah-leader-killed-by-israel\" target=\"_blank\">Hassan Nasrallah</a>.</p><p>Israel and Iran traded direct airstrikes for the first time in 2024 as part of that conflict.</p><p>Israel's bombing of Iranian weapons shipments in Syria also helped weaken the regime of Syria's then-dictator, Bashar al-Assad, an important ally of Iran. Assad fell in December 2024 and fled to Russia in early January 2025.</p><p>By the time Khamenei died, his legacy was in tatters. Israel had hobbled two key proxies, Hamas and Hezbollah, and had wiped out Iran's air defenses. With U.S. help, it left Iran's nuclear program in shambles.</p><p>What remains is a robust ballistic missile program, the brainchild of Khamenei. It's unclear who will replace him to lead a now weakened and vulnerable Iran.</p>","contentLength":10412,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47200879"},{"title":"We do not think Anthropic should be designated as a supply chain risk","url":"https://twitter.com/OpenAI/status/2027846016423321831","date":1772313856,"author":"golfer","guid":156,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47200420"},{"title":"Our Agreement with the Department of War","url":"https://openai.com/index/our-agreement-with-the-department-of-war","date":1772310929,"author":"surprisetalk","guid":155,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47199948"},{"title":"Qwen3.5 122B and 35B models offer Sonnet 4.5 performance on local computers","url":"https://venturebeat.com/technology/alibabas-new-open-source-qwen3-5-medium-models-offer-sonnet-4-5-performance","date":1772310000,"author":"lostmsu","guid":154,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47199781"},{"title":"Block the ‚ÄúUpgrade to Tahoe‚Äù alerts","url":"https://robservatory.com/block-the-upgrade-to-tahoe-alerts-and-system-settings-indicator/","date":1772305441,"author":"todsacerdoti","guid":153,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47198977"},{"title":"Techno‚Äëfeudal elite are attempting to build a twenty‚Äëfirst‚Äëcentury fascist state","url":"https://collapseofindustrialcivilization.com/2026/02/16/americas-oligarchic-techno-feudal-elite-are-attempting-to-build-a-twenty-first-century-fascist-state/","date":1772305063,"author":"measurablefunc","guid":152,"unread":true,"content":"<p><strong>Introduction: Fascism at the End of Industrial Civilization</strong></p><p>This essay argues that the United States is drifting toward a distinctly twenty‚Äëfirst‚Äëcentury form of fascism driven not by mass parties in brownshirts, but by an oligarchic techno‚Äëfeudal elite. Neoliberal capitalism has hollowed out democratic institutions and concentrated power in a transnational ‚Äúauthoritarian international‚Äù of billionaires, security chiefs, and political fixers who monetize state power while shielding one another from accountability. At the same time, Big Tech platforms have become neo‚Äëfeudal estates that extract rent from our data and behavior, weaponize disinformation, and provide the surveillance backbone of an emerging global police state.</p><p>Drawing on the work of Robert Reich, William I. Robinson, Yanis Varoufakis, and others, alongside historian Heather Cox Richardson‚Äôs detailed account of Trump‚Äëera patronage, whistleblower suppression, and DHS/ICE mega‚Äëdetention plans, the essay contends that America is rapidly constructing a system of concentration‚Äëcamp infrastructure and paramilitary policing designed to manage ‚Äúsurplus‚Äù populations and political dissent. Elite impunity, entrenched through national‚Äësecurity exceptionalism, legal immunities, and revolving‚Äëdoor careers, means that those directing lawless violence face virtually no consequences. Elections still happen, courts still sit, newspapers still publish, but substantive power is increasingly exercised by unelected oligarchs, tech lords, and security bureaucracies.</p><p>This authoritarian drift cannot be separated from the broader crisis of industrial civilization. Ecological overshoot, climate chaos, resource constraints, and structural economic stagnation have undermined the promise of endless growth on which liberal democracy once rested. Rather than using the remnants of industrial wealth to democratize a just transition, ruling elites are hardening borders, expanding carceral infrastructure, and building a security regime to contain ‚Äúsurplus‚Äù humanity in a world of shrinking energy and material throughput. America‚Äôs oligarchic techno‚Äëfeudal fascism is thus not an anomaly, but one plausible endgame of industrial civilization: a stratified order of gated enclaves above and camps and precarity below, designed to preserve elite power as the old industrial world comes apart.</p><p><strong>I. From liberal promise to oligarchic capture</strong></p><p>The American republic was founded on a promise that power would be divided, constrained, and answerable: a written constitution, separated branches, periodic elections, and a Bill of Rights that set bright lines even the sovereign could not cross. That promise was always compromised by slavery, settler colonialism, and gendered exclusion, but it retained real, if uneven, force as a normative horizon. What has shifted over the past half‚Äëcentury is not simply the familiar gap between creed and practice, but the underlying structure of the system itself: the center of gravity has moved from public institutions toward a private oligarchy whose wealth and leverage allow it to function as a parallel sovereign.</p><p>The neoliberal turn of the 1970s and 1980s marked the decisive inflection point. Deregulation, financial liberalization, the crushing of organized labor, and the privatization of public goods redistributed power and income upward on a historic scale. Trade liberalization and capital mobility allowed corporations and investors to pit governments and workers against one another, extracting subsidies and tax concessions under the permanent threat of capital flight. At the same time, Supreme Court decisions eroded limits on political spending, redefining ‚Äúspeech‚Äù as something that could be purchased in unlimited quantities by those with the means.</p><p>The result, as Robert Reich notes, has been the consolidation of an American oligarchy that ‚Äúpaved the road to fascism‚Äù by ensuring that public policy reflects donor preferences far more consistently than popular majorities. In issue after issue, such as taxation, labor law, healthcare, and environmental regulation, there is a clear skew: the wealthy get what they want more often than not, while broadly popular but redistributive policies routinely die in committee or are gutted beyond recognition. This is not a conspiracy in the melodramatic sense; it is how the wiring of the system now works.</p><p>William Robinson‚Äôs analysis of ‚Äútwenty‚Äëfirst‚Äëcentury fascism‚Äù sharpens the point. Global capitalism in its current form generates chronic crises: overproduction, under‚Äëconsumption, ecological breakdown, and a growing population that capital cannot profitably employ. Under such conditions, democratic politics becomes dangerous for elites, because electorates might choose structural reforms such as wealth taxes, public ownership, strong unions, and Green New Deal‚Äëstyle transitions that would curb profits. Faced with this prospect, segments of transnational capital begin to see authoritarian solutions as rational: better to hollow out democracy, harden borders, and construct a global police state than to accept serious redistribution.</p><p>American politics in the early twenty‚Äëfirst century fits this pattern with unsettling precision. A decaying infrastructure, stagnant wages, ballooning personal debt, militarized policing, and permanent war have produced widespread disillusionment. As faith in institutions erodes, public life is flooded with resentment and nihilism that can be redirected against scapegoats (immigrants, racial minorities, feminists, and queer and trans people) rather than against the oligarchic‚Äëpower‚Äëcomplex that profits from the decay. It is in this vacuum that a figure like Donald Trump thrives: a billionaire demagogue able to channel anger away from the class that actually governs and toward those even more marginalized.</p><p>The decisive shift from plutocratic dysfunction to fascist danger occurs when oligarchs cease to see constitutional democracy as even instrumentally useful and instead invest in movements openly committed to minority rule. Koch‚Äëstyle networks, Mercer‚Äëfunded operations, and Silicon Valley donors willing to underwrite hard‚Äëright projects are not supporting democracy‚Äëenhancing reforms; they are building the infrastructure for authoritarianism, from voter suppression to ideological media to data‚Äëdriven propaganda. The system that emerges is hybrid: elections still occur, courts still sit, newspapers still publish, but substantive power is increasingly concentrated in unelected hands.</p><p><strong>II. The ‚Äúauthoritarian international‚Äù and the shadow world of deals</strong></p><p>Historian Heather Cox Richardson‚Äôs <a href=\"https://www.youtube.com/watch?v=ajZudGu4exA\">recent analysis</a> captures a formation that much mainstream commentary still struggles to name: a transnational <strong>‚Äúauthoritarian international‚Äù</strong> in which oligarchs, political operatives, royal families, security chiefs, and organized criminals cooperate to monetize state power while protecting one another from scrutiny. This is not a formal alliance; it is an overlapping ecology of relationships, exclusive vacations, investment vehicles, shell companies, foundations, and intelligence ties, through which information, favors, and money flow.</p><p>The key is that this network is structurally post‚Äëideological. As Robert Mueller warned in his 2011 description of an emerging ‚Äúiron triangle‚Äù of politicians, businesspeople, and criminals, these actors are not primarily concerned with religion, nationality, or traditional ideology. They will work across confessional and national lines so long as the deals are lucrative and risk is manageably socialized onto others. Saudi royals invest alongside Western hedge funds; Russian oligarchs launder money through London property and American private equity; Israeli and Emirati firms collaborate with U.S. tech companies on surveillance products that are then sold worldwide.</p><p>Within this milieu, the formal distinction between public office and private interest blurs. Richardson‚Äôs analysis of Donald Trump‚Äôs abrupt reversal on the Gordie Howe International Bridge after a complaint by a billionaire competitor with ties to Jeffrey Epstein‚Äîreads less like the exercise of public policy judgment and more like feudal patronage: the sovereign intervenes to protect a favored lord‚Äôs toll road. Tiny shifts in regulatory posture or federal support can move billions of dollars; for those accustomed to having the president‚Äôs ear, such interventions are simply part of doing business.</p><p>The same logic governs foreign policy. The Trump‚ÄëKushner axis exemplifies this fusion of public and private. When a whistleblower alleges that the Director of National Intelligence suppressed an intercept involving foreign officials discussing Jared Kushner and sensitive topics like Iran, and when the complaint is then choked off with aggressive redaction and executive privilege, we see <strong>the machinery of secrecy misused not to protect the national interest but to shield a member of the family‚Äëcum‚Äëbusiness empire at the center of power</strong>. It is as if the state has become a family office with nuclear weapons.</p><p>Josh Marshall‚Äôs phrase <strong>‚Äúauthoritarian international‚Äù</strong> is apt because it names both the class composition and the political function of this network. The same names recur across far‚Äëright projects: donors and strategists who back nationalist parties in Europe, ultras in Latin America, Modi‚Äôs BJP in India, and the MAGA movement in the United States. Their interests are not identical, but they overlap around a shared agenda: weakening labor and environmental protections, undermining independent media and courts, militarizing borders, and securing immunity for themselves and their peers.</p><p>This world is lubricated by blackmail and mutually assured destruction. As Richardson notes, players often seem to hold compromising material on one another, whether in the form of documented sexual abuse, financial crime, or war crimes. This shared vulnerability paradoxically stabilizes the network: as long as everyone has something on everyone else, defection is dangerous, and a predatory equilibrium holds. From the standpoint of democratic publics, however, this stability is catastrophic, because it means that scandal‚Äîonce a mechanism for enforcing norms‚Äîloses much of its power. When ‚Äúeveryone is dirty,‚Äù no one can be clean enough to prosecute the others without risking exposure.</p><p><strong>III. Techno‚Äëfeudal aristocracy and the colonization of everyday life</strong></p><p>Layered atop this transnational oligarchy is the digital order that Varoufakis and others describe as techno‚Äëfeudalism: a regime in which a handful of platforms function like neo‚Äëfeudal estates, extracting rent from their ‚Äúserfs‚Äù (users, gig workers, content creators) rather than competing in open markets. This shift is more than metaphor. In classical capitalism, firms profited primarily by producing goods or services and selling them on markets where competitors could, in principle, undercut them. In the platform order, gatekeepers profit by controlling access to the marketplace itself, imposing opaque terms on those who must use their infrastructure to communicate, work, or even find housing.</p><p>This can be seen across sectors:</p><ul><li><p>Social media platforms own the digital public square. They monetize attention by selling advertisers access to finely sliced demographic and psychographic segments, while their recommendation algorithms optimize for engagement, often by privileging outrage and fear.</p></li><li><p>Ride‚Äëhailing and delivery apps control the interface between customers and labor, setting prices unilaterally and disciplining workers through ratings, algorithmic management, and the ever‚Äëpresent threat of ‚Äúdeactivation.‚Äù</p></li><li><p>Cloud providers and app stores gatekeep access to the basic infrastructure upon which countless smaller firms depend, taking a cut of transactions and reserving the right to change terms or remove competitors from the ecosystem entirely.</p></li></ul><p>In each case, the platform is less a company among companies and more a landlord among tenants, collecting tolls for the right to exist within its domain. Users produce the very capital stock, data, content, behavioral profiles, that platforms own and monetize, yet they have little say over how this material is used or how the digital environment is structured. The asymmetry of power is profound: the lords can alter the code of the world; the serfs can, at best, adjust their behavior to avoid algorithmic invisibility or sanction.</p><p>For authoritarian politics, this structure is a gift. First, platforms have become the primary vectors of disinformation and propaganda. Cambridge Analytica‚Äôs work for Trump in 2016, funded by billionaires like the Mercers, was an early prototype: harvest data, micro‚Äëtarget individuals with tailored&nbsp;messaging, and flood their feeds with narratives designed to activate fear and resentment. Since then, the techniques have grown more sophisticated, and far‚Äëright movements worldwide have learned to weaponize meme culture, conspiracy theories, and ‚Äúshitposting‚Äù as recruitment tools.</p><p>Second, the same infrastructures that enable targeted advertising enable granular surveillance. Location data, social graphs, search histories, and facial‚Äërecognition databases provide an unprecedented toolkit for monitoring and disciplining populations. In the hands of a regime sliding toward fascism, these tools can be turned against dissidents with terrifying efficiency: geofencing protests to identify attendees, scraping social media to build dossiers, using AI to flag ‚Äúpre‚Äëcriminal‚Äù behavior. The emerging ‚Äúglobal police state‚Äù that Robinson describes depends heavily on such techno‚Äëfeudal capacities.</p><p>Third, the digital order corrodes the very preconditions for democratic deliberation. Information overload, filter bubbles, and algorithmic amplification of sensational content produce a public sphere saturated with noise. Under these conditions, truth becomes just another aesthetic, and the distinction between fact and fiction collapses into vibes. This is the post‚Äëmodern nihilism you name: a sense that nothing is stable enough to believe in, that everything is spin. Fascist movements do not seek to resolve this condition; they weaponize it, insisting that only the Leader and his trusted media tell the real truth, while everything else is a hostile lie.</p><p>Finally, the techno‚Äëfeudal aristocracy‚Äôs material interests align with authoritarianism. Privacy regulations, antitrust enforcement, data localization rules, and strong labor rights all threaten platform profits. Democratic movements that demand such reforms are therefore adversaries. Conversely, strongman leaders who promise deregulation, tax breaks, and law‚Äëand‚Äëorder crackdowns, even if they occasionally threaten specific firms, are often acceptable partners. The result is a convergence: oligarchs of data and oligarchs of oil, real estate, and finance finding common cause in an order that disciplines the many and exempts the few.</p><p><strong>IV. Elite impunity and the machinery of lawlessness</strong></p><p>Authoritarianism is not only about who holds power; it is about who is answerable for wrongdoing. A system where elites can violate laws with impunity while ordinary people are punished harshly for minor infractions is already halfway to fascism, whatever labels it wears. The United States has, over recent decades, constructed precisely such a system.</p><p>The Arab Center‚Äôs ‚ÄúMachinery of Impunity‚Äù report details how, in areas ranging from mass surveillance to foreign wars to domestic policing, senior officials who authorize illegal acts almost never face criminal consequences. Edward Snowden‚Äôs revelations exposed systemic violations of privacy and civil liberties, yet it was the whistleblower who faced prosecution and exile, not the architects of the programs. Torture during the ‚Äúwar on terror‚Äù was acknowledged, even documented in official reports, but those who designed and approved the torture regime kept their law licenses, academic posts, and media gigs. Lethal strikes on small boats in the Caribbean and Pacific, justified by secret intelligence and shielded by classified legal opinions, have killed dozens with no public evidence that the targets posed imminent threats.</p><p>This pattern is not an aberration but a feature. As a Penn State law review article <a href=\"https://insight.dickinsonlaw.psu.edu/cgi/viewcontent.cgi?article=1144&amp;context=jlia\">notes</a>, the U.S. legal system builds in multiple layers of protection for high officials: sovereign immunity, state secrets privilege, narrow standing rules, and prosecutorial discretion all combine to make it extraordinarily difficult to hold the powerful to account. Violations of the Hatch Act, campaign‚Äëfinance laws, or ethics rules are often treated as technicalities, and when reports do document unlawful behavior, as in the case of Mike Pompeo‚Äôs partisan abuse of his diplomatic office, there are ‚Äúno consequences‚Äù beyond mild censure. Jamelle Bouie‚Äôs recent video essay for the New York Times drives the point home: America is ‚Äúbad at accountability‚Äù because institutions have been designed and interpreted to favor elite impunity.</p><p>Richardson shows how this culture functions inside the national‚Äësecurity state. A whistleblower complaint alleging that the Director of National Intelligence suppressed an intelligence intercept involving Jared Kushner and foreign officials was not allowed to run its course. Instead, it was bottled up, then transmitted to congressional overseers in a highly redacted form, with executive privilege invoked to shield the president‚Äôs involvement. The same mechanisms that insulate covert operations abroad from democratic oversight are deployed to protect domestic political allies from scrutiny.</p><p>Immigration enforcement offers another window. The Arab Center notes that ICE raids, family separation, and other abuses ‚Äúescalated under the current Trump administration into highly visible kidnappings, abuse, and deportations‚Äù with little accountability for senior officials. The National Immigrant Justice Center documents a detention system where 90 percent of detainees are held in for‚Äëprofit facilities, where medical neglect, punitive solitary confinement, and preventable deaths are common, yet contracts are renewed and expanded. A culture of impunity allows agents and managers to treat rights violations not as career‚Äëending scandals but as acceptable collateral damage.</p><p>Latin American scholars of impunity warn that such selective enforcement produces a ‚Äúquiet crisis of accountability‚Äù in which the rule of law is hollowed out from within. Laws remain on the books, but their application is skewed: harsh on the poor and marginalized, permissive toward the powerful. Over time, this normalizes the idea that some people are above the law, while others exist primarily as objects of control. When a polity internalizes this hierarchy, fascism no longer needs to arrive in jackboots; it is already present in the daily operations of the justice system.</p><p>The danger, as the Arab Center emphasizes, is that the costs of impunity ‚Äúcome home to roost.‚Äù Powers originally justified as necessary to fight terrorism or foreign enemies migrate back into domestic politics. Surveillance tools built for foreign intelligence monitoring are turned on activists and journalists; militarized police tactics perfected in occupied territories are imported into American streets. A population taught to accept lawless violence against outsiders (migrants, foreigners, enemy populations) is gradually conditioned to accept similar violence against internal opponents.</p><p><strong>V. Concentration camps, paramilitary policing, and ritualized predatory violence</strong></p><p>In this context of oligarchic capture, techno‚Äëfeudal control, and elite impunity, the rapid expansion of detention infrastructure and the deployment of paramilitary ‚Äúfederal agents‚Äù across the interior United States are not aberrations; they are central pillars of an emergent fascist order.</p><p>Richardson‚Äôs insistence on calling these facilities concentration camps is analytically exact. A concentration camp, in the historical sense, is not necessarily a death camp; it is a place where a state concentrates populations it considers threats or burdens, subjecting them to confinement, disease, abuse, and often death through neglect rather than industrialized extermination. By that definition, the sprawling network of ICE and Border Patrol detention centers, where people are warehoused for months to years, often in horrific conditions, qualifies.</p><p>New reporting details how this system is poised to scale up dramatically. An internal ICE memo, recently surfaced, outlines a $38 billion plan for a ‚Äúnew detention center model‚Äù that would, in one year, create capacity for roughly 92,600 people by purchasing eight ‚Äúmega centers,‚Äù 16 processing centers, and 10 additional facilities. The largest of these warehouses would hold between 7,000 and 10,000 people each for average stays of about 60 days, more than double the size of the largest current federal prison. Separate reporting has mapped at least 23 industrial warehouses being surveyed for conversion into mass detention camps, with leases already secured at several sites.</p><p>Investigations by Amnesty International and others into prototype facilities have found detainees shackled in overcrowded cages, underfed, forced to use open‚Äëair toilets that flood, and routinely denied medical care. Sexual assault and extortion by guards, negligent deaths, and at least one homicide have been documented. These are not accidents; they are predictable outcomes of a profit‚Äëdriven system where private contractors are paid per bed and oversight is weak, and of a political culture that dehumanizes migrants as ‚Äúinvaders‚Äù or ‚Äúanimals.‚Äù</p><p>Richardson highlights another crucial dimension: the way DHS has been retooled to project this violence into the interior as a form of political terror. Agents from ICE and Border Patrol, subdivisions of a relatively new department lacking the institutional restraints of the military, have been deployed in cities far from any border, often in unmarked vehicles, wearing masks and lacking visible identification. Secret legal memos under Trump gutted the traditional requirement of a judicial warrant for entering homes, replacing it with internal sign‚Äëoff by another DHS official, a direct violation of the Fourth Amendment‚Äôs protection against unreasonable searches and seizures.</p><p>This matters both instrumentally and symbolically. Instrumentally, it enables efficient mass raids and ‚Äúsnatch and grab‚Äù operations that bypass local law‚Äëenforcement norms and judicial oversight. Symbolically, it communicates that the state reserves the right to operate as a lawless force, unconstrained by the very constitution it claims to defend. When masked, unidentified agents can seize people off the streets, shove them into unmarked vans, and deposit them in processing centers without due process, the aesthetic of fascism‚Ä¶thugs in the night‚Ä¶becomes reality.</p><p>Richardson rightly connects this to the post‚ÄëReconstruction South, where paramilitary groups like the Ku Klux Klan, often tolerated or quietly aided by local officials, used terror to destroy a biracial democracy that had briefly flourished. Today‚Äôs difference is that communications technology allows rapid mobilization of witnesses and counter‚Äëprotesters: people can rush to the scene when agents arrive, document abuses on smartphones, and coordinate legal support. Yet even this can be folded into the logic of spectacle. The images of militarized agents confronting crowds under the glow of streetlights and police floodlamps serve as warnings: this is what happens when you resist.</p><p>The planned network of processing centers and mega‚Äëwarehouses adds another layer of menace. As Richardson points out, if the stated goal is deportation, there is no clear need for facilities capable of imprisoning tens of thousands for months. Part of the answer is coercive leverage: detained people are easier to pressure into abandoning asylum claims and accepting removal, especially when they are told, day after day, that they could walk free if they ‚Äújust sign.‚Äù But the architecture also anticipates a future in which new categories of internal enemies, protesters, ‚ÄúAntifa,‚Äù ‚Äúdomestic extremists,‚Äù can be funneled into the same carceral estate once migrant flows diminish or political needs change.</p><p>Economically, the camps generate their own constituency. ICE and DHS tout job creation numbers to local officials, promising hundreds of stable, often union‚Äëfree positions in communities hollowed out by deindustrialization. Private prison firms and construction companies see lucrative contracts; investors see secure returns backed by federal guarantees. A web of stakeholders thus becomes materially invested in the continuation and expansion of mass detention. <strong>This is techno‚Äëfeudalism in concrete and razor wire: a carceral estate in which bodies are the rent‚Äëproducing asset.</strong></p><p>Once such an estate exists, its logic tends to spread. Border‚Äëstyle tactics migrate into ordinary policing; surveillance tools trialed on migrants are turned on domestic movements; legal doctrines crafted to justify raids and warrantless searches in the name of immigration control seep into other domains. The fascist gradient steepens: more people find themselves at risk of sudden disappearance into a system where rights are theoretical and violence is routine.</p>","contentLength":25529,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47198912"},{"title":"The whole thing was a scam","url":"https://garymarcus.substack.com/p/the-whole-thing-was-scam","date":1772297509,"author":"guilamu","guid":151,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47197505"},{"title":"Obsidian Sync now has a headless client","url":"https://help.obsidian.md/sync/headless","date":1772296313,"author":"adilmoujahid","guid":150,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47197267"},{"title":"Cognitive Debt: When Velocity Exceeds Comprehension","url":"https://www.rockoder.com/beyondthecode/cognitive-debt-when-velocity-exceeds-comprehension/","date":1772293150,"author":"pagade","guid":149,"unread":true,"content":"<img src=\"https://www.rockoder.com/images/beyondthecode/cognitive-debt-hero.svg\" alt=\"\" loading=\"eager\"><p>The engineer shipped seven features in a single sprint. DORA metrics looked immaculate. The promotion packet practically wrote itself.</p><p>Six months later, an architectural change required modifying those features. No one on the team could explain why certain components existed or how they interacted. The engineer who built them stared at her own code like a stranger‚Äôs.</p><p><strong>Code has become cheaper to produce than to perceive.</strong></p><p>When an engineer writes code manually, two parallel processes occur. The first is production: characters appear in files, tests get written, systems change. The second is absorption: mental models form, edge cases become intuitive, architectural relationships solidify into understanding. These processes are coupled. The act of typing forces engagement. The friction of implementation creates space for reasoning.</p><p>AI-assisted development decouples these processes. A prompt generates hundreds of lines in seconds. The engineer reviews, adjusts, iterates. Output accelerates. But absorption cannot accelerate proportionally. The cognitive work of truly understanding what was built, why it was built that way, and how it relates to everything else remains bounded by human processing speed.</p><p><strong>This gap between output velocity and comprehension velocity is cognitive debt.</strong></p><p>Unlike technical debt, which surfaces through system failures or maintenance costs, <strong>cognitive debt remains invisible to velocity metrics</strong>. The code works. The tests pass. The features ship. The deficit exists only in the minds of the engineers who built the system, manifesting as uncertainty about their own work.</p><p>The debt is not truly invisible. It eventually appears in reliability metrics: Mean Time to Recovery stretches longer, Change Failure Rate creeps upward. But these are lagging indicators, separated by months from the velocity metrics that drive quarterly decisions. By the time MTTR signals a problem, the comprehension deficit has already compounded.</p><h2>What Organizations Actually Measure</h2><p>Engineering performance systems evolved to measure observable outputs. Story points completed. Features shipped. Commits merged. Review turnaround time. These metrics emerged from an era when output and comprehension were tightly coupled, when shipping something implied understanding something.</p><p>The metrics never measured comprehension directly because comprehension was assumed. An engineer who shipped a feature was presumed to understand that feature. <strong>The presumption held because the production process itself forced understanding.</strong></p><p><strong>That presumption no longer holds.</strong> An engineer can now ship features while maintaining only surface familiarity with their implementation. The features work. The metrics register success. The organizational knowledge that would traditionally accumulate alongside those features simply does not form at the same rate.</p><p>Performance calibration committees see velocity improvements. They do not see comprehension deficits. They cannot, because no artifact of the organizational measurement system captures that dimension.</p><p>The discussion of cognitive debt typically focuses on the engineer who generates code. The more acute problem sits with the engineer who reviews it.</p><p>Code review evolved as a quality gate. A senior engineer examines a junior engineer‚Äôs work, catching errors, suggesting improvements, transferring knowledge. The rate-limiting factor was always the junior engineer‚Äôs output speed. Senior engineers could review faster than juniors could produce.</p><p>AI-assisted development inverts this relationship. <strong>A junior engineer can now generate code faster than a senior engineer can critically audit it.</strong> The volume of generated code exceeds the bandwidth available for deep review. Something has to give, and typically it is review depth.</p><p>The reviewer faces an impossible choice. Maintain previous review standards and become a bottleneck that negates the velocity gains AI provides. Or approve code at the rate it arrives and hope the tests catch what the review missed. Most choose the latter, often unconsciously, because organizational pressure favors throughput.</p><p>This is where cognitive debt compounds fastest. The author‚Äôs comprehension deficit might be recoverable through later engagement with the code. The reviewer‚Äôs comprehension deficit propagates: they approved code they do not fully understand, which now carries implicit endorsement. <strong>The organizational assumption that reviewed code is understood code no longer holds.</strong></p><p>Engineers working extensively with AI tools report a specific form of exhaustion that differs from traditional burnout. Traditional burnout emerges from sustained cognitive load, from having too much to hold in mind while solving complex problems. The new pattern emerges from something closer to cognitive disconnection.</p><p>The work happens quickly. Progress is visible. But the engineer experiences a persistent sense of not quite grasping their own output. They can execute, but explanation requires reconstruction. They can modify, but prediction becomes unreliable. The system they built feels slightly foreign even as it functions correctly.</p><p>This creates a distinctive psychological state: <strong>high output combined with low confidence</strong>. Engineers produce more while feeling less certain about what they have produced. In organizations that stack-rank based on visible output, this creates pressure to continue generating despite the growing uncertainty.</p><p>The engineer who pauses to deeply understand what they built falls behind in velocity metrics. The engineer who prioritizes throughput over comprehension meets their quarterly objectives. <strong>The incentive structure selects for the behavior that accelerates cognitive debt accumulation.</strong></p><h2>When Organizational Memory Fails</h2><p>Knowledge in engineering organizations exists in two forms. The first is explicit: documentation, design documents, recorded decisions. The second is tacit: understanding held in the minds of people who built and maintained systems over time. Tacit knowledge cannot be fully externalized because much of it exists as intuition, pattern recognition, and contextual judgment that formed through direct engagement with the work.</p><p>When the people who built a system leave or rotate to new projects, tacit knowledge walks out with them. Organizations traditionally replenished this knowledge through the normal process of engineering work. New engineers building on existing systems developed their own tacit understanding through the friction of implementation.</p><p>AI-assisted development potentially short-circuits this replenishment mechanism. If new engineers can generate working modifications without developing deep comprehension, they never form the tacit knowledge that would traditionally accumulate. <strong>The organization loses knowledge not just through attrition but through insufficient formation.</strong></p><p>This creates a delayed failure mode. The system continues to function. New features continue to ship. But the reservoir of people who truly understand the system gradually depletes. When circumstances eventually require that understanding, when something breaks in an unexpected way or requirements change in a way that demands architectural reasoning, the organization discovers the deficit.</p><p>Three failure modes emerge as cognitive debt accumulates.</p><p>The first involves the reversal of a normally reliable heuristic. Engineers typically trust code that has been in production for years. If it survived that long, it probably works. The longer code exists without causing problems, the more confidence it earns. AI-generated code inverts this pattern. <strong>The longer it remains untouched, the more dangerous it becomes</strong>, because the context window of the humans around it has closed completely. Code that was barely understood when written becomes entirely opaque after the people who wrote it have moved on.</p><blockquote>They are debugging a black box written by a black box.</blockquote><p>The second failure mode surfaces during incidents. An alert fires at 3:00 AM. The on-call engineer opens a system they did not build, generated by tools they did not supervise, documented in ways that assume familiarity they do not possess. <strong>They are debugging a black box written by a black box.</strong> What would have been a ten-minute fix when someone understood the system becomes a four-hour forensic investigation when no one does. Multiply this across enough incidents and the aggregate cost exceeds whatever velocity gains the AI-assisted development provided.</p><blockquote>The organization is effectively trading its pipeline of future Staff Engineers for this quarter's feature delivery.</blockquote><p>The third failure mode operates on a longer timescale. Junior engineers who rely primarily on AI-assisted development never develop the intuition that comes from manual implementation. They ship features without forming the scar tissue that informs architectural judgment. The organization is effectively trading its pipeline of future Staff Engineers for this quarter‚Äôs feature delivery. The cost does not appear in current headcount models because the people who would have become senior architects five years from now are not yet absent. </p><p>From the perspective of engineering leadership, AI-assisted development presents as productivity gain. Teams ship faster. Roadmaps compress. Headcount discussions become more favorable. These are the observable signals that propagate upward through organizational reporting structures.</p><p>The cognitive debt accumulating in those teams does not present as a signal. There is no metric for ‚Äúengineers who can explain their own code without re-reading it.‚Äù There is no dashboard for ‚Äúorganizational comprehension depth.‚Äù The concept does not fit into quarterly business review formats or headcount justification narratives.</p><p>Directors make decisions based on observable signals. When those signals uniformly indicate success, the decision to double down on the approach that produced those signals is rational within the information environment available to leadership. <strong>The decision is not wrong given the data. The data is incomplete.</strong></p><p>The cognitive debt framing does not apply uniformly across all engineering work. Some tasks genuinely are mechanical. Some codebases genuinely benefit from rapid iteration without deep architectural understanding. Some features genuinely do not require the level of comprehension that would traditionally form through manual implementation.</p><p>The model also assumes that comprehension was previously forming at adequate rates. This assumption may be generous. Engineers have always varied in how deeply they understood their own work. The distribution may simply be shifting rather than a new phenomenon emerging.</p><p>Additionally, tooling and documentation practices may evolve to partially close the comprehension gap. If organizations develop methods for capturing and transmitting the understanding that AI-assisted development fails to form organically, the debt may prove manageable rather than accumulative.</p><blockquote>The system is optimizing correctly for what it measures. What it measures no longer captures what matters.</blockquote><p>The fundamental challenge is that <strong>organizations cannot optimize for what they cannot measure</strong>. Velocity is measurable. Comprehension is not, or at least not through any mechanism that currently feeds into performance evaluation, promotion decisions, or headcount planning.</p><p>Until comprehension becomes legible to organizational decision-making systems, the incentive structure will continue to favor velocity. Engineers who prioritize understanding over output will appear less productive than peers who prioritize output over understanding. Performance calibration will reward the behavior that accumulates debt faster.</p><p>This is not a failure of individual managers or engineers. It is a measurement system designed for an era when production and comprehension were coupled, operating in an era when that coupling no longer holds. <strong>The system is optimizing correctly for what it measures. What it measures no longer captures what matters.</strong></p><p>The gap will eventually manifest. Whether through maintenance costs that exceed projections, through incidents that require understanding no one possesses, or through new requirements that expose the brittleness of systems built without deep comprehension. The timing and form of manifestation remain uncertain. The underlying dynamic does not.</p>","contentLength":12316,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47196582"},{"title":"Addressing Antigravity Bans and Reinstating Access","url":"https://github.com/google-gemini/gemini-cli/discussions/20632","date":1772286613,"author":"RyanShook","guid":148,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47195371"},{"title":"OpenAI fires an employee for prediction market insider trading","url":"https://www.wired.com/story/openai-fires-employee-insider-trading-polymarket-kalshi/","date":1772286380,"author":"bookofjoe","guid":147,"unread":true,"content":"<p> an employee following an investigation into their activity on <a href=\"https://www.wired.com/story/the-political-war-over-prediction-markets-is-just-getting-started/\">prediction market platforms</a> including Polymarket, WIRED has learned.</p><p>OpenAI CEO of Applications, <a href=\"https://www.wired.com/story/fidji-simo-is-openais-other-ceo-and-she-swears-shell-make-chatgpt-profitable/#intcid=_wired-verso-hp-trending_ea249350-52ab-42d0-9cfe-e91d580f41e8_popular4-2\">Fidji Simo</a>, disclosed the termination in an internal message to employees earlier this year. The employee, she said, ‚Äúused confidential OpenAI information in connection with external prediction markets (e.g. Polymarket).‚Äù</p><p>‚ÄúOur policies prohibit employees from using confidential OpenAI information for personal gain, including in prediction markets,‚Äù says spokesperson Kayla Wood. OpenAI has not revealed the name of the employee or the specifics of their trades.</p><p>Evidence suggests that this was not an isolated event. Polymarket runs on the Polygon blockchain network, so its trading ledger is pseudonymous but traceable. According to an analysis by the financial data platform Unusual Whales, there have been clusters of activities, which the service flagged as suspicious, around OpenAI-themed events since March 2023.</p><p>Unusual Whales flagged 77 positions in 60 wallet addresses as suspected insider trades, looking at the age of the account, trading history, and significance of investment, among other factors. Suspicious trades hinged on the release dates of products like <a href=\"https://www.wired.com/story/openai-launches-sora-2-tiktok-like-app/\">Sora</a>, <a href=\"https://www.wired.com/story/gpt-5-coding-review-software-engineering/\">GPT-5</a>, and the ChatGPT Browser, as well as CEO Sam Altman‚Äôs employment status. In November 2023, two days after Altman was dramatically ousted from the company, a new wallet placed a significant bet that he would return, netting over $16,000 in profits. The account never placed another bet.</p><p>The behavior fits into patterns typical of insider trades. ‚ÄúThe tell is the clustering. In the 40 hours before OpenAI launched its browser, 13 brand-new wallets with zero trading history appeared on the site for the first time to collectively bet $309,486 on the right outcome,‚Äù says Unusual Whales CEO Matt Saincome. ‚ÄúWhen you see that many fresh wallets making the same bet at the same time, it raises a real question about whether the secret is getting out.‚Äù</p><p>Prediction markets have exploded in popularity in recent years. These platforms allow customers to buy ‚Äúevent contracts‚Äù on the outcomes of future events ranging from the winner of the Super Bowl to the daily price of Bitcoin to whether the United States will go to war with Iran. There are a wide array of markets tied to events in the technology sector; you can trade on what Nvidia‚Äôs quarterly earnings will be, or when Tesla will launch a new car, or which AI companies will IPO in 2026.</p><p>As the platforms have grown, so have concerns that they allow traders to profit from insider knowledge. ‚ÄúThis prediction market world makes the Wild West look tame in comparison,‚Äù says Jeff Edelstein, a senior analyst at the betting news site InGame. ‚ÄúIf there's a market that exists where the answer is known, somebody's going to trade on it.‚Äù</p><p>Earlier this week, Kalshi <a href=\"https://www.wired.com/story/kalshi-insider-trading-california-politician-and-youtuber/\">announced</a> that it had reported several suspicious insider trading cases to the Commodity Futures Trading Commission, the government agency overseeing these markets. In one instance, an employee of the popular YouTuber Mr. Beast was suspended for two years and fined $20,000 for making trades related to the streamer‚Äôs activities; in another, the far-right political candidate Kyle Langford was banned from the platform for making a trade on his own campaign. The company also announced a number of initiatives to prevent insider trading and market manipulation.</p><p>While Kalshi has heavily promoted its crackdown on insider trading, Polymarket has stayed silent on the matter. The company did not return requests for comments.</p><p>In the past, major trades on technology-themed markets have sparked speculation that there are Big Tech employees profiting by using their insider knowledge to gain an edge. One notorious example is the so-called ‚ÄúGoogle whale,‚Äù a <a data-offer-url=\"https://polymarket.com/profile/%400xafEe\" data-event-click=\"{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://polymarket.com/profile/%400xafEe&quot;}\" href=\"https://polymarket.com/profile/%400xafEe\" rel=\"nofollow noopener\" target=\"_blank\">pseudonymous account</a> on Polymarket that made over $1 million trading on Google-related events, including a market on who the most-searched person of the year would be in 2025. (It was the singer D4vd, who is best known for his connection to an ongoing murder investigation after a young fan‚Äôs remains were found in a vehicle registered to him.)</p>","contentLength":4190,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47195317"},{"title":"Show HN: Now I Get It ‚Äì Translate scientific papers into interactive webpages","url":"https://nowigetit.us/","date":1772285376,"author":"jbdamask","guid":115,"unread":true,"content":"<p>Drop your PDF here, or </p><p>Works best with files under 10 MB</p>","contentLength":56,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47195123"},{"title":"What AI coding costs you","url":"https://tomwojcik.com/posts/2026-02-15/finding-the-right-amount-of-ai/","date":1772283903,"author":"tomwojcik","guid":146,"unread":true,"content":"<p>Every developer I know uses AI for coding now. The productivity gains are real, but there are costs that don‚Äôt show up on any dashboard.</p><p>Imagine a spectrum. On the far left are humans typing on the keyboard, seeing the code in the IDE. On the far right: AGI. It implements everything on its own. Cheaply, flawlessly, better than any human, and no human overseer is required. Somewhere between those two extremes there‚Äôs you, using AI, today. That threshold moves to the right every week as models improve, tools mature, and workflows get refined.</p><blockquote><p>Which is higher risk, using AI too much, or using AI too little?</p></blockquote><p>and it made me think about LLMs for coding differently, especially after reading what other devs share on AI adoption in different workplaces. You can be wrong in both directions, but is the desired amount of AI usage at work changing as the models improve?</p><p>Not long ago the first AI coding tools like Cursor (2023) or Copilot (2022) emerged. They were able to quickly index the codebase using RAG, so they had the local context. They had all the knowledge of the models powering them, so they had an external knowledge of the Internet as well. Googling and browsing StackOverflow wasn‚Äôt needed anymore. Cursor gave the users a custom IDE with built in AI powered autocomplete and other baked-in AI tools, like chat, to make the experience coherent.</p><p>Then came the agent promise. MCPs, autonomous workflows, <a href=\"https://michaelxbloch.substack.com/p/no-coding-before-10am\">articles about agents running overnight</a> started to pop up left and right. It was a different use of AI than Cursor. <strong>It was no longer an AI-assisted human coding, but a human-assisted AI coding.</strong></p><p>Many devs tried it and got burned. Agents made tons of small mistakes. The AI-first process required a complete paradigm shift in how devs think about coding, in order to achieve great results. Also, agents often got stuck in loops, hallucinate dependencies, and produced code that looks almost right but isn‚Äôt. You needed to learn about a completely new tech, fueled by FOMO. And this new shiny tool never got it 100% right on the first try.</p><p>Software used to be deterministic. You controlled it with if/else branches, explicit state machines, clear logic. The new reality is controlling the development process with prompts, system instructions, and CLAUDE.md files, and hope the model produces the output you expect.</p><blockquote><p>An engineer at Spotify on their morning commute from Slack on their cell phone can tell Claude to fix a bug or add a new feature to the iOS app. And once Claude finishes that work, the engineer then gets a new version of the app, pushed to them on Slack on their phone, so that he can then merge it to production, all before they even arrive at the office.‚Äù</p></blockquote><p>I hope they at least review the code before merging.</p><p>The next stage is an (almost) full automation. That‚Äôs what many execs want and try to achieve. It‚Äôs a capitalistic wet dream, a worker that never sleeps, never gets tired, always wants to work, is infinitely productive. But Geoffrey Hinton predicted in 2016 that deep learning would outperform radiologists at image analysis within five years. Anthropic‚Äôs CEO predicted AI would write 90% of code within three to six months of March 2025. None of this happened as predicted. The trajectory is real, but the timeline keeps slipping.</p><p>In 2012, neuroscientist Manfred Spitzer published <a href=\"https://en.wikipedia.org/wiki/Digital_Dementia_(book)\">Digital Dementia</a>, arguing that when we outsource mental tasks to digital devices, the brain pathways responsible for those tasks atrophy. Use it or lose it. Not all of this is proven scientifically, but neuroplasticity research shows the brain strengthens pathways that get used and weakens ones that don‚Äôt. The core principle of the book is that the cognitive skills that you stop practicing will decline.</p><p>Margaret-Anne Storey, a software engineering researcher, recently gave this a more precise name: <a href=\"https://margaretstorey.com/blog/2026/02/09/cognitive-debt/\">cognitive debt</a>. Technical debt lives in the code. Cognitive debt lives in developers‚Äô heads. It‚Äôs the accumulated loss of understanding that happens when you build fast without comprehending what you built. She grounds it in Peter Naur‚Äôs 1985 theory that a program is a theory existing in developers‚Äô minds, capturing what it does, how intentions map to implementation, and how it can evolve. When that theory fragments, the system becomes a black box.</p><p>Apply this directly to fully agentic coding. If you stop writing code and only review AI output, your ability to reason about code atrophies. Slowly, invisibly, but inevitably. You can‚Äôt deeply review what you can no longer deeply understand.</p><p>This isn‚Äôt just theory. A <a href=\"https://arxiv.org/abs/2601.20245\">2026 randomized study by Shen and Tamkin</a> tested this directly: 52 professional developers learning a new async library were split into AI-assisted and unassisted groups. The AI group scored 17% lower on conceptual understanding, debugging, and code reading. The largest gap was in debugging, the exact skill you need to catch what AI gets wrong. One hour of passive AI-assisted work produced measurable skill erosion.</p><p>The insidious part is that you don‚Äôt notice the decline because the tool compensates for it. You feel productive. The PRs are shipping. Mihaly Csikszentmihalyi‚Äôs research on <a href=\"https://en.wikipedia.org/wiki/Flow_(psychology)\">flow</a> showed that the state of flow depends on a balance between challenge and skill. Your mind needs to be stretched just enough. Real flow produces growth. Rachel Thomas called what AI-assisted work produces <a href=\"https://www.fast.ai/posts/2026-01-28-dark-flow/\">‚Äúdark flow‚Äù</a>, a term borrowed from gambling research, describing the trance-like state slot machines are designed to induce. You feel absorbed, but the challenge-skill balance is gone because the AI handles the challenge. It feels like the flow state of deep work, but the feedback loop is broken. You‚Äôre not getting better, you‚Äôre getting dependent.</p><p>There‚Äôs this observation that keeps coming up in HN comments: if the AI writes all the code and you only review it, where does the skill to review come from? You can‚Äôt have one without the other. You don‚Äôt learn to recognize good code by reading about it in a textbook, or a PR. You learn by writing bad code, getting it torn apart, and building intuition through years of practice.</p><p>This creates what I‚Äôd call the review paradox: the more AI writes, the less qualified humans become to review what it wrote. The Shen-Tamkin study puts numbers on this. Developers who fully delegated to AI finished tasks fastest but scored worst on evaluations. The novices who benefit most from AI productivity are exactly the ones who need debugging skills to supervise it, and AI erodes those skills first.</p><p>Storey‚Äôs proposed fix is simple: ‚Äúrequire humans to understand each AI-generated change before deployment.‚Äù That‚Äôs the right answer. It‚Äôs also the one that gets skipped first when velocity is the metric.</p><p>This goes deeper than individual skill decay. We used to have juniors, mids, seniors, staff engineers, architects. It was a pipeline where each level built on years of hands-on struggle. A junior spends years writing code that is rejected during the code review not because they were not careful, but didn‚Äôt know better. It‚Äôs how you build the judgment that separates someone who can write a function from someone who can architect a system. You can‚Äôt become a senior overnight.</p><p>Unless you use AI, of course. Now, a junior with Claude Code (Opus 4.5+) delivers PRs that look like senior engineer work. And overall that‚Äôs a good thing, I think. But does it mean that the senior hat fits everyone now? From day one? But the head underneath hasn‚Äôt changed. That junior doesn‚Äôt know  that architecture was chosen. From my experience, sometimes CC misses a new DB transaction where it‚Äôs needed. Sometimes it creates a lock on a resource, that shouldn‚Äôt be locked, due to number of reasons. I can defend my decisions and I enjoy when my code is challenged, when reviewers disagree, and we have a discussion. What will a junior do? Ask Claude.</p><p>It‚Äôs a two-sided collapse. Seniors who stop writing code and only review AI output lose their own depth. Juniors who skip the struggle never build it. Organizations are spending senior time every day on reviews while simultaneously breaking the mechanisms that create it. The pipeline that produced senior engineers, writing bad code, getting bad code reviewed, building intuition through failure, is being bypassed entirely. Nobody‚Äôs talking about what happens when that pipeline runs dry.</p><h2>What C-Levels Got Right and Wrong</h2><p>The problem is that predictions come from people selling AI or trying to prop the stock with AI hype. They have every incentive to accelerate adoption and zero accountability when the timelines slip, which, historically, they always do. And ‚Äú50% of code characters‚Äù at Google, a company that has built its own models, tooling, and infrastructure from scratch, says very little about what your team can achieve with off-the-shelf agents next Monday.</p><p>AI adoption is not a switch to flip, rather a skill to calibrate. It‚Äôs not as simple as mandating specific tools, setting ‚ÄúAI-first‚Äù policies, measuring developers on how much AI they use (/r/ExperiencedDevs is full of these stories). A lot of good practices like usage of design patterns, proper test coverage, manual testing before merging, are often skipped these days because it reduces the pace. AI broke it? AI will fix it. You need a review? AI will do it. Not even Greptile or CodeRabbit. Just delegate the PR to Claude Code reviewer agent. Or Gemini. Or Codex. Pick your poison.</p><p>And here‚Äôs what actually happens when you force the AI usage. One developer on r/ExperiencedDevs <a href=\"https://www.reddit.com/r/ExperiencedDevs/comments/1o643iz/i_am_blissfully_using_ai_to_do_absolutely_nothing/\">described</a> their company tracking AI usage per engineer: ‚ÄúI just started asking my bots to do random things I don‚Äôt even care about. The other day I told Claude to examine random directories to ‚Äòfind bugs‚Äô or answer questions I already knew the answer to.‚Äù <a href=\"https://www.reddit.com/r/ExperiencedDevs/comments/1r4u0mo/comment/o5e5r2w/\">This thread</a> is full of engineers reporting that AI has made code reviews ‚Äúinfinitely harder due to the AI slop produced by tech leads who have been off the tools long enough to be dangerous.‚Äù</p><p>This is sad, because being able to work with the AI tools is a perk for developers and since it improves pace, it‚Äôs something management wants as well. It‚Äôs obvious that the people gaming the metrics (not really using the AI the way the should) would be fired on the spot if the management learned how they are gaming the metrics (and it‚Äôs fair), but they are gaming the metrics because they don‚Äôt want to be fired‚Ä¶</p><p>Who should be responsible for setting the threshold of AI usage at the company? What if your top performing engineer just refuses to use AI? What if the newly hired junior uses AI all the time? These are the new questions and management is trying to find an answer to them, but it‚Äôs not as simple as measuring the AI usage.</p><p>This is <a href=\"https://en.wikipedia.org/wiki/Goodhart%27s_law\">Goodhart‚Äôs law</a> in action: ‚ÄúWhen a measure becomes a target, it ceases to be a good measure.‚Äù Track AI usage per engineer and you won‚Äôt get better engineering, you‚Äôll get compliance theater. Developers game the metrics, resent the tools, and the actual productivity gains that AI  deliver get buried under organizational dysfunction.</p><h2>The Cost Nobody Talks About</h2><p>The financial cost is obvious. Agent time for non-trivial features is measured in hours, and those hours aren‚Äôt free. But the human cost is potentially worse, and it‚Äôs barely discussed.</p><p>Writing code can put you in a flow state, mentioned before. That deep, focused, creative problem-solving where hours disappear and you emerge with something you built and understand. And you‚Äôre proud of it. Someone wrote under your PR ‚ÄúGood job!‚Äù and gave you an approval. Reviewing AI-generated code does not do this. It‚Äôs the opposite. It‚Äôs a mental drain.</p><p>Developers need the dopamine hit of creation. That‚Äôs not a perk, it‚Äôs what keeps good engineers engaged, learning, retained, and prevents burnout. The joy of coding is probably what allowed them to become experienced devs in the first place. Replace creation with oversight and you get faster burnout, not faster shipping. You‚Äôve turned engineering, the creative work, into the worst form of QA. The AI does all the art, the human folds the laundry.</p><p>I use AI every day. I use AI heavily at work, I use AI in my sideprojects, and I don‚Äôt want to go back. I love it! That‚Äôs why I‚Äôm worried. I‚Äôm afraid I became addicted and dependent. I‚Äôve implemented countless custom commands, skills, and agents. I check CC release notes daily. And I know many are in similar situation right now, and we all wonder about what the future brings. Are we going to replace ourselves with AI? Or will we be responsible for cleaning AI slop? What‚Äôs the right amount of AI usage for me?</p><p>AI is just a tool. An extraordinarily powerful one, but a tool nonetheless. You wouldn‚Äôt mandate that every engineer uses a specific IDE, or measure people on how many lines they write per day (‚Ä¶right?). You‚Äôd let them pick the tools that make  most effective and measure what actually matters, the work that ships.</p><p>The right amount of AI is not zero. And it‚Äôs not maximum.</p><p>The Shen-Tamkin study identified six distinct AI interaction patterns among developers. Three led to poor learning: full delegation, progressive reliance, and outsourcing debugging to AI. Three preserved learning even with full AI access: asking for explanations, posing conceptual questions, and writing code independently while using AI for clarification. The differentiator wasn‚Äôt whether developers used AI, it was whether they stayed cognitively engaged.</p><p>Software engineering was never just about typing code. It‚Äôs defining the problem well, understanding the problem, translating the language from business to product to code, clarifying ambiguity, making tradeoffs, understanding what breaks when you change something. Someone has to do that before AGI, and AGI is nowhere close (luckily). You‚Äôre on call, the phone rings at 3am, can you triage the issue without an agent? If not, you‚Äôve probably taken AI coding too far. If the AI usage becomes a new performance metric of developer, maybe using AI too often, too much, should be discouraged as well? Not because these tools are bad, but because the coding skills are worth maintaining.</p><h3>The Risk of Too Little (anecdata)</h3><p>If you‚Äôre using no AI at all in 2026, you are leaving real gains on the table:</p><ul><li> AI is genuinely better than Google for navigating unfamiliar codebases, understanding legacy code, and finding relevant patterns. This alone justifies having it in your workflow (since 2023, Cursor etc)</li><li><strong>Boilerplate and scaffolding.</strong> Writing the hundredth CRUD endpoint, config file, or test scaffold by hand when an agent can produce it in seconds isn‚Äôt craftsmanship, it‚Äôs stubbornness. Just use AI. You‚Äôre not a CRUD developer anymore anyway, because we all wear many hats these days (post 2025 Sonnet)</li><li> The investigate, plan, implement, test, validate cycle that works with customized agents is a real improvement in how features get delivered. Hours instead of days for non-trivial work. It‚Äôs not the 10x that was promised, but 2x or 4x on an established codebases is low-hanging fruit. You must understand the output though and all the decisions AI made! (post 2025 Opus 4.5)</li><li> ‚ÄúWhat does this module do? How does this API work? What would break if I changed this?‚Äù AI is excellent at these questions. It won‚Äôt replace reading the code, but it‚Äôll get you to the right file in the right minute. (since 2023)</li></ul><p>Refusing to use AI out of principle is as irrational as adopting it out of hype.</p><h3>The Risk of Too Much (anecdata and my predictions)</h3><p>If you go all-in on autonomous AI coding (especially without learning how it all actually works), you risk something worse than slow velocity, you risk  degradation:</p><ul><li><strong>Bugs that look like features.</strong> AI-generated code passes CI. The types check. The tests are green. And somewhere inside there‚Äôs a subtle logic error, a hallucinated edge case, a pattern that‚Äôll collapse under load. In domains like finance or healthcare, a wrong number that doesn‚Äôt throw an error is worse than a crash. (less and less relevant, but still relevant)</li><li><strong>A codebase nobody understands.</strong> When the agent writes everything and humans only review, six months later nobody on the team can explain why the system is architected the way it is. The AI made choices. Nobody questioned them because the tests passed. Storey <a href=\"https://margaretstorey.com/blog/2026/02/09/cognitive-debt/\">describes</a> a student team that hit exactly this wall: they couldn‚Äôt make simple changes without breaking things, and the problem wasn‚Äôt messy code, it was that no one could explain why certain design decisions had been made. Her conclusion: ‚Äúvelocity without understanding is not sustainable.‚Äù (will always be a problem, IMO)</li><li> Everything in the Digital Dementia section above. Skills you stop practicing will decline. (will always be a problem, IMO)</li><li><strong>The seniority pipeline drying up.</strong> Also covered above. This one takes years to manifest, which is exactly why nobody‚Äôs planning for it. (It‚Äôs a new problem, I have no idea what it looks like in the future)</li><li> Reviewing AI output all day without the dopamine of creation is not a sustainable job description. (Old problem, but potentially hits faster?)</li></ul><p>Here‚Äôs what keeps me up at night. By every metric on every dashboard, AI-assisted human development and human-assisted AI development is improving. More PRs shipped. More features delivered. Faster cycle times. The charts go up and to the right.</p><p>But metrics don‚Äôt capture what‚Äôs happening underneath. The mental fatigue of reviewing code you didn‚Äôt write all day. The boredom of babysitting an agent instead of solving problems. The slow, invisible erosion of the hard skills that made you good at this job in the first place. You stop holding the architecture in your head because the agent handles it. You stop thinking through edge cases because the tests pass. You stop  to dig deep because it‚Äôs easier to prompt and approve. There‚Äôs no spark in you anymore.</p><p>In this meme the developers are the butter robot. The ones with no mental capacity to review the plans and PRs from AI, will only click Accept, instead of doing the creative, challenging work. Oh the irony.</p><p>Simon Willison, one of the most ambitious developer of our time, <a href=\"https://simonwillison.net/tags/cognitive-debt/\">admitted this is already happening to him</a>. On projects where he prompted entire features without reviewing implementations, he ‚Äúno longer has a firm mental model of what they can do and how they work.‚Äù</p><p>And then, one day, the metrics start slipping‚Ä¶ Not because the tool got worse, but because you did. Not from lack of effort, but from lack of practice. It‚Äôs a feedback loop that looks like progress right up until it doesn‚Äôt.</p><p>No executive wants to measure this. ‚ÄúWhat is the effect of AI usage on our engineers‚Äô cognitive abilities over 18 months?‚Äù is not an easy KPI. It doesn‚Äôt fit in a quarterly review. It doesn‚Äôt get tracked, and what doesn‚Äôt get tracked doesn‚Äôt get managed, until it shows up as a production incident that nobody on the team can debug without an agent, and the agent can‚Äôt debug either.</p><p>I‚Äôm not anti-AI, I like it a lot. I‚Äôm addicted to prompting, I get high from it. I‚Äôm just worried that this new dependency degrades us over time, quietly, and nobody‚Äôs watching for it.</p>","contentLength":19251,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47194847"},{"title":"Don't trust AI agents","url":"https://nanoclaw.dev/blog/nanoclaw-security-model","date":1772282372,"author":"gronky_","guid":145,"unread":true,"content":"<p>When you‚Äôre building with AI agents, they should be treated as untrusted and potentially malicious. Whether you‚Äôre worried about prompt injection, a model trying to escape its sandbox, or something nobody‚Äôs thought of yet, regardless of what your threat model is, you shouldn‚Äôt be trusting the agent. The right approach isn‚Äôt better permission checks or smarter allowlists. It‚Äôs architecture that assumes agents will misbehave and contains the damage when they do.</p><p>OpenClaw runs directly on the host machine by default. It has an opt-in Docker sandbox mode, but it‚Äôs turned off out of the box, and most users never turn it on. Without it, security relies entirely on application-level checks: allowlists, confirmation prompts, a set of ‚Äúsafe‚Äù commands. These checks come from a place of implicit trust that the agent isn‚Äôt going to try to do something wrong. Once you adopt the mindset that an agent is potentially malicious, it‚Äôs obvious that application-level blocks aren‚Äôt enough. They don‚Äôt provide hermetic security. A determined or compromised agent can find ways around them.</p><p>In NanoClaw, container isolation is a core part of the architecture. Each agent runs in its own container, on Docker or an Apple Container on macOS. Containers are ephemeral, created fresh per invocation and destroyed afterward. The agent runs as an unprivileged user and can only see directories that have been explicitly mounted in. A container boundary is enforced by the OS.</p><p>Even when OpenClaw‚Äôs sandbox is enabled, all agents share the same container. You might have one agent as a personal assistant and another for work, in different WhatsApp groups or Telegram channels. They‚Äôre all in the same environment, which means information can leak between agents that are supposed to be accessing different data.</p><p>Agents shouldn‚Äôt trust each other any more than you trust them. In NanoClaw, each agent gets its own container, filesystem, and Claude session history. Your personal assistant can‚Äôt see your work agent‚Äôs data because they run in completely separate sandboxes.</p><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 960 460\" font-family=\"'JetBrains Mono', 'SF Mono', 'Fira Code', monospace\" role=\"img\" aria-label=\"Shared container vs per-agent containers: in a shared container all agents see everything, with per-agent containers each agent is isolated\"></svg><p>The container boundary is the hard security layer ‚Äî the agent can‚Äôt escape it regardless of configuration. On top of that, a mount allowlist at <code>~/.config/nanoclaw/mount-allowlist.json</code> acts as an additional layer of defense-in-depth: it exists to prevent the  from accidentally mounting something that shouldn‚Äôt be exposed, not to prevent the agent from breaking out. Sensitive paths (, , , , , ) are blocked by default. The allowlist lives outside the project directory, so a compromised agent can‚Äôt modify its own permissions. The host application code is mounted read-only, so nothing an agent does can persist after the container is destroyed.</p><p>People in your groups shouldn‚Äôt be trusted either. Non-main groups are untrusted by default. Other groups, and the people in them, can‚Äôt message other chats, schedule tasks for other groups, or view other groups‚Äô data. Anyone in a group could send a prompt injection, and the security model accounts for that.</p><h2>Don‚Äôt trust what you can‚Äôt read</h2><p>OpenClaw has nearly half a million lines of code, 53 config files, and over 70 dependencies. This breaks the basic premise of open source security. Chromium has 35+ million lines, but you trust Google‚Äôs review processes. Most open source projects work the other way: they stay small enough that many eyes can actually review them. Nobody has reviewed OpenClaw‚Äôs 400,000 lines. It was written in weeks with no proper review process. Complexity is where vulnerabilities hide, and <a href=\"https://www.microsoft.com/en-us/security/blog/2026/02/19/running-openclaw-safely-identity-isolation-runtime-risk/\">Microsoft‚Äôs analysis</a> confirmed this: OpenClaw‚Äôs risks could emerge through normal API calls, because no one person could see the full picture.</p><p>NanoClaw is one process and a handful of files. We rely heavily on Anthropic‚Äôs Agent SDK, the wrapper around Claude Code, for session management, memory compaction, and a lot more, instead of reinventing the wheel. A competent developer can review the entire codebase in an afternoon. This is <a href=\"https://nanoclaw.dev/#philosophy\">a deliberate constraint, not a limitation</a>. Our <a href=\"https://github.com/qwibitai/nanoclaw/blob/main/CONTRIBUTING.md\">contribution guidelines</a> accept bug fixes, security fixes, and simplifications only.</p><p>New functionality comes through skills: instructions with a full working reference implementation that a coding agent merges into your codebase. You review exactly what code will be added before it lands. And you only add the integrations you actually need. Every installation ends up as a few thousand lines of code tailored to the owner‚Äôs exact requirements.</p><p>This is the real difference. With a monolithic codebase of 400,000 lines, even if you only enable two integrations, the rest of the code is still there. It‚Äôs still loaded, still part of your attack surface, still reachable by prompt injections and rogue agents. You can‚Äôt disentangle what‚Äôs active from what‚Äôs dormant. You can‚Äôt audit it because you can‚Äôt even define the boundary of what ‚Äúyour code‚Äù is. With skills, the boundary is obvious: it‚Äôs a few thousand lines, it‚Äôs all code you chose to add, and you can read every line of it. The core is actually getting smaller over time: WhatsApp support, for example, is being pulled out and packaged as a skill.</p><p>If a hallucination or a misbehaving agent can cause a security issue, then the security model is broken. Security has to be enforced outside the agentic surface, not depend on the agent behaving correctly. Containers, mount restrictions, and filesystem isolation all exist so that even when an agent does something unexpected, the blast radius is contained.</p><p>None of this eliminates risk. An AI agent with access to your data is inherently a high-risk arrangement. But the right response is to make that trust as narrow and as verifiable as possible. Don‚Äôt trust the agent. Build walls around it.</p>","contentLength":5783,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47194611"},{"title":"OpenAI ‚Äì How to delete your account","url":"https://help.openai.com/en/articles/6378407-how-to-delete-your-account","date":1772275315,"author":"carlosrg","guid":144,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47193478"},{"title":"MCP server that reduces Claude Code context consumption by 98%","url":"https://mksg.lu/blog/context-mode","date":1772272880,"author":"mksglu","guid":143,"unread":true,"content":"<p>Every MCP tool call in Claude Code dumps raw data into your 200K context window. A Playwright snapshot costs 56 KB. Twenty GitHub issues cost 59 KB. One access log ‚Äî 45 KB. After 30 minutes, 40% of your context is gone.</p><p>Context Mode is an MCP server that sits between Claude Code and these outputs. 315 KB becomes 5.4 KB. 98% reduction.</p><p>MCP became the standard way for AI agents to use external tools. But there's a tension at its core: every tool interaction fills the context window from both sides ‚Äî definitions on the way in, raw output on the way out.</p><p>With 81+ tools active, 143K tokens (72%) get consumed before your first message. Then the tools start returning data. A single Playwright snapshot burns 56 KB. A  dumps 59 KB. Run a test suite, read a log file, fetch documentation ‚Äî each response eats into what remains.</p><p>Cloudflare showed that tool definitions can be compressed by 99.9% with Code Mode. We asked: what about the other direction?</p><p>Each  call spawns an isolated subprocess with its own process boundary. Scripts can't access each other's memory or state. The subprocess runs your code, captures stdout, and only that stdout enters the conversation context. The raw data ‚Äî log files, API responses, snapshots ‚Äî never leaves the sandbox.</p><p>Ten language runtimes are available: JavaScript, TypeScript, Python, Shell, Ruby, Go, Rust, PHP, Perl, R. Bun is auto-detected for 3-5x faster JS/TS execution.</p><p>Authenticated CLIs (, , , , ) work through credential passthrough ‚Äî the subprocess inherits environment variables and config paths without exposing them to the conversation.</p><h2>How the Knowledge Base Works</h2><p>The  tool chunks markdown content by headings while keeping code blocks intact, then stores them in a  (Full-Text Search 5) virtual table. Search uses  ‚Äî a probabilistic relevance algorithm that scores documents based on term frequency, inverse document frequency, and document length normalization.  is applied at index time so \"running\", \"runs\", and \"ran\" match the same stem.</p><p>When you call , it returns exact code blocks with their heading hierarchy ‚Äî not summaries, not approximations, the actual indexed content.  extends this to URLs: fetch, convert HTML to markdown, chunk, index. The raw page never enters context.</p><p>Validated across 11 real-world scenarios ‚Äî test triage, TypeScript error diagnosis, git diff review, dependency audit, API response processing, CSV analytics. All under 1 KB output each.</p><ul><li> 56 KB ‚Üí 299 B</li><li> 59 KB ‚Üí 1.1 KB</li><li><strong>Access log (500 requests):</strong> 45 KB ‚Üí 155 B</li><li><strong>Analytics CSV (500 rows):</strong> 85 KB ‚Üí 222 B</li><li> 11.6 KB ‚Üí 107 B</li><li><strong>Repo research (subagent):</strong> 986 KB ‚Üí 62 KB (5 calls vs 37)</li></ul><p>Over a full session: 315 KB of raw output becomes 5.4 KB. Session time before slowdown goes from ~30 minutes to ~3 hours. Context remaining after 45 minutes: 99% instead of 60%.</p><p>Two ways. Plugin Marketplace gives you auto-routing hooks and slash commands:</p><figure data-rehype-pretty-code-figure=\"\"><pre tabindex=\"0\" data-language=\"bash\" data-theme=\"github-light\"><code data-language=\"bash\" data-theme=\"github-light\"></code></pre></figure><p>Or MCP-only if you just want the tools:</p><figure data-rehype-pretty-code-figure=\"\"><pre tabindex=\"0\" data-language=\"bash\" data-theme=\"github-light\"><code data-language=\"bash\" data-theme=\"github-light\"></code></pre></figure><p>Restart Claude Code. Done.</p><p>You don't change how you work. Context Mode includes a PreToolUse hook that automatically routes tool outputs through the sandbox. Subagents learn to use  as their primary tool. Bash subagents get upgraded to  so they can access MCP tools.</p><p>The practical difference: your context window stops filling up. Sessions that used to hit the wall at 30 minutes now run for 3 hours. The same 200K tokens, used more carefully.</p><p>I run the MCP Directory &amp; Hub. 100K+ daily requests. See every MCP server that ships. The pattern was clear: everyone builds tools that dump raw data into context. Nobody was solving the output side.</p><p>Cloudflare's Code Mode blog post crystallized it. They compressed tool definitions. We compress tool outputs. Same principle, other direction.</p><p>Built it for my own Claude Code sessions first. Noticed I could work 6x longer before context degradation. Open-sourced it.</p>","contentLength":3826,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47193064"}],"tags":["dev","hn"]}