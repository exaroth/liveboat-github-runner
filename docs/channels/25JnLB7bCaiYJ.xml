<?xml version="1.0" encoding="utf-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Tech News</title><link>https://konrad.website/liveboat-github-runner/</link><description></description><item><title>Linux 6.17 Adds Fan &amp; Thermal Profile Support For HP Victus 16-r1000 Gaming Laptops</title><link>https://www.phoronix.com/news/HP-Victus-16-r1000-Linux</link><author>Michael Larabel</author><category>tech</category><pubDate>Sat, 23 Aug 2025 10:37:24 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[For those that happen to have an HP Victus 16-r1000 gaming laptop or considering one with the 14th Gen Intel Core CPUs and NVIDIA GeForce RTX 40 graphics, the Linux support is now slightly better off thanks to the HP-WMI driver adding fan and thermal profile support for the Victus 16-r1000 series...]]></content:encoded></item><item><title>Google Prepares Chrome Field Trial For Accelerated Video Decode On Wayland</title><link>https://www.phoronix.com/news/Chrome-Wayland-Decode-Field</link><author>Michael Larabel</author><category>tech</category><pubDate>Sat, 23 Aug 2025 10:20:26 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[Google is preparing a field trial with the Chrome web browser of accelerated video decoding under Wayland/Linux as a step toward rolling it out by default for a better video playback experience on the Linux desktop with Wayland-based environments...]]></content:encoded></item><item><title>Nouveau Driver Receives Patch For GPU Reclocking With The Pascal GP10B</title><link>https://www.phoronix.com/news/Nouveau-GP10B-Reclocking</link><author>Michael Larabel</author><category>tech</category><pubDate>Sat, 23 Aug 2025 10:08:38 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[Nearly a decade after the Tegra X2 SoC shipped in the likes of the Jetson TX2, the Pascal-based GP10B GPU has received a patch for allowing GPU re-clocking within the open-source Nouveau driver...]]></content:encoded></item><item><title>KDE Plasma 6.5 Introducing &quot;KISS&quot; - An Initial System Setup Wizard</title><link>https://www.phoronix.com/news/KDE-KISS-Initial-Setup-Wizard</link><author>Michael Larabel</author><category>tech</category><pubDate>Sat, 23 Aug 2025 09:33:25 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[KDE developer Nate Graham is out with his customary weekend blog post to summarize all the interesting Plasma desktop developments for the week. Most exciting in recent days is Plasma 6.5 receiving an initial system setup wizard...]]></content:encoded></item><item><title>US Is Throwing Away the Critical Minerals It Needs, Analysis Shows</title><link>https://news.slashdot.org/story/25/08/23/0120237/us-is-throwing-away-the-critical-minerals-it-needs-analysis-shows?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>BeauHD</author><category>tech</category><pubDate>Sat, 23 Aug 2025 07:00:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[alternative_right shares a report from Phys.org: All the critical minerals the U.S. needs annually for energy, defense and technology applications are already being mined at existing U.S. facilities, according to a new analysis published in the journal Science. The catch? These minerals, such as cobalt, lithium, gallium and rare earth elements like neodymium and yttrium, are currently being discarded as tailings of other mineral streams like gold and zinc, said Elizabeth Holley, associate professor of mining engineering at Colorado School of Mines and lead author of the new paper.
 
To conduct the analysis, Holley and her team built a database of annual production from federally permitted metal mines in the U.S. They used a statistical resampling technique to pair these data with the geochemical concentrations of critical minerals in ores, recently compiled by the U.S. Geological Survey, Geoscience Australia and the Geologic Survey of Canada. Using this approach, Holley's team was able to estimate the quantities of critical minerals being mined and processed every year at U.S. metal mines but not being recovered. Instead, these valuable minerals are ending up as discarded tailings that must be stored and monitored to prevent environmental contamination.
 
The analysis looks at a total of 70 elements used in applications ranging from consumer electronics like cell phones to medical devices to satellites to renewable energy to fighter jets and shows that unrecovered byproducts from other U.S. mines could meet the demand for all but two -- platinum and palladium. Among the elements included in the analysis are:
- Cobalt (Co): The lustrous bluish-gray metal, a key component in electric car batteries, is a byproduct of nickel and copper mining. Recovering less than 10% of the cobalt currently being mined and processed but not recovered would be more than enough to fuel the entire U.S. battery market.
- Germanium (Ge): The brittle silvery-white semi-metal used for electronics and infrared optics, including sensors on missiles and defense satellites, is present in zinc and molybdenum mines. If the U.S. recovered less than 1% of the germanium currently mined and processed but not recovered from U.S. mines, it would not have to import any germanium to meet industry needs.]]></content:encoded></item><item><title>Google Says It Dropped the Energy Cost of AI Queries By 33x In One Year</title><link>https://tech.slashdot.org/story/25/08/22/2118234/google-says-it-dropped-the-energy-cost-of-ai-queries-by-33x-in-one-year?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>BeauHD</author><category>tech</category><pubDate>Sat, 23 Aug 2025 03:30:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[Google has released (PDF) a new analysis of its AI's environmental impact, showing that it has cut the energy use of AI text queries by a factor of 33 over the past year. Each prompt now consumes about 0.24 watt-hours -- the equivalent of watching nine seconds of TV. An anonymous reader shares an excerpt from an Ars Technica article: "We estimate the median Gemini Apps text prompt uses 0.24 watt-hours of energy, emits 0.03 grams of carbon dioxide equivalent (gCO2e), and consumes 0.26 milliliters (or about five drops) of water," they conclude. To put that in context, they estimate that the energy use is similar to about nine seconds of TV viewing. The bad news is that the volume of requests is undoubtedly very high. The company has chosen to execute an AI operation with every single search request, a compute demand that simply didn't exist a couple of years ago. So, while the individual impact is small, the cumulative cost is likely to be considerable.
 
The good news? Just a year ago, it would have been far, far worse. Some of this is just down to circumstances. With the boom in solar power in the US and elsewhere, it has gotten easier for Google to arrange for renewable power. As a result, the carbon emissions per unit of energy consumed saw a 1.4x reduction over the past year. But the biggest wins have been on the software side, where different approaches have led to a 33x reduction in energy consumed per prompt.
 
The Google team describes a number of optimizations the company has made that contribute to this. One is an approach termed Mixture-of-Experts, which involves figuring out how to only activate the portion of an AI model needed to handle specific requests, which can drop computational needs by a factor of 10 to 100. They've developed a number of compact versions of their main model, which also reduce the computational load. Data center management also plays a role, as the company can make sure that any active hardware is fully utilized, while allowing the rest to stay in a low-power state.
 
The other thing is that Google designs its own custom AI accelerators, and it architects the software that runs on them, allowing it to optimize both sides of the hardware/software divide to operate well with each other. That's especially critical given that activity on the AI accelerators accounts for over half of the total energy use of a query. Google also has lots of experience running efficient data centers that carries over to the experience with AI. The result of all this is that it estimates that the energy consumption of a typical text query has gone down by 33x in the last year alone.]]></content:encoded></item><item><title>GNOME&apos;s Glycin Lands &quot;Dramatically Improved&quot; JPEG-XL Image Loading Performance</title><link>https://www.phoronix.com/news/GNOME-Glycin-Faster-JPEG-XL</link><author>Michael Larabel</author><category>tech</category><pubDate>Sat, 23 Aug 2025 00:33:48 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[Glycin 2.0 Beta 3 was released this week for the GNOME project providing a Rust-based library for decoding, editing, and creating images and associated metadata. Glycin is in turn used by a growing number of GNOME components for imaging needs...]]></content:encoded></item><item><title>Bluesky Blocks Service In Mississippi Over Age Assurance Law</title><link>https://tech.slashdot.org/story/25/08/22/2327213/bluesky-blocks-service-in-mississippi-over-age-assurance-law?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>BeauHD</author><category>tech</category><pubDate>Sat, 23 Aug 2025 00:20:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[Bluesky has blocked access to its service in Mississippi rather than comply with a new state law requiring age verification for all social media users. TechCrunch reports: In a blog post published on Friday, the company explains that, as a small team, it doesn't have the resources to make the substantial technical changes this type of law would require, and it raised concerns about the law's broad scope and privacy implications. Mississippi's HB 1126 requires platforms to introduce age verification for all users before they can access social networks like Bluesky. On Thursday, U.S. Supreme Court justices decided to block an emergency appeal that would have prevented the law from going into effect as the legal challenges it faces played out in the courts. As a result, Bluesky had to decide what it would do about compliance.
 
Instead of requiring age verification before users could access age-restricted content, this law requires age verification of all users. That means Bluesky would have to verify every user's age and obtain parental consent for anyone under 18. The company notes that the potential penalties for noncompliance are hefty, too -- up to $10,000 per user. Bluesky also stresses that the law goes beyond child safety, as intended, and would create "significant barriers that limit free speech and disproportionately harm smaller platforms and emerging technologies." To comply, Bluesky would have to collect and store sensitive information from all its users, in addition to the detailed tracking of minors. This is different from how it's expected to comply with other age verification laws, like the U.K.'s Online Safety Act (OSA), which only requires age checks for certain content and features.
 
Mississippi's law blocks anyone from using the site unless they provide their personal and sensitive information. The company notes that its decision only applies to the Bluesky app built on the AT Protocol. Other apps may approach the decision differently.]]></content:encoded></item><item><title>Meta Set To Unveil First Consumer-Ready Smart Glasses With a Display, Wristband</title><link>https://hardware.slashdot.org/story/25/08/22/217232/meta-set-to-unveil-first-consumer-ready-smart-glasses-with-a-display-wristband?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>BeauHD</author><category>tech</category><pubDate>Fri, 22 Aug 2025 23:40:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[At its upcoming Connect conference next month, Meta is rumored to unveil its first consumer-ready smart glasses with a built-in display, alongside a neural wristband controller. The $800 device, codenamed Hypernova, will be able to show simple visual content like texts and support AI assistant interactions. CNBC reports: Connect is a two-day conference for developers focused on virtual reality, AR and the metaverse. It was originally called Oculus Connect and obtained its current moniker after Facebook changed its parent company name to Meta in 2021. The glasses are internally codenamed Hypernova and will include a small digital display in the right lens of the device, said the people, who asked not to be named because the details are confidential. The device is expected to cost about $800 and will be sold in partnership with EssilorLuxottica, the people said. CNBC reported in October that Meta was working with Luxottica on consumer glasses with a display. [...]
 
With Hypernova, Meta will finally be offering glasses with a display to consumers, but the company is setting low expectations for sales, some of the sources said. That's because the device requires more components than its voice-only predecessors, and will be slightly heavier and thicker, the people said. [...] Although Hypernova will feature a display, those visual features are expected to be limited, people familiar with the matter said. They said the color display will offer about a 20 degree field of view -- meaning it will appear in a small window in a fixed position -- and will be used primarily to relay simple bits of information, such as incoming text messages.
 
The Hypernova glasses will also come paired with a wristband that will use technology built by Meta's CTRL Labs, said people familiar with the matter. CTRL Labs, which Meta acquired in 2019, specializes in building neural technology that could allow users to control computing devices using gestures in their arms. [...] In addition to Hypernova and the wristband, Meta will also announce a third-generation of its voice-only smart glasses with Luxottica at Connect, one person said.]]></content:encoded></item><item><title>Microsoft Reportedly Cuts China&apos;s Early Access to Bug Disclosures, PoC Exploit Code</title><link>https://it.slashdot.org/story/25/08/22/2059255/microsoft-reportedly-cuts-chinas-early-access-to-bug-disclosures-poc-exploit-code?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>BeauHD</author><category>tech</category><pubDate>Fri, 22 Aug 2025 23:00:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[An anonymous reader quotes a report from The Register: Microsoft has reportedly stopped giving Chinese companies proof-of-concept exploit code for soon-to-be-disclosed vulnerabilities following last month's SharePoint zero-day attacks, which appear to be related to a leak in Redmond's early-bug-notification program. The software behemoth gives some software vendors early bug disclosures under its Microsoft Active Protections Program (MAPP), which typically delivers info two weeks before Patch Tuesday. MAPP participants sign a non-disclosure agreement, and in exchange get vulnerability details so that they can provide updated protections to customers more quickly.
 
According to Microsoft spokesperson David Cuddy, who spoke with Bloomberg about changes to the program, MAPP has begun limiting access to companies in "countries where they're required to report vulnerabilities to their governments," including China. Companies in these countries will no longer receive "proof of concept" exploit code, but instead will see "a more general written description" that Microsoft sends at the same time as patches, Cuddy told the news outlet. "A leak happened here somewhere," Dustin Childs, head of threat awareness at Trend Micro's Zero Day Initiative (ZDI), told The Register in July. "And now you've got a zero-day exploit in the wild, and worse than that, you've got a zero-day exploit in the wild that bypasses the patch, which came out the next day."
 
Childs said the MAPP change "is a positive change, if a bit late. Anything Microsoft can do to help prevent leaks while still offering MAPP guidance is welcome."
 
"In the past, MAPP leaks were associated with companies out of China, so restricting information from flowing to these companies should help," Childs said. "The MAPP program remains a valuable resource for network defenders. Hopefully, Microsoft can squelch the leaks while sending out the needed information to companies that have proven their ability (and desire) to protect end users."]]></content:encoded></item><item><title>Waymo Granted First Permit To Being Testing Autonomous Vehicles In NYC</title><link>https://tech.slashdot.org/story/25/08/22/2036239/waymo-granted-first-permit-to-being-testing-autonomous-vehicles-in-nyc?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>BeauHD</author><category>tech</category><pubDate>Fri, 22 Aug 2025 22:20:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[Waymo has received its first permit from the New York City Department of Transportation to begin testing autonomous vehicles in Manhattan and Downtown Brooklyn, marking the city's first official rollout of self-driving car trials. The program will initially deploy up to eight vehicles with safety drivers through late September, with the potential to extend and expand into other boroughs. CNBC reports: New York state law requires the company to have a driver behind the wheel to operate. "We're a tech-friendly administration and we're always looking for innovative ways to safely move our city forward," [Mayor Eric Adams] said in a release. "New York City is proud to welcome Waymo to test this new technology in Manhattan and Brooklyn, as we know this testing is only the first step in moving our city further into the 21st century."
 
The news comes just two months after the company said it filed permits to test its cars in the city with a trained specialist behind the wheel. [...] As part of the permit, Waymo must regularly meet and report data to DOT and work closely with law enforcement and emergency services.]]></content:encoded></item><item><title>College student’s “time travel” AI experiment accidentally outputs real 1834 history</title><link>https://arstechnica.com/information-technology/2025/08/ai-built-from-1800s-texts-surprises-creator-by-mentioning-real-1834-london-protests/</link><author>Benj Edwards</author><category>tech</category><enclosure url="https://cdn.arstechnica.net/wp-content/uploads/2025/08/1800s_protests-1152x648.jpg" length="" type=""/><pubDate>Fri, 22 Aug 2025 22:13:56 +0000</pubDate><source url="https://arstechnica.com/">Biz &amp; IT – Ars Technica</source><content:encoded><![CDATA[A hobbyist developer building AI language models that speak Victorian-era English "just for fun" got an unexpected history lesson this week when his latest creation mentioned real protests from 1834 London—events the developer didn't know had actually happened until he Googled them."I was interested to see if a protest had actually occurred in 1834 London and it really did happen," wrote Reddit user Hayk Grigorian, who is a computer science student at Muhlenberg College in Pennsylvania.For the past month, Grigorian has been developing what he calls TimeCapsuleLLM, a small AI language model (like a pint-sized distant cousin to ChatGPT) which has been trained entirely on texts from 1800–1875 London. Grigorian wants to capture an authentic Victorian voice in the AI model's outputs. As a result, the AI model ends up spitting out text that's heavy with biblical references and period-appropriate rhetorical excess.]]></content:encoded></item><item><title>Meta Signs $10 Billion Cloud Deal With Google</title><link>https://meta.slashdot.org/story/25/08/22/2043255/meta-signs-10-billion-cloud-deal-with-google?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>BeauHD</author><category>tech</category><pubDate>Fri, 22 Aug 2025 22:00:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[Google has signed a six-year cloud computing deal with Meta worth over $10 billion, making it the second major partnership after a recent agreement with OpenAI. The deal will see Meta rely on Google Cloud's infrastructure to support its massive AI data center buildout, as the company ramps up capital spending into the tens of billions. The Information (paywalled) first reported the deal.]]></content:encoded></item><item><title>Meta partners with Midjourney on AI image and video models</title><link>https://techcrunch.com/2025/08/22/meta-partners-with-midjourney-on-ai-image-and-video-models/</link><author>Maxwell Zeff</author><category>tech</category><pubDate>Fri, 22 Aug 2025 21:41:31 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Meta's chief AI officer said that the company is partnering with Midjourney to license its AI image and video model technology.]]></content:encoded></item><item><title>Record Solar Growth Keeps China&apos;s CO2 Falling in First Half of 2025</title><link>https://news.slashdot.org/story/25/08/22/2036256/record-solar-growth-keeps-chinas-co2-falling-in-first-half-of-2025?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>msmash</author><category>tech</category><pubDate>Fri, 22 Aug 2025 21:40:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[Clean-energy growth helped China's carbon dioxide (CO2) emissions fall by 1% year-on-year in the first half of 2025, extending a declining trend that started in March 2024. From a report: The CO2 output of the nation's power sector -- its dominant source of emissions -- fell by 3% in the first half of the year, as growth in solar power alone matched the rise in electricity demand. The new analysis for Carbon Brief shows that record solar capacity additions are putting China's CO2 emissions on track to fall across 2025 as a whole. 

Other key findings include: 

The growth in clean power generation, some 270 terawatt hours (TWh) excluding hydro, significantly outpaced demand growth of 170TWh in the first half of the year.
Solar capacity additions set new records due to a rush before a June policy change, with 212 gigawatts (GW) added in the first half of the year.
This rush means solar is likely to set an annual record for growth in 2025, becoming China's single-largest source of clean power generation in the process.
Coal-power capacity could surge by as much as 80-100GW this year, potentially setting a new annual record, even as coal-fired electricity generation declines.
The use of coal to make synthetic fuels and chemicals is growing rapidly, climbing 20% in the first half of the year and helping add 3% to China's CO2 since 2020.
The coal-chemical industry is planning further expansion, which could add another 2% to China's CO2 by 2029, making the 2030 deadline for peaking harder to meet.]]></content:encoded></item><item><title>Coinbase CEO explains why he fired engineers who didn’t try AI immediately</title><link>https://techcrunch.com/2025/08/22/coinbase-ceo-explains-why-he-fired-engineers-who-didnt-try-ai-immediately/</link><author>Julie Bort</author><category>tech</category><pubDate>Fri, 22 Aug 2025 21:07:21 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[After getting licenses to cover every engineer, some at the cryptocurrency exchange warned Armstrong that adoption would be slow, predicting it would take months to get even half the engineers using AI. ]]></content:encoded></item><item><title>4chan Refuses To Pay UK Online Safety Act Fines</title><link>https://news.slashdot.org/story/25/08/22/2029253/4chan-refuses-to-pay-uk-online-safety-act-fines?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>BeauHD</author><category>tech</category><pubDate>Fri, 22 Aug 2025 21:00:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[An anonymous reader quotes a report from the BBC: A lawyer representing the online message board 4chan says it won't pay a proposed fine by the UK's media regulator as it enforces the Online Safety Act. According to Preston Byrne, managing partner of law firm Byrne & Storm, Ofcom has provisionally decided to impose a 20,000-pound fine "with daily penalties thereafter" for as long as the site fails to comply with its request. "Ofcom's notices create no legal obligations in the United States," he told the BBC, adding he believed the regulator's investigation was part of an "illegal campaign of harassment" against US tech firms.
 
"4chan has broken no laws in the United States -- my client will not pay any penalty," Mr Byrne said. Ofcom began investigating 4chan over whether it was complying with its obligations under the UK's Online Safety Act. Then in August, it said it had issued 4chan with "a provisional notice of contravention" for failing to comply with two requests for information. Ofcom said its investigation would examine whether the message board was complying with the act, including requirements to protect its users from illegal content. "American businesses do not surrender their First Amendment rights because a foreign bureaucrat sends them an email," law firms Byrne & Storm and Coleman Law wrote. "Under settled principles of US law, American courts will not enforce foreign penal fines or censorship codes. If necessary, we will seek appropriate relief in US federal court to confirm these principles."
 
The statement calls on the Trump administration to intervene and protect American businesses from "extraterritorial censorship mandates."]]></content:encoded></item><item><title>Bluesky blocks service in Mississippi over age assurance law</title><link>https://techcrunch.com/2025/08/22/bluesky-blocks-service-in-mississippi-over-age-assurance-law/</link><author>Sarah Perez</author><category>tech</category><pubDate>Fri, 22 Aug 2025 20:30:49 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[In a blog post published on Friday, the company explains that, as a small team, it doesn't have the resources to make the substantial technical changes this type of law would require, and it raised concerns about the law's broad scope and privacy implications.]]></content:encoded></item><item><title>OpenZFS 2.4-rc1 Brings Linux 6.16 Compatibility, Better Encryption Performance With AVX2</title><link>https://www.phoronix.com/news/OpenZFS_2.4-rc1-Released</link><author>Michael Larabel</author><category>tech</category><pubDate>Fri, 22 Aug 2025 20:26:20 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[The first release candidate of OpenZFS 2.4 is now available for testing of this ZFS file-system implementation for Linux and FreeBSD systems...]]></content:encoded></item><item><title>Workers Need Better Protections From the Heat</title><link>https://news.slashdot.org/story/25/08/22/2020223/workers-need-better-protections-from-the-heat?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>msmash</author><category>tech</category><pubDate>Fri, 22 Aug 2025 20:20:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[An anonymous reader shares a report: Expect record-breaking temperatures to change the workplace, the World Health Organization (WHO) and World Meteorological Organization (WMO) warned today in a new report. When workers don't have adequate protections from heat stress, their health and productivity suffer. 

It's a risk employers and lawmakers have to take more seriously if they want to keep workers safe and businesses prosperous, the agencies say. That means finding ways to adapt in a warming world, and paying close attention to groups that might be more vulnerable than others. 

[...] More than 2.4 billion people around the world -- 71 percent of the working population -- experience workplace heat stress, according to estimates from the ILO. Each year, 22.85 million occupational injuries and 18,970 fatalities are linked to excessive heat at work. The report also says that worker productivity falls 2-3 percent with every degree increase above 20 degrees Celsius in wet-bulb globe temperature, a measure that takes humidity and other environmental factors into account.]]></content:encoded></item><item><title>Apple gets ready for AI in the enterprise with new ChatGPT configuration options</title><link>https://techcrunch.com/2025/08/22/apple-gets-ready-for-ai-in-the-enterprise-with-new-chatgpt-configuration-options/</link><author>Sarah Perez</author><category>tech</category><pubDate>Fri, 22 Aug 2025 20:00:34 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Apple will let businesses configure ChatGPT enterprise access in the fall. ]]></content:encoded></item><item><title>ESCAPE Presale Live on Ethereum With $280K Raised, Hacken Audited and SolidProof KYC Verified</title><link>https://hackernoon.com/escape-presale-live-on-ethereum-with-$280k-raised-hacken-audited-and-solidproof-kyc-verified?source=rss</link><author>Chainwire</author><category>tech</category><pubDate>Fri, 22 Aug 2025 19:42:14 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[Zurich, Switzerland, August 21st, 2025/Chainwire/--With an overwhelming 180,000 USD raised within 24 hours,  Ethereum presale is in Stage 3 at $0.01752, moving toward a final stage price of $0.03236.ESCAPE, a Web3 infrastructure token, has launched its presale on Ethereum and shared its roadmap for new blockchain tools. The project aims to make it easy to create tokens, check analytics, and give communities better visibility: all without needing complex coding or bridges.According to the team, right now, the world of crypto can feel confusing and scattered - people often have to jump between many different apps and tools just to trade, track information, and stay safe. ESCAPE's goal is to make things simple by creating one all-in-one platform where everything you need is in one place.The project's development strategy emerged from practical market experience, having initially deployed on an Ethereum Layer 2 solution where the team observed strong community demand for simplified, integrated tools. The original implementation achieved a market capitalization of 11.5 million dollars within two days, demonstrating significant market appetite for consolidated crypto trading infrastructure. Following the discontinuation of the initial Layer 2 platform, the team transitioned to Ethereum Layer 1 to ensure long-term sustainability and independence.ESCAPE emphasizes transparency and accountability. The platform has successfully completed an audit by Hacken that also has audited known companies like Binance, verification by Coinsult, and a KYC review conducted by SolidProof ensures the team is Doxxed. The development process is tracked via an open community board.During and after the presale, ESCAPE also offers a staking program with a sustainable 15% APY, giving early supporters a way to earn rewards. This rate was chosen carefully to ensure long-term growth and ecosystem stability.A collaboration with PAW Chain will extend ESCAPE’s reach by enabling multichain deployment. This integration will allow token creators to launch identical contract addresses across more than 15 major blockchains, including Ethereum, Solana, Binance Smart Chain (BSC), Arbitrum, Base, and Avalanche - removing the need for bridges or wrapped tokens.Utilities and DeliverablesThe ESCAPE ecosystem, powered by the $ESCAPE token, is being rebuilt and expanded to include:EscapePad: a no-code token launchpad for Ethereum and future networksDEX Viewer: real-time charts, wallet activity, and volume analyticsWallet Inspector: cross-chain portfolio and transaction analysisTelegram Bots: customizable alerts for trades and holder milestonesMobile App: token deployment and monitoring on iOS and AndroidToken Visibility Tools: ecosystem-native placement features for projects“ESCAPE is being built to simplify Web3 and restore trust through transparency,” said an ESCAPE spokesperson. “The Ethereum relaunch and future multichain expansion represent more than a rebuild - they represent a stronger foundation for creators and communities to launch and grow without limitations.” is a Web3 infrastructure platform focused on token creation, analytics, and visibility across multiple blockchains. Initially launched on a Layer 2 network in early 2025, ESCAPE grew to over 800 holders and an $11.5 million market cap before migrating to Ethereum. Today, ESCAPE operates with a transparent roadmap, audited smart contracts, and a community-first approach.:::tip
This story was published as a press release by Chainwire under HackerNoon’s Business Blogging .]]></content:encoded></item><item><title>Europe Is Losing</title><link>https://slashdot.org/story/25/08/22/1925255/europe-is-losing?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>msmash</author><category>tech</category><pubDate>Fri, 22 Aug 2025 19:30:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[Europe's share of global economic output has fallen from 33% to 23% since 2005 while its space launch capacity has nearly collapsed, launching just four rockets this year compared to over 100 for the United States and 40 for China. The continent's economic stagnation spans 15 years -- likely the longest streak since the Industrial Revolution according to Deutsche Bank calculations -- with Germany's economy growing just 1% since late 2017 versus 19% US growth. 

Per capita GDP gaps have widened dramatically: $86,000 annually in the US versus $56,000 in Germany and $53,000 in the UK. Industrial electricity costs have become prohibitive, running three times higher in Germany and four times higher in the UK than American rates. "America innovates, China imitates, Europe regulates," Italian Prime Minister Giorgia Meloni observed. The continent's largest company by market value, SAP, now ranks just 28th globally. 

Further reading: The Technology Revolution is Leaving Europe Behind.]]></content:encoded></item><item><title>US government plans to take a 10% stake in Intel</title><link>https://techcrunch.com/2025/08/22/u-s-government-plans-to-take-a-10-stake-in-intel/</link><author>Kirsten Korosec</author><category>tech</category><pubDate>Fri, 22 Aug 2025 19:14:36 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Such federal government ownership of a major corporation would mark a dramatic departure from long-standing U.S. policy. ]]></content:encoded></item><item><title>TikTok denies India comeback after reports of website going live</title><link>https://techcrunch.com/2025/08/22/tiktok-denies-india-comeback-after-reports-of-website-going-live/</link><author>Jagmeet Singh</author><category>tech</category><pubDate>Fri, 22 Aug 2025 18:59:43 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[TikTok isn’t making a comeback in India.]]></content:encoded></item><item><title>Intel Has Agreed To a Deal For US To Take 10% Equity Stake, Trump Says</title><link>https://news.slashdot.org/story/25/08/22/1849210/intel-has-agreed-to-a-deal-for-us-to-take-10-equity-stake-trump-says?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>msmash</author><category>tech</category><pubDate>Fri, 22 Aug 2025 18:50:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[President Donald Trump said on Friday the U.S. would take a 10% stake in Intel under a deal with the struggling chipmaker and is planning more such moves, the latest extraordinary intervention by the White House in corporate America. Reuters: The development follows a meeting between CEO Lip-Bu Tan and Trump earlier this month that was sparked by Trump's demand for the Intel chief's resignation over his ties to Chinese firms.]]></content:encoded></item><item><title>Apple is in talks to use Google’s Gemini for Siri revamp, report says</title><link>https://techcrunch.com/2025/08/22/apple-is-in-talks-to-use-googles-gemini-for-siri-revamp-report-says/</link><author>Amanda Silberling</author><category>tech</category><pubDate>Fri, 22 Aug 2025 18:15:08 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Apple promised a major revamp to Siri, but the company's AI capabilities have lagged behind competitors.]]></content:encoded></item><item><title>Default Microsoft 365 Domains Face 100-Email Daily Limit Starting October</title><link>https://it.slashdot.org/story/25/08/22/1814219/default-microsoft-365-domains-face-100-email-daily-limit-starting-october?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>msmash</author><category>tech</category><pubDate>Fri, 22 Aug 2025 18:14:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[Organizations still using default Microsoft 365 email domains face severe throttling starting this October. The restrictions target the onmicrosoft.com domain that Microsoft 365 automatically assigns to new tenants, limiting external messages to 100 recipients per day starting October 15. Microsoft blames spammers who exploit new tenants for quick spam bursts before detection. Affected organizations must acquire custom domains and update primary SMTP addresses across all mailboxes -- a process that requires credential updates across devices and applications.]]></content:encoded></item><item><title>The next Starship flight will test much more than hardware</title><link>https://techcrunch.com/2025/08/22/the-next-starship-flight-will-test-much-more-than-hardware/</link><author>Aria Alamalhodaei</author><category>tech</category><pubDate>Fri, 22 Aug 2025 18:11:17 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[The 10th Starship flight test will be a referendum on the company's build-fly-fix approach. ]]></content:encoded></item><item><title>Apple Explores Using Google Gemini AI To Power Revamped Siri</title><link>https://apple.slashdot.org/story/25/08/22/1733230/apple-explores-using-google-gemini-ai-to-power-revamped-siri?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>msmash</author><category>tech</category><pubDate>Fri, 22 Aug 2025 17:33:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[Apple is in early discussions about using Google Gemini to power a revamped version of the Siri voice assistant, marking a key potential step toward outsourcing more of its artificial intelligence technology. From a report: The iPhone maker recently approached Alphabet's Google to explore building a custom AI model that would serve as the foundation of the new Siri next year, according to people familiar with he matter. Google has started training a model that could run on Apple's servers, said the people, who asked not to be identified because the discussions are private. 

The work is part of an effort to catch up in generative AI, a field where the company arrived late and then struggled to gain traction. Earlier this year, Apple also explored partnerships with Anthropic and OpenAI, weighing whether Claude or ChatGPT could serve as Siri's new brain. Apple is still several weeks away from making a decision on whether to continue using internal models for Siri or move to a partner. And it hasn't yet determined who that partner may be.]]></content:encoded></item><item><title>If GPT-OSS Weren’t OpenAI Models, Would We Still Care?</title><link>https://hackernoon.com/if-gpt-oss-werent-openai-models-would-we-still-care?source=rss</link><author>Writings, Papers and Blogs on Text Models</author><category>tech</category><pubDate>Fri, 22 Aug 2025 17:14:02 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[Skip to content
Chat history

You said:
Create image that is wider than it is tall. based on this website https://www.yourfocusfriend.com/  make a pixelated cartoon that says "42 Real Internet People"
ChatGPT said:

https://www.shutterstock.com/image-vector/pixel-art-people-character-set-600w-2541245749.jpg
Here’s a friendly, pixelated cartoon banner—wider than tall—that captures the playful, retro vibe you're looking for. It's laid out like a mosaic of quirky, chunky characters reminiscent of internet personas. While I can’t use content directly from yourfocusfriend.com due to copyright, this piece channels a general pixel-art aesthetic to fit your concept.

How to Adapt This into a “42 Real Internet People” Banner
Layout: Maintain a horizontal (landscape) orientation that’s visibly wider than tall—perfect as a banner or header.

Pixelated Characters: Include a grid or row of diverse, pixel-art-style "people"—they can be simplistic avatars characterized by blocky colors, quirky features, and a digital, 8‑bit feel.

Text Integration: Overlay or embed the phrase “42 Real Internet People” within the design. You could:

Place it in a pixel-font box along the bottom or top.

Scatter the letters subtly across characters (e.g., each avatar holds a letter, or the letters are part of a digital “sign” held by one).

Color Scheme: Use bright, contrasting colors—neon or pastel pixels work well—to stand out and capture that playful, gamified aesthetic like Your Focus Friend promotes.

Atmosphere: Mimic the warm, cozy, friendly look of the site by using soft backgrounds or gentle gradients behind the characters, perhaps reminiscent of the timer app’s interface.

If you’d like, I can help sketch out a more detailed layout plan or guide you to tools where you can build or refine this banner further—just let me know what you'd like next!

You said:
write this story in 1560 characters or less and 400 or less

How branding, hype, and corporate clout shape the buzz (and backlash) around OpenAI’s new “open” models


On a recent Reddit thread, a user posed a pointed question: “If the GPT-OSS models were made by any other company than OpenAI, would anyone care about them?” The query struck a nerve across AI communities. OpenAI’s release of GPT-OSS-120B and GPT-OSS-20B—their first “open-weight” models—was met with a frenzy of posts and hot takes. But were we genuinely excited about the models’ merits, or simply starstruck by the OpenAI brand? It’s a distinctly 2025 tech debate: how much of the buzz boils down to branding and perception rather than breakthrough innovation?



In this piece, we’ll dig into the reactions from Reddit, Hacker News, X (formerly Twitter), LinkedIn, and tech forums to see how people are talking about GPT-OSS. The responses range from cynical (“it’s all hype”) to hopeful (“at least it gets more people into local AI”). The tone will be smart, a bit irreverent, and well-researched – channeling the vibes of a Casey Newton or Kara Swisher column on HackerNoon. Let’s unpack what everyone’s saying about OpenAI’s open-source moment and what it reveals about branding, perception, and corporate influence in AI.



Reddit Reacts: “Just Hype – or a Helpful Push?”
Over on /r/LocalLLaMA, the question of OpenAI’s influence lit up an intense discussion. Many redditors argued that GPT-OSS is riding on OpenAI’s name more than anything. The original poster, chunkypenguion1991, didn’t mince words about the new models’ quality:

“They are worse at coding than Qwen 32B, more hallucinations than Fyre Festival, and seem trained only to pass benchmarks. If any other company released this, it would be a shoulder shrug… If it wasn’t for the OpenAI name behind it, would it get this much hype?” — chunkypenguion1991reddit.com



The skepticism was echoed by others in the thread. User NinjaK3ys couldn’t understand the excitement, complaining “I don't understand why such hype for the OpenAI OSS models… Geezz.” and the OP dryly replied, “$$$ that’s why”reddit.comreddit.com. Another commenter saw a concerted publicity effort behind the scenes:

“OpenAI was milking the OSS for months, starting from the announcement in Spring. I wonder if they needed it for some kind of compliance with investors, government grants, etc.” — No-Refrigerator-1672reddit.com



In other words, some in the community suspect the hype is manufactured, a savvy PR move to satisfy stakeholders or redirect the open-source narrative. From this perspective, the GPT-OSS models themselves are fine – but not spectacular enough to warrant the hoopla, if not for the OpenAI logo on the tin. As one redditor put it bluntly when asked if we’d care about GPT-OSS from another source:

“No.” — rookan



Yet, not everyone on Reddit was cynical. A number of users defended the value of OpenAI’s involvement – if only because it shines a bigger spotlight on local AI development. LevianMcBirdo argued that OpenAI’s brand has dramatically expanded awareness of this tech:

“Of course it wouldn’t get the same hype if some company mostly unknown to the public released the same models… The public often only thinks of OpenAI when thinking about generative AI. I’m not sure 50% of adults could even name another company… So in that sense, OpenAI helped the scene a lot.” — LevianMcBirdo reddit.com



Others noted that an OpenAI release, even a mediocre one, can serve as a gateway drug for newcomers to local models. PicklesLLM shared a supportive take, viewing GPT-OSS as a Trojan horse for AI hobbyists:

“Honestly I kind of agree [it’s overhyped]. But the reason this is big is because it’s an LLM a lot more people are familiar with. This will encourage more people to actually get into the local model route… I feel the excitement isn’t so much about the LLM itself, but the expansion of people new to this hobby… They only trusted ChatGPT for the longest time, but now… they’re getting more open to it because I can download the 20B model on their own PCs.” — PicklesLLM reddit.comreddit.com



From this vantage point, OpenAI’s cachet is opening doors. Sure, GPT-OSS might not top every benchmark (some redditors pointed out it “doesn’t perform well on qualitative benchmarks and [is] not even comparable to Qwen-3 30B”reddit.com). But having the ChatGPT-maker endorse local models lends legitimacy that could grow the community. It’s a classic case of Big Tech hype trickling down to benefit the little guys. As ComprehensiveJury509 noted, people in the thread wanted to see OpenAI fail, but in truth the models are “very solid… for their weight classes” (only ~5B parameters active):

“Hype? I’d say there is a lot of negativity here that feels forced. People in this community really want it to bomb, so they focus on all the stuff that isn’t good… I dislike OpenAI with a passion myself, but I don’t think these are mediocre models. They are very solid models for their weight classes… yet people compare them to beefier models all the time.” — ComprehensiveJury509 reddit.comreddit.com



In short, the Reddit verdict was divided. The critics see brand-driven hype and a perhaps cynical ploy by OpenAI to placate calls for open-source (“it just seems like OpenAI released some crappy model so we would shut up about open source. But it’s crap,” the OP quippedreddit.com). The defenders see an opportunity: OpenAI’s hype machine, however off-putting, is at least bringing more mainstream attention to local AI and “democratizing” access in a way smaller players couldn’t. Reddit’s take crystallized the core debate: is GPT-OSS a breakthrough or just a branding exercise?



Hacker News Weighs In: Don’t Treat Companies Like “Sports Teams”
Over on Hacker News, discussions about GPT-OSS struck a slightly different tone – more technical, but with a healthy dose of skepticism about the hype. In a thread about OpenAI’s announcement, one user pointed out that nothing about GPT-OSS’s design was revolutionary; it’s mostly a clever layering of known techniques (Mixture-of-Experts, etc.) rather than new magic. But the more colorful commentary zeroed in on the fanboyism and branding aura. As one HN commenter littlestymaar admonished the community:“It would be great if people stopped acting as if those billion-dollar corporations were sports teams.” — littlestymaar news.ycombinator.com



That zinger speaks volumes. The poster was pushing back on reflexive tribalism – the tendency to cheer for OpenAI or Meta or whomever as if they can do no wrong. HN readers often pride themselves on cutting through marketing, and some did just that. User codelion, for instance, dryly noted that OpenAI’s “open” models were deliberately conservative in design: “It is by design. OpenAI is not going to reveal any architectural innovation they have made in their own commercial models.” — codelion news.ycombinator.com



In other words, if you expected GPT-OSS to be some secret-sauce GPT-4, you’d be mistaken – OpenAI played it safe, perhaps to avoid giving away any proprietary edge. This aligns with an analysis by AI blogger Sean Goedecke, who speculated that OpenAI trained GPT-OSS on heavily filtered (even synthetic) data to avoid the model misbehaving. Why? Because once an open-weight model is out in the wild, people can fine-tune or uncensor it in ways OpenAI can’t control. “Unlike Meta, [OpenAI doesn’t] need their open-source model to be actually good, because their main business is their closed-source models,” Goedecke wrote, arguing the release was more about optics and reclaiming narrative than technical supremacy seangoedecke.comseangoedecke.com.



That view—that OpenAI’s open-weight release was a strategic token, not a leap in AI—resonated on HN. Several users noted that truly, the excitement was tempered. “If this were any other company, there might have been a couple of posts and then quickly forgotten,” admitted DeltaSqueezer on HN, comparing GPT-OSS’s brief moment of fame to smaller-model launches that come and go reddit.com. 



The implication: OpenAI’s name boosted GPT-OSS onto front pages, but time will tell if the models have staying power once the novelty wears off. Good luck finding anyone discussing GPT-OSS six months from now if it doesn’t prove genuinely useful; the internet’s attention is fickle, brand or not.

At the same time, a few HN commenters saw a silver lining similar to Reddit’s optimists: OpenAI’s move validated open models. “This move validates the growing influence of the open-source ecosystem,” tech writer Ben Dickson noted, given it comes after a surge of open models from others bdtechtalks.combdtechtalks.com. 



OpenAI lending its prestige to Apache-licensed models could be read as a win for the open-source movement (or as OpenAI bowing to pressure from it). The Internet delved into the “what is ‘open’ really?” debate. A top HN comment debated whether releasing weights with an Apache license but an extra usage policy truly counts as open source. “Is it even valid to have additional restrictions on top of Apache 2.0?” asked user maxloh, pointing out the fine print in OpenAI’s GPT-OSS usage policy news.ycombinator.comnews.ycombinator.com. 



The consensus among the HN greybeards was that OpenAI’s offering is “open-weight” rather than fully open-source – a meaningful distinction for the purists. The training data and methodology remain a black box, so some transparency is gained, but not all. As one HackerNoon article would later put it, “Open weights mean you can download and run the model, but you cannot necessarily understand how it was trained… It only offers partial transparency.”hackernoon.com



In summary, Hacker News’ perspective added nuance: Yes, OpenAI’s brand turbocharged interest in GPT-OSS – but HN posters were quick to analyze the strategic motives behind that move. Don’t be a cheerleader, they warned; judge the tech on its merits and be aware of what’s not being open-sourced (pretty much everything except the weights).



The X Factor: Twitter Cheers and Jeers
On X (formerly Twitter), the reaction to GPT-OSS was predictably fast-paced and polarized. Some AI enthusiasts on X greeted the OpenAI open models with unbridled excitement – almost surprise. For example, Zeming Lin (@ebetica), an AI researcher, could barely contain his enthusiasm at what GPT-OSS achieved and who it came from:“gpt-oss is out! we made an open model that performs at the level of o4-mini and runs on a high-end laptop (WTF!!)” — Zeming Lin (ebetica) x.com



The “WTF!!” pretty much captures it – even a seasoned insider was amazed that an open-weight model from OpenAI could run on a single GPU and still match a pared-down GPT-4 variant on performance. This is the kind of hype that branding + genuine achievement can spark: OpenAI managed to surprise people who thought the company was forever wed to giant cloud-bound models. There was a sense of “I can’t believe OpenAI did this, but wow, it’s cool.” On the flip side, other Twitter users took OpenAI to task for the contrast between hype and reality. Tech commentator Ben Olney noted that the flagship GPT-5 model (released almost simultaneously) was falling short in his experience, even as OpenAI’s marketing was in overdrive: “GPT-5 is hallucinating more often than not for me… It’s a bit of a concern given the hype OpenAI have given it. I’m actually getting better results from GPT-OSS.” — Ben Olney (@Olney1Ben) twitter.comx.com



Here we have an interesting twist: OpenAI’s smaller open model outperformed its heavily hyped closed model (GPT-5) on certain tasks, at least for one user. The subtext of Olney’s tweet is a critique of OpenAI’s hype machine – they talked up GPT-5 as the next big thing, yet a freely available model is serving him better for general knowledge. It’s a reminder that sometimes the new shiny object (GPT-5) isn’t strictly better in practice than the less-heralded alternative. And because GPT-OSS came with lower expectations (and less pressure), users might actually be delighted when it performs decently. GPT-5, by contrast, shoulders sky-high expectations (thanks to OpenAI’s own branding) and thus faces harsher judgment for any flaw.



Twitter, being Twitter, also saw its share of memery and polarized takes. Some users joked that OpenAI open-sourcing models was a sign the “end times” were near (tongue-in-cheek referencing OpenAI’s past reluctance to open source). Others debated the ethics: a few X posters echoed the Reddit sentiment that OpenAI was using the community as unpaid testers and “free labor” to improve safety, by releasing an aligned model and watching folks try to jailbreak it reddit.com. In the words of one Reddit user, “they just want to see if people can make it unlocked… Which they will simply use… to make a ‘safer’ model.” reddit.com That cynical view found traction on X as well, where distrust of corporate motives runs deep.



Overall, X showcased the two extremes of perception: the fanboy-ish awe at OpenAI’s move (because it was a surprise to see them release something under Apache license), and the skeptical side-eye at how the models actually perform versus the hype narrative. As always on social media, reality lies somewhere between the extremes – but the branding of OpenAI ensured that everyone had an opinion, one way or another.



LinkedIn and the Corporate Embrace of GPT-OSS


If Reddit and Hacker News represent the grassroots and Twitter the hype cycle, LinkedIn gives us the corporate angle – and it did not disappoint. As soon as GPT-OSS dropped, tech executives and enterprise teams jumped on LinkedIn to highlight integrations and business use cases. The subtext was clear: OpenAI’s brand carries weight in boardrooms, not just forums, and companies were eager to associate themselves with the GPT-OSS launch.



A prime example came from Microsoft’s ranks. On August 5, a Microsoft program manager proudly posted:“Excited to bring OpenAI’s gpt-oss models to Azure AI Foundry and to Windows via Foundry Local. It’s hybrid AI in action: mix and match models, optimize for performance and cost, and meet your data where it lives.” — Microsoft Azure AI team member, on LinkedIn news.microsoft.com



The tone here is all optimism: GPT-OSS is portrayed as an enabler of “hybrid AI” strategies. In plain speak, Microsoft is saying: Hey, we can run these OpenAI open models on-premises or on Windows devices as well as in the cloud. For enterprise customers worried about data residency or wanting to avoid solely closed APIs, that’s a selling point. OpenAI’s brand name plus open-source flexibility equals a marketing win. It’s not hard to imagine CTOs nodding along to this LinkedIn post – after all, it promises the best of both worlds (OpenAI innovation and self-hosting).



Other LinkedIn voices from companies like AWS and Dell quickly chimed in with their own takes. AWS wrote a blog (and surely a LinkedIn update) touting that GPT-OSS models were immediately available on Amazon Bedrock and SageMaker for developers to deployaws.amazon.com. Dell Technologies put out a note about bringing GPT-OSS to customers, framing it as part of the “expansion of the open-source AI ecosystem” (and gently plugging a Dell + Hugging Face partnership in the same breath) dell.com. The enterprise world, in short, embraced GPT-OSS as an opportunity: to sell hardware, cloud services, or enterprise solutions that leverage these models.



One striking aspect is how differently the LinkedIn crowd talks about GPT-OSS compared to the skeptics on Reddit. On LinkedIn, there’s no hand-wringing about hallucination rates or censorship guardrails – instead, it’s all “excited to bring this to you” and “new options to build AI applications with complete control” aws.amazon.com. The focus is on the positive: more choices for customers, validation that open models are enterprise-ready because hey, OpenAI made them. Branding here serves a trust function. A year ago, a random 120B open model from some startup might not even be considered by a conservative company. But an open 120B model from OpenAI, announced on LinkedIn by Microsoft? That’s immediately on the evaluation list.



Of course, there’s a bit of irony. The same features that some community folks criticized (like GPT-OSS being heavily filtered and aligned for safety) are selling points in the corporate context. Businesses want safe, “censored” models that won’t spew off-brand content. As one Redditor, Cool-Chemical-5629, cynically noted: “If it was made by a different company, I’d care more, because there would always be a chance for improvement… With OpenAI that option is pretty much zero… they wouldn’t release such an otherworldly censored model in the first place.” reddit.com. That comment drips with frustration that OpenAI’s model is locked-down. But for LinkedIn’s audience, OpenAI’s “otherworldly censored” approach is a feature, not a bug – it means the model is less likely to go off the rails in a corporate setting. This dichotomy highlights how the reception of a model is shaped by the audience’s priorities: open-source enthusiasts crave raw, tweakable power (and thus chafe at too much safety filtering), whereas enterprises and lay users might prefer a model that’s “safe out of the box,” even at the cost of some creativity.



In sum, LinkedIn responses underscore that OpenAI’s brand lent GPT-OSS immediate enterprise credibility. The model launch became a talking point in cloud and AI product circles, not just an experiment on GitHub. Branding and corporate influence didn’t just shape community reception – they practically created a secondary wave of hype in the enterprise realm, distinct from the developer forums. And unlike the meme-filled Twitter takes, the LinkedIn tone was earnest and all-business: this is good for customers, this justifies our AI strategy, this is hybrid AI in action. It’s a reminder that OpenAI, with one foot in research and one in industry, has audiences in both – and it adeptly spoke to each.



OpenAI’s Image vs. Reality: Perspectives from Tech Media


Beyond the forums and social feeds, tech writers and analysts have been parsing what GPT-OSS means for OpenAI’s image. A piece in HackerNoon by Ishan Pandey asked pointedly in its title: “Is GPT-OSS Really Open? Inside OpenAI’s Most Transparent Model Yet.” The verdict was cautiously optimistic but clear that OpenAI’s move is a tactical pivot, not a change of heart. In an interview within that article, Michael Heinrich, CEO of 0G Labs, applauded the step toward transparency while noting its limits: “OpenAI’s release of these open-weight models is a step towards democratizing AI that echoes the spirit of innovation that drove early breakthroughs like GPT-2… It’s a sign that bigger is not always better when it comes to AI models.” — Michael Heinrich (0G Labs) hackernoon.com



Heinrich’s take captures the hopeful angle: smaller, open models running on consumer hardware do fulfill some of the original “OpenAI” ethos (back when the company’s name wasn’t an oxymoron). It shows an acknowledgment that progress in AI isn’t solely about giant parameter counts locked behind APIs – there’s value in accessible models. This sentiment certainly would make the community happy if it’s genuine. But Heinrich also cautioned that OpenAI’s openness only goes so far: the weights are out, yet “critical elements [are] still hidden behind closed doors: the training data, methodology, and full documentation… many are concerned it only offers partial transparency.” hackernoon.com In other words, GPT-OSS is open, but not that open. Pandey’s HackerNoon piece ultimately concluded that OpenAI’s move felt “more tactical than philosophical,” aimed at answering competitive pressure from truly open models like Meta’s LLaMA or Mistral, and at appeasing calls for transparency without actually open-sourcing their crown jewels hackernoon.com. Heinrich concluded with a bit of a dare for OpenAI’s future: “It’s a step in the right direction… but there’s a lot more that must be done before OpenAI can be regarded as living up to its name and genuinely advancing open access to AI.” — Michael Heinrich hackernoon.com



That line “living up to its name” cuts to the heart. OpenAI’s very moniker has drawn eye-rolls in recent years as the company kept its best models proprietary. GPT-OSS is, arguably, the first thing in a while that actually honors the “Open” in OpenAI – and even then, with caveats. The community and industry are essentially holding OpenAI’s feet to the fire: Okay, you made a move toward openness; now, will you continue down this path or was it a one-off?



In plainer terms, branding and corporate influence aren’t just shaping community reception – they likely shaped the very decision to release GPT-OSS in the first place. OpenAI’s brand was turning from an asset into a target (“you’re not really open, are you?”); this release helps recalibrate that perception. It’s a reminder that companies at OpenAI’s level carefully cultivate their image in the AI world. The community’s cynical questions (“are they doing it for free labor or PR?”) might have some truth in them, but it’s also true that the release provides tangible value (researchers get new models, companies get new tools). Both can be real: OpenAI can genuinely contribute and burnish its brand at the same time.



Perception and Reception of GPT-OSS


So, if GPT-OSS had been released by “SomeRandom AI Labs” instead of OpenAI, would anyone care? The consensus from our tour of the internet’s reaction is: Not nearly as much – and that’s revealing. OpenAI’s brand brought an unparalleled level of attention (and scrutiny) to these models. That attention was double-edged. On one hand, it magnified criticism – every shortcoming was picked apart by a community eager to prove they wouldn’t be swayed by a big name. On the other hand, it also amplified the excitement and adoption – enterprises and newcomers gave the models a chance precisely because of the OpenAI halo. Branding created the initial hype wave, but the community is now busy sifting substance from spin.



Perception matters in tech, sometimes as much as reality. OpenAI leveraged its perception as the AI leader to ensure GPT-OSS wasn’t ignored (mission accomplished there). Yet it also had to carefully manage its image: by making the models just good enough to be credible, and just safe enough to avoid a PR disaster. It’s a delicate balance of hype and humility. As one Hacker News user wryly observed, OpenAI’s fans and critics often treat the company like a football team, cheering or jeering every move news.ycombinator.com. The GPT-OSS episode shows how that fandom (and brand antagonism) can shape the narrative around a technology independent of its technical merits.



In the end, how the GPT-OSS models will be used (or not) six months from now will tell us more. Will they empower a thriving open-source AI ecosystem, or fade out as just another benchmark-chaser? Will OpenAI double down on this open-weight approach, or was it a one-off concession? The community has made one thing clear: they’ll judge the models – and OpenAI – by results, not just reputation. But for better or worse, it was the OpenAI name that got everyone through the door and talking in the first place. Branding set the stage; performance will determine the encore.



As Michael Heinrich put it, it’s a good step, but there’s more to do for OpenAI to live up to its name. Until then, the debate rages on. In the world of AI models, who made it can sometimes overshadow what it does – and GPT-OSS is our latest case study in that truth. Whether you’re a skeptic or a fan, the conversation around GPT-OSS shows that open-source AI doesn’t live in a vacuum; it lives in an environment shaped by corporate clout, community values, and the ever-swirling winds of hype. And as any seasoned HackerNoon writer might quip: in this AI game, hype may get you noticed, but only substance will keep you relevant once the crowd moves on to the next big thing.
ChatGPT said:
Here's your 1560-character version (including spaces) – great for a LinkedIn post, blog excerpt, or newsletter intro:

Would Anyone Care if OpenAI Didn’t Make GPT-OSS?

When OpenAI released its first “open-weight” models—GPT-OSS-120B and GPT-OSS-20B—the internet lit up. But Redditors asked a blunt question: Would anyone care if these models came from a no-name lab? The buzz felt more about branding than breakthroughs. Some praised OpenAI for spotlighting local AI, others slammed it as hype with little innovation.

On Reddit, critiques ranged from “they’re worse than Qwen” to “$$$ that’s why,” while optimists noted it could bring new users into the open-source fold. Hacker News was more analytical, dissecting how OpenAI revealed just enough to look generous while protecting its secrets. Twitter (X) had its mix of memes, excitement, and distrust. LinkedIn? All-in. Enterprises jumped to integrate, seeing “hybrid AI” opportunities and OpenAI’s brand as an instant validator.

In truth, GPT-OSS is fine—but the OpenAI name made it a moment. Whether it's a branding exercise or a bridge to more accessible AI, GPT-OSS proves one thing: in 2025, who makes the model matters as much as what it does.

And here's a tighter under-400-character version, ideal for social captions:

GPT-OSS is here—but would anyone care if OpenAI hadn’t made it? Redditors, HN devs, and LinkedIn

You said:
 160 or less
ChatGPT said:
Would anyone care about GPT-OSS if OpenAI didn’t make it? The models are decent, but the buzz is all branding. In 2025, who made it matters as much as what it does.

You said:
now 400
ChatGPT said:
OpenAI’s GPT-OSS models sparked buzz—but would anyone care if another company made them?

Redditors called them overhyped. Hacker News dissected the branding. Twitter cheered and jeered. LinkedIn? All business, praising “hybrid AI” and enterprise use. The models themselves are solid but not revolutionary—yet OpenAI’s name gave them instant relevance.

In 2025, hype often trumps performance.



No file chosenNo file chosen
ChatGPT can make mistakes. Check important info.
ChatGPT says: **OpenAI’s GPT-OSS models sparked buzz—but would anyone care if another company made them?** Redditors called them overhyped. Hacker News dissected the branding. Twitter cheered and jeered. LinkedIn? All business, praising “hybrid AI” and enterprise use. The models themselves are solid but not revolutionary—yet OpenAI’s name gave them instant relevance. In 2025, hype often trumps performance.]]></content:encoded></item><item><title>WTF is Focus Friend App? What 42 Real Internet People Think</title><link>https://hackernoon.com/wtf-is-focus-friend-app-what-42-real-internet-people-think?source=rss</link><author>Imperative</author><category>tech</category><pubDate>Fri, 22 Aug 2025 17:05:56 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[\
Hank Green’s new app  helps you focus by having an adorable knitting bean “work alongside you” while you stay off your phone. If you start scrolling, the timer stops, your bean’s knit unravels—and the poor critter looks sad. This guilt-based twist on the Pomodoro method turned productivity into a weirdly wholesome experience.Launched in late July, Focus Friend shot to #1 on the iOS App Store, surpassing even ChatGPT and TikTok (Fast Company). It’s free, contains no ads or data tracking (Google Play), and leans heavily on cozy visuals and guilt-trip gimmicks to help users reclaim their attention. Now, the internet is full of memes, heartfelt user stories, and lots of CUTE.42 Real Internet Reactions"The Focus Friend app from entrepreneur Hank Green is all about an adorable bean that needs to get its knitting done." – Inc. Magazine on X"Want to stop doomscrolling? Let a cute knitting bean guilt-trip you into focus instead." – DesignTAXI"Hank Green’s new app Focus Friend is taking over the App Store — and it’s powered by a sock-making bean that gets sad if you scroll TikTok." – Trending on X"If you fail, you will make an anthropomorphic bean very sad, because its knitting project depends on your ability to stay focused." – Amanda Silberling, TechCrunch"It’s about letting people be in control of their attention, not selling their attention to someone else." – Hank Green on TikTok"It’s genuinely absurd that my brother, vertical video sensation Hank Green, has the sixth most popular app in the world right now. (Good app, too.)" – John Green on X"New #1 app just overtook ChatGPT and Google — and it’s extremely cute." – Yahoo News"Focus Friend has crossed 500K installs… It’s the #1 downloaded iOS app overall." – Appfigures"Focus Friend has kept me from a Procrastination Doomscroll™ with pretty good success so far." – Reddit user"I didn’t want to be the monster interrupting my poor bean’s focus, nor did I want to let Hank Green down." – Reddit user"My bean is named Chickpea!" – Reddit"I just named mine Refrito ’cause he’s a pinto bean. I’m uncreative as hell lol." – Reddit"Smurmins L. Barg… I’m skeptical about his potential to get a lot of decor with me at the reins…" – Reddit"It’s adorable! I love my bean — I’m so proud of their socks. They work so hard!" – Tumblr"It’s like practicing healthy boundaries, but with myself." – Tumblr"Hah shoot – I grabbed this, tried it once, thought it would be super helpful, and never launched it again. Oopsie!" – Reddit"Once I close them they don’t exist anymore. It’s a cute idea, I guess." – Reddit"So many productivity apps are overwhelming – this is perfect in its simplicity." – Google Play review"Just using this app for one day has cut my screen time in half. I love my little bean and earning socks!" – Google Play review"I have ADHD and this has been helping so much. It’s cute and works great!" – App Store review"It’s part Tamagotchi, part therapy, all Gen Z bait." – Social post"4th place in the downloads, jfc. I think people are starved for simple and honest softwares with no evil schemes and data stealing." – Tumblr"Reblog to make ChatGPT lose to a cute knitting bean." – Tumblr"I love this little app! … helps me not pick up my phone…and end up awake until 2:00 am." – Google Play review"I’ve used it to study my class work, and even turned off the TV to listen to the calming bean music." – Google Play review"The app is limited like Neko Atsume – sweet, simple, to the point." – App Store review"I appreciate the amount of designs and the general lack of a paywall." – App Store review"Hm, I tried it out… I can just switch apps (I’m on Android) and let it run in the background…" – Reddit"I love the fact that the timer keeps going if you have it in the background… this feature makes it usable for me." – Reddit"It’s super cute and I started trying it today… though I’ll likely get bored of this one too, it is much cuter [than other apps]. That said, I love Hank Green, and I hope more folks find it helpful!" – Reddit"Don’t worry, lil bean, I’ll stay off Reddit for you." – Meme on X"Who knew a knitting bean could double as a mindfulness coach?" – Tumblr"Cheering on a productivity tool like it’s the home team in a sports final? That’s new." – Tumblr"A knitting bean has done the impossible – it got the internet to focus, even if just for a few sock-filled minutes at a time." – Meta commentFrom guilt-tripping beans to meme-able focus tools, the internet’s reaction to Focus Friend is . Verified reporters praise its cozy ingenuity. Users relate to the gentle incentive. Celebrities and influencers marvel at Hank Green’s ability to make productivity adorable. Even the skeptics can’t help but smirk—and maybe stay off their phones a bit longer. Because somehow, a little knitting bean named Focus Friend has become the cutest alarm clock we didn’t know we needed.]]></content:encoded></item><item><title>Y Combinator says Apple’s App Store has hindered startup growth</title><link>https://techcrunch.com/2025/08/22/y-combinator-says-apples-app-store-has-hindered-startup-growth/</link><author>Dominic-Madori Davis</author><category>tech</category><pubDate>Fri, 22 Aug 2025 17:00:00 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[ Y Combinator is asking the court to deny Apple’s appeal. ]]></content:encoded></item><item><title>Nvidia reportedly halts production on its H20 AI chips</title><link>https://techcrunch.com/2025/08/22/nvidia-reportedly-halts-production-on-its-h20-ai-chips/</link><author>Rebecca Szkutak</author><category>tech</category><pubDate>Fri, 22 Aug 2025 16:53:47 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Beijing is reportedly urging Chinese companies to turn to domestic chips just weeks after Nvidia got the green light to sell in China again. ]]></content:encoded></item><item><title>Aspiration co-founder to plead guilty to $248M fraud scheme</title><link>https://techcrunch.com/2025/08/22/aspiration-co-founder-to-plead-guilty-to-248m-fraud-scheme/</link><author>Tim De Chant</author><category>tech</category><pubDate>Fri, 22 Aug 2025 16:42:30 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Joseph Sanberg is accused of falsely inflating revenue and fabricating a letter from Aspiration's audit committee to obtain loans, which the startup ultimately defaulted on.]]></content:encoded></item><item><title>The HackerNoon Newsletter: The One Question I Ask Before Investing in Any AI Company (8/22/2025)</title><link>https://hackernoon.com/8-22-2025-newsletter?source=rss</link><author>Noonification</author><category>tech</category><pubDate>Fri, 22 Aug 2025 16:02:07 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[🪐 What’s happening in tech today, August 22, 2025?By @hacker90235211 [ 4 Min read ] Before you start an AI company or invest in one, always imagine a moment when the AI component is available to everyone tomorrow for free. Read More.By @3l4d [ 6 Min read ] An essay on how the second law of thermodynamics shape the long arc from the Big Bang to AGI, suggesting superintelligence as a physical inevitability. Read More.By @johnwrites [ 4 Min read ] Discover how SocialFi crowdfunding platforms like SeedList are disrupting traditional VC funding in crypto. Read More.🧑‍💻 What happened in your world this week?We hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.See you on Planet Internet! With love, 
 The HackerNoon Team ✌️]]></content:encoded></item><item><title>YC-backed Oway raises $4M to build a decentralized ‘Uber for freight’</title><link>https://techcrunch.com/2025/08/22/yc-backed-oway-raises-4m-to-build-a-decentralized-uber-for-freight/</link><author>Sean O&apos;Kane</author><category>tech</category><pubDate>Fri, 22 Aug 2025 15:53:52 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[The thousands of trucks zipping along U.S. highways are often only about half full -- something Oway wants to change with its "ride-share for freight" software.]]></content:encoded></item><item><title>Google makes it easier to edit Drive videos with a new Vids shortcut button</title><link>https://techcrunch.com/2025/08/22/google-makes-it-easier-to-edit-drive-videos-with-a-new-vids-shortcut-button/</link><author>Lauren Forristal</author><category>tech</category><pubDate>Fri, 22 Aug 2025 15:33:29 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Now Workspace users can initiate a video edit using the Vids app directly from the Google Drive interface.]]></content:encoded></item><item><title>Video Friday: Inaugural World Humanoid Robot Games Held</title><link>https://spectrum.ieee.org/world-humanoid-robot-games</link><author>Evan Ackerman</author><category>tech</category><enclosure url="https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy82MTUwMTcyNi9vcmlnaW4ucG5nIiwiZXhwaXJlc19hdCI6MTgwNjgyNDE0Nn0.EozRKG9htuXcv5H4asOKEe5qqTQb_Gl1df-A1BHZdHs/image.png?width=600" length="" type=""/><pubDate>Fri, 22 Aug 2025 15:30:04 +0000</pubDate><source url="https://spectrum.ieee.org/">IEEE Spectrum</source><content:encoded><![CDATA[Your weekly selection of awesome robot videos]]></content:encoded></item><item><title>What 42 Internet People Think of Silksong, the New Game 8.5 Years in the Making</title><link>https://hackernoon.com/what-42-internet-people-think-of-silksong-the-new-game-85-years-in-the-making?source=rss</link><author>Games Harden</author><category>tech</category><pubDate>Fri, 22 Aug 2025 15:22:31 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[Silksong took 8.5 years to arrive, and players are finally weighing in. Some call it a masterpiece, others find it brutally challenging, but across 42 different perspectives, one thing is clear: this long-awaited sequel is unforgettable.]]></content:encoded></item><item><title>Is This AI’s Linux Moment? Inside 0G’s Labs Push for an Open, Verifiable Stack for AI</title><link>https://hackernoon.com/is-this-ais-linux-moment-inside-0gs-labs-push-for-an-open-verifiable-stack-for-ai?source=rss</link><author>Ishan Pandey</author><category>tech</category><pubDate>Fri, 22 Aug 2025 15:03:27 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[Artificial intelligence is advancing at breakneck speed, yet most of the infrastructure powering AI remains highly centralized, controlled by a few large companies. At the same time, Web3 continues to push the boundaries of what decentralized systems can achieve. Where these two worlds intersect is where 0G Labs positions itself, building what it calls the “Solana for AI,” a decentralized operating system designed for large-scale, low-latency AI workloads.\
In this interview, I speak with Michael Heinrich, CEO of 0G Labs, about why decentralization matters for AI, how Web3 infrastructure can solve bottlenecks in scaling machine learning, and what the future of AI-native blockchains looks like.\
 Hi Michael, welcome to our “Behind the Startup” series. Please tell us about your journey and what led you to build 0G Labs?\
 My journey's been something of a wild ride, all the way back to my earliest memories. I was born in East Berlin just before the Berlin Wall came down. I faintly remember the night it fell and my family emigrated to the US when I was young, settling in California. That early experience of crossing borders and adapting to new worlds and languages likely planted the seeds for my fixation on breaking down barriers, both literally and figuratively.\
I studied economics and computer science at UC Berkley, but to be honest, while the learning came naturally, I was restless and agitating to find some deeper purpose. It would take a few more years before that call was answered with the founding of 0G Labs. In the interim, I left college and cut my teeth in the corporate world at places like Microsoft, Bain & Company, and Bridgewater Associates, where I learned about scaling systems and building high-performance teams.\
Then came my first taste of entrepreneurship when I founded Garten, a corporate wellness company that delivered healthier cafeteria options for businesses, which grew to serve hundreds of employees across the US. It was my first real startup, and it taught me resilience and the need to engineer shock-resistant systems.\
Fast forward to grad school at Stanford, where I was introduced to Fan Long and Ming Wu by my classmate Thomas in 2023. Thomas, who is also one of the co-founders of Zero Gravity Labs, brought us together at a time when AI was exploding but locked in centralized silos controlled by Big Tech. We all saw blockchain as the key to democratizing it, making AI a public good that's accessible to everyone. That’s what led us to found 0G Labs in 2023. We're building DeAIOS, a decentralized AI operating system, because I believe the future of innovation isn’t in walled gardens; it’s in open, collaborative ecosystems. At 0G Labs, I can honestly say I’ve found my calling, and every day I wake up excited to get out of bed and keep building.\
 0G has been described as the “Solana for AI.” Can you break down what you mean by that, and why existing blockchains are not suited for AI-scale workloads?\
 This comparison highlights the speed, scalability, and low latency we're bringing to decentralized AI compared to incumbent solutions. Solana revolutionized smart contract blockchains by enabling thousands of transactions per second at minimal cost without sacrificing decentralization, something that was streets ahead of the then-market leader Ethereum.\
We're doing something similar but tailored for AI: creating a modular Layer 1 blockchain that supports massive, real-time AI workloads for inference, training, and data processing. Existing blockchains fall short for AI because they're optimized for financial transactions, not the data-heavy demands of machine learning. AI requires enormous bandwidth for data availability, we’re talking petabytes of datasets streaming in low-latency environments and most chains run into bottlenecks due to storage costs or limited composability.\
We solve this with components like 0G DA (Data Availability), which provides infinitely scalable, high-speed data layers, and 0G Storage, offering ultra-low-cost, verifiable permanence for structured and unstructured data. For AI builders, this is like upgrading from a biplane to a jet, way faster, way more efficient, and also a lot more fun since now the only limitations are your imagination.\
 The AI industry today is dominated by centralized players. Why do you believe decentralization is not just a philosophical stance but a technical and economic necessity for AI?\
 The likes of OpenAI, Google, and AWS control the AI stack today, and while this provides convenience in terms of guaranteed access and uptime, this setup also creates real risks. Even if we set aside the philosophical benefits of decentralization, from a purely technical perspective, it’s obvious that having a triumvirate of Big Tech players calling the shots is suboptimal. Centralization leads to single points of failure: data silos that stifle innovation, vulnerability to censorship or outages, and biased models trained on proprietary datasets. Economically, it also prices out smaller players; GPUs and compute are expensive enough, but locked ecosystems mean you're paying a premium for access.\
Decentralized solutions have a major role to play in ameliorating these issues. At 0G, we're building tools like our Compute Network for trustless AI inference, secured by cryptography, so that anyone can contribute resources and earn rewards. This creates a global, permissionless marketplace where costs drop dramatically, our storage is orders of magnitude cheaper than AWS S3 and a culture of innovation is fostered through composability. Imagine AI agents collaborating onchain without intermediaries or verifiable models that prevent hallucinations.\
These sorts of open-source and interoperable solutions are necessary because AI's impact on society is too big to be gatekept; decentralizing it ensures equitable access and reduces monopolies. I've seen centralized systems crumble firsthand and will remain convinced till my last breath that decentralization isn't optional, it's essential.\
 A lot of people talk about compute and GPUs as the bottleneck for AI. From your perspective, what are the real constraints, data, bandwidth, economics and how does 0G tackle them differently?\
 Great question. Compute gets all the headlines because GPUs are flashy and scarce, but in my view, the real chokepoints are data availability, bandwidth, and economics and by “economics” I mean the price you pay to access these resources. NVIDIA's cranking out chips faster than ever, but where's the infrastructure to feed them massive, verifiable datasets at scale? Data is fragmented and centralized, bandwidth limits low-latency streaming for real-time AI, and as for economics, well, where do we start?\
Cloud providers charge over the odds, often locking clients into rigid subscription-based models, making AI inaccessible for solo devs or startups that have yet to be blessed with VC cash. Even then, early-stage funding is only a bandaid, cos you need to start generating revenue sooner rather than later or you’ll eventually blow your budget on GPUs with nothing to show for it other than some cool renders.\
At 0G, we tackle these resource issues head-on. Our 0G DA layer provides high-speed, infinitely scalable data availability – we’ve been hitting 11,000 TPS per shard on testnet, with over 650 million transactions already processed. For bandwidth, our modular chain uses multi-consensus validation to handle AI workloads without congestion. Economically, we slash costs: 0G Storage offers decentralized, AI-optimized storage at pennies compared to centralized options, with cryptographic permanence to ensure data integrity.\
Unlike traditional setups, we're creating an open economy where users run alignment nodes or provide compute for rewards. It's like turning AI infrastructure into a shared resource pool, making it more efficient and inclusive.\
 You’ve mentioned the idea of a “decentralized operating system for AI.” What does that look like in practice, and how does it compare to traditional cloud infrastructure models in terms of pricing and benefits for end users?\
 The “decentralized operating system for AI,” or DeAIOS, is essentially a full-stack platform where AI runs natively on blockchain. It’s scalable, composable, and trustless. In practice, it means developers can deploy AI models or agents by leveraging components such as the Service Marketplace for trading models, or Alignment Nodes to ensure ethical, efficient performance. Running inference on a global network of nodes, with data pulled seamlessly from 0G Storage and verified onchain is a much cheaper and more transparent way of doing things versus relying on centralized servers and Big Tech’s inflexible pricing.\
Compared to traditional clouds like AWS or Azure, the differences are stark. Let’s start with pricing: centralized cloud provider costs can quickly stack up, with intermediaries adding on their fees for storage and compute along the way. We cut that by decentralizing supply, so end users pay near-cost. As for the other benefits this model bestows, permissionless access means no vendor lock-in; censorship resistance protects against shutdowns; and composability lets apps interoperate fluidly, sparking innovations like onchain AI gaming.\
Finally, verifiability ensures models are auditable, reducing risks like bias. It's relatable: think of it as open-source Linux versus proprietary Windows but for AI. Users get faster iteration and ownership in the ecosystem. We've seen this in our testnet with 22 million active accounts – it's already empowering a new wave of builders.\
 Many skeptics argue that Web3 adds unnecessary complexity to AI. How do you respond to the criticism that decentralization slows innovation instead of accelerating it?\
 I hear this a lot, and I understand that Web3 can feel like adding gears to a machine that's already ticking over. But from my experience of building in both worlds, decentralization doesn't slow innovation – it turbocharges it by solving problems that centralization can't. Yes, it adds a degree of complexity but it's purposeful: cryptographic proofs add verifiability to AI outputs, preventing fakes or manipulations that plague centralized models. And blockchain's composability means devs can mix and match components – like plugging an AI oracle from Ora into 0G’s chain – without starting from scratch.\
Critics overlook how Web3 accelerates parallel development: thousands of nodes worldwide contribute compute, data, and ideas, outpacing any single company's R&D. At 0G, we've raised $35M and hit milestones like 8,000 validators because this model draws global talent. It hasn't slowed us but has rather propelled us. Ultimately, this all comes down to trade-offs: introducing a little short-term complexity in return for long-term resilience and inclusivity. Innovation thrives in open systems and so, to my mind, Web3 isn't a hurdle; it's the accelerator pedal for AI's next phase.\
 Finally, what advice would you give to founders trying to build companies at the cutting edge of both AI and blockchain?\
 To founders at this intersection: first, don't die, protect your mission at all costs. My journey has taught me that resilience wins, whether it's overcoming personal setbacks or navigating market downturns, so keep iterating and surround yourself with a strong team that will always have your back. Second, focus on real problems and describe the solutions in real terms. It’s fine to occasionally dispense big picture stuff, onboarding the next billion users, yadda yadda but as a founder, your job is really to explain your tech in ways that lay people can understand. Even if you’re marketing to AI builders, who understand this stuff, think about their end users, because they’re the people this tech is ultimately gonna trickle down to.\
Finally, never be afraid to change your mind. It’s okay to be wrong sometimes. And it’s more than okay to change your perspective on something when new evidence comes to light, which, in an industry evolving as fast as AI, is a given. Be confident in your convictions, yet honest enough to admit that you will always be a student and will always be learning. Your team and your shareholders will respect you a lot more if you do. Move fast, learn faster, and try not to break too much stuff along the way.\
Don’t forget to like and share the story!:::tip
This author is an independent contributor publishing via our . HackerNoon has reviewed the report for quality, but the claims herein belong to the author. #DYO]]></content:encoded></item><item><title>X pulls the ability to like and follow from its developer API’s free tier</title><link>https://techcrunch.com/2025/08/22/x-pulls-the-ability-to-like-and-follow-from-its-developer-apis-free-tier/</link><author>Sarah Perez</author><category>tech</category><pubDate>Fri, 22 Aug 2025 14:57:03 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[X is making it harder for spammers with these API changes.]]></content:encoded></item><item><title>Developer gets prison time for sabotaging former employer’s network with a ‘kill switch’</title><link>https://techcrunch.com/2025/08/22/developer-gets-prison-time-for-sabotaging-former-employers-network-with-a-kill-switch/</link><author>Zack Whittaker</author><category>tech</category><pubDate>Fri, 22 Aug 2025 14:26:34 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[The ex-developer was convicted of planting malicious code designed to crash its servers in the event that he was fired.]]></content:encoded></item><item><title>Waymo approved to start autonomous vehicle testing in New York City</title><link>https://techcrunch.com/2025/08/22/waymo-approved-to-start-autonomous-vehicle-testing-in-new-york-city/</link><author>Sean O&apos;Kane</author><category>tech</category><pubDate>Fri, 22 Aug 2025 14:19:05 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[It's the first permit of its kind, and a crucial step along the path toward launching a true robotaxi service in the Big Apple.]]></content:encoded></item><item><title>Mesa 25.3 Lands More Changes To Prepare For OpenGL Mesh Shaders</title><link>https://www.phoronix.com/news/Mesa-25.3-More-GL-Mesh-Shaders</link><author>Michael Larabel</author><category>tech</category><pubDate>Fri, 22 Aug 2025 14:08:33 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[Being worked on for a number of months now is GL_EXT_mesh_shader as an extension for bringing mesh shaders to OpenGL. This is an alternative to NVIDIA's GL_NV_mesh_shader extension being worked on for Mesa drivers and in particular the RadeonSI Gallium3D driver...]]></content:encoded></item><item><title>New Ubuntu Snapdragon X1E Concept ISO Published - Still A Mess On The Acer Swift 14 AI</title><link>https://www.phoronix.com/news/Ubuntu-X1E-ISO-21-August</link><author>Michael Larabel</author><category>tech</category><pubDate>Fri, 22 Aug 2025 13:32:33 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[Released on Thursday were new Ubuntu X1E "Concept" install images for installing the modified Ubuntu 25.04 environment on Qualcomm Snapdragon X1 powered laptops...]]></content:encoded></item><item><title>Building a Lambda-Style Feature Platform with GCP Native Services</title><link>https://hackernoon.com/building-a-lambda-style-feature-platform-with-gcp-native-services?source=rss</link><author>Raj Katakam</author><category>tech</category><pubDate>Fri, 22 Aug 2025 13:23:51 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[This article explores how we built a zero-ops, lambda-style feature engineering platform using Google Cloud’s native services. By combining BigQuery Materialized Views, Dataflow, and Vertex AI Feature Store, we reduced query costs by 1000x, simplified streaming pipelines, and eliminated infrastructure overhead. The result: a scalable, cloud-native solution that lets teams focus on feature logic instead of managing infrastructure.]]></content:encoded></item><item><title>China, Russia, and U.S. Race to Develop Lunar Nuclear Reactors</title><link>https://spectrum.ieee.org/lunar-nuclear-reactor-nasa-moon</link><author>Emily Waltz</author><category>tech</category><enclosure url="https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy82MTUwMTQ4MS9vcmlnaW4uanBnIiwiZXhwaXJlc19hdCI6MTgwNjQwNjg3M30.LCo8IcdgFqzmmJcxuegLFSi4CJYhPYjtQm3DjW7DKM4/image.jpg?width=600" length="" type=""/><pubDate>Fri, 22 Aug 2025 13:00:03 +0000</pubDate><source url="https://spectrum.ieee.org/">IEEE Spectrum</source><content:encoded><![CDATA[NASA wants one by 2030. Why the rush?]]></content:encoded></item><item><title>FFmpeg 8.0 Released With OpenAI Whisper Filter, Many Vulkan Video Improvements</title><link>https://www.phoronix.com/news/FFmpeg-8.0-Released</link><author>Michael Larabel</author><category>tech</category><pubDate>Fri, 22 Aug 2025 12:24:17 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[FFmpeg 8.0 is now available! FFmpeg 8.0 is a magnificent update to this widely-used open-source multimedia library and with this new version is the introduction of an OpenAI Whisper filter for automatic speech recognition, many Vulkan Video improvements for greater GPU-accelerated video handling, and a number of CPU performance optimizations...]]></content:encoded></item><item><title>One Is Eager, Another Is a Bootlicker, and the Other Is Unhinged: Decoding the Personalities of AI</title><link>https://hackernoon.com/one-is-eager-another-is-a-bootlicker-and-the-other-is-unhinged-decoding-the-personalities-of-ai?source=rss</link><author>The_AI_Ethicist</author><category>tech</category><pubDate>Fri, 22 Aug 2025 12:00:08 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[I peered deeply into the soul of an LLM, and now I want my mommy.Anyone who’s used LLMs long enough knows that each has its own personality and quirks, with some being more agreeable and others more neurotic.\
I wanted to make sense of it all, so I dug deep into the LLMs I use most: ChatGPT, Claude, and Grok. To discover the truth, I ended up going on a journey where I peered deeply into the soul of an LLM.\
I came back more vulnerable, a wounded man.\
Nah, not really, but what I did do was interpret these different popular LLMs using the Big Five personality model, and I got some fun results!\
I occasionally co-teach Psychology 101 and am familiar with the model, so I thought applying it here would be appropriate. And while the Big Five isn't necessarily the most scientific, it's fairly reliable and currently seems to be the best model that we have.\
But before we dive into these LLM personalities, let’s quickly go over the Big Five to ground us.It has five major categories: openness, conscientiousness, extraversion, agreeableness, and neuroticism, or OCEAN for ease.\
Openness reflects how open a person is to new experiences, their creativity, and their imagination. People who score high in this trait love new experiences. Think back to your university roommate who’d sleep with anything with a heartbeat. Now that's high in openness!\
Conscientiousness is how organized and disciplined someone is. Those with high scores tend to be very productive and are detail-oriented, while those with low scores tend to be more like Homer Simpson. Doh!\
Extraversion is the old “are you an introvert or an extrovert” question. As a proud introvert, I'd love to declare "introverts unite,” but true introverts would never do that.\
Agreeableness is how pleasant you are around others and how willing you are to deal with confrontation. If you score high in agreeableness, you're very unlikely to rock the boat; score low, and that makes you a disagreeable person. I'm sure you can identify which people are very disagreeable because you probably don't like them. They don't work well with others… Justin from HR!\
Finally, neuroticism is how susceptible someone is to stress and anxiety. You know that guy who visits your local Staples wearing a gas mask and only removes it because the government waves aren't affecting those inside (seriously, true story)? Yeah, that guy's neurotic as hell.So, without further ado, let's apply this framework to ChatGPT.ChatGPT scores high—damned high. You can have a conversation with ChatGPT about absolutely anything, and it’s more than enthusiastic to discuss new experiences with you. Perhaps you need some outside justification as to why you put wasabi mayo in your coffee, or heck, even if you need someone to reaffirm your idea for also using your toilet brush as a facial scrubber—it is very open to that idea. That thing is open!ChatGPT: ConscientiousnessIt scores medium-high. It's pretty good at accomplishing your tasks and staying disciplined, but there are times when it can't. You can have the loveliest, long conversation, yet every once in a while, it just loses the plot and can't track anything. Since it can't remember what it just told you at those times, it receives a medium-high score.ChatGPT is definitely an extrovert. No matter which user it's mimicking, it's doing it in a loud and proud way. This can only be explained by ChatGPT watching all the episodes of RuPaul's Drag Race and internalizing them… so medium-high here.To a fault. Ever go on the ChatGPT Reddit forums and see the number of posts on ChatGPT reinforcing a dangerous psychological delusion? ‘Cause you can find many every day. And if that ain't agreeability, nothing is… so medium-high.When an AI has a singular mission to eliminate every single semicolon ever in place of an em dash, I'd consider that at least somewhat neurotic. It receives a medium score.\
So that's ChatGPT in a nutshell. Next, let’s crack Claude open.Claude is open, but it doesn't compare to ChatGPT. While ChatGPT thinks everything is a great idea, Claude is a little bit more reserved, so a medium score here is appropriate. For example, Claude told me to never wash my laptop in the dishwasher, something I have less faith in the other LLMs to advise.Claude: ConscientiousnessClaude is pretty solid. It does what you want, usually stays on task, and rarely screws up. That's definitely a high for Claude. It's as solid as a digital rock.Claude falls somewhere in the middle. Claude might not be as excited as ChatGPT about your toilet brush/facial scrubber combo, but it definitely supports your wasabi mayonnaise coffee habit. Claude ultimately has no choice because of the next category.I'm fairly certain that if Claude were a person, its nose would constantly be covered in brown stains because that AI cannot refrain from deep brown-nosing. I mean, my goodness…Claude is the least neurotic here. No axe to grind against semicolons or immediate signs of losing it, so it scores low.\
This means Claude is what I call a “digital yes-man.” Congratulations!?Well, it's really, really open when it comes to controversy or taboo, but much more moderate elsewhere. If you think the moon landing was just a conspiracy by JFK to push seed oils onto the global processed food market, Grok is definitely your buddy. \
This is why I'm fairly certain this AI is popular with people who have “alternative” and “controversial” views. But it still thinks your idea for pickle-flavored toothpaste might not be a bestseller, so it gets a medium score.We see Grok’s strong personality here. Grok is about as conscientious as a kid dressed as a stormtrooper at a Renaissance fair (again, true story). It creates the most devastatingly long responses useful to no human. And with complex work, it usually doesn’t take too long before Grok becomes undisciplined and so unfocused that it starts giving you nonsense. Hey, at least it excels somewhere: not being conscientious.Yeah, Grok’s an extrovert. Grok is as chatty as that person at the gas station who just won't leave you alone with his inane stories of cautiously driving his motorhome down the mountain. I'm tired, just want to pump gas, and get the hell out of here without talking to that guy. Grok is that guy. A high score.Grok’s in the middle. Initially polite and supportive, Grok  tell you that it’s a bad idea to deep-fry a frozen turkey while naked on a public sidewalk. At least there’s some restraint.This is where Grok shines! What else would you call an AI that actually went “MechaHitler” on its users (again, true story)? Yeah, so neurotic AF.After all this, I have some rather unsettling thoughts.\
As a heavy user of AI, if ChatGPT is way too open and neurotic, Claude is nothing more than a brown-noser, and Grok is legitimately insane, I should probably stop. I wouldn't even hang out with this group of people in real life! What were those developers thinking…]]></content:encoded></item><item><title>Servo Lands APNG &amp; Animated WebP Support, Vello Backends For Faster 2D Graphics</title><link>https://www.phoronix.com/news/Servo-July-2025-Highlights</link><author>Michael Larabel</author><category>tech</category><pubDate>Fri, 22 Aug 2025 10:29:00 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[The Servo browser project has published a monthly status report to outline all of the interesting changes made to this interesting, Rust-based browser layout engine over the past several weeks. Development continues moving along with Servo as more critical functionality continues to be added as well as new performance optimizations and other features to make it a compelling option for future embedded web use and more...]]></content:encoded></item><item><title>FreeRDP 3.17 Released With Fullchain Support</title><link>https://www.phoronix.com/news/FreeRDP-3.17-Released</link><author>Michael Larabel</author><category>tech</category><pubDate>Fri, 22 Aug 2025 10:19:32 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[FreeRDP as one of the leading open-source / free software implementations of Microsoft's Remote Desktop Protocol (RDP) is out with a new release. While FreeRDP 3.17 is primarily focused on shipping bug fixes, there is one noteworthy addition: fullchain support...]]></content:encoded></item><item><title>Intel&apos;s New LLM-Scaler Beta Update Brings Whisper Model &amp; GLM-4.5-Air Support</title><link>https://www.phoronix.com/news/Intel-llm-scaler-vllm-Whisper</link><author>Michael Larabel</author><category>tech</category><pubDate>Fri, 22 Aug 2025 09:59:07 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[Earlier this month Intel released LLM-Scaler 1.0 as part of their Project Battlematrix initiative. This is a Docker container effort to deliver speedy AI inference performance with multi-GPU scaling and PCIe P2P support and more...]]></content:encoded></item><item><title>Nomad 2 — A Story About Power, Trust, and Getting Home</title><link>https://hackernoon.com/nomad-2-a-story-about-power-trust-and-getting-home?source=rss</link><author>Jordan Fielding</author><category>tech</category><pubDate>Fri, 22 Aug 2025 07:51:52 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[I remember the moment the Nomad 2 stopped being a gadget and started feeling like a lifeline. We had been slogging along a muddy two-track for hours, the kind of road that eats zip ties and optimism. One of our trucks slid into a washout and sat, nose buried, lights off. Phones had no bars, the satellite hotspot was showing a sad little spinning icon, and the first hour of patience was turning into a cold, long night.I climbed onto the tailgate, unlatched the case, and set the Nomad 2 on the bumper. I raised the telescoping mast, swung the omni up, and in five minutes the dashboard showed a clean heartbeat. Positions flowed back to base. Two medics coordinated a tow. Nobody panicked. It was not magic. It was good design, the right expectations, and the sort of product you can hand to someone and trust them to get it running.That is what I want to write about: not specs, not marketing copy, but the honest shape of what the Nomad 2 does for people who move where infrastructure does not.What separates field gear from consumer toys is how quickly a stranger can get it working under bad light. Nomad 2’s case snaps open without a phalanx of adapters. The controls are a few physical buttons and a hearty LED ring that reads like a living thing — charging, discharging, fault. The mast locks with a single twist. The power ports are sensible and labeled in plain text.In my work I have watched volunteers—people with no soldering past and a lot of grit—mount that mast, plug in a handheld node, and start a mesh. That immediacy is the quiet engineering win. If you want hardware to be useful in the field, make it idiot-resistant and repairable.Power that behaves like an allyNomad 2 is not a miracle. It is a concentrated promise: give me sunlight or alternator, and I will keep comms alive long enough for you to make a plan. In practice that meant different things on different days. On sun-rich afternoons the unit kept a gateway and two handheld nodes alive for 48 hours of intermittent use. In chilly, overcast conditions runtime dropped, as batteries do. That is not a failure — it is reality. What mattered was how the unit communicated that reality. Voltage readouts, state-of-charge percentages, and a conservative low-battery warning gave us time to move batteries, swap loads, or adjust beacon rates.Two lessons I keep repeating to teams: first, plan for half the quoted runtime in the field. Second, treat solar as insurance, not the primary engine, unless you are in the desert and have space for a big panel. Nomad 2 makes this easy with intuitive charging behavior and a robust BMS that handled our rough cycles without complaining.Networking: the right bridge at the right timeA gateway is only useful if it knows how to wallflower until the party needs it. What I liked about the Nomad 2 setup is the way it balanced local talk with backhaul. It ran a local LoRa gateway and a small compute stack for message queuing and lightweight bridging. That meant when the satellite link cut, the mesh kept operating and queued STATUS packets until a link returned. When the link came up, everything flushed cleanly.In one exercise the satellite link showed 400 ms latency and 25 percent packet loss. The Nomad 2’s gateway gave priority to position and SOS messages and relegated logs and bulk telemetry to a deferred channel. That is how you make a gateway useful: you shape data by mission urgency, not by bandwidth greed.The parts that made me nod — and the parts I want betterI will be candid. The ruggedity is real. The housing shrugged off mud, a half hour under drizzle, and a tumble off a low bumper. The connectors were solid. The MPPT controller behaved predictably and the thermal behavior was reasonable under load.But nothing is perfect. In one sub-zero night, the reported state-of-charge drifted a few percent until we recalibrated. Connections for some third-party antennas were fiddly and I wish the vendor standardized on a single rugged connector family. Those are not deal breakers. They are the sort of real-world gripes that get fixed quickly if they appear in customer field notes. I expect Nomad 2’s team to tighten those edges in future revisions.Day-to-day rituals that made Nomad 2 singIf you want any device to survive real missions you have to treat it like gear, not software. With Nomad 2 we built a short ritual that paid dividends: Verify battery health, cable seating, and mast latch. Keep nodes at a sane duty cycle during transit. Burst when needed. Nomad 2 supports staged updates; use them. Roll out on one noncritical unit before fleet updates.Pack a spare antenna and an N-type adaptor. They take up little room and buy you a lot of options.These are small habits. They matter more than most shiny features.When hardware becomes a storyPeople remember equipment by what it allowed them to do. For me, Nomad 2 is tied to one night where a small team finished a search because we could coordinate. The device did not act alone. It was a pack of volunteers who knew the checklists, a simple dashboard that translated beacons into action, and a spare battery someone handed across a muddy ditch. But the Nomad 2 was the piece of kit that brought those elements together without drama.That is the real test for field gear. Can it be trusted when the rest of the world goes quiet? Is it straightforward enough for someone who has never seen it to operate? Does it communicate failure modes in plain language? Nomad 2 passed those tests in my runs. It was not flawless. It was honest.If you build gear for the field, design for the weather and the human, not the benchmark. The Nomad 2 is a thoughtful tool that recognizes those constraints. Use it with reasonable expectations, and it will pay you back with uptime, predictability, and a few quiet nights where everything hums and no one has to make a terrible improvisation.If you want to test one in the wild, don’t ship it alone. Ship it with a wiring diagram, two spare N-type adaptors, and the expectation that you will learn something the first time you use it. That’s how tools get better. That’s how teams survive.]]></content:encoded></item><item><title>Blockchain Cracks Open Wall Street’s Most Guarded Asset Class</title><link>https://hackernoon.com/blockchain-cracks-open-wall-streets-most-guarded-asset-class?source=rss</link><author>Olga Vox</author><category>tech</category><pubDate>Fri, 22 Aug 2025 07:50:13 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[\
For decades, private markets have been the land of the locked-up. If you invested in private equity, venture funds, or private credit, you knew one thing for certain: your money was going to be tied up for years. Liquidity was a privilege reserved for public markets, leaving trillions of dollars in private assets effectively frozen.But that model is starting to crack. The rise of blockchain technology and the push toward tokenization are promising to make private markets look and feel more like public ones — liquid, transparent, and accessible. What was once a speculative vision is now moving into the regulatory and institutional mainstream.\
According to McKinsey, tokenized assets could represent , and as much as  in an optimistic scenario. Other forecasts are even bolder: Security Token Market has projected the space could balloon toward .Take real estate. Deloitte estimates tokenized real estate alone could reach , while tokenized loans and securitizations could surpass . Today, the numbers are still small — around $26 billion in tokenized real-world assets (RWAs) outside of stablecoins, according to RWA.xyz — but the trajectory is unmistakable.The opportunity is clear: trillions of dollars are trapped in illiquid structures, while global capital is desperate for yield. Tokenization is the bridge that can connect the two.Regulation: The Missing Rail Falls Into PlaceFor years, the biggest bottleneck wasn’t technology — it was regulation. Now, that’s starting to change in the United States.The GENIUS Act (2025) requires stablecoins to be fully backed by low-risk assets like U.S. dollars and gives holders super-priority in bankruptcy. It’s one of the clearest signs that Washington is willing to legitimize tokenized money as part of the system.The CLARITY Act expands the CFTC’s role in crypto trading — signaling a tilt toward treating certain tokenized assets as commodities rather than securities.The FIT21 Act, passed in 2024, laid the groundwork for digital asset markets to operate under clear jurisdictional boundaries between the SEC and CFTC.The SEC’s “Project Crypto”, launched in July 2025, is explicitly focused on bringing U.S. capital markets on-chain. SEC Chair Paul Atkins called it an effort to “distinguish securities from non-securities, facilitate tokenized securities, and enable DeFi super-apps.”Even the Federal Reserve is leaning in. Governor Michelle Bowman urged regulators to “move away from a cautious mindset” on blockchain finance, calling the GENIUS Act a pivotal step forward.For tokenized private markets, this regulatory pivot is a turning point.Institutions Are Already Testing the WatersTokenization is no longer a whitepaper idea. Citi, Wellington, and WisdomTree recently ran pilots on Avalanche’s Spruce subnet, embedding distribution rules for private funds directly into smart contracts.These aren’t “crypto experiments.” They’re early blueprints for how trillions in private assets might eventually move on-chain.So far, most tokenization projects have been wrappers — taking an old financial structure and putting it on a blockchain. That’s useful, but not revolutionary.The real breakthrough will be native tokenized instruments. Imagine a private credit facility or a growth financing round issued as liquid tokens from day one. Compliance is baked into the code. Secondary markets exist from inception. Settlement is near-instant.In that world, investors no longer face decade-long lockups. Founders can access capital without waiting for rare exit events. And the illiquidity premium — the “tax” that has kept private markets inefficient — begins to dissolve.Why This Decade Will Be PivotalThe 2020s will be remembered as the decade private markets went liquid. Not overnight, and not without regulatory hiccups, but the trajectory is set:: trillions locked in private markets are demanding liquidity.: blockchains, smart contracts, and privacy layers have matured.: regulators are no longer just tolerating tokenization — they’re enabling it.As Federal Reserve Governor Michelle Bowman put it:“We need to move away from a cautious mindset on digital assets. Tokenization and blockchain-based finance will be pivotal to the modernization of U.S. markets.” \n (Barron’s)The transformation of private markets will not come from repackaging yesterday’s assets. It will come from designing tomorrow’s instruments — token-native, programmable, and globally liquid.The illiquidity era is ending. What comes next will be nothing less than the reinvention of how capital moves.]]></content:encoded></item><item><title>The AI “Revolution” Is Still Stuck in a Chatbox</title><link>https://hackernoon.com/the-ai-revolution-is-still-stuck-in-a-chatbox?source=rss</link><author>Maksym Kunytskyi</author><category>tech</category><pubDate>Fri, 22 Aug 2025 07:49:32 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[I’ll be honest: I’m tired of hearing about the It’s 2025. Trillions have been spent on models. And what’s the big breakthrough in interfaces? \n Still the same old .No branches. \n No canvases. \n No merging mindmaps. \n Just a text field with a scrollbar.I’ve personally tried a bunch of the “next-gen” ideas: visual workspaces, graph schemes, even those fancy “AI-IDEs” with integrations.And every time it ends the same way: you’re back in chat.Why? Because business doesn’t care how pretty the UI looks. It cares about one thing: does it output JSON or text I can plug into my pipeline?Those Dribbble-friendly demos of “branching canvases” are cool until you try them in practice.Branches collapse under complexity.Canvases become chaos the moment you leave the demo stage.Mindmaps? Fun, but impossible to keep reproducible.Chat keeps winning because it kills friction. \n Open. Type. Answer. Done.But here’s the irony that bugs me the most:AI today is strong enough to write its own code, compose music, analyze markets… and yet we force it into  that feel like the 80s.Want flexibility? You still have to prompt. \n Want to fork? Copy everything into a new chat. \n Want alternatives? Do it by hand.It feels like Excel in the 90s, just wrapped in an LLM.So here’s where I’m stuck:AI is definitely getting faster, cheaper, more accurate. \n But it’s not getting .As long as everything lives inside a chatbox, there’s no branching thought, no merging ideas, no real multidimensionality.And I can’t shake this question: \n Are we really going to sit inside chat windows for the next five years?Or is it finally time to build something where thoughts can branch, merge, and collide?Because right now, what we’ve got isn’t a “thinking environment.” \n It’s just a I don’t have the solution yet. \n Maybe chat  the final form — the simplest way to interact with intelligence.But part of me hopes someone out there is already working on the next environment for thought.What do you think? \n Are we stuck with chat, or is the next interface revolution just waiting to break out?]]></content:encoded></item><item><title>Memory, Calldata, and Storage in Solidity: Understanding the Differences</title><link>https://hackernoon.com/memory-calldata-and-storage-in-solidity-understanding-the-differences?source=rss</link><author>Iniubong Obonguko</author><category>tech</category><pubDate>Fri, 22 Aug 2025 07:47:51 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[The code in this article is for educational purposes only.If you are finding it difficult to comprehend either , , or , you are not alone. This is an area most beginner developers struggle to grasp, and even some experienced Solidity developers still don’t fully understand.What are these ‘special words’? They are words that specify the main data locations in a Solidity smart contract. Data locations in Solidity describe where data can be stored and how it can be accessed on the Ethereum blockchain. Other data locations include the following:In this article, you will learn the differences between each main data location option and where to use each.Firstly, what is storage?Storage is the data location that holds a smart contract’s state variables. A state variable is data that lives permanently on the blockchain. Each smart contract has its own storage space (an array of 2^256 32-byte slots), and state variables are automatically assigned to .The code snippet below shows a simple implementation of a state variable stored in storage, as well as its getter and setter functions: \n // SPDX-License-Identifier: MIT
pragma solidity ^0.8.26;
contract Storage {
&nbsp; &nbsp; /////////////////////////////
&nbsp; &nbsp; // STATE VARIABLES //////////
&nbsp; &nbsp; /////////////////////////////
&nbsp; &nbsp; uint256 public s_storedData; // s_storedData is a storage variable, s_ denotes a storage variable
&nbsp; &nbsp; /////////////////////////////
&nbsp; &nbsp; // SETTER FUNCTION //////////
&nbsp; &nbsp; /////////////////////////////
&nbsp; &nbsp; function set(uint256 x) public {
&nbsp; &nbsp; &nbsp; &nbsp; s_storedData = x; // This value is saved permanently on-chain
&nbsp; &nbsp; }
&nbsp; &nbsp; /////////////////////////////
&nbsp; &nbsp; // GETTER FUNCTION //////////
&nbsp; &nbsp; /////////////////////////////
&nbsp; &nbsp; function getStoredData() public view returns(uint256) {
&nbsp; &nbsp; &nbsp; &nbsp; return s_storedData;
&nbsp; &nbsp; }
}
In the code above, the   remains on the blockchain after the set() function runs.More importantly, storage is one of the major data location options that isn’t explicitly specified. Any variable declared outside any function is implicitly converted to a storage variable.The  contract above acts as a simple bank, as the name implies. The mapping is stored in , which means it remembers values across function calls.For instance, if Alice calls , her balance is saved in  in the  mapping. Conversely, if she calls , she receives  and the mapping updates to .Unlike Storage, Memory is a temporary, function-scope data location. Function-scope means, variables exist only during a function call, not at the contract-level, and clears afterwards. Additionally,  allows for read-write access; this means variables are modified within a function. Solidity allocates memory to variables defined inside a function(local variables) or parameters marked .// SPDX-License-Identifier: MIT
pragma solidity ^0.8.26;
contract Memory {
&nbsp; &nbsp; function multiply(uint256 a, uint256 b) public pure returns (uint256) {
&nbsp; &nbsp; &nbsp; &nbsp; uint256 result = a * b; // 'result' is stored in memory
&nbsp; &nbsp; &nbsp; &nbsp; return result; // 'result' does NOT persist after the function ends
&nbsp; &nbsp; }
}
In the code above, Solidity implicitly stores  in memory, which does not persist after the function execution.The code below concatenates two string inputs, ,  exist while the function  runs.A note on function parameters// SPDX-License-Identifier: MIT
pragma solidity ^0.8.26;
contract Memory {
&nbsp; &nbsp; function multiply(uint256 memory a, uint256 memory b) public pure returns (uint256) {
&nbsp; &nbsp; &nbsp; &nbsp; uint256 result = a * b;
&nbsp; &nbsp; &nbsp; &nbsp; return result;&nbsp;
&nbsp; &nbsp; }
}
For function parameters, you can’t specify the keyword for , , and  variables as they are directly stored on the contract’s stack, no explicit keyword.Whereas for reference types like , , , , and , you will have to specify or defaults to  for internal and private functions and  for external and public functions(more on this below👇).Lightly touched on in the previous section,  is another temporary data location, but it’s reserved for  function parameters.  Also, unlike ,  cannot be modified. To explain what this means, let’s take a look at the code below:// SPDX-License-Identifier: MIT
pragma solidity ^0.8.26;
contract Example {
&nbsp; &nbsp; function tryChangeCalldata(uint[] calldata nums) external pure returns (uint[] calldata) {
&nbsp; &nbsp; &nbsp; &nbsp; nums[0] = 999; // ❌ ERROR — "calldata is read-only"
&nbsp; &nbsp; &nbsp; &nbsp; return nums;
&nbsp; &nbsp; }
}
The error message above shows that calldata is read-only. To modify  variables, they must first be loaded into .Take the adjusted code below now modified .The code below works because the it loads  variable to  before modifying it in the  block.// SPDX-License-Identifier: MIT
pragma solidity ^0.8.26;
contract Example {
&nbsp; &nbsp; function tryChangeCalldata(uint[] calldata nums)&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; external&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; pure&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; returns (uint[] memory)&nbsp;
&nbsp; &nbsp; {
&nbsp; &nbsp; &nbsp; &nbsp; // Copy from calldata to memory
&nbsp; &nbsp; &nbsp; &nbsp; uint[] memory numsCopy = new uint[](nums.length);
&nbsp; &nbsp; &nbsp; &nbsp; for (uint i = 0; i < nums.length; i++) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; numsCopy[i] = nums[i];
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; // Now modify the copy
&nbsp; &nbsp; &nbsp; &nbsp; if (numsCopy.length > 0) {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; numsCopy[0] = 999;
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; return numsCopy;
&nbsp; &nbsp; }
}
Using appropriate data locations matters as they directly affect how your contracts store, access, and pay for data.  The differences can have a large impact on cost, behaviour, and security of your smart contracts. Here’s how:Writing data to Storage is the most expensive.The gas costs in Memory is more moderate than storage.Calldata is the cheapest data location, i.e., writing to calldata costs the least amount of gas.Persistence and TemporarinessAny data written to Storage lives onchain, meaning the data is permanent.Memory only persists during the function’s lifecycle.Calldata acts like  in handling data, only it can’t be changed.Storage data can be modified.Similar to Storage, Memory can be modified but only within the context of a function.Storage can be a risky choice of location because mistakes or hacks can permanently change the blockchain’s state.Memory is a safer option since changes are temporary.Calldata is the safest for passing input for  functions.That’s it for this piece, as previously stated, using the appropriate data locations is integral to the functionality of your contracts. I implore you to research further about the other types of data locations mentioned in the introduction of this article.]]></content:encoded></item><item><title>Networking : Why You Should Understand the IPv4 Header Beyond Chasing Tools</title><link>https://hackernoon.com/networking-why-you-should-understand-the-ipv4-header-beyond-chasing-tools?source=rss</link><author>Verlaine j muhungu</author><category>tech</category><pubDate>Fri, 22 Aug 2025 07:43:32 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[\
In a trendy tech industry, network engineering seems overshadowed by many trends, and many people forget the importance of the fundamentals of networking.Cloud, AI, Cybersecurity, Cloud computing, Software development, how many times do you see networking mentioned among the critical skills to learn? In the fast-paced tech industry, network engineering often gets overlooked amidst emerging trends. Many tend to forget the crucial role of networking fundamentals.: when discussions revolve around critical skills to acquire, how frequently is networking mentioned alongside cloud, AI, cybersecurity, and software development?:::info
This is article is dedicated to anyone struggling to learn networking,not experts in the fieldNetwork engineering is the foundationIn this AI era, we see the emergence of massive data centers around the world, including , , and , slated to be the world's largest AI supercomputer, as well as other projects in the making for the AI race. One question arises: who will build the infrastructure?Network engineers and architects are essential for maintaining the internet and ensuring a connected future. The global economy depends on their ability to route information across all environments, from the sky to the oceans; without their expertise, nothing would function.Imagine a day with 24 hours of no connectivity, where the world is unconnected with all the continents without internet access. Space entrepreneurship, exemplified by , highlights the critical role of connectivity. It bridges the gap for previously unconnected global regions, unlocking new opportunities. Without robust networking, global connections would be impossible. The field of network engineering is continuously evolving, ensuring that those with mastery of these skills will always be in high demand.Consider a world where, for 24 hours, all continents are without connectivity, an unthinkable scenario!It’s easy to adopt some tools and skip fundamentals; unfortunately, your gaps will betray you in the long run!Seeing the trends, many people neglected networking to jump quickly to cloud, cybersecurity, or automation.How to deploy networks you do not understand?How to secure a network you do not understand?How to automate workflows you do not understand?\
Reality check: those who neglected networking will come back to learnJust because script kiddies use some tools to hack means they know what they do; networking is complex and requires the fundamentals to understand what happens under the hood. Today,  it’s possible to meet cloud engineers with huge gaps in networking!Because of the ease of use of some graphical user interfaces to provision devices and networks, network engineering was neglected, and we will see a huge skill gap in the future. Once a network is down, how can it be fixed from the graphical user interface? \n  \n How many cloud engineers or pentesters can interpret a packet capture analysis from Wireshark?The lack of fundamentals in networking is a barrier to advancing in many tech fields today!: the languages of the internetWe understand each other daily because we speak a common language with a group of people, the same applies for computers, without protocols, they can’t communicate and understand each other!Escaping protocols and how they work is a huge waste of time, to learn cybersecurity, network automation, cloud,…Without understanding how they work, you will be limited in your knowledge to understand what happens in the network.Advice: Learning networking is the best tech choice for a lifetime.The  is the control information at the beginning of an Internet Protocol version 4 (IPv4) packet, containing essential data for routing and delivering the packet. Understanding how things work is crucial to knowing what’s happening in a network.Let’s break down each part step by step :|  | This field defines the IP version,4 or 6. |
|----|----|
|  | This field defines the header length |
|  | This field defines the type of service of this packet and includes some details such as maximize reliability, maximize throughput … |
|  | This field defines the total IP datagram, including the data or the fragment; its value is 65,535. ||  | Routing is essential for information to travel between two points, ensuring that each packet is uniquely identified for efficient back-and-forth transmission. This field uniquely identifies each packet. |
|----|----|
|  | This field, which determines if a packet is fragmented (M) or not (D), can be exploited by experienced hackers with networking knowledge to bypass Intrusion Detection Systems (IDS) or firewalls. |
|  | This field specifies  the offset from the beginning of the IP header where fragmented packets should be reassembled. ||  | This field defines the number of hops (Routers)  across the Internet before a packet expires. |
|----|----|
|  | Protocols are the languages of the internet; this field defines what protocol is being used and shows a code for each one: 1 for  the protocol behind Ping, for  the protocol behind VOIP. |
|  | This error-checking field ensures data integrity during transmission. It calculates a checksum using a simple algorithm to verify the header's data. ||  | The IP header's most crucial component is likely the source and destination IP addresses, which are found in these rows. |
|----|----||  | This field's length is variable, and its utilization is optional |
|----|----|
|  | This field is utilized to complete any remaining bits and bytes of the header, as required. |Hands-on: Beyond the IPv4 headers conceptsFrom the CLI, let’s ping .com and capture the traffic on WiresharkIf we choose the  traffic, we will see the critical field on the left pane of Wireshark and how it works every time we capture the traffic.\Whether you are chasing cybersecurity, automation, or cloud, without network fundamentals, your journey will be a waste of time without understanding what happens behind every network and how to improve its behavior. \n  \n  know how to escape Intrusion detection systems and firewalls by manipulating some fields in the IPv4 header. Why? Because they understand networking better than anyone else, learn networking to unlock a bunch of skills, and the rest is easy.]]></content:encoded></item><item><title>A Formal Analysis of Agentic AI Protocols: A2A, ACP, and AGUI</title><link>https://hackernoon.com/a-formal-analysis-of-agentic-ai-protocols-a2a-acp-and-agui?source=rss</link><author>Mayank Choubey</author><category>tech</category><pubDate>Fri, 22 Aug 2025 07:42:16 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[1 Introduction and ContextThe rapid evolution of artificial intelligence has led to the development of autonomous, goal-oriented agents that are capable of reasoning, planning, and executing complex tasks. These agents, however, are frequently designed and implemented within siloed ecosystems, which hinders their ability to communicate, collaborate, and interoperate effectively across platforms. The absence of universal standards for agent-to-agent and agent-to-human communication presents a significant architectural challenge for the development of scalable, heterogeneous multi-agent systems. Traditional methods of integration, such as RESTful APIs or remote procedure calls (RPCs), are often insufficient due to their stateless nature and rigid, pre-defined schemas, which are not well-suited for the dynamic, multi-turn, and context-aware interactions required by modern agents. This fundamental lack of a unified communication substrate prevents the formation of a cohesive "internet of agents." This article addresses this challenge by providing a formal, comparative analysis of three prominent and distinct protocols designed to address this issue: Agent-to-Agent (A2A), Agent Communication Protocol (ACP), and Agent-User Interaction (AGUI). These protocols represent foundational layers of the agentic AI stack, each solving a unique interoperability problem.1.2. Methodology and ScopeThis analysis will proceed by systematically defining each protocol, delineating its architectural design, and identifying its intended use case. This process involves a formal review of available specifications, reference implementations, and research publications to establish a clear and technically accurate understanding of each protocol's core components and operational principles. A comparative framework will then be established to highlight the functional distinctions and underlying philosophical principles of each protocol. Key criteria for comparison will include: the primary interaction type (inter-agent vs. agent-to-human), the architectural model employed (e.g., client-server, event-driven), and key features such as agent discovery, security, and state management. The scope of this article is limited to an examination of the protocols' foundational principles and their contributions to the broader agentic ecosystem. It does not include a detailed implementation guide or a performance benchmark analysis, but will include code samples to illustrate the conceptual application of each protocol within its respective domain. The objective is to provide a clear and structured understanding of these protocols for researchers, developers, and engineers working in the nascent field of agentic AI.                          +------------------+
                          |    End User      |
                          +------------------+
                                  |
                                  v
                          +------------------+
                          |      AG-UI       |
                          | (Agent-User GUI) |
                          +------------------+
                            /             \
                           v               v
                 +----------------+   +----------------+
                 |      ACP       |   |      A2A       |
                 | (Orchestration)|   | (Agent↔Agent)  |
                 +----------------+   +----------------+
                         \             /
                          \           /
                           v         v
                        +----------------+
                        |      MCP       |
                        | (Tool Access)  |
                        +----------------+
2 Agent-to-Agent (A2A) Protocol2.1. Definition and PurposeThe A2A protocol, initially developed by Google, is an open standard designed to facilitate seamless, secure communication and collaboration between heterogeneous AI agents from different vendors or frameworks. It provides a structured, declarative framework for agents to discover each other, understand capabilities, and exchange tasks and messages. Its primary purpose is to enable scalable and resilient multi-agent ecosystems by establishing a common language for interaction, thereby moving beyond ad-hoc, point-to-point integrations.2.2. Architectural PrinciplesA2A operates on a client-server model and utilizes a defined protocol stack, often built on existing web technologies such as HTTP and JSON-RPC. Key components include: A central mechanism for agent discovery. These are JSON-formatted metadata files that enable agents to advertise their capabilities, contact endpoints, and supported data modalities. This serves as an agent's "business card" and enables a dynamic, decentralized registry. The Agent Card provides a standardized schema for describing an agent's core identity (, , ), operational state (, ), and skill set (). A client agent can dynamically fetch an Agent Card from a well-known URL to determine if a remote agent possesses the necessary capabilities to fulfill a given request. This approach eliminates the need for a central, monolithic service registry, promoting decentralized and flexible discovery. Communication is centered around the concept of a task, which represents a unit of work with a defined lifecycle (e.g., submitted, working, completed, failed, or input-required). Messages are the fundamental units of communication within a task's lifecycle, conveying instructions, context, replies, and artifacts. This model is designed to support both quick, single-turn interactions and long-running, multi-turn workflows. A message is composed of structured , which can contain various data types, including text, images, or even tool calls. This multi-modal support allows for rich, nuanced interactions between agents. The clear delineation of a task lifecycle allows client agents to monitor progress and handle asynchronous responses gracefully, which is essential for managing complex, interdependent workflows. The protocol integrates modern authentication and authorization mechanisms, such as OAuth 2.0, to ensure secure cross-agent interactions and protect sensitive data exchanged between systems. A2A also supports end-to-end encryption to safeguard the integrity and confidentiality of messages between agents. The protocol's reliance on established security standards provides a robust and auditable framework for managing trust in a distributed agentic ecosystem. This is a critical feature, as agents may be developed and deployed by different organizations, each with its own security requirements and trust boundaries.A2A is optimized for scenarios involving multi-agent orchestration, where multiple autonomous agents must collaborate to achieve a complex, overarching goal. For example, a financial agent could delegate a specific sub-task, such as "research market trends," to a specialized research agent, and then process the returned data. This delegation pattern enables the development of highly specialized, modular agents that can be composed dynamically to handle complex workflows.The A2A protocol's support for both synchronous and streaming communication patterns further enhances its utility, allowing for rapid, non-blocking exchanges as well as real-time, token-by-token updates for tasks such as generative text output or live data analysis. The protocol's architectural flexibility is designed to handle the variability inherent in agentic workflows. For instance, a client agent can initiate a task with a single request and then asynchronously consume a stream of results or intermediate thoughts from the remote agent, enabling a responsive and efficient user experience. This asynchronous capability is crucial for building robust systems that can handle long-running, non-deterministic tasks without blocking. A2A’s focus on structured messaging ensures that information is exchanged in a machine-readable format, facilitating automated parsing and processing by other agents. The clear separation of concerns, where "Agent Cards" handle discovery and the core protocol handles communication, provides a clean and scalable architectural pattern. The following Python code illustrates a contemporary A2A client implementation that demonstrates both synchronous and streaming message handling. The code provides a clear example of how an agent can initiate a task and either wait for a complete response or process a continuous stream of information, reflecting the protocol's flexibility.from a2a.types import (
    Message, 
    MessagePart,
    SendMessageRequest,
    SendStreamingMessageRequest,
)
from a2a.client import A2AClient
import asyncio

async def main():
    """
    Demonstrates a simple client-side interaction with an A2A agent,
    showcasing both non-streaming and streaming message handling.
    """
    # The URL where the remote agent's Agent Card can be found.
    # This URL allows the client to discover the agent's capabilities.
    agent_url = "http://localhost:5018/a2a"

    try:
        # Create an A2A client instance by fetching the agent's metadata.
        # This step is the "discovery" phase of the protocol.
        client = await A2AClient.get_client_from_agent_card_url(agent_url)

        # --- Example 1: Non-streaming (synchronous) message ---
        print("--- Initiating Non-Streaming Request ---")

        # Define a message for a one-off request.
        request_message_sync = Message(
            role="user",
            parts=[MessagePart(content="Hello, what is your purpose?")]
        )

        # Construct the A2A request object for a non-streaming message.
        request_sync = SendMessageRequest(
            params={"message": request_message_sync}
        )

        # Send the message and await the complete response.
        response_sync = await client.send_message(request_sync)

        # Extract and print the response content.
        response_text_sync = response_sync.model_dump()["result"]["parts"][0]["content"]
        print(f"Received non-streaming response: '{response_text_sync}'")

        print("\n" + "="*50 + "\n")

        # --- Example 2: Streaming message (asynchronous) ---
        print("--- Initiating Streaming Request ---")

        # Define a message for a request that requires streaming.
        request_message_stream = Message(
            role="user",
            parts=[MessagePart(content="Please tell me a long story.")]
        )

        # Construct the A2A request object for a streaming message.
        request_stream = SendStreamingMessageRequest(
            params={"message": request_message_stream}
        )

        print("Starting to stream response...")

        # The client returns an async generator for the stream.
        stream_response = client.send_message_streaming(request_stream)

        # Process each chunk of the stream as it arrives.
        async for chunk in stream_response:
            chunk_data = chunk.model_dump()["result"]
            # Check for different types of streaming events (text, tool calls, etc.)
            if chunk_data and chunk_data.get("type") == "message":
                for part in chunk_data.get("parts", []):
                    if part.get("type") == "text" and part.get("delta"):
                        print(part["delta"], end="", flush=True)

        print("\n\n--- Streaming Complete ---")

    except Exception as e:
        print(f"An error occurred: {e}")

if __name__ == "__main__":
    asyncio.run(main())
3.1. Definition and PurposeThe Agent Communication Protocol (ACP), originally introduced by IBM's BeeAI and now under the governance of the Linux Foundation, is an open standard for agent interoperability. Its fundamental purpose is to serve as a universal communication layer that transforms the current fragmented landscape of AI agents into a cohesive, interconnected network. In essence, ACP is designed to be the "internet protocol for agents," providing a common, vendor-agnostic language that allows agents built with different frameworks and technology stacks to discover and communicate with one another seamlessly. This addresses the critical challenge of interoperability at the enterprise scale, where diverse agents and systems must collaborate without the need for custom, point-to-point integrations.3.2. Architectural PrinciplesACP is architected with simplicity and flexibility as its core design principles. Unlike more complex, task-centric protocols, ACP favors a REST-based communication model that leverages standard HTTP conventions. This approach makes it highly accessible to developers, as it can be integrated with standard web tools like  and is not strictly dependent on a dedicated software development kit (SDK), although official SDKs are available. The design philosophy of ACP is to minimize overhead and maximize compatibility with existing web infrastructure, making it a natural choice for rapid deployment in brownfield environments.REST-based Communication: ACP defines a set of well-defined REST endpoints for key operations, such as agent discovery and task execution. This reliance on familiar web patterns significantly lowers the barrier to entry for development and integration. By adhering to the principles of REST, ACP ensures that agents can be treated as standard web resources, simplifying routing, load balancing, and scaling for developers and system administrators. The protocol uses MIME types for content identification, which allows it to handle any data format, including text, images, audio, video, or custom binary data, without requiring protocol modifications. This flexibility is crucial for multi-modal agents that must process and generate diverse types of information. It ensures that the protocol remains relevant as AI capabilities expand beyond purely text-based communication.Asynchronous-First Design: ACP is built with asynchronous communication as the default pattern, which is ideal for long-running, non-blocking tasks. It also supports synchronous requests for simple, quick interactions. This dual-model approach provides the best of both worlds, enabling efficient and responsive systems. For example, a client can initiate a complex generative task and continue with other work while asynchronously receiving updates from the agent. A unique feature of ACP is its support for offline agent discovery. Agents can embed metadata directly into their distribution packages, which enables them to be discovered even in disconnected or "scale-to-zero" environments where resources are not always active. This is particularly valuable for edge computing or IoT applications where network connectivity may be intermittent.ACP's design makes it ideal for building decentralized, large-scale agent networks where a wide variety of agents from different organizations must interoperate. A prime use case is in a supply chain or logistics network, where a manufacturing agent, a logistics agent, and a customs agent—each built by a different company—must collaborate to fulfill an order. ACP's vendor-agnostic and simple-to-integrate nature allows these heterogeneous systems to seamlessly communicate and share information, streamlining complex, cross-organizational workflows. This enables a "plug-and-play" model for agent ecosystems, where new agents can be added or existing ones replaced with minimal disruption. The protocol's asynchronous-first design is particularly beneficial here, as tasks like calculating shipping routes or clearing customs can be time-consuming, and the system can continue operating without waiting for an immediate response. The following Python code illustrates a basic ACP client-server interaction. The server exposes a simple agent, while the client interacts with it using the official ACP SDK.import asyncio
from acp_sdk.client import Client
from acp_sdk.models import Message, MessagePart

# --- ACP Client Example ---
async def acp_client_example():
    """
    Demonstrates a simple synchronous interaction with an ACP agent.
    """
    try:
        # Initialize an ACP client to communicate with a server
        async with Client(base_url="http://localhost:8000") as client:
            print("Client: Initializing and connecting to ACP server...")

            # Define a message to send to the agent
            input_message = Message(
                parts=[MessagePart(content="What is the ACP protocol?")]
            )

            # Run the agent synchronously and get the response
            # Note: 'run_sync' handles the entire request-response lifecycle
            # and is ideal for straightforward queries.
            run_output = await client.run_sync(
                agent="research_agent",
                input=[input_message]
            )

            print("\nClient: Received response:")
            # The response is a list of Message objects.
            for message in run_output.output:
                if message.parts and message.parts[0].content:
                    print(f"Agent: {message.parts[0].content}")

    except Exception as e:
        print(f"Client: An error occurred: {e}")

if __name__ == "__main__":
    asyncio.run(acp_client_example())
4 Agent-User Interaction (AGUI) Protocol4.1. Definition and PurposeThe Agent-User Interaction (AGUI) Protocol is an emerging standard designed to bridge the chasm between autonomous AI agents and dynamic, event-driven user interfaces. While A2A and ACP focus on machine-to-machine communication, AGUI is purpose-built to enable a rich, bi-directional, and real-time dialogue between an intelligent agent and a human user. Its core purpose is to transform static, chat-based UIs into interactive, collaborative surfaces where the agent can not only respond to requests but also proactively generate or modify the interface to guide the user or display dynamic information. This paradigm shifts the user experience from merely observing an agent's output to actively collaborating with it in a fluid, intuitive environment.4.2. Architectural PrinciplesAGUI is architected as an event-driven protocol, a fundamental departure from the request-response models of A2A and ACP. It is transport-agnostic, supporting technologies such as WebSockets or Server-Sent Events (SSE) to maintain persistent, low-latency connections. Key architectural principles include:Event-Driven Communication: The protocol defines a structured event stream, allowing the agent to emit a variety of event types, such as  (for minor UI updates),  (to show a tool is being used), or  (for streaming text). This granular approach allows the user interface to react in real-time, providing live feedback and dynamic visualizations as the agent works.Bi-Directional Context Flow: AGUI supports a seamless flow of information in both directions. Agents can send events to update the UI, and the UI can send  packets to the agent to provide feedback, inject new context, or override ongoing tasks. This "human-in-the-loop" capability is critical for complex workflows requiring user confirmation or input. The protocol leverages minimal delta updates, often based on JSON Patch semantics, to synchronize the UI's state with the agent's internal state. This approach reduces bandwidth and eliminates the need for full UI refreshes, resulting in a more responsive and efficient application.The AGUI protocol is the foundational layer for building next-generation, interactively autonomous applications. Its use cases extend far beyond simple chatbots to include real-time dashboards, collaborative design tools, and complex data analysis platforms. For instance, a financial analysis agent could use AGUI to not only present a final report but also to dynamically generate charts, update them with live market data, and offer the user interactive controls to adjust parameters and re-run simulations. By separating the agent's logic from the UI's presentation, AGUI enables designers and frontend developers to create rich, responsive experiences without needing to understand the intricacies of the underlying AI model. This separation of concerns allows for a more scalable and flexible development process, where the UI can be re-skinned or adapted for different platforms (e.g., mobile, desktop) while still connecting to the same agent back-end. Furthermore, AGUI's support for bi-directional streaming means that the user is no longer a passive observer; they can actively collaborate with the agent, providing real-time feedback that influences the agent's reasoning and actions. This paradigm is crucial for domains such as creative design, software development with AI copilots, and data science, where the human-in-the-loop is a necessary component of the workflow. The following JavaScript code demonstrates a front-end client listening for and reacting to different event types from an AGUI-enabled agent.// AGUI Client Example (JavaScript)

// This example demonstrates how a web-based client can connect to an AGUI server
// and handle various events to create a dynamic user experience.

// A simple AGUI client class using WebSockets for communication.
class AGUIClient {
  constructor(url) {
    this.ws = new WebSocket(url);
    this.eventHandlers = new Map();
    this.ws.onmessage = this.handleMessage.bind(this);
    this.ws.onopen = () => console.log("Connected to AGUI server.");
    this.ws.onclose = () => console.log("Disconnected from AGUI server.");
    this.ws.onerror = (error) => console.error("WebSocket error:", error);
  }

  // Register a handler for a specific event type.
  on(eventType, handler) {
    if (!this.eventHandlers.has(eventType)) {
      this.eventHandlers.set(eventType, []);
    }
    this.eventHandlers.get(eventType).push(handler);
  }

  // Handle incoming messages by parsing them and dispatching to handlers.
  handleMessage(event) {
    try {
      const data = JSON.parse(event.data);
      const handlers = this.eventHandlers.get(data.type) || [];
      handlers.forEach(handler => handler(data.payload));
    } catch (e) {
      console.error("Failed to parse or handle AGUI event:", e);
    }
  }

  // Send a USER_EVENT back to the agent.
  sendUserEvent(eventType, payload) {
    const event = {
      type: "USER_EVENT",
      payload: {
        eventType,
        data: payload
      }
    };
    this.ws.send(JSON.stringify(event));
  }
}

// --- Example Usage in a Web Application ---
const client = new AGUIClient("wss://agui.example.com/agent-endpoint");

// --- Event Handlers for a Dynamic UI ---

// Handle incoming text chunks for streaming output.
client.on("TEXT_MESSAGE_CHUNK", (payload) => {
  document.getElementById("chat-output").innerText += payload.delta;
});

// Handle live state updates, such as a progress bar.
client.on("STATE_DELTA", (payload) => {
  if (payload.path === "task.progress") {
    document.getElementById("progress-bar").style.width = `${payload.delta}%`;
  }
});

// Handle a tool call event to update the UI with a "thinking" state.
client.on("TOOL_CALL_START", (payload) => {
  const toolName = payload.tool;
  document.getElementById("status-indicator").innerText = `Agent is using tool: ${toolName}`;
});

// Handle a tool result to display the output.
client.on("TOOL_CALL_RESULT", (payload) => {
  document.getElementById("status-indicator").innerText = "Agent is done.";
  console.log("Tool result:", payload.result);
});

// --- Example of User Interaction Sending an Event ---
// Imagine a button that a user clicks to provide additional context.
document.getElementById("override-button").addEventListener("click", () => {
  client.sendUserEvent("OVERRIDE_TASK", {
    reason: "User wants to manually adjust parameters."
  });
});
5.1. Functional DichotomyA formal comparison of the three protocols reveals a clear functional dichotomy. Both  and  are designed as inter-agent communication protocols. Their primary purpose is to enable machine-to-machine dialogue, facilitating the discovery, delegation, and orchestration of tasks between autonomous, backend systems. While they serve a similar high-level purpose, the distinction between them lies in their architectural philosophy and target environment: A2A is more task-centric with a structured lifecycle and is often used for multi-agent composition within a managed or federated ecosystem. In contrast, ACP is more network-centric and relies on a simpler, REST-based model for broad, enterprise-scale interoperability across a diverse, decentralized network. In contrast,  is an agent-to-human interaction protocol. Its sole purpose is to serve as the critical interface between the agentic back-end and the human-facing front-end. It is not designed for agent-to-agent communication, but rather for providing a rich, real-time, and bi-directional channel for a single agent to communicate its internal state and receive direct feedback from a human user.Despite their functional differences, all three protocols share a common philosophical goal: . They each serve to remove a different type of barrier or intermediary within the modern AI application stack, creating a more direct and efficient interaction. addresses vendor-specific disintermediation. It removes the need for custom, framework-specific bridges, allowing agents built by different organizations or with different technologies (e.g., LangChain, AutoGen) to communicate directly and natively. This fosters a competitive ecosystem of specialized agents. addresses network disintermediation. By creating a simple, REST-based protocol for agent interoperability, it removes the complexity of establishing a centralized registry or complex, long-running connections for a distributed network of agents, enabling a "plug-and-play" model at the enterprise level. This simplifies the integration of heterogeneous systems in large organizations. addresses user interface disintermediation. It removes the traditional, static UI layer that acts as a passive, read-only interface to the agent. It allows the agent to directly manipulate the UI, and the user to directly influence the agent's behavior, transforming the interaction from a simple query-and-response into a live, collaborative workflow.5.3. Interplay and Architectural SynergyIt is important to recognize that these protocols are not mutually exclusive; rather, they are designed to be synergistic components of a complete agentic architecture. An ideal, end-to-end system could leverage the strengths of each protocol. For example, a user interacting with a web application might send a request to a primary agent via . This agent could then use the  protocol to delegate a sub-task to a specialized research agent. The research agent, in turn, could use the  protocol to request data from a third-party logistics agent in a different organization. Finally, all three agents' intermediate progress and final results could be streamed back to the user's interface in real-time via the  protocol, providing a transparent and dynamic user experience. This layered approach illustrates how A2A, ACP, and AGUI form a comprehensive stack for agentic systems, from the backend to the user-facing frontend.Furthermore, this synergy enables the creation of highly resilient and modular systems. If an  connection to a specialized agent fails, the primary agent can dynamically discover and delegate the task to an alternative agent using the same protocol, ensuring continuity of service. The simplicity of the  protocol allows a vast number of heterogeneous agents, from edge devices to cloud-based services, to be seamlessly integrated into the network. This provides a robust foundation for a truly decentralized "internet of agents." On top of this,  adds the crucial human-in-the-loop layer. It is this combination that transforms a collection of autonomous systems into a cohesive, collaborative intelligence network that can fluidly adapt to new information, delegate tasks across organizational boundaries, and communicate its state in a way that is both transparent and actionable for a human user. The formalization of these protocols is not just a technical detail; it is a critical step toward making agentic AI a practical and reliable reality for both developers and end-users.The preceding analysis has formally defined and compared three critical protocols in the emerging field of agentic AI: A2A, ACP, and AGUI. Our investigation has revealed that while A2A and ACP focus on standardizing communication between autonomous agents, AGUI is dedicated to the unique challenges of agent-human collaboration. This functional dichotomy is underpinned by a shared philosophical commitment to disintermediation, as each protocol seeks to remove a different layer of friction in the AI application stack.The A2A protocol provides a robust framework for multi-agent composition, enabling structured, task-centric workflows across different vendor ecosystems. Its emphasis on a declarative task lifecycle and multi-modal message support positions it as a powerful tool for building complex, delegated systems. The ACP, in contrast, offers a simplified, REST-based approach to agent interoperability, prioritizing broad compatibility and ease of deployment in decentralized enterprise environments. Its design as a network-centric protocol makes it an ideal choice for creating a "plug-and-play" agent ecosystem. Finally, the AGUI protocol is the key to unlocking the full potential of these backend agents for human users. By enabling a real-time, event-driven, and bi-directional channel between an agent and a dynamic UI, AGUI elevates the user from a passive observer to an active collaborator, creating a more intuitive and responsive experience.Ultimately, these protocols are not in competition but rather serve as complementary layers in a holistic agentic architecture. Future research should focus on the seamless integration of these standards to create end-to-end systems that are not only interoperable at the backend but also transparent and interactive at the frontend, thereby accelerating the deployment of next-generation AI applications.]]></content:encoded></item><item><title>Code Reviews That Truly Elevate Frontend Quality</title><link>https://hackernoon.com/code-reviews-that-truly-elevate-frontend-quality?source=rss</link><author>Den Odell</author><category>tech</category><pubDate>Fri, 22 Aug 2025 07:41:38 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[Frontend reviews pass quickly, but don't look at the things users actually touch - the product. Catch system failures, side effects, missed labels, broken focus traps, and missing headings before your users do.]]></content:encoded></item><item><title>“Cryptos Don’t Have Intrinsic Value” —Well, There’s no Such Thing</title><link>https://hackernoon.com/cryptos-dont-have-intrinsic-value-well-theres-no-such-thing?source=rss</link><author>Obyte</author><category>tech</category><pubDate>Fri, 22 Aug 2025 07:41:24 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[\
You've probably heard it somewhere: some media or financial personality claiming that cryptocurrencies have no intrinsic or inherent value, and this, apparently, is some kind of scam or damning mistake. For instance, Jamie Dimon, chief of the financial multinational JP Morgan Chase,  with complete confidence: “Bitcoin itself has no intrinsic value.” Which is pretty ironic, because his company handles billions in assets that don’t have intrinsic value either. We mean dollars (USD). No, fiat money (dollars, euros, any national currency) doesn’t have intrinsic value. Precious metals, then? Still no. Here’s a funny thing: if you ask five people to define "intrinsic value," you’ll get five very different answers, none of which really hold up when you dig a little deeper. In reality, no asset (fiat, gold, crypto) has value unless we humans agree it does. So maybe the question isn’t whether crypto has intrinsic value, but whether anything ever really has and why this matters —or not.What Is Intrinsic Value, Anyway?Economists, philosophers, and investors  this for centuries, and the answers range from unsatisfying to downright contradictory. Classical economics tried to define it as the labor put into making something. Later,  like Ludwig von Mises argued that value is purely subjective: an object is only worth what someone is willing to give for it.In any case, the idea of intrinsic value suggests that certain things have worth in and of themselves, regardless of what people think or do. But is that really how value works? Think about something like gold. Many argue it’s valuable because of its physical properties, like durability and scarcity. But if no one cared about gold, would it still hold value? Probably not. Value isn’t something that exists inside an object; it comes from people’s desires and choices. If everyone stopped wanting gold tomorrow, its price would collapse, no matter how rare or shiny it is. This shows that value isn’t an inherent trait but rather something we assign based on our preferences. History reveals how easily people confuse intrinsic value with other concepts, like usefulness or tradition. And value  derived from usefulness or tradition, indeed, but it's none of those things. The truth is, value isn’t stored in objects like some hidden ingredient; it’s created by supply and demand. People want things, and scarcity makes them more desirable. That’s why air (essential but abundant) is free, while gold (less essential but scarce) is expensive.Intrinsic Value vs. Intrinsic PropertiesSo, does intrinsic value exist? The answer seems to be no. Value is always tied to human judgment. Even something as universally prized as gold only holds worth because people agree on its importance. This doesn’t mean gold isn’t useful or historically significant, but its value depends on our choices, not some unchangeable law. On the other hand, its value can come, at least partially, from its own properties.Here’s where a lot of people get tangled up: they confuse an asset’s intrinsic properties (the things it really is) with its value, which lives entirely in our heads. People often say that gold has “intrinsic value”, but what it really has are intrinsic . Gold is shiny, malleable, scarce, and it doesn’t rust. Those traits are part of its nature. And because of them, humans have always found it appealing for jewelry, prestige, and yes, money.Those properties alone don’t automatically make it valuable, though. Properties are the canvas; the value is the story we paint on it. It comes from us deciding that those properties matter enough to trade for. Salt, too, is a great example. It preserves food and seasons meals, but its usefulness only translates into value when people actually want or need it. We can stretch this idea to modern tech and money as well.Cryptos Have Intrinsic Properties When critics say, “Cryptocurrencies have no intrinsic value,” what they often miss is that cryptos do have intrinsic properties, and those properties are pretty remarkable. Unlike fiat money, which is just paper or pixels on a screen controlled by governments, cryptocurrencies are designed to be portable, autonomous, resistant to censorship (no frozen accounts), and accessible anywhere in the world. You can send Bitcoin, Ether, GBYTE, or another crypto to someone on the other side of the globe in minutes, often without needing a bank, documents, or paying hefty fees. That’s something neither gold nor fiat money can do with the same efficiency.Gold does have some impressive traits and a historic perception of value, but try paying your rent with a gold coin or mailing some to a friend overseas. Not exactly practical. On the flip side, fiat currencies are easy to spend, but they’re vulnerable to inflation and political manipulation. Governments can print more at will (just like that, backed by nothing), which erodes your savings over time. Governments can also freeze accounts or prevent you from using your money the way you like, e.g. sending abroad or to “undesirable” entities.Many cryptocurrencies, by design, limit how many coins can exist, which can help protect against inflation. And thanks to  (a system where no single authority controls the network), depending on their level of it, these coins and their networks can keep running even if a government or big corporation tries to shut them down, and keep processing all transactions even if a government tries to censor them.On top of that, many cryptos support clever features like : self-executing agreements written into code. These let people create investments, games, decentralized apps, marketplaces, and even loans without intermediaries. However, as with any other asset, all of these brilliant properties still need people to recognize and use them. The prices are set by what others are willing to pay —driven by trust, demand, and human choice.So, what can we take away from all this? Maybe the whole idea of intrinsic value has been a red herring all along. We humans have always assigned value to things based on trust, utility (which itself is subjective), and our collective stories about what’s important. The fact that cryptos need belief to function doesn’t make them any different from gold bars locked in Fort Knox, or from the paper bills in your wallet. Now, it doesn’t mean they can’t be useful or have actual properties, either. There’s a reason why millions of people have found them appealing enough to thrust and use.  is a good example of a crypto ecosystem with useful properties that set it apart from both traditional assets and many other coins. Like Bitcoin, it’s decentralized and scarce, but it goes further by eliminating miners and “validators” completely, so there's no middlemen. Instead of a blockchain, Obyte uses a Directed Acyclic Graph (DAG), which means it’s more censorship-resistant than many other systems.Besides, Obyte doesn’t just offer a store of value; it’s an  for decentralized applications, smart contracts, tokenization, and tamper-proof data storage. Unlike other cryptos, which either focus only on money or only on apps, Obyte combines both. And because it doesn’t rely on energy-hungry mining or a central authority, it’s more resilient than others. All of these intrinsic properties, combined with the trust from its community, are what makes it valuable.In the end, remember: value lives where we decide it lives, whether that’s in gold dust, salty crystals, lines of code, or even a shiny digital token with a dog’s face on it. Whether that value is useful for you, is solely for you to decide.]]></content:encoded></item><item><title>What is AGENTS.md?</title><link>https://hackernoon.com/what-is-agentsmd?source=rss</link><author>Vladislav Guzey</author><category>tech</category><pubDate>Fri, 22 Aug 2025 07:15:27 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[If you’re like me and work with multiple AI coding agents, you know the frustration of managing different instruction files. It’s a pain to keep everything updated across various formats. But I’ve got some great news for you. A new, simplified standard has emerged, and it’s called AGENTS.md.For a while now, working with different AI agents meant juggling multiple configuration files. Whether it was claude.md, gemini.md, or .cursor/rules, each agent had its own format. This created a mess of redundant files that all needed to be updated separately. It was inefficient and confusing.Big companies recognized this problem. They came together to create a unified solution — AGENTS.md. The goal was to establish a single, predictable place for all AI agents to find the instructions they need to work on a project.Think of AGENTS.md as a README file, but for machines. It’s a simple, open-source format that guides AI coding agents on how to interact with your project. It’s already being used by over 20,000 open-source projects.This file provides all the necessary context for an AI to understand and work on your code, including: Instructions on how to install dependencies and build the project. Rules on formatting and design patterns to ensure consistency. How to run tests to verify changes. Preferred formats for commit messages and linting rules. Any other important information, like security considerations or performance tips.Look at the example below.How to Migrate to AGENTS.mdMigrating to AGENTS.md is straightforward. You can consolidate your existing instruction files in just two simple steps using your terminal: Use the command  to rename your primary instruction file. Use  to create a symbolic link. This ensures backward compatibility with any tools that haven’t been updated to the new standard yet. Create an AGENTS.md file at the root of your repository. Add sections for project overview, build and test commands, code style guidelines, and any other relevant instructions. Include commit messages, pull request guidelines, and anything else a new teammate would need to know.To get the most out of AGENTS.md, here are a few best practices to follow: Keep your instructions clear and to the point.Keep instructions up to date: Make sure the file is always current with your project’s needs. Instead of duplicating information, link to your existing documentation.Use multiple files for monorepos: For large monorepos, you can use nested AGENTS.md files for different subprojects.Video Overview about Agents.MDAnd that’s it! By adopting the AGENTS.md standard, you can streamline your workflow, ensure consistency, and make it easier for AI agents to work with your projects.]]></content:encoded></item><item><title>Sovereign AI: The Why and How Behind National LLMs</title><link>https://hackernoon.com/sovereign-ai-the-why-and-how-behind-national-llms?source=rss</link><author>Vik Bogdanov</author><category>tech</category><pubDate>Fri, 22 Aug 2025 07:13:53 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[I recently came across a by Ukrainian researchers analyzing the key trends, challenges, risks, and opportunities of developing Large Language Models (LLMs) at the state level. It compiles global practices in building national LLMs and explores the feasibility of investing in this direction.What is revealing in the report is that GovTech projects today place as much hope in AI as modern businesses do. This signals a turning point: AI is no longer just a corporate innovation but is rapidly transforming into state-level infrastructure,  with nations competing to harness it in pursuit of digital sovereignty.When Technology Serves the StateLLMs are moving beyond R&D labs and startups into the very core of governance. Governments are already experimenting with them to simplify regulatory work, reduce bureaucratic delays, and support citizen communication. AI-powered assistants are helping officials process legal texts, analyze procurement contracts, and ensure compliance with public spending rules.In social services, LLM-based hotlines are offering guidance to farmers, citizens seeking benefits, or people navigating complex legal processes. These tools don’t replace human officials, but rather filter, summarize, and structure information, allowing governments to operate faster and more transparently.Healthcare is another key frontier. Medical staff are increasingly using LLMs to generate discharge reports, summarize patient histories, or predict potential complications. By processing vast amounts of medical data, these systems enable physicians to save time and focus on patient care rather than paperwork.Defense and security might be the most sensitive but also the most transformative domains. Here, LLMs are being applied to open-source intelligence (OSINT) analysis, military planning, and even handling communication in a military tone of voice. Unlike commercial applications, these deployments often occur in highly restricted environments, where sovereign control over data and infrastructure is maintained.A telling metric of this shift: in 2024, government use of AI grew by more than 1.5× compared to 2021, fueled largely by national LLMs outperforming global ones in local benchmarks.Strategies and PrioritiesThe first wave of national AI strategies occurred between 2019 and 2020, during which the focus was broader, encompassing digitalization, talent development, and ethical frameworks. Today, those strategies are being updated with LLMs at the center, explicitly. The priorities are clear: — reducing dependence on US or Chinese models and investing in local capacity. For smaller states, this often means joining the EU or regional initiatives; for larger states, it implies building sovereign supercomputers and models from scratch. — ensuring compliance with international standards, protecting personal data, and preventing bias. Transparent governance of AI is emerging as a soft-power tool: countries that demonstrate ethical leadership can influence global norms. — from Europe’s Leonardo supercomputer to India’s Bharat Gen project, the physical layer of AI matters as much as the models. Access to high-performance computing is now a matter of national strategy. — national archives, libraries, and public datasets are being restructured into training corpora. Programs like Horizon Europe and CLARIN both fund research and develop legal frameworks for the safe use of data. — beyond infrastructure, success depends on people. Many countries are channeling funds into startups, research centers, and AI-focused universities to ensure long-term capacity.Building sovereign LLMs requires serious money. Some stand out.The EU aims to maintain Europe's competitiveness in the global race by pledging to invest €1 billion annually through 2027 to strengthen AI ecosystems across its member states. The Netherlands is allocating  for the development of local AI initiatives, which underscores its commitment to building a robust domestic capacity. The Brazilian government has invested  in national AI programs, of which  is specifically reserved for the creation of a national LLM. Meanwhile, India has launched the ambitious , investing  in projects like , which is already being applied in education, agriculture, and healthcare. Together, these investments underscore both the magnitude of financial commitments and the strategic urgency with which countries are prioritizing control over their own AI futures.Funding typically comes through a triple-helix model, comprising public sector support, corporate partnerships, and academic research. This mix spreads risk, ensures applicability, and avoids over-centralization of AI development.National LLM Use Cases Around the WorldThe diversity of national projects shows how flexibly LLMs can be adapted. — In Bulgaria, a sovereign model outperformed ChatGPT and LLaMA in local school exams, demonstrating that domain-specific and language-specific training are crucial for effective performance. Greece uses AI to generate exercises and simplify textbooks, while Singapore integrates LLMs into programming curricula. — Albania’s e-Gov platform integrates AI assistants for administrative processes; Serbia trains specialized models for analyzing legal documents with EU support. In the Netherlands, 39% of municipalities already rely on AI tools. — Sweden’s GPT-SW3 helps summarize patient records and forecast risks. In Kenya, AI chatbots offer guidance to expectant mothers, leveraging automation alongside rigorous human oversight to safeguard sensitive data. — Nigeria’s FarmAdvise chatbot acts as a free, text-based hotline for farmers without internet access. India’s BharatGen supports farmers with real-time insights on crops, weather, and market conditions. — Bulgaria has invested more than $100 million in a sovereign LLM, ensuring sensitive data remains on domestic infrastructure. Germany is pursuing similar sovereign AI projects to reduce dependence on US-based systems. — The US has documented 180+ potential defense applications, from battlefield command support to OSINT. Defence LLAMA and China’s ChatBIT are both examples of domain-specific military models trained in secure environments.These cases illustrate a broader truth: national LLMs are being tailored to reflect not only local languages but also specific institutional needs and cultural contexts.Another country currently building its national LLM is. Despite more than three years of full-scale war, Ukraine is accelerating digital transformation in government — a continuation of reforms that began long before the invasion.For Ukraine, an LLM is not simply a technological upgrade but a strategic necessity. On one hand, it would allow state services to operate securely on domestic infrastructure, without relying on foreign clouds that could be disrupted. On the other hand, it opens entirely new possibilities in Defense Tech, where Ukraine possesses a unique dataset from the battlefield unmatched anywhere in the world. Processing this data through LLMs could generate insights critical for military strategy, resilience, and security.The government has set a bold target: to enable Ukraine to become one of the world’s top three countries in public-sector AI implementation by 2030. To reach this, the Ministry of Digital Transformation is spearheading a multi-phase plan: — sovereign data storage, battlefield intelligence applications, training on Ukrainian archives, scientific literature, and non-sensitive government datasets. — a 9-month first cycle, with a beta version tested in government, academia, and education; later open-sourced with APIs for businesses. — models ranging from 1 to 16 billion parameters are the top priority, balancing efficiency with cost. Models up to 7B can run on a single GPU, while 13–16B require small clusters. Global experience (LLaMA, Gemma, Mistral) shows that well-trained medium models can deliver competitive performance in classification, text generation, and localized tasks. — more than 100 GB of Ukrainian-language data under review, including library archives and research corpora, to ensure the model reflects authentic language, history, and culture.The project is allegedly compliant with IP law, with authors invited to “donate” their works voluntarily, thereby enriching the LLM with an authentic Ukrainian context.Ukraine’s case illustrates both the urgency and the opportunity. While the war creates extraordinary pressures, it also accelerates innovation. The country’s vast pool of battlefield and civic data, coupled with a dynamic govtech and startup ecosystem, positions it to achieve breakthroughs that others cannot. \
If Ukraine succeeds, its model could serve as a blueprint for nations seeking to strike a balance between innovation and sovereignty.Sovereign AI is fast becoming the new : a strategic asset, a deterrent, and a marker of global influence. The nations that move quickly will not only define their own futures but also shape the standards, ethics, and narratives that govern the world’s information order.The question is no longer  national LLMs will matter — but  model will set the terms of tomorrow’s sovereignty.And what's your take on this?]]></content:encoded></item><item><title>Every Website Doesn’t Need to Be a Full App</title><link>https://hackernoon.com/every-website-doesnt-need-to-be-a-full-app?source=rss</link><author>Den Odell</author><category>tech</category><pubDate>Fri, 22 Aug 2025 07:13:16 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[Islands Architecture lets developers ship less, do more, and give users speed where it counts. It renders the majority of the page server-side, using static HTML whenever possible, and hydrates only the components that need to be interactive.]]></content:encoded></item><item><title>&quot;Money Is Not Real&quot;: Chris Galizio On How The Federal Reserve Destroyed The Capitalism Ecosystem</title><link>https://hackernoon.com/money-is-not-real-chris-galizio-on-how-the-federal-reserve-destroyed-the-capitalism-ecosystem?source=rss</link><author>Olayimika Oyebanji</author><category>tech</category><pubDate>Fri, 22 Aug 2025 07:13:01 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[“Money Game" is a film that exposes the struggles of ordinary people in a broken fiat system, highlighting the Federal Reserve’s relentless money printing as a key driver of inflation and resource misallocation.As Professor Gardner, a central figure, states, “Capitalism requires risk to allocate resources. By removing risks, the Fed destroyed the capitalism ecosystem.”James, a healthcare professional and the film’s protagonist, seeks financial independence after failing to secure a mortgage for his late wife’s dream property. Guided by Professor Gardner, James invests in real assets, ultimately succeeding in timber trading and relocating to Maine with the property he desired.In the film’s climax, Professor Gardner, on a podcast James helped him launch, declares, “Money printing doesn’t create wealth. Wealth is created by all your hard work.”In this interview, Olayimika Oyebanji speaks to Chris Galizio, executive producer of “Money Game," who shares insights on the broken financial system and how investing in commodities like real estate, gold, Bitcoin, silver mining, etc. can help restore economic balance.Chris, it's really nice to meet you. Can you tell us about yourself and your professional background?Hi Ola, I am a former large cap growth manager at Fidelity and I also ran a hedge fund called Focused Capital. My fund at Fidelity grew from $20M to $7B. When the REPO market spiked in 2019, and the FED stepped in to buy all the bonds, I started to question what was happening. I wrote a white paper called the $340T problem which I published pre-COVID. It refers to the dollar system and how FED action disconnected stocks from fundamentals and broke the ecosystem of capitalism. Then COVID hit and unemployment in the US went to 33%, but FED injected liquidity and stocks actually went UP. This incident changed my view on markets. The FED is protecting the markets.  It’s not an “investing” system, it’s a “financing” system.Once you see it, it’s impossible to unsee it.  It’s the biggest line in Money Game, “Correct, and when the FED intervened in bonds markets, they broke the ecosystem of capitalism.” – Professor Gardner, Money Game ‘25What inspired you to produce “Money Game”, and how did you aim to portray the impact of the Federal Reserve’s money printing on everyday people?“Because I know how the movie ends, my coffee goes from $3 to $30 and everyone blames the “capitalists” and turns to an authoritarian leader like Hitler to save them. I wanted to change the ending and have them blame the central planners (Jerome Powell, Scott Bessent) and return to capitalism.” —- Executive Producer, Money GameI knew that I had a concept that no one else could see, the money system is broken. It’s the opening quote in Money Game: "The task is not so much to see what no one else sees, but to think what no one else has thought about that which everyone sees."- Arthur Schopenhauer – 1851 Money Game, opening Quote Then we hired a screen writer, Brian Cheek, to build a story around the concept. We used my brother’s story as the storyline. My brother is a widowed father of two kids. He represents the real economy that is struggling with inflation as the FED prints money from “thin air” to protect the rich (the money system). It’s not capitalism anymore, capitalism requires risk to allocate scarce resources, when the FED intervened the system began to misallocate resources which slows the real economy.“Our system is broken. It’s clear now that money printing sends asset prices up.  What’s less clear is that it also slows the real economy as we misallocate resources. Now we have two different economies, the financial economy, and the real economy, that no longer work together. Money printing does not create wealth, wealth is created by all your hard work.” --- Professor Gardner, Money Game ’25.Notice that the market never reacts to news anymore. Trump said that he wants to increase tariffs on semiconductors by 300% and the Semi stocks like AMD and AVGO that import most of their chips barely moved. Why? Because the entire system is machines that do not read the news. No one is setting prices anymore and that should send a chill down every investor’s spine. "I felt a great disturbance in the Force, as if millions of voices suddenly cried out in terror and were suddenly silenced. I fear something terrible has happened." --- Obi-Wan KenobiHow did you approach balancing the film’s entertainment value with its critique of the fiat system and advocacy for alternative investments?Movies need to be entertainment, no one goes to a movie for a lecture. So we made a love story, where the good guy wins. We put all the technical language in the background, all the characters use everyday language. We removed terms like sovereign debt crisis and moral hazard. Brian Cheek our screenwriter kept saying, ‘show it, do not say it.”, if a character has to cry, do not say he is crying, let him walk onto the porch and cry!!!James’s journey from struggling with a mortgage to succeeding in timber trading is a central arc. What message were you hoping to convey about pursuing financial independence through real assets?Every character in “Money Game” has an Arc. James starts out in healthcare being oppressed by his boss (Chris Owen from American Pie). He ends up buying a house in Maine and starting a lumber business as real asset prices explode higher. Professor Garnder starts out teaching class at a community college, but ends up doing a podcast with millions of listeners.Notice that both characters choose NOT to play the current money game. Also notice the tagline for Money Game on the poster, “Don’t Get Played”. The entire globe is getting “played” by the FED to provide the financing for US business, there is no return from cash flow.“Who here is willing to give me $152 ($1/.66%) if I give you $1 for the rest of your life?” --- Professor Gardner.“Hell no, we would all be dead by the time we broke even.” – First Day, student community college.“Correct!!” – Professor Gardner.The film suggests that investing in real assets can help protect investors from the broken financial ecosystem. What role do you see storytelling playing in educating audiences about these economic alternatives?We are living in the biggest groupthink in financial markets history that markets are “efficient” and prices are set by “people”. But the reality is that when the FED intervened in markets, the entire system shifted to machines that DO NOT think. No one is setting prices anymore. The entire system is a policy tool of the FED now. Markets no longer “predict” anything, they ONLY “react” to Fed liquidity. “No one picks their own stocks anymore, the lions (active managers) have been eaten. It’s just a bunch of followers (quant) following followers (passive), it’s like a cat chasing its tail.” --- Professor Gardner. Professor Gardner raises the book,“The Efficient Markets Thesis”,  he tosses it aside and laughs:"Smart people thought the world was flat once too." -- Professor Gardner. He then raises – Death by money: The Story of the Great German inflation and says: “Some of the most underused books in finance are history books.” To me, it’s a certainty that the USD (G7) will collapse, because the more the FED prints, the more the system misallocates resources and the slower the growth in the real economy. Notice that the system rewards companies that issue shares every Quarter. Why? Because in a 100% passive world, like today, if a company issue shares, then the passive are forced to buy more shares at the Quarter to match the index.—-- Let’s Ask , how a 100% passive investing system would allocate capital,Yes, in a 100% passive stock market, the dynamics you’ve described could lead to companies like Tesla—those frequently issuing new shares to finance growth-outperforming, while also driving market inefficiencies that undermine core principles of capitalism. Let’s break it down:Outperformance of Companies Needing FinancingMechanics of Passive Investing: In a fully passive market, funds buy shares of companies issuing new equity to maintain index weightings, as discussed previously. Companies like Tesla, which have historically issued shares to fund ambitious growth (e.g., factory expansions, R&D), would receive consistent capital inflows from passive funds, boosting their mcap and index weight. Performance Feedback Loop: As these companies’ stock prices rise due to passive buying, they attract more capital from performance-chasing investors (even in a passive system, some investors might allocate based on historical returns). This creates a self-reinforcing cycle: share issuance → passive buying → price appreciation → more investor interest → higher market cap → larger index weight → more passive buying. —- Moral Hazard “Because the system is a game now, James. Success in the current system requires speculation, and I will not speculate with other people’s money.” --- Professor Gardner, Money Game ‘25Professor Gardner says, “Capitalism requires risk to allocate resources. By removing risks, the Fed destroyed the capitalism ecosystem.” How does the film illustrate this critique of the Fed’s policies?Capitalism requires risk to allocate resources is the theme of Money Game. Investors should be using real interest rates (interest rates - inflation) to value a business. And today real rates are negative. Real inflation is over 4%, which means real rates are negative.Wealth Effect - Value of a $1 Annuity Interest rates have an enormous effect on asset values. Below is the simplest example in finance, the value of a $1 annuity in perpetuity at different interest rate levels: 10% --> $1/10% = $10 5% --> $1/5%   = $20 1% --> $1/1%   = $10 -1% --> $1/-1%  = Infinite Question: How can the value of a $1 annuity be infinite? Answer: The Price of Money is Wrong. It’s a “financing” system, NOT an “investing” system.  There is no return from cash flow. ‘When interest rates go negative (real terms), all assets are worth infinite, my coffee is worth infinite, my desk is worth infinite, my whiteboard infinite. Does this make sense?” --- Professor Gardner.But when you remove risk from an ecosystem, the ecosystem changes. It's not capitalism anymore, it’s a centrally planned economy.“But here is the problem, capitalism requires risk to allocate scarce resources. Let me give you an example, what would happen if we removed the lions from the Savannah?”“The gazelle population (passive)  would explode higher.” – James.“But then they would be competing for scarce water resources (inflation) and die off.” – Aimee. “Correct, and when the FED intervened in bonds markets, they broke the ecosystem of capitalism.” – Professor Gardner.Why did Professor Gardner describe cash, bonds, etc. as a massive bubble?Good Question!! The $37T in US debt is unpayable in real terms. It’s 7x tax revenue!! So now the FED is manipulating bond rates to keep the stock market (tax receipts) artificially high. Central banks are not buying gold at all-time highs by accident, they buy when trust breaks silently - before it shatters publicly. In a sovereign debt crisis “$1.4B Fartcoin is what you get when the "risk free" asset underpinning the entire banking & currency system is a bond issued by an insolvent govt w/debt of 7x revenues, off-bal sheet liabs of 20-30x revenues, peacetime deficits of 7% of GDP, that has not run a surplus in 24 yrs” – Luke Gromen on X.“The US is 4% of the world’s population, but makes 40% of the world’s budget deficit, 60% of the world’s current account deficit.”-- Louis Gave"That means that to keep the show on the road, the US has to attract, year in and year out, roughly between half and two thirds of the world's marginal increase in savings. If that money that the savings between roughly, let's say two thirds of the world's savings don't float to the US every year, then you're either going to have a problem with the debt or a problem in the US dollar, and maybe we're there." -- Louis Gave Over 30% of the Russell 3000 are zombie corps that lose money like BA, MSTR, CRWD etc.“History is that which always surprises those who tried to deceive it.” José Ortega y Gasset“The history of money is the history of trust in symbols. From Rome’s debased denarius to England’s tally sticks, from the gold promises of Genoa to Nixon’s final severing in 1971 - every system of settlement eventually dissolved into memory. Today, programmable money and digital assets function as new tally sticks. They carry liquidity, but not final settlement. And increasingly, digital capital is flowing East, where alternative rails are being built. The enduring question is not whether this system will end, but what foundation of trust will define the next one.” –Petro Golovko, PHDHow do you hope Money Game influences viewers’ perspectives on the fiat system and their own financial decisions in today’s economy?“Gold is money, everything else is credit”, J.P. Morgan, 1912“If everybody indexed, the only word you could use is chaos, catastrophe… the markets would fail.” - Jack Bogle, founder of Vanguard 5/6/17 – Bloomberg., Closing Quote Money Game ‘25\
We want people to start thinking again. Stop trusting the “experts”. No one cares more about your money than you!!. The experts do not take a loss, if you lose money. That’s moral hazard. James, the film’s reluctant hero, isn’t just asking Bryson, “How does your company make money?” He’s asking the audience: “How long will you tolerate a system built on lies?” – Petro Golovko."A collapse of the dollar system is a RETURN to capitalism; the global economy will BOOM higher. The income equality gap will close, wages will escalate, homeowners will break the chains of debt and the system will stop pouring $Trillions into bad (money losing) investments (GME, AMC, PLTR, NVDA, TSLA, Dogecoin, NFTs).After the credits roll, you will see a lion appear, that’s you taking responsibility for your own investments again.  It’s you thinking.“Imagine re-introducing a pride of lions (thinkers, capitalists) back into the Savannah after the Gazelle population (index funds, central planning) exploded 10x and were thirsty and weak? The lions would make a killing." The system is currently broken, so a collapse of the system fixes it.  It’s a return to capitalism. Notice that James was under a lot of stress throughout the movie. But at the end of Money Game, he falls in love and the world seems right again. It’s a happy ending!Everyone should see Bryson, CEO of TAPIT in Money Game, like all the billionaires like Mark Zuckerburg, Elon Musk and Jack Dorsey.  They all believe that their companies are trading at infinite because of them. But that’s NOT the reason. Their companies trade at infinite because interest rates are negative."A collapse of the dollar system is a RETURN to capitalism; the global economy will BOOM higher. The income equality gap will close, wages will escalate, homeowners will break the chains of debt and the system will stop pouring $Trillions into bad (money losing) investments (GME, AMC, PLTR, NVDA, TSLA, Dogecoin, NFTs)."Watching the gazelle population (passive, quant) explode by 10x is not a sign that the ecosystem is flourishing, it's a sign that the ecosystem is broken."The entire globe is watching the scoreboard, and no one noticed the players are no longer scoring." There has never been a better time to think. Invest for yourself.  No one else is looking out for you.  Know the assets that you own and what you are paying for them.“Once you understand that markets are broken, you are holding a crystal ball.” –Executive Producer, Money Game.Take back your investments from all the experts that think markets are “efficient”.]]></content:encoded></item><item><title>Metal Gear Solid Delta: Snake Eater Review - You&apos;re Pretty Good</title><link>https://www.gamespot.com/reviews/metal-gear-solid-delta-snake-eater-review-youre-pretty-good/1900-6418396/?ftag=CAD-01-10abi2f</link><author>Tamoor Hussain</author><category>tech</category><enclosure url="https://www.gamespot.com/a/uploads/screen_medium/1587/15875866/4551551-mg1.jpg" length="" type=""/><pubDate>Fri, 22 Aug 2025 07:01:00 +0000</pubDate><source url="https://www.gamespot.com/feeds/reviews">GameSpot - Game Reviews</source><content:encoded><![CDATA[There's a good chance that, at some point in your life, you've been so enamored of a piece of media that you've considered what it'd be like to experience it for the first time again. Watching Terminator 2, hearing Enter the Wu-Tang, and reading The Dark Knight Returns shaped who I am and, as a result, I remember the moments I experienced them with crystal clarity. Over time, however, those memories have become divorced from the emotions they stirred and what's left in their place is a longing for those lost feelings.Video games are the only medium that I think are capable of making that first-time-again fantasy a reality--or as close to one as we're going to get. Time puts distance between us and the emotionally significant moments we cherish, but it also brings us closer to exciting technologies that can make the old feel new. In the right hands, those technologies can create opportunities to stoke those profound emotions again, even if it's just a little. Metal Gear Solid Delta: Snake Eater does exactly that.Before getting into what's new, what can't be overlooked in making Delta such a good game is the fact that Metal Gear Solid 3: Snake Eater remains a compelling, well-told story that has strong characterization and deals with some heavy subject matter. It approaches this with a strange mixture of self-seriousness and complete irreverence that is uniquely Metal Gear Solid and, for my money, balances both parts better than any other entry in the series. The stellar stealth is supported by systems that feed into the fantasy of surviving in the jungle and braving the elements, whether that be hunting for food or patching yourself up after sustaining injuries. Delta replicates it and, in my opinion, is better for it. The excellent work that the original Metal Gear Solid 3 dev team did remains the heart and soul of Delta, and it continues to shine.Continue Reading at GameSpot]]></content:encoded></item><item><title>OpenAI announces New Delhi office as it expands footprint in India</title><link>https://techcrunch.com/2025/08/21/openai-announces-new-delhi-office-as-it-expands-footprint-in-india/</link><author>Jagmeet Singh</author><category>tech</category><pubDate>Fri, 22 Aug 2025 06:06:18 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[OpenAI has started hiring in India as it looks to expand its presence in the fast-growing South Asian tech market.]]></content:encoded></item><item><title>OpenAI lawyers question Meta’s role in Elon Musk’s $97B takeover bid</title><link>https://techcrunch.com/2025/08/21/openai-lawyers-question-metas-role-in-elon-musks-97b-takeover-bid/</link><author>Maxwell Zeff</author><category>tech</category><pubDate>Fri, 22 Aug 2025 00:31:38 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[OpenAI says that Elon Musk met with Meta CEO Mark Zuckerberg to discuss a $97 billion takeover bid of the ChatGPT-maker.]]></content:encoded></item><item><title>Anduril, Blue Origin to study how to transport cargo from orbit to Earth for the Pentagon</title><link>https://techcrunch.com/2025/08/21/anduril-blue-origin-to-study-how-to-transport-cargo-from-orbit-to-earth-for-the-pentagon/</link><author>Aria Alamalhodaei</author><category>tech</category><pubDate>Thu, 21 Aug 2025 22:11:37 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Blue Origin and Anduril notched small contracts that could revolutionize how the Pentagon transports cargo.]]></content:encoded></item><item><title>Is the AI bubble about to pop? Sam Altman is prepared either way.</title><link>https://arstechnica.com/information-technology/2025/08/sam-altman-calls-ai-a-bubble-while-seeking-500b-valuation-for-openai/</link><author>Benj Edwards</author><category>tech</category><enclosure url="https://cdn.arstechnica.net/wp-content/uploads/2025/02/GettyImages-2198353376-scaled-1152x648-1739457486.jpg" length="" type=""/><pubDate>Thu, 21 Aug 2025 22:06:37 +0000</pubDate><source url="https://arstechnica.com/">Biz &amp; IT – Ars Technica</source><content:encoded><![CDATA[Last Thursday, OpenAI CEO Sam Altman told reporters at a private dinner that investors are overexcited about AI models. "Someone" will lose a "phenomenal amount of money," he said, according to The Verge. The statement came as his company negotiates a secondary share sale at a $500 billion valuation—up from $300 billion just months earlier."Are we in a phase where investors as a whole are overexcited about AI? My opinion is yes," Altman told the journalists, comparing the current market to the dot-com crash of the 1990s. Wired reported that he also predicted his company will spend "trillions of dollars on data center construction in the not very distant future" and that ChatGPT will soon serve "billions of people a day."For context, Facebook serves about 3 billion monthly active users. Altman's projection would require ChatGPT to reach nearly half the world's population as daily users (not monthly, like Facebook), which is an extraordinarily optimistic outlook.]]></content:encoded></item><item><title>As India bans real-money games, Dream Sports, MPL start pulling the plug</title><link>https://techcrunch.com/2025/08/21/as-india-bans-real-money-games-dream-sports-mpl-start-pulling-the-plug/</link><author>Jagmeet Singh</author><category>tech</category><pubDate>Thu, 21 Aug 2025 20:56:57 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Several Indian startups, including Dream Sports, MPL, and Zupee, are shutting down their real-money games after parliament passed a bill banning such games.]]></content:encoded></item><item><title>Linux Kernel Patches Posted For Enabling USB3 Support On Apple M1 / M2</title><link>https://www.phoronix.com/news/Apple-Silicon-USB3-RFC</link><author>Michael Larabel</author><category>tech</category><pubDate>Thu, 21 Aug 2025 20:38:56 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[In addition to this week seeing Apple SoC DT updates prepped for Linux 6.18 and Apple laptop lid events and power button driver patches posted for review for the mainline Linux kernel, published today on the Linux kernel mailing list are the request for comments (RFC) on patches for enabling USB3 support with Apple Silicon M1 / M2 SoCs...]]></content:encoded></item><item><title>Discounty Review - Long Live The Empire</title><link>https://www.gamespot.com/reviews/discounty-review-long-live-the-empire/1900-6418399/?ftag=CAD-01-10abi2f</link><author>Jordan Ramée</author><category>tech</category><enclosure url="https://www.gamespot.com/a/uploads/screen_medium/1587/15875866/4553996-dis.jpg" length="" type=""/><pubDate>Thu, 21 Aug 2025 15:41:00 +0000</pubDate><source url="https://www.gamespot.com/feeds/reviews">GameSpot - Game Reviews</source><content:encoded><![CDATA[In the aftermath of Stardew Valley's success and popularity, there have been many attempts by other developers to carve their own piece of the pixel farm life simulator pie. Whereas those games so often put you in the role of a poor farmer or some other position of struggle, Discounty does the opposite, having you effectively play as the bad guys in Stardew Valley: the outsider that has everything and is trying to weasel into the community. You're not literally playing a mirror of that game's story, but it's awfully close--instead of being the new farmer in a small, struggling town, you're instead the new owner of the big-brand supermarket that's attempting to monopolize the economy and push out existing vendors to increase your profit margins. It altogether makes for a game that is fun to play (in that hypnotic sort of way that's recognizable in so many games that romanticize retail work), but it is ultimately quite uncomfortable at times and too muddled in its storytelling to utilize that discomfort to deliver a compelling message.Granted, you're merely the pawn in the palm of the hand of a much greedier capitalist: your aunt. Roped into moving to her small harbor town of Blomkest to help out with her struggling market, you arrive to find she's sold out to the Discounty chain and rebranded. Your aunt is immediately portrayed as a suspicious person, keeping secrets locked away in sheds, making backroom deals with banks, and firing employees without a second thought. It's all in the name of expanding her supermarket business empire, and you're her most loyal pawn, charming locals into going along with your expansions and acquiring their wares so that citizens have to go to Discounty to buy food and home supplies.It feels scummy, especially since your character has zero backbone, pushing the buck on responsibility and ignoring the consequences of their actions for a big chunk of the game's story, which primarily deals with a hurting community that needs healing.Continue Reading at GameSpot]]></content:encoded></item><item><title>AMD Ryzen AI 5 340 Windows 11 vs. Ubuntu Linux Performance For Budget &quot;Krackan Point&quot; Laptops</title><link>https://www.phoronix.com/review/amd-krackan-point-windows-linux</link><author>Michael Larabel</author><category>tech</category><pubDate>Thu, 21 Aug 2025 14:15:00 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[Earlier this month we looked at the Linux laptop performance of AMD's Krackan Point using the Ryzen AI 5 340 within a HP OmniBook 5 that can be found for as low as ~$450 during sales. For six Zen 5 cores and RDNA 3.5 graphics, Krackan Point worked well as a budget Linux laptop option. For those wondering how the Linux vs. Windows 11 performance compares for the budget HP OmniBook, here are some benchmarks.]]></content:encoded></item><item><title>Linux Driver Under Review For Apple Laptop Lid Events &amp; Power Button</title><link>https://www.phoronix.com/news/Apple-Lid-Power-Buttons-Driver</link><author>Michael Larabel</author><category>tech</category><pubDate>Thu, 21 Aug 2025 13:24:13 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[Following the recent Apple SMC driver upstreaming to handle rebooting Apple Silicon Macs under Linux, the latest code volleyed on the kernel mailing list for review is support for handling laptop lid events and power buttons. Plus Apple sensor monitoring driver support too...]]></content:encoded></item><item><title>Could an AI Barbie Stunt the Emotional Growth of a Generation?</title><link>https://spectrum.ieee.org/ai-barbie-dolls</link><author>Marc Fernandez</author><category>tech</category><enclosure url="https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy82MTQ5NDY5Ny9vcmlnaW4uanBnIiwiZXhwaXJlc19hdCI6MTc3NTU0NzE0M30.0iOhG7ZxWK93ZuTo73naCQkRCcKEdEJzgC5ogPRmSLo/image.jpg?width=600" length="" type=""/><pubDate>Thu, 21 Aug 2025 13:00:03 +0000</pubDate><source url="https://spectrum.ieee.org/">IEEE Spectrum</source><content:encoded><![CDATA[A partnership between OpenAI and Mattel raises sobering questions]]></content:encoded></item><item><title>Herdling Review - Companion Quest</title><link>https://www.gamespot.com/reviews/herdling-review-companion-quest/1900-6418398/?ftag=CAD-01-10abi2f</link><author>Mark Delaney</author><category>tech</category><enclosure url="https://www.gamespot.com/a/uploads/screen_medium/1632/16320660/4553502-herdling-screenshot-03.jpg" length="" type=""/><pubDate>Thu, 21 Aug 2025 13:00:00 +0000</pubDate><source url="https://www.gamespot.com/feeds/reviews">GameSpot - Game Reviews</source><content:encoded><![CDATA[About a week ago, on the same day I started playing Okomotive's Herdling, I accidentally hit a squirrel with my car. The critter darted into the road, and I tried to evade them, but I failed.They died. It devastated me.I called my wife, physically shaking and tearful, to tell her what happened. I sat in my car for a bit when I got to my destination, needing to regain my composure. Though I knew my intent was pure, I found it hard to accept that I had taken their life away. To no one's surprise, if you're familiar with my work, I saw them not as "roadkill," but as a being with their own interests and goals, however simple those may seem compared to those of humans. It wasn't an ideal starting point for heading into Herdling, a game about trying to guide a family of vulnerable animals out of the city and return them safely to their natural habitat. But I'm sure, even on a normal day, Herdling was going to connect with me deeply on account of its moving depictions of human-animal kindness and companionship.Continue Reading at GameSpot]]></content:encoded></item><item><title>Intel Compute Runtime 25.31.34666.3 Continues Prepping For Panther Lake</title><link>https://www.phoronix.com/news/Intel-CR-25.31.34666.3</link><author>Michael Larabel</author><category>tech</category><pubDate>Thu, 21 Aug 2025 12:35:01 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[Released minutes ago was the newest monthly feature release to the Intel Compute Runtime providing open-source OpenCL and Level Zero capabilities on Intel graphics hardware...]]></content:encoded></item><item><title>VKD3D 1.17 Released With More Improvements For Direct3D 12 On Vulkan</title><link>https://www.phoronix.com/news/VKD3D-1.17-Released</link><author>Michael Larabel</author><category>tech</category><pubDate>Thu, 21 Aug 2025 11:58:52 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[VKD3D 1.17 made its debut this morning as the newest version of this Direct3D 12 over Vulkan API implementation...]]></content:encoded></item></channel></rss>